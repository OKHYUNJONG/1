{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "cifar100 data augmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6426a6b0b68942e393b9d4eba5afc408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ee7ff4f1c1a4476be2e699fa461bb54",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_70ce1282012d475280bded84edb3f4e4",
              "IPY_MODEL_27322d55811f4d2a9841160ee7cb97d2"
            ]
          }
        },
        "6ee7ff4f1c1a4476be2e699fa461bb54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70ce1282012d475280bded84edb3f4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_045735eb29d749ef871ba4130e1f68a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 169001437,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 169001437,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_879a2f2f48d9417faca2aca67dd80ae8"
          }
        },
        "27322d55811f4d2a9841160ee7cb97d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a0c1a3948b3443e89a8ef0585ded7a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 169001984/? [01:46&lt;00:00, 1587153.95it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b04a177a676d47518a0ebc58a6e6303f"
          }
        },
        "045735eb29d749ef871ba4130e1f68a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "879a2f2f48d9417faca2aca67dd80ae8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7a0c1a3948b3443e89a8ef0585ded7a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b04a177a676d47518a0ebc58a6e6303f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jM90JIvkwgS3"
      },
      "source": [
        "## **Motivation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0sxzBAV1Qt9"
      },
      "source": [
        "  \n",
        "이전 결과를 생각해보면 현재 데이터에서 이 모델을 써서 성능이 향상 시킬려면 overfitting문제를 해결해야한다.      \n",
        "Object Detection기법 중 하나를 이용하고 이를 통해 객체를 탐지하고 나머지를 부분을 그림자처리하기(RSH)(인물사진 모드와 유사)를 통해 중요한 부분의 특징을 CNN이 더 잘 인식하게 하여 학습시킬 계획이다.  \n",
        "이는 배경을 완전 배재한 것보다 testdata와 traindata의 괴리가 적을 것으로 예상된다.  \n",
        "검은색에 RGD값은 0이고 convolution layer는 곱연산이기때문에 검은색에 가까울수록 중요도를 낮추는 효과가 어느정도 있다고 생각한다.    \n",
        "코드 수정에 제한이 있어 object dectection을 따로 적용하는 모델을 만드는 것은 불가능하여 cifar data특성상 중앙에 중요 데이터가 있는 경우가 많아 중앙에 boundingbox를 지정하여 나머지 부분을 그림자처리하기로 한다.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uQn6vIPwn8t"
      },
      "source": [
        "## **핵심아이디어, 구현 방법**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWCPpp_Zwqbg"
      },
      "source": [
        "아래의 그림과 같이 중앙 부분을 밝기를 어둡게 처리하고 일정부분을 밝게 처리한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "zAJxHP6T78ZF",
        "outputId": "b5eaf44d-11a4-42dd-9de7-5834dfd90b70"
      },
      "source": [
        "for input,target in train_loader:\n",
        "  x_test = input[0]\n",
        "  break\n",
        "\n",
        "plt.imshow(x_test[0,:,:],cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f18311e06d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "U9UqLn9-8Fet",
        "outputId": "7e6b6080-d1a4-4d77-8ddf-65439859a241"
      },
      "source": [
        "#Cutshadow + local_augment (인용출처 부분에 논문 참조)\n",
        "for input,target in train_loader:\n",
        "  input,target = local_augment(input,target)\n",
        "  x_test = input[0]\n",
        "  break\n",
        "\n",
        "plt.imshow(x_test[0,:,:],cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f5db78a06d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "TPzQMCO18SzV",
        "outputId": "b8a20366-13a6-4c98-fca6-35f77c11860c"
      },
      "source": [
        "#Cutshadow + Cutmix\n",
        "for input,target in train_loader:\n",
        "  input,target = cutmix(input, target, 0.01)\n",
        "  x_test = input[0]\n",
        "  break\n",
        "\n",
        "plt.imshow(x_test[0,:,:],cmap=\"gray\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f181e517e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lz8aBK40Wu6Z"
      },
      "source": [
        "## **Import all neceassary packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UFtfkXsMwYOF"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from tqdm.notebook import tqdm as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import cv2\n",
        "from PIL import Image, ImageChops\n",
        "import torchvision.transforms.functional as TF"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgIRYDwiWyRu"
      },
      "source": [
        "## **Model - Define ResNet Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29JdAnY5wbQU"
      },
      "source": [
        "'''ResNet18/34/50/101/152 in Pytorch.'''\n",
        "\n",
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_planes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion*planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = conv3x3(3,64)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18(num_classes=10):\n",
        "    return ResNet(BasicBlock, [2,2,2,2], num_classes)\n",
        "\n",
        "def ResNet34(num_classes=10):\n",
        "    return ResNet(BasicBlock, [3,4,6,3], num_classes)\n",
        "\n",
        "def ResNet50(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,4,6,3], num_classes)\n",
        "\n",
        "def ResNet101(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,4,23,3], num_classes)\n",
        "\n",
        "def ResNet152(num_classes=10):\n",
        "    return ResNet(Bottleneck, [3,8,36,3], num_classes)\n",
        "\n",
        "def test_resnet():\n",
        "    net = ResNet50()\n",
        "    y = net(Variable(torch.randn(1,3,32,32)))\n",
        "    print(y.size())\n",
        "\n",
        "# test_resnet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0yp01dJW3WG"
      },
      "source": [
        "## **Utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJ1k3hwswbTc"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    r\"\"\"Computes and stores the average and current value\n",
        "    \"\"\"\n",
        "    def __init__(self, name, fmt=':f'):\n",
        "        self.name = name\n",
        "        self.fmt = fmt\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count\n",
        "\n",
        "    def __str__(self):\n",
        "        fmtstr = '{name} {val' + self.fmt + '} ({avg' + self.fmt + '})'\n",
        "        return fmtstr.format(**self.__dict__)\n",
        "\n",
        "\n",
        "class ProgressMeter(object):\n",
        "    def __init__(self, num_batches, *meters, prefix=\"\"):\n",
        "        self.batch_fmtstr = self._get_batch_fmtstr(num_batches)\n",
        "        self.meters = meters\n",
        "        self.prefix = prefix\n",
        "\n",
        "    def print(self, batch):\n",
        "        entries = [self.prefix + self.batch_fmtstr.format(batch)]\n",
        "        entries += [str(meter) for meter in self.meters]\n",
        "        print('\\t'.join(entries))\n",
        "\n",
        "    def _get_batch_fmtstr(self, num_batches):\n",
        "        num_digits = len(str(num_batches // 1))\n",
        "        fmt = '{:' + str(num_digits) + 'd}'\n",
        "        return '[' + fmt + '/' + fmt.format(num_batches) + ']'\n",
        "\n",
        "\n",
        "def accuracy(output, target, topk=(1,)):\n",
        "    r\"\"\"Computes the accuracy over the $k$ top predictions for the specified values of k\n",
        "    \"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "        _, idx = output.sort(descending=True)\n",
        "        pred = idx[:,:maxk]\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh-ai6RtW-jJ"
      },
      "source": [
        "## **data augmentation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rQSNlQDiwbWp"
      },
      "source": [
        "class CutShadow(object):\n",
        "\n",
        "    def __init__(self, n_holes, length):\n",
        "        self.n_holes = n_holes\n",
        "        self.length = length\n",
        "\n",
        "    def __call__(self, img):\n",
        "\n",
        "        h = img.size(1)\n",
        "        w = img.size(2)\n",
        "\n",
        "        mask = np.zeros((h, w), np.float32)\n",
        "\n",
        "        for n in range(self.n_holes):\n",
        "            y = 16\n",
        "            x = 16\n",
        "\n",
        "            y1 = np.clip(y - self.length // 2, 0, h)\n",
        "            y2 = np.clip(y + self.length // 2, 0, h)\n",
        "            x1 = np.clip(x - self.length // 2, 0, w)\n",
        "            x2 = np.clip(x + self.length // 2, 0, w)\n",
        "\n",
        "            mask[:,:] = 1.\n",
        "            mask[y1: y2, x1: x2] = 8. #밝기 차이를 나타내는 수\n",
        "\n",
        "        mask = torch.from_numpy(mask)\n",
        "        mask = mask.expand_as(img)\n",
        "        img = img * mask\n",
        "        return img\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTMVyMb_7rLr"
      },
      "source": [
        "def rand_bbox(size, lam):\n",
        "    W = size[2]\n",
        "    H = size[3]\n",
        "    cut_rat = np.sqrt(1. - lam)\n",
        "    cut_w = np.int(W * cut_rat)\n",
        "    cut_h = np.int(H * cut_rat)\n",
        "\n",
        "    cx = np.random.randint(W)\n",
        "    cy = np.random.randint(H)\n",
        "\n",
        "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
        "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
        "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
        "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
        "    return bbx1, bby1, bbx2, bby2\n",
        "    \n",
        "def cutmix(data, target, alpha):\n",
        "    indices = torch.randperm(data.size(0))\n",
        "    shuffled_data = data[indices]\n",
        "    shuffled_target = target[indices]\n",
        "\n",
        "    lam = np.clip(np.random.beta(alpha, alpha),0.1,0.1)\n",
        "    bbx1, bby1, bbx2, bby2 = rand_bbox(data.size(), lam)\n",
        "    new_data = data.clone()\n",
        "    new_data[:, :, bby1:bby2, bbx1:bbx2] = data[indices, :, bby1:bby2, bbx1:bbx2]\n",
        "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (data.size()[-1] * data.size()[-2]))\n",
        "    targets = (target, shuffled_target, lam)\n",
        "    return new_data, targets\n",
        "\n",
        "def local_augment(data,target):\n",
        "  image= data.clone()\n",
        "\n",
        "  h = image.size(2)\n",
        "  w = image.size(3)\n",
        "  for i in range(image.size(0)):\n",
        "    mask1 = image[i,:,0:h//2,0:w//2]\n",
        "    mask1[0] = torch.rot90(mask1[0]) \n",
        "    mask1[1] = torch.rot90(mask1[1]) \n",
        "    mask1[2] = torch.rot90(mask1[2]) \n",
        "\n",
        "    image[i,:,0:h//2,0:w//2] = mask1\n",
        "\n",
        "    mask2 = image[i,:,0:h//2,w//2:w]\n",
        "    mask2[0] = torch.rot90(mask2[0]) \n",
        "    mask2[1] = torch.rot90(mask2[1]) \n",
        "    mask2[2] = torch.rot90(mask2[2]) \n",
        "    mask2[0] = torch.rot90(mask2[0]) \n",
        "    mask2[1] = torch.rot90(mask2[1]) \n",
        "    mask2[2] = torch.rot90(mask2[2]) \n",
        "    image[i,:,0:h//2,w//2:w] = mask2\n",
        "\n",
        "    mask3 = image[i,:,h//2:h,0:w//2]\n",
        "    mask3[0] = torch.rot90(mask3[0]) \n",
        "    mask3[1] = torch.rot90(mask3[1]) \n",
        "    mask3[2] = torch.rot90(mask3[2]) \n",
        "\n",
        "    image[i,:,h//2:h,0:w//2] = mask3\n",
        "\n",
        "    mask4 = image[i,:,h//2:h,w//2:w]\n",
        "    mask4[0] = torch.rot90(mask4[0]) \n",
        "    mask4[1] = torch.rot90(mask4[1]) \n",
        "    mask4[2] = torch.rot90(mask4[2]) \n",
        "    mask4[0] = torch.rot90(mask4[0]) \n",
        "    mask4[1] = torch.rot90(mask4[1]) \n",
        "    mask4[2] = torch.rot90(mask4[2]) \n",
        "    image[i,:,h//2:h,w//2:w] = mask4\n",
        "\n",
        "  return image,target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QsrBYsvyXHrY"
      },
      "source": [
        "## **Parameter Settings**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zm0jA3hwbZb"
      },
      "source": [
        "dataset = 'cifar100' # cifar10 or cifar100\n",
        "model = 'resnet34' # resnet18, resnet50, resnet101\n",
        "batch_size = 128  # Input batch size for training (default: 128)\n",
        "epochs = 150 # Number of epochs to train (default: 200)\n",
        "learning_rate = 0.1 # Learning rate\n",
        "data_augmentation = True # Traditional data augmentation such as augmantation by flipping and cropping?\n",
        "cutshadow = True \n",
        "n_holes = 1 # Number of holes to cut out from image\n",
        "length = 14  # box크기(수정됨)\n",
        "seed = 0 # Random seed (default: 0)\n",
        "print_freq = 30\n",
        "cuda = torch.cuda.is_available()\n",
        "cudnn.benchmark = True  # Should make training should go faster for large models\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "if cuda:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "\n",
        "test_id = dataset + '_' + model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pt6PSICXKcQ"
      },
      "source": [
        "## **Load and preprocess data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117,
          "referenced_widgets": [
            "6426a6b0b68942e393b9d4eba5afc408",
            "6ee7ff4f1c1a4476be2e699fa461bb54",
            "70ce1282012d475280bded84edb3f4e4",
            "27322d55811f4d2a9841160ee7cb97d2",
            "045735eb29d749ef871ba4130e1f68a1",
            "879a2f2f48d9417faca2aca67dd80ae8",
            "7a0c1a3948b3443e89a8ef0585ded7a6",
            "b04a177a676d47518a0ebc58a6e6303f"
          ]
        },
        "id": "6MQWkEXSwbcT",
        "outputId": "1f86c705-6cd0-48f9-fc17-b962c54548d0"
      },
      "source": [
        "# Image Preprocessing\n",
        "normalize = transforms.Normalize(mean=[x / 255.0 for x in [125.3, 123.0, 113.9]],\n",
        "                                     std=[x / 255.0 for x in [63.0, 62.1, 66.7]])\n",
        "\n",
        "train_transform = transforms.Compose([])\n",
        "if data_augmentation:\n",
        "    train_transform.transforms.append(transforms.RandomCrop(32, padding=4))\n",
        "    train_transform.transforms.append(transforms.RandomHorizontalFlip())\n",
        "train_transform.transforms.append(transforms.ToTensor())\n",
        "train_transform.transforms.append(normalize)\n",
        "if cutshadow:\n",
        "    train_transform.transforms.append(CutShadow(n_holes=n_holes, length=length))\n",
        "\n",
        "\n",
        "\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    normalize])\n",
        "\n",
        "if dataset == 'cifar10':\n",
        "    num_classes = 10\n",
        "    train_dataset = datasets.CIFAR10(root='data/',\n",
        "                                     train=True,\n",
        "                                     transform=train_transform,\n",
        "                                     download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR10(root='data/',\n",
        "                                    train=False,\n",
        "                                    transform=test_transform,\n",
        "                                    download=True)\n",
        "elif dataset == 'cifar100':\n",
        "    num_classes = 100\n",
        "    train_dataset = datasets.CIFAR100(root='data/',\n",
        "                                      train=True,\n",
        "                                      transform=train_transform,\n",
        "                                      download=True)\n",
        "\n",
        "    test_dataset = datasets.CIFAR100(root='data/',\n",
        "                                     train=False,\n",
        "                                     transform=test_transform,\n",
        "                                     download=True)\n",
        "\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                           batch_size=batch_size,\n",
        "                                           shuffle=True,\n",
        "                                           pin_memory=True,\n",
        "                                           num_workers=2)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle=False,\n",
        "                                          pin_memory=True,\n",
        "                                          num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to data/cifar-100-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6426a6b0b68942e393b9d4eba5afc408",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=169001437.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/cifar-100-python.tar.gz to data/\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra9Qxx7TXM2o"
      },
      "source": [
        "## **Main Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvW-gUlic4YT"
      },
      "source": [
        "## 세팅조건\n",
        "가장 중요한 변수는 박스의 크기(length)와 밝기 차이(p)이다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAhT9d9gc4YU"
      },
      "source": [
        "length = 12, p = 5 -> Top-1: 77.1 Top5: 93.92\n",
        "length = 14, p = 2 -> Top-1: 74.85 Top5: 93.02 \n",
        "length = 14, p = 5 -> Top-1: 76.78 Top5: 93.8  \n",
        "length = 14, p = 8 -> Top-1: 77.39 Top5: 93.82   \n",
        "length = 18, p = 2 -> Top-1: 71.96 Top5: 90.92  \n",
        "length = 18, p = 3 -> Top-1: 69.49 Top5: 89.93   \n",
        "length = 18, p = 5 -> Top-1: 72.67 Top5: 93.26  \n",
        "length = 18, p = 8 -> Top-1: 74.66 Top5: 92.62  \n",
        "length = 22, p = 5 -> Top-1: 56.38 Top5: 80.2  \n",
        "length = 26, p = 5 -> Top-1: 35.86 Top5: 61.54  \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "kgSNVFcuc4YU",
        "outputId": "d5386611-9885-47f9-f415-2d9a349e260b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(16, 5))\n",
        "plt.subplot(1, 2, 1) \n",
        "plt.plot([12,14,18,22,26], [77.1,76.78,72.67,56.38,35.86])\n",
        "plt.title(\"p = 5\")\n",
        "plt.xlabel('legnth')\n",
        "plt.ylabel('Top-1 Accuracy')\n",
        "plt.subplot(1, 2, 2)  \n",
        "plt.plot([2,5,8], [74.85,76.78,77.39])\n",
        "plt.title(\"length = 14\")\n",
        "plt.xlabel('p')\n",
        "plt.ylabel('Top-1 Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1152x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxpfsQ48c4YU"
      },
      "source": [
        "length가 작을수록 대체로 성능이 좋고 밝기 차이가 클수록 좋다. 하지만 이는 더 많은 학습을 진행을 못해 length가 더 작아지거나 밝기대비가 커질수록 더 성능이 안좋아 질 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCMqZeCIY8zK",
        "outputId": "7cc987d7-eb17-479f-ac9c-553ed429bdec"
      },
      "source": [
        "#크기 14 밝기 8\n",
        "def train(train_loader, epoch, model, optimizer, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(len(train_loader), batch_time, losses,\n",
        "                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        # measure data loading time\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss, accuracy \n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "def test(test_loader,epoch, model):\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    model.eval()\n",
        "    for i,(input,target) in enumerate(test_loader):\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        output = model(input)\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "model = ResNet34(num_classes=num_classes).cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
        "\n",
        "scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "###########################################################\n",
        "best_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n",
        "        epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "    # train for one epoch\n",
        "    start_time = time.time()\n",
        "    train(train_loader, epoch, model, optimizer, criterion)\n",
        "    test_acc = test(test_loader,epoch,model)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n",
        "    # learning rate scheduling\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Save model for best accuracy\n",
        "    if best_acc < test_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'model_best.pt')\n",
        "\n",
        "torch.save(model.state_dict(),'model_latest.pt')\n",
        "print(f\"Best Top-1 Accuracy: {best_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----- epoch: 0, lr: 0.1 -----\n",
            "Epoch: [0][  0/391]\tTime  0.307 ( 0.307)\tLoss 4.7202e+00 (4.7202e+00)\tAcc@1   0.78 (  0.78)\tAcc@5   4.69 (  4.69)\n",
            "Epoch: [0][ 30/391]\tTime  0.170 ( 0.173)\tLoss 4.5532e+00 (5.1999e+00)\tAcc@1   3.12 (  1.36)\tAcc@5  10.16 (  6.02)\n",
            "Epoch: [0][ 60/391]\tTime  0.173 ( 0.171)\tLoss 4.5141e+00 (4.9110e+00)\tAcc@1   2.34 (  1.36)\tAcc@5  11.72 (  6.47)\n",
            "Epoch: [0][ 90/391]\tTime  0.172 ( 0.171)\tLoss 4.3181e+00 (4.7582e+00)\tAcc@1   2.34 (  1.79)\tAcc@5  16.41 (  8.50)\n",
            "Epoch: [0][120/391]\tTime  0.173 ( 0.172)\tLoss 4.1890e+00 (4.6416e+00)\tAcc@1   4.69 (  2.28)\tAcc@5  17.97 ( 10.43)\n",
            "Epoch: [0][150/391]\tTime  0.170 ( 0.171)\tLoss 4.1694e+00 (4.5475e+00)\tAcc@1   1.56 (  2.89)\tAcc@5  23.44 ( 12.52)\n",
            "Epoch: [0][180/391]\tTime  0.170 ( 0.171)\tLoss 4.1695e+00 (4.4728e+00)\tAcc@1   3.91 (  3.36)\tAcc@5  20.31 ( 14.00)\n",
            "Epoch: [0][210/391]\tTime  0.170 ( 0.171)\tLoss 4.0378e+00 (4.4096e+00)\tAcc@1   8.59 (  3.81)\tAcc@5  25.00 ( 15.45)\n",
            "Epoch: [0][240/391]\tTime  0.168 ( 0.171)\tLoss 4.0275e+00 (4.3586e+00)\tAcc@1   7.03 (  4.20)\tAcc@5  23.44 ( 16.78)\n",
            "Epoch: [0][270/391]\tTime  0.169 ( 0.170)\tLoss 4.0077e+00 (4.3156e+00)\tAcc@1   7.03 (  4.59)\tAcc@5  19.53 ( 17.87)\n",
            "Epoch: [0][300/391]\tTime  0.164 ( 0.170)\tLoss 3.8377e+00 (4.2770e+00)\tAcc@1   8.59 (  5.02)\tAcc@5  35.16 ( 18.84)\n",
            "Epoch: [0][330/391]\tTime  0.166 ( 0.170)\tLoss 4.1216e+00 (4.2450e+00)\tAcc@1   4.69 (  5.28)\tAcc@5  23.44 ( 19.68)\n",
            "Epoch: [0][360/391]\tTime  0.166 ( 0.169)\tLoss 3.8960e+00 (4.2137e+00)\tAcc@1   7.03 (  5.60)\tAcc@5  25.78 ( 20.59)\n",
            "Epoch: [0][390/391]\tTime  0.151 ( 0.169)\tLoss 3.9603e+00 (4.1874e+00)\tAcc@1   8.75 (  5.88)\tAcc@5  40.00 ( 21.34)\n",
            "==> Train Accuracy: Acc@1 5.882 || Acc@5 21.342\n",
            "==> Test Accuracy:  Acc@1 3.970 || Acc@5 16.090\n",
            "==> 70.27 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 1, lr: 0.1 -----\n",
            "Epoch: [1][  0/391]\tTime  0.294 ( 0.294)\tLoss 3.9159e+00 (3.9159e+00)\tAcc@1   7.81 (  7.81)\tAcc@5  24.22 ( 24.22)\n",
            "Epoch: [1][ 30/391]\tTime  0.166 ( 0.170)\tLoss 3.6410e+00 (3.7707e+00)\tAcc@1  11.72 ( 10.94)\tAcc@5  36.72 ( 34.10)\n",
            "Epoch: [1][ 60/391]\tTime  0.168 ( 0.169)\tLoss 3.6885e+00 (3.7643e+00)\tAcc@1   7.81 ( 10.82)\tAcc@5  34.38 ( 33.80)\n",
            "Epoch: [1][ 90/391]\tTime  0.167 ( 0.168)\tLoss 3.6993e+00 (3.7562e+00)\tAcc@1  10.16 ( 10.65)\tAcc@5  37.50 ( 33.88)\n",
            "Epoch: [1][120/391]\tTime  0.169 ( 0.168)\tLoss 3.8251e+00 (3.7461e+00)\tAcc@1   8.59 ( 10.78)\tAcc@5  37.50 ( 34.33)\n",
            "Epoch: [1][150/391]\tTime  0.169 ( 0.168)\tLoss 3.6579e+00 (3.7406e+00)\tAcc@1  10.94 ( 10.89)\tAcc@5  35.16 ( 34.45)\n",
            "Epoch: [1][180/391]\tTime  0.168 ( 0.168)\tLoss 3.7113e+00 (3.7372e+00)\tAcc@1  14.06 ( 10.83)\tAcc@5  32.03 ( 34.46)\n",
            "Epoch: [1][210/391]\tTime  0.168 ( 0.168)\tLoss 3.4376e+00 (3.7254e+00)\tAcc@1   9.38 ( 10.97)\tAcc@5  43.75 ( 34.82)\n",
            "Epoch: [1][240/391]\tTime  0.169 ( 0.168)\tLoss 3.6226e+00 (3.7176e+00)\tAcc@1  15.62 ( 11.23)\tAcc@5  38.28 ( 35.05)\n",
            "Epoch: [1][270/391]\tTime  0.169 ( 0.168)\tLoss 3.5648e+00 (3.7060e+00)\tAcc@1  14.84 ( 11.44)\tAcc@5  42.19 ( 35.43)\n",
            "Epoch: [1][300/391]\tTime  0.169 ( 0.168)\tLoss 3.5955e+00 (3.6950e+00)\tAcc@1  14.06 ( 11.63)\tAcc@5  42.97 ( 35.76)\n",
            "Epoch: [1][330/391]\tTime  0.171 ( 0.168)\tLoss 3.5228e+00 (3.6881e+00)\tAcc@1  17.97 ( 11.80)\tAcc@5  35.94 ( 36.00)\n",
            "Epoch: [1][360/391]\tTime  0.169 ( 0.168)\tLoss 3.6630e+00 (3.6798e+00)\tAcc@1  14.84 ( 11.98)\tAcc@5  34.38 ( 36.26)\n",
            "Epoch: [1][390/391]\tTime  0.146 ( 0.168)\tLoss 3.8370e+00 (3.6687e+00)\tAcc@1  13.75 ( 12.23)\tAcc@5  26.25 ( 36.59)\n",
            "==> Train Accuracy: Acc@1 12.228 || Acc@5 36.594\n",
            "==> Test Accuracy:  Acc@1 5.490 || Acc@5 19.070\n",
            "==> 69.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 2, lr: 0.1 -----\n",
            "Epoch: [2][  0/391]\tTime  0.291 ( 0.291)\tLoss 3.4429e+00 (3.4429e+00)\tAcc@1  21.88 ( 21.88)\tAcc@5  45.31 ( 45.31)\n",
            "Epoch: [2][ 30/391]\tTime  0.168 ( 0.172)\tLoss 3.5785e+00 (3.4773e+00)\tAcc@1  13.28 ( 16.46)\tAcc@5  39.84 ( 42.94)\n",
            "Epoch: [2][ 60/391]\tTime  0.168 ( 0.170)\tLoss 3.3218e+00 (3.4786e+00)\tAcc@1  21.09 ( 16.12)\tAcc@5  40.62 ( 42.44)\n",
            "Epoch: [2][ 90/391]\tTime  0.168 ( 0.169)\tLoss 3.5867e+00 (3.4639e+00)\tAcc@1  14.84 ( 16.16)\tAcc@5  37.50 ( 42.86)\n",
            "Epoch: [2][120/391]\tTime  0.167 ( 0.169)\tLoss 3.5842e+00 (3.4538e+00)\tAcc@1  13.28 ( 16.40)\tAcc@5  39.84 ( 43.16)\n",
            "Epoch: [2][150/391]\tTime  0.165 ( 0.169)\tLoss 3.2865e+00 (3.4432e+00)\tAcc@1  20.31 ( 16.59)\tAcc@5  49.22 ( 43.57)\n",
            "Epoch: [2][180/391]\tTime  0.167 ( 0.168)\tLoss 3.3721e+00 (3.4375e+00)\tAcc@1  16.41 ( 16.48)\tAcc@5  47.66 ( 43.76)\n",
            "Epoch: [2][210/391]\tTime  0.170 ( 0.168)\tLoss 3.4268e+00 (3.4286e+00)\tAcc@1  17.97 ( 16.56)\tAcc@5  46.88 ( 43.94)\n",
            "Epoch: [2][240/391]\tTime  0.167 ( 0.168)\tLoss 3.3924e+00 (3.4154e+00)\tAcc@1  20.31 ( 16.88)\tAcc@5  45.31 ( 44.25)\n",
            "Epoch: [2][270/391]\tTime  0.168 ( 0.168)\tLoss 3.1741e+00 (3.4020e+00)\tAcc@1  25.78 ( 17.21)\tAcc@5  52.34 ( 44.65)\n",
            "Epoch: [2][300/391]\tTime  0.169 ( 0.168)\tLoss 3.3476e+00 (3.3882e+00)\tAcc@1  17.97 ( 17.46)\tAcc@5  42.97 ( 45.01)\n",
            "Epoch: [2][330/391]\tTime  0.170 ( 0.168)\tLoss 3.2252e+00 (3.3777e+00)\tAcc@1  22.66 ( 17.72)\tAcc@5  52.34 ( 45.30)\n",
            "Epoch: [2][360/391]\tTime  0.167 ( 0.168)\tLoss 3.0672e+00 (3.3668e+00)\tAcc@1  21.09 ( 17.90)\tAcc@5  57.03 ( 45.57)\n",
            "Epoch: [2][390/391]\tTime  0.151 ( 0.168)\tLoss 3.1639e+00 (3.3546e+00)\tAcc@1  22.50 ( 18.09)\tAcc@5  53.75 ( 45.93)\n",
            "==> Train Accuracy: Acc@1 18.092 || Acc@5 45.934\n",
            "==> Test Accuracy:  Acc@1 12.090 || Acc@5 33.910\n",
            "==> 69.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 3, lr: 0.1 -----\n",
            "Epoch: [3][  0/391]\tTime  0.301 ( 0.301)\tLoss 2.9461e+00 (2.9461e+00)\tAcc@1  25.78 ( 25.78)\tAcc@5  53.12 ( 53.12)\n",
            "Epoch: [3][ 30/391]\tTime  0.168 ( 0.171)\tLoss 3.0537e+00 (3.1447e+00)\tAcc@1  29.69 ( 20.97)\tAcc@5  55.47 ( 51.79)\n",
            "Epoch: [3][ 60/391]\tTime  0.168 ( 0.170)\tLoss 3.1330e+00 (3.1351e+00)\tAcc@1  18.75 ( 21.66)\tAcc@5  56.25 ( 51.99)\n",
            "Epoch: [3][ 90/391]\tTime  0.170 ( 0.169)\tLoss 3.1312e+00 (3.1215e+00)\tAcc@1  25.00 ( 22.20)\tAcc@5  49.22 ( 52.08)\n",
            "Epoch: [3][120/391]\tTime  0.169 ( 0.169)\tLoss 3.3865e+00 (3.1254e+00)\tAcc@1  14.06 ( 22.06)\tAcc@5  38.28 ( 51.96)\n",
            "Epoch: [3][150/391]\tTime  0.169 ( 0.169)\tLoss 2.9971e+00 (3.1186e+00)\tAcc@1  21.88 ( 22.07)\tAcc@5  57.03 ( 52.14)\n",
            "Epoch: [3][180/391]\tTime  0.168 ( 0.169)\tLoss 3.1569e+00 (3.1095e+00)\tAcc@1  25.78 ( 22.30)\tAcc@5  45.31 ( 52.32)\n",
            "Epoch: [3][210/391]\tTime  0.167 ( 0.169)\tLoss 3.1934e+00 (3.1041e+00)\tAcc@1  23.44 ( 22.53)\tAcc@5  48.44 ( 52.57)\n",
            "Epoch: [3][240/391]\tTime  0.168 ( 0.169)\tLoss 3.3691e+00 (3.0960e+00)\tAcc@1  15.62 ( 22.66)\tAcc@5  46.88 ( 52.78)\n",
            "Epoch: [3][270/391]\tTime  0.169 ( 0.169)\tLoss 3.2283e+00 (3.0841e+00)\tAcc@1  17.19 ( 22.83)\tAcc@5  50.00 ( 53.10)\n",
            "Epoch: [3][300/391]\tTime  0.168 ( 0.168)\tLoss 2.9922e+00 (3.0736e+00)\tAcc@1  23.44 ( 23.08)\tAcc@5  53.12 ( 53.37)\n",
            "Epoch: [3][330/391]\tTime  0.162 ( 0.168)\tLoss 2.9717e+00 (3.0622e+00)\tAcc@1  28.12 ( 23.32)\tAcc@5  60.94 ( 53.74)\n",
            "Epoch: [3][360/391]\tTime  0.166 ( 0.168)\tLoss 2.9306e+00 (3.0539e+00)\tAcc@1  28.12 ( 23.48)\tAcc@5  56.25 ( 53.88)\n",
            "Epoch: [3][390/391]\tTime  0.148 ( 0.168)\tLoss 2.8818e+00 (3.0412e+00)\tAcc@1  31.25 ( 23.79)\tAcc@5  62.50 ( 54.18)\n",
            "==> Train Accuracy: Acc@1 23.794 || Acc@5 54.182\n",
            "==> Test Accuracy:  Acc@1 15.830 || Acc@5 40.840\n",
            "==> 69.95 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 4, lr: 0.1 -----\n",
            "Epoch: [4][  0/391]\tTime  0.266 ( 0.266)\tLoss 2.8604e+00 (2.8604e+00)\tAcc@1  25.00 ( 25.00)\tAcc@5  58.59 ( 58.59)\n",
            "Epoch: [4][ 30/391]\tTime  0.167 ( 0.171)\tLoss 2.9781e+00 (2.8351e+00)\tAcc@1  21.88 ( 27.24)\tAcc@5  53.91 ( 59.38)\n",
            "Epoch: [4][ 60/391]\tTime  0.169 ( 0.169)\tLoss 2.7602e+00 (2.8410e+00)\tAcc@1  27.34 ( 27.25)\tAcc@5  60.16 ( 59.34)\n",
            "Epoch: [4][ 90/391]\tTime  0.168 ( 0.169)\tLoss 2.5786e+00 (2.8268e+00)\tAcc@1  33.59 ( 27.76)\tAcc@5  64.84 ( 59.68)\n",
            "Epoch: [4][120/391]\tTime  0.167 ( 0.169)\tLoss 2.7577e+00 (2.8186e+00)\tAcc@1  29.69 ( 28.09)\tAcc@5  59.38 ( 59.85)\n",
            "Epoch: [4][150/391]\tTime  0.167 ( 0.169)\tLoss 2.7839e+00 (2.8110e+00)\tAcc@1  28.12 ( 28.30)\tAcc@5  54.69 ( 60.04)\n",
            "Epoch: [4][180/391]\tTime  0.170 ( 0.169)\tLoss 3.0655e+00 (2.8029e+00)\tAcc@1  21.88 ( 28.36)\tAcc@5  50.78 ( 60.20)\n",
            "Epoch: [4][210/391]\tTime  0.168 ( 0.169)\tLoss 2.6767e+00 (2.7949e+00)\tAcc@1  35.16 ( 28.50)\tAcc@5  60.16 ( 60.52)\n",
            "Epoch: [4][240/391]\tTime  0.167 ( 0.169)\tLoss 2.7226e+00 (2.7879e+00)\tAcc@1  32.81 ( 28.68)\tAcc@5  64.84 ( 60.65)\n",
            "Epoch: [4][270/391]\tTime  0.169 ( 0.169)\tLoss 2.8088e+00 (2.7798e+00)\tAcc@1  27.34 ( 28.83)\tAcc@5  67.97 ( 60.86)\n",
            "Epoch: [4][300/391]\tTime  0.169 ( 0.169)\tLoss 2.9252e+00 (2.7728e+00)\tAcc@1  25.78 ( 29.02)\tAcc@5  59.38 ( 61.02)\n",
            "Epoch: [4][330/391]\tTime  0.169 ( 0.169)\tLoss 2.4486e+00 (2.7636e+00)\tAcc@1  37.50 ( 29.27)\tAcc@5  69.53 ( 61.29)\n",
            "Epoch: [4][360/391]\tTime  0.166 ( 0.169)\tLoss 2.8586e+00 (2.7597e+00)\tAcc@1  24.22 ( 29.34)\tAcc@5  58.59 ( 61.36)\n",
            "Epoch: [4][390/391]\tTime  0.151 ( 0.169)\tLoss 2.6631e+00 (2.7488e+00)\tAcc@1  31.25 ( 29.58)\tAcc@5  66.25 ( 61.63)\n",
            "==> Train Accuracy: Acc@1 29.584 || Acc@5 61.626\n",
            "==> Test Accuracy:  Acc@1 18.080 || Acc@5 43.860\n",
            "==> 70.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 5, lr: 0.1 -----\n",
            "Epoch: [5][  0/391]\tTime  0.280 ( 0.280)\tLoss 2.5089e+00 (2.5089e+00)\tAcc@1  30.47 ( 30.47)\tAcc@5  60.94 ( 60.94)\n",
            "Epoch: [5][ 30/391]\tTime  0.171 ( 0.171)\tLoss 2.3520e+00 (2.5385e+00)\tAcc@1  35.94 ( 33.67)\tAcc@5  74.22 ( 66.43)\n",
            "Epoch: [5][ 60/391]\tTime  0.168 ( 0.169)\tLoss 2.5099e+00 (2.5304e+00)\tAcc@1  35.94 ( 33.95)\tAcc@5  68.75 ( 66.53)\n",
            "Epoch: [5][ 90/391]\tTime  0.167 ( 0.169)\tLoss 2.6726e+00 (2.5488e+00)\tAcc@1  26.56 ( 33.40)\tAcc@5  64.06 ( 66.11)\n",
            "Epoch: [5][120/391]\tTime  0.168 ( 0.169)\tLoss 2.7485e+00 (2.5469e+00)\tAcc@1  25.78 ( 33.48)\tAcc@5  61.72 ( 66.39)\n",
            "Epoch: [5][150/391]\tTime  0.169 ( 0.168)\tLoss 2.1522e+00 (2.5407e+00)\tAcc@1  42.19 ( 33.62)\tAcc@5  71.09 ( 66.47)\n",
            "Epoch: [5][180/391]\tTime  0.165 ( 0.168)\tLoss 2.5874e+00 (2.5328e+00)\tAcc@1  32.03 ( 33.72)\tAcc@5  65.62 ( 66.53)\n",
            "Epoch: [5][210/391]\tTime  0.166 ( 0.168)\tLoss 2.4351e+00 (2.5321e+00)\tAcc@1  37.50 ( 33.80)\tAcc@5  70.31 ( 66.54)\n",
            "Epoch: [5][240/391]\tTime  0.168 ( 0.168)\tLoss 2.5002e+00 (2.5331e+00)\tAcc@1  34.38 ( 33.69)\tAcc@5  72.66 ( 66.49)\n",
            "Epoch: [5][270/391]\tTime  0.169 ( 0.168)\tLoss 2.4276e+00 (2.5290e+00)\tAcc@1  34.38 ( 33.80)\tAcc@5  69.53 ( 66.63)\n",
            "Epoch: [5][300/391]\tTime  0.170 ( 0.168)\tLoss 2.4630e+00 (2.5187e+00)\tAcc@1  38.28 ( 33.96)\tAcc@5  70.31 ( 66.93)\n",
            "Epoch: [5][330/391]\tTime  0.168 ( 0.168)\tLoss 2.5186e+00 (2.5123e+00)\tAcc@1  35.16 ( 34.10)\tAcc@5  64.84 ( 67.11)\n",
            "Epoch: [5][360/391]\tTime  0.168 ( 0.168)\tLoss 2.4258e+00 (2.5085e+00)\tAcc@1  41.41 ( 34.19)\tAcc@5  67.19 ( 67.13)\n",
            "Epoch: [5][390/391]\tTime  0.149 ( 0.168)\tLoss 2.6299e+00 (2.4992e+00)\tAcc@1  38.75 ( 34.50)\tAcc@5  61.25 ( 67.34)\n",
            "==> Train Accuracy: Acc@1 34.498 || Acc@5 67.336\n",
            "==> Test Accuracy:  Acc@1 22.700 || Acc@5 53.590\n",
            "==> 69.96 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 6, lr: 0.1 -----\n",
            "Epoch: [6][  0/391]\tTime  0.296 ( 0.296)\tLoss 2.4884e+00 (2.4884e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  64.84 ( 64.84)\n",
            "Epoch: [6][ 30/391]\tTime  0.168 ( 0.171)\tLoss 2.2560e+00 (2.3546e+00)\tAcc@1  40.62 ( 39.11)\tAcc@5  71.88 ( 70.46)\n",
            "Epoch: [6][ 60/391]\tTime  0.167 ( 0.169)\tLoss 2.2441e+00 (2.3489e+00)\tAcc@1  39.06 ( 38.40)\tAcc@5  74.22 ( 70.61)\n",
            "Epoch: [6][ 90/391]\tTime  0.167 ( 0.169)\tLoss 2.4326e+00 (2.3498e+00)\tAcc@1  32.81 ( 38.00)\tAcc@5  71.09 ( 70.60)\n",
            "Epoch: [6][120/391]\tTime  0.169 ( 0.169)\tLoss 2.1668e+00 (2.3370e+00)\tAcc@1  36.72 ( 38.11)\tAcc@5  82.03 ( 70.81)\n",
            "Epoch: [6][150/391]\tTime  0.168 ( 0.168)\tLoss 2.2220e+00 (2.3202e+00)\tAcc@1  38.28 ( 38.50)\tAcc@5  75.78 ( 71.24)\n",
            "Epoch: [6][180/391]\tTime  0.167 ( 0.168)\tLoss 2.2718e+00 (2.3135e+00)\tAcc@1  35.16 ( 38.56)\tAcc@5  74.22 ( 71.31)\n",
            "Epoch: [6][210/391]\tTime  0.168 ( 0.168)\tLoss 2.4441e+00 (2.3129e+00)\tAcc@1  32.81 ( 38.62)\tAcc@5  71.88 ( 71.30)\n",
            "Epoch: [6][240/391]\tTime  0.169 ( 0.168)\tLoss 2.0177e+00 (2.3140e+00)\tAcc@1  46.09 ( 38.57)\tAcc@5  73.44 ( 71.29)\n",
            "Epoch: [6][270/391]\tTime  0.168 ( 0.168)\tLoss 2.1275e+00 (2.3093e+00)\tAcc@1  47.66 ( 38.68)\tAcc@5  79.69 ( 71.42)\n",
            "Epoch: [6][300/391]\tTime  0.169 ( 0.168)\tLoss 2.3196e+00 (2.3049e+00)\tAcc@1  41.41 ( 38.79)\tAcc@5  71.09 ( 71.50)\n",
            "Epoch: [6][330/391]\tTime  0.169 ( 0.168)\tLoss 2.4179e+00 (2.3018e+00)\tAcc@1  32.81 ( 38.77)\tAcc@5  67.19 ( 71.60)\n",
            "Epoch: [6][360/391]\tTime  0.169 ( 0.168)\tLoss 2.4368e+00 (2.2978e+00)\tAcc@1  36.72 ( 38.86)\tAcc@5  68.75 ( 71.66)\n",
            "Epoch: [6][390/391]\tTime  0.152 ( 0.168)\tLoss 2.4715e+00 (2.2918e+00)\tAcc@1  38.75 ( 39.08)\tAcc@5  63.75 ( 71.81)\n",
            "==> Train Accuracy: Acc@1 39.082 || Acc@5 71.806\n",
            "==> Test Accuracy:  Acc@1 26.450 || Acc@5 54.910\n",
            "==> 69.94 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 7, lr: 0.1 -----\n",
            "Epoch: [7][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.9505e+00 (1.9505e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  82.81 ( 82.81)\n",
            "Epoch: [7][ 30/391]\tTime  0.172 ( 0.171)\tLoss 2.3215e+00 (2.0850e+00)\tAcc@1  35.94 ( 43.55)\tAcc@5  75.78 ( 76.66)\n",
            "Epoch: [7][ 60/391]\tTime  0.168 ( 0.170)\tLoss 2.5792e+00 (2.1037e+00)\tAcc@1  30.47 ( 43.31)\tAcc@5  62.50 ( 76.09)\n",
            "Epoch: [7][ 90/391]\tTime  0.167 ( 0.169)\tLoss 2.1230e+00 (2.1175e+00)\tAcc@1  38.28 ( 43.21)\tAcc@5  78.91 ( 75.58)\n",
            "Epoch: [7][120/391]\tTime  0.167 ( 0.169)\tLoss 2.0054e+00 (2.1139e+00)\tAcc@1  50.00 ( 43.30)\tAcc@5  77.34 ( 75.75)\n",
            "Epoch: [7][150/391]\tTime  0.169 ( 0.168)\tLoss 2.4521e+00 (2.1221e+00)\tAcc@1  32.03 ( 42.94)\tAcc@5  69.53 ( 75.51)\n",
            "Epoch: [7][180/391]\tTime  0.167 ( 0.168)\tLoss 2.0060e+00 (2.1198e+00)\tAcc@1  42.97 ( 42.98)\tAcc@5  81.25 ( 75.50)\n",
            "Epoch: [7][210/391]\tTime  0.168 ( 0.168)\tLoss 2.1614e+00 (2.1235e+00)\tAcc@1  39.06 ( 42.79)\tAcc@5  81.25 ( 75.49)\n",
            "Epoch: [7][240/391]\tTime  0.167 ( 0.168)\tLoss 2.3767e+00 (2.1252e+00)\tAcc@1  36.72 ( 42.66)\tAcc@5  70.31 ( 75.48)\n",
            "Epoch: [7][270/391]\tTime  0.168 ( 0.168)\tLoss 2.1750e+00 (2.1295e+00)\tAcc@1  43.75 ( 42.57)\tAcc@5  74.22 ( 75.40)\n",
            "Epoch: [7][300/391]\tTime  0.169 ( 0.168)\tLoss 2.2004e+00 (2.1331e+00)\tAcc@1  43.75 ( 42.59)\tAcc@5  70.31 ( 75.21)\n",
            "Epoch: [7][330/391]\tTime  0.167 ( 0.168)\tLoss 2.0276e+00 (2.1350e+00)\tAcc@1  48.44 ( 42.56)\tAcc@5  79.69 ( 75.19)\n",
            "Epoch: [7][360/391]\tTime  0.167 ( 0.168)\tLoss 2.2305e+00 (2.1358e+00)\tAcc@1  41.41 ( 42.51)\tAcc@5  71.88 ( 75.19)\n",
            "Epoch: [7][390/391]\tTime  0.152 ( 0.168)\tLoss 1.8408e+00 (2.1347e+00)\tAcc@1  47.50 ( 42.53)\tAcc@5  80.00 ( 75.17)\n",
            "==> Train Accuracy: Acc@1 42.528 || Acc@5 75.172\n",
            "==> Test Accuracy:  Acc@1 35.520 || Acc@5 67.530\n",
            "==> 69.83 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 8, lr: 0.1 -----\n",
            "Epoch: [8][  0/391]\tTime  0.279 ( 0.279)\tLoss 2.1286e+00 (2.1286e+00)\tAcc@1  36.72 ( 36.72)\tAcc@5  73.44 ( 73.44)\n",
            "Epoch: [8][ 30/391]\tTime  0.171 ( 0.171)\tLoss 2.2178e+00 (2.0524e+00)\tAcc@1  36.72 ( 43.52)\tAcc@5  74.22 ( 77.14)\n",
            "Epoch: [8][ 60/391]\tTime  0.168 ( 0.170)\tLoss 1.9778e+00 (2.0171e+00)\tAcc@1  40.62 ( 44.95)\tAcc@5  77.34 ( 77.75)\n",
            "Epoch: [8][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.8553e+00 (1.9978e+00)\tAcc@1  44.53 ( 45.23)\tAcc@5  80.47 ( 78.06)\n",
            "Epoch: [8][120/391]\tTime  0.169 ( 0.169)\tLoss 1.9734e+00 (2.0026e+00)\tAcc@1  42.19 ( 45.42)\tAcc@5  79.69 ( 77.73)\n",
            "Epoch: [8][150/391]\tTime  0.166 ( 0.169)\tLoss 2.0909e+00 (2.0080e+00)\tAcc@1  43.75 ( 45.35)\tAcc@5  75.00 ( 77.65)\n",
            "Epoch: [8][180/391]\tTime  0.167 ( 0.168)\tLoss 1.8530e+00 (2.0035e+00)\tAcc@1  50.78 ( 45.42)\tAcc@5  75.00 ( 77.79)\n",
            "Epoch: [8][210/391]\tTime  0.168 ( 0.168)\tLoss 2.0461e+00 (2.0079e+00)\tAcc@1  45.31 ( 45.33)\tAcc@5  73.44 ( 77.57)\n",
            "Epoch: [8][240/391]\tTime  0.168 ( 0.168)\tLoss 2.1110e+00 (2.0069e+00)\tAcc@1  42.97 ( 45.43)\tAcc@5  78.12 ( 77.65)\n",
            "Epoch: [8][270/391]\tTime  0.172 ( 0.168)\tLoss 2.2359e+00 (2.0108e+00)\tAcc@1  42.19 ( 45.38)\tAcc@5  71.88 ( 77.52)\n",
            "Epoch: [8][300/391]\tTime  0.167 ( 0.168)\tLoss 1.9725e+00 (2.0061e+00)\tAcc@1  42.19 ( 45.49)\tAcc@5  78.12 ( 77.53)\n",
            "Epoch: [8][330/391]\tTime  0.169 ( 0.168)\tLoss 2.1165e+00 (2.0095e+00)\tAcc@1  41.41 ( 45.40)\tAcc@5  74.22 ( 77.48)\n",
            "Epoch: [8][360/391]\tTime  0.167 ( 0.168)\tLoss 2.1782e+00 (2.0094e+00)\tAcc@1  36.72 ( 45.35)\tAcc@5  77.34 ( 77.48)\n",
            "Epoch: [8][390/391]\tTime  0.151 ( 0.168)\tLoss 1.7511e+00 (2.0076e+00)\tAcc@1  50.00 ( 45.43)\tAcc@5  86.25 ( 77.55)\n",
            "==> Train Accuracy: Acc@1 45.426 || Acc@5 77.552\n",
            "==> Test Accuracy:  Acc@1 36.690 || Acc@5 68.400\n",
            "==> 69.86 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 9, lr: 0.1 -----\n",
            "Epoch: [9][  0/391]\tTime  0.271 ( 0.271)\tLoss 1.9647e+00 (1.9647e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  79.69 ( 79.69)\n",
            "Epoch: [9][ 30/391]\tTime  0.170 ( 0.171)\tLoss 1.6253e+00 (1.8792e+00)\tAcc@1  57.81 ( 48.44)\tAcc@5  83.59 ( 80.27)\n",
            "Epoch: [9][ 60/391]\tTime  0.172 ( 0.170)\tLoss 2.0804e+00 (1.8951e+00)\tAcc@1  46.09 ( 47.89)\tAcc@5  76.56 ( 79.73)\n",
            "Epoch: [9][ 90/391]\tTime  0.171 ( 0.169)\tLoss 1.7560e+00 (1.8980e+00)\tAcc@1  50.00 ( 47.64)\tAcc@5  83.59 ( 79.50)\n",
            "Epoch: [9][120/391]\tTime  0.168 ( 0.169)\tLoss 1.8285e+00 (1.9002e+00)\tAcc@1  52.34 ( 47.61)\tAcc@5  80.47 ( 79.67)\n",
            "Epoch: [9][150/391]\tTime  0.169 ( 0.169)\tLoss 1.8726e+00 (1.8993e+00)\tAcc@1  50.00 ( 47.72)\tAcc@5  78.91 ( 79.62)\n",
            "Epoch: [9][180/391]\tTime  0.167 ( 0.169)\tLoss 1.8662e+00 (1.8911e+00)\tAcc@1  47.66 ( 47.98)\tAcc@5  75.00 ( 79.74)\n",
            "Epoch: [9][210/391]\tTime  0.169 ( 0.169)\tLoss 2.1639e+00 (1.8927e+00)\tAcc@1  39.84 ( 47.83)\tAcc@5  75.00 ( 79.82)\n",
            "Epoch: [9][240/391]\tTime  0.168 ( 0.169)\tLoss 1.9158e+00 (1.8981e+00)\tAcc@1  46.09 ( 47.71)\tAcc@5  78.91 ( 79.70)\n",
            "Epoch: [9][270/391]\tTime  0.167 ( 0.169)\tLoss 1.7514e+00 (1.9008e+00)\tAcc@1  52.34 ( 47.72)\tAcc@5  85.16 ( 79.61)\n",
            "Epoch: [9][300/391]\tTime  0.167 ( 0.168)\tLoss 1.8209e+00 (1.9004e+00)\tAcc@1  47.66 ( 47.78)\tAcc@5  78.12 ( 79.58)\n",
            "Epoch: [9][330/391]\tTime  0.169 ( 0.168)\tLoss 1.9631e+00 (1.8997e+00)\tAcc@1  50.78 ( 47.78)\tAcc@5  82.03 ( 79.60)\n",
            "Epoch: [9][360/391]\tTime  0.164 ( 0.168)\tLoss 1.8911e+00 (1.8987e+00)\tAcc@1  50.78 ( 47.90)\tAcc@5  81.25 ( 79.59)\n",
            "Epoch: [9][390/391]\tTime  0.152 ( 0.168)\tLoss 2.0835e+00 (1.8961e+00)\tAcc@1  45.00 ( 47.94)\tAcc@5  75.00 ( 79.67)\n",
            "==> Train Accuracy: Acc@1 47.940 || Acc@5 79.670\n",
            "==> Test Accuracy:  Acc@1 41.590 || Acc@5 74.110\n",
            "==> 69.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 10, lr: 0.1 -----\n",
            "Epoch: [10][  0/391]\tTime  0.297 ( 0.297)\tLoss 1.6218e+00 (1.6218e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  83.59 ( 83.59)\n",
            "Epoch: [10][ 30/391]\tTime  0.163 ( 0.171)\tLoss 2.0635e+00 (1.7807e+00)\tAcc@1  41.41 ( 50.98)\tAcc@5  78.12 ( 82.41)\n",
            "Epoch: [10][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.7503e+00 (1.7759e+00)\tAcc@1  51.56 ( 51.10)\tAcc@5  79.69 ( 82.16)\n",
            "Epoch: [10][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.7658e+00 (1.7985e+00)\tAcc@1  51.56 ( 50.39)\tAcc@5  80.47 ( 81.59)\n",
            "Epoch: [10][120/391]\tTime  0.168 ( 0.169)\tLoss 1.8074e+00 (1.8056e+00)\tAcc@1  48.44 ( 50.20)\tAcc@5  82.81 ( 81.52)\n",
            "Epoch: [10][150/391]\tTime  0.168 ( 0.169)\tLoss 2.1952e+00 (1.8040e+00)\tAcc@1  41.41 ( 50.35)\tAcc@5  71.88 ( 81.49)\n",
            "Epoch: [10][180/391]\tTime  0.169 ( 0.169)\tLoss 1.8019e+00 (1.7994e+00)\tAcc@1  48.44 ( 50.54)\tAcc@5  80.47 ( 81.55)\n",
            "Epoch: [10][210/391]\tTime  0.173 ( 0.169)\tLoss 1.8373e+00 (1.8045e+00)\tAcc@1  48.44 ( 50.41)\tAcc@5  80.47 ( 81.36)\n",
            "Epoch: [10][240/391]\tTime  0.167 ( 0.169)\tLoss 1.9585e+00 (1.8096e+00)\tAcc@1  48.44 ( 50.25)\tAcc@5  76.56 ( 81.33)\n",
            "Epoch: [10][270/391]\tTime  0.168 ( 0.168)\tLoss 1.7219e+00 (1.8122e+00)\tAcc@1  57.03 ( 50.19)\tAcc@5  80.47 ( 81.27)\n",
            "Epoch: [10][300/391]\tTime  0.168 ( 0.168)\tLoss 1.7786e+00 (1.8172e+00)\tAcc@1  47.66 ( 50.08)\tAcc@5  82.03 ( 81.11)\n",
            "Epoch: [10][330/391]\tTime  0.168 ( 0.168)\tLoss 1.9469e+00 (1.8173e+00)\tAcc@1  45.31 ( 50.07)\tAcc@5  79.69 ( 81.07)\n",
            "Epoch: [10][360/391]\tTime  0.167 ( 0.168)\tLoss 1.8927e+00 (1.8175e+00)\tAcc@1  50.00 ( 50.05)\tAcc@5  78.91 ( 81.10)\n",
            "Epoch: [10][390/391]\tTime  0.149 ( 0.168)\tLoss 2.0882e+00 (1.8190e+00)\tAcc@1  48.75 ( 50.04)\tAcc@5  80.00 ( 81.08)\n",
            "==> Train Accuracy: Acc@1 50.044 || Acc@5 81.080\n",
            "==> Test Accuracy:  Acc@1 34.790 || Acc@5 66.160\n",
            "==> 69.92 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 11, lr: 0.1 -----\n",
            "Epoch: [11][  0/391]\tTime  0.289 ( 0.289)\tLoss 1.8482e+00 (1.8482e+00)\tAcc@1  43.75 ( 43.75)\tAcc@5  82.03 ( 82.03)\n",
            "Epoch: [11][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.8204e+00 (1.6989e+00)\tAcc@1  46.09 ( 52.27)\tAcc@5  82.81 ( 82.84)\n",
            "Epoch: [11][ 60/391]\tTime  0.169 ( 0.169)\tLoss 1.6602e+00 (1.6850e+00)\tAcc@1  54.69 ( 52.74)\tAcc@5  82.81 ( 83.15)\n",
            "Epoch: [11][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.7359e+00 (1.7060e+00)\tAcc@1  53.12 ( 52.58)\tAcc@5  83.59 ( 82.86)\n",
            "Epoch: [11][120/391]\tTime  0.168 ( 0.169)\tLoss 2.0755e+00 (1.7239e+00)\tAcc@1  39.84 ( 52.10)\tAcc@5  76.56 ( 82.62)\n",
            "Epoch: [11][150/391]\tTime  0.168 ( 0.168)\tLoss 1.6845e+00 (1.7174e+00)\tAcc@1  52.34 ( 52.14)\tAcc@5  79.69 ( 82.71)\n",
            "Epoch: [11][180/391]\tTime  0.168 ( 0.168)\tLoss 1.8017e+00 (1.7239e+00)\tAcc@1  46.09 ( 51.99)\tAcc@5  83.59 ( 82.67)\n",
            "Epoch: [11][210/391]\tTime  0.168 ( 0.168)\tLoss 1.5510e+00 (1.7263e+00)\tAcc@1  57.81 ( 51.91)\tAcc@5  86.72 ( 82.64)\n",
            "Epoch: [11][240/391]\tTime  0.169 ( 0.168)\tLoss 1.7940e+00 (1.7299e+00)\tAcc@1  51.56 ( 51.87)\tAcc@5  78.12 ( 82.58)\n",
            "Epoch: [11][270/391]\tTime  0.173 ( 0.168)\tLoss 1.7681e+00 (1.7341e+00)\tAcc@1  50.00 ( 51.85)\tAcc@5  84.38 ( 82.44)\n",
            "Epoch: [11][300/391]\tTime  0.168 ( 0.168)\tLoss 1.5844e+00 (1.7377e+00)\tAcc@1  52.34 ( 51.86)\tAcc@5  85.16 ( 82.39)\n",
            "Epoch: [11][330/391]\tTime  0.168 ( 0.168)\tLoss 1.8082e+00 (1.7383e+00)\tAcc@1  50.78 ( 51.84)\tAcc@5  81.25 ( 82.39)\n",
            "Epoch: [11][360/391]\tTime  0.168 ( 0.168)\tLoss 1.9564e+00 (1.7427e+00)\tAcc@1  46.88 ( 51.65)\tAcc@5  79.69 ( 82.35)\n",
            "Epoch: [11][390/391]\tTime  0.150 ( 0.168)\tLoss 1.9337e+00 (1.7430e+00)\tAcc@1  40.00 ( 51.63)\tAcc@5  86.25 ( 82.33)\n",
            "==> Train Accuracy: Acc@1 51.632 || Acc@5 82.330\n",
            "==> Test Accuracy:  Acc@1 42.090 || Acc@5 73.730\n",
            "==> 69.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 12, lr: 0.1 -----\n",
            "Epoch: [12][  0/391]\tTime  0.299 ( 0.299)\tLoss 1.4717e+00 (1.4717e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [12][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.8256e+00 (1.6585e+00)\tAcc@1  53.12 ( 54.26)\tAcc@5  82.81 ( 83.77)\n",
            "Epoch: [12][ 60/391]\tTime  0.164 ( 0.169)\tLoss 1.6614e+00 (1.6481e+00)\tAcc@1  51.56 ( 54.37)\tAcc@5  84.38 ( 84.18)\n",
            "Epoch: [12][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.6069e+00 (1.6450e+00)\tAcc@1  56.25 ( 54.03)\tAcc@5  83.59 ( 84.14)\n",
            "Epoch: [12][120/391]\tTime  0.168 ( 0.169)\tLoss 1.6389e+00 (1.6528e+00)\tAcc@1  51.56 ( 53.88)\tAcc@5  81.25 ( 84.05)\n",
            "Epoch: [12][150/391]\tTime  0.167 ( 0.168)\tLoss 1.8446e+00 (1.6527e+00)\tAcc@1  46.09 ( 53.93)\tAcc@5  80.47 ( 83.84)\n",
            "Epoch: [12][180/391]\tTime  0.169 ( 0.168)\tLoss 1.4667e+00 (1.6541e+00)\tAcc@1  55.47 ( 53.90)\tAcc@5  86.72 ( 83.91)\n",
            "Epoch: [12][210/391]\tTime  0.168 ( 0.168)\tLoss 1.5794e+00 (1.6583e+00)\tAcc@1  56.25 ( 53.82)\tAcc@5  85.94 ( 83.75)\n",
            "Epoch: [12][240/391]\tTime  0.168 ( 0.168)\tLoss 1.6729e+00 (1.6594e+00)\tAcc@1  53.12 ( 53.71)\tAcc@5  82.03 ( 83.75)\n",
            "Epoch: [12][270/391]\tTime  0.168 ( 0.168)\tLoss 1.5013e+00 (1.6689e+00)\tAcc@1  60.94 ( 53.48)\tAcc@5  82.03 ( 83.55)\n",
            "Epoch: [12][300/391]\tTime  0.167 ( 0.168)\tLoss 1.8082e+00 (1.6707e+00)\tAcc@1  49.22 ( 53.44)\tAcc@5  81.25 ( 83.55)\n",
            "Epoch: [12][330/391]\tTime  0.169 ( 0.168)\tLoss 1.4519e+00 (1.6729e+00)\tAcc@1  62.50 ( 53.36)\tAcc@5  89.06 ( 83.56)\n",
            "Epoch: [12][360/391]\tTime  0.167 ( 0.168)\tLoss 1.8124e+00 (1.6765e+00)\tAcc@1  53.12 ( 53.25)\tAcc@5  82.03 ( 83.47)\n",
            "Epoch: [12][390/391]\tTime  0.150 ( 0.168)\tLoss 1.8280e+00 (1.6759e+00)\tAcc@1  51.25 ( 53.30)\tAcc@5  78.75 ( 83.44)\n",
            "==> Train Accuracy: Acc@1 53.296 || Acc@5 83.442\n",
            "==> Test Accuracy:  Acc@1 47.380 || Acc@5 78.060\n",
            "==> 69.83 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 13, lr: 0.1 -----\n",
            "Epoch: [13][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.5935e+00 (1.5935e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [13][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.5551e+00 (1.5967e+00)\tAcc@1  61.72 ( 55.34)\tAcc@5  85.94 ( 85.01)\n",
            "Epoch: [13][ 60/391]\tTime  0.163 ( 0.169)\tLoss 1.5413e+00 (1.5760e+00)\tAcc@1  54.69 ( 55.44)\tAcc@5  85.94 ( 85.19)\n",
            "Epoch: [13][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.6704e+00 (1.5851e+00)\tAcc@1  51.56 ( 55.23)\tAcc@5  84.38 ( 85.25)\n",
            "Epoch: [13][120/391]\tTime  0.166 ( 0.168)\tLoss 1.8232e+00 (1.5897e+00)\tAcc@1  53.12 ( 55.16)\tAcc@5  78.91 ( 85.08)\n",
            "Epoch: [13][150/391]\tTime  0.168 ( 0.168)\tLoss 1.5130e+00 (1.5926e+00)\tAcc@1  57.03 ( 54.89)\tAcc@5  86.72 ( 85.05)\n",
            "Epoch: [13][180/391]\tTime  0.167 ( 0.168)\tLoss 1.6710e+00 (1.5923e+00)\tAcc@1  53.91 ( 54.85)\tAcc@5  83.59 ( 85.12)\n",
            "Epoch: [13][210/391]\tTime  0.169 ( 0.168)\tLoss 1.5620e+00 (1.6071e+00)\tAcc@1  52.34 ( 54.49)\tAcc@5  87.50 ( 84.87)\n",
            "Epoch: [13][240/391]\tTime  0.168 ( 0.168)\tLoss 1.3750e+00 (1.6121e+00)\tAcc@1  67.97 ( 54.38)\tAcc@5  86.72 ( 84.85)\n",
            "Epoch: [13][270/391]\tTime  0.165 ( 0.168)\tLoss 1.8941e+00 (1.6137e+00)\tAcc@1  44.53 ( 54.46)\tAcc@5  81.25 ( 84.75)\n",
            "Epoch: [13][300/391]\tTime  0.167 ( 0.168)\tLoss 1.7802e+00 (1.6147e+00)\tAcc@1  46.88 ( 54.58)\tAcc@5  80.47 ( 84.71)\n",
            "Epoch: [13][330/391]\tTime  0.168 ( 0.168)\tLoss 1.6605e+00 (1.6171e+00)\tAcc@1  51.56 ( 54.58)\tAcc@5  84.38 ( 84.62)\n",
            "Epoch: [13][360/391]\tTime  0.168 ( 0.168)\tLoss 1.5100e+00 (1.6177e+00)\tAcc@1  58.59 ( 54.62)\tAcc@5  85.16 ( 84.55)\n",
            "Epoch: [13][390/391]\tTime  0.152 ( 0.168)\tLoss 1.4404e+00 (1.6184e+00)\tAcc@1  57.50 ( 54.60)\tAcc@5  88.75 ( 84.58)\n",
            "==> Train Accuracy: Acc@1 54.602 || Acc@5 84.582\n",
            "==> Test Accuracy:  Acc@1 46.170 || Acc@5 77.390\n",
            "==> 69.89 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 14, lr: 0.1 -----\n",
            "Epoch: [14][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.5464e+00 (1.5464e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [14][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.6002e+00 (1.5503e+00)\tAcc@1  52.34 ( 56.55)\tAcc@5  85.94 ( 85.56)\n",
            "Epoch: [14][ 60/391]\tTime  0.168 ( 0.170)\tLoss 1.4540e+00 (1.5507e+00)\tAcc@1  60.16 ( 56.13)\tAcc@5  85.94 ( 85.36)\n",
            "Epoch: [14][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.6528e+00 (1.5338e+00)\tAcc@1  54.69 ( 56.69)\tAcc@5  82.03 ( 85.75)\n",
            "Epoch: [14][120/391]\tTime  0.173 ( 0.169)\tLoss 1.3704e+00 (1.5469e+00)\tAcc@1  64.06 ( 56.39)\tAcc@5  89.84 ( 85.69)\n",
            "Epoch: [14][150/391]\tTime  0.166 ( 0.169)\tLoss 1.5141e+00 (1.5554e+00)\tAcc@1  58.59 ( 56.18)\tAcc@5  82.03 ( 85.55)\n",
            "Epoch: [14][180/391]\tTime  0.168 ( 0.169)\tLoss 1.4457e+00 (1.5630e+00)\tAcc@1  60.16 ( 55.89)\tAcc@5  86.72 ( 85.47)\n",
            "Epoch: [14][210/391]\tTime  0.168 ( 0.168)\tLoss 1.7244e+00 (1.5621e+00)\tAcc@1  48.44 ( 55.84)\tAcc@5  82.81 ( 85.49)\n",
            "Epoch: [14][240/391]\tTime  0.167 ( 0.168)\tLoss 1.7961e+00 (1.5657e+00)\tAcc@1  55.47 ( 55.80)\tAcc@5  76.56 ( 85.34)\n",
            "Epoch: [14][270/391]\tTime  0.167 ( 0.168)\tLoss 1.5165e+00 (1.5681e+00)\tAcc@1  59.38 ( 55.71)\tAcc@5  83.59 ( 85.30)\n",
            "Epoch: [14][300/391]\tTime  0.168 ( 0.168)\tLoss 1.8112e+00 (1.5705e+00)\tAcc@1  46.88 ( 55.64)\tAcc@5  83.59 ( 85.26)\n",
            "Epoch: [14][330/391]\tTime  0.168 ( 0.168)\tLoss 1.8420e+00 (1.5726e+00)\tAcc@1  51.56 ( 55.61)\tAcc@5  79.69 ( 85.25)\n",
            "Epoch: [14][360/391]\tTime  0.168 ( 0.168)\tLoss 1.7792e+00 (1.5717e+00)\tAcc@1  53.12 ( 55.72)\tAcc@5  78.91 ( 85.26)\n",
            "Epoch: [14][390/391]\tTime  0.152 ( 0.168)\tLoss 1.5515e+00 (1.5718e+00)\tAcc@1  56.25 ( 55.74)\tAcc@5  82.50 ( 85.28)\n",
            "==> Train Accuracy: Acc@1 55.738 || Acc@5 85.276\n",
            "==> Test Accuracy:  Acc@1 48.770 || Acc@5 78.810\n",
            "==> 69.88 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 15, lr: 0.1 -----\n",
            "Epoch: [15][  0/391]\tTime  0.295 ( 0.295)\tLoss 1.5428e+00 (1.5428e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  82.03 ( 82.03)\n",
            "Epoch: [15][ 30/391]\tTime  0.168 ( 0.172)\tLoss 1.5596e+00 (1.4433e+00)\tAcc@1  54.69 ( 59.58)\tAcc@5  86.72 ( 86.64)\n",
            "Epoch: [15][ 60/391]\tTime  0.170 ( 0.170)\tLoss 1.3731e+00 (1.4453e+00)\tAcc@1  61.72 ( 59.40)\tAcc@5  85.94 ( 87.01)\n",
            "Epoch: [15][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.4174e+00 (1.4620e+00)\tAcc@1  57.81 ( 58.89)\tAcc@5  92.19 ( 86.84)\n",
            "Epoch: [15][120/391]\tTime  0.171 ( 0.169)\tLoss 1.4710e+00 (1.4923e+00)\tAcc@1  58.59 ( 58.06)\tAcc@5  88.28 ( 86.34)\n",
            "Epoch: [15][150/391]\tTime  0.169 ( 0.168)\tLoss 1.7234e+00 (1.5017e+00)\tAcc@1  56.25 ( 57.82)\tAcc@5  82.03 ( 86.32)\n",
            "Epoch: [15][180/391]\tTime  0.169 ( 0.168)\tLoss 1.5420e+00 (1.5008e+00)\tAcc@1  56.25 ( 57.83)\tAcc@5  81.25 ( 86.30)\n",
            "Epoch: [15][210/391]\tTime  0.163 ( 0.168)\tLoss 1.5642e+00 (1.5035e+00)\tAcc@1  53.91 ( 57.56)\tAcc@5  86.72 ( 86.32)\n",
            "Epoch: [15][240/391]\tTime  0.167 ( 0.168)\tLoss 1.4328e+00 (1.5111e+00)\tAcc@1  61.72 ( 57.45)\tAcc@5  86.72 ( 86.24)\n",
            "Epoch: [15][270/391]\tTime  0.170 ( 0.168)\tLoss 1.4614e+00 (1.5116e+00)\tAcc@1  58.59 ( 57.43)\tAcc@5  88.28 ( 86.26)\n",
            "Epoch: [15][300/391]\tTime  0.166 ( 0.168)\tLoss 1.4198e+00 (1.5147e+00)\tAcc@1  60.94 ( 57.36)\tAcc@5  89.84 ( 86.17)\n",
            "Epoch: [15][330/391]\tTime  0.166 ( 0.168)\tLoss 1.7485e+00 (1.5183e+00)\tAcc@1  53.91 ( 57.25)\tAcc@5  85.94 ( 86.10)\n",
            "Epoch: [15][360/391]\tTime  0.167 ( 0.168)\tLoss 1.5801e+00 (1.5189e+00)\tAcc@1  58.59 ( 57.25)\tAcc@5  84.38 ( 86.09)\n",
            "Epoch: [15][390/391]\tTime  0.150 ( 0.168)\tLoss 1.4985e+00 (1.5200e+00)\tAcc@1  57.50 ( 57.25)\tAcc@5  86.25 ( 86.02)\n",
            "==> Train Accuracy: Acc@1 57.248 || Acc@5 86.016\n",
            "==> Test Accuracy:  Acc@1 42.020 || Acc@5 73.750\n",
            "==> 69.79 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 16, lr: 0.1 -----\n",
            "Epoch: [16][  0/391]\tTime  0.291 ( 0.291)\tLoss 1.5993e+00 (1.5993e+00)\tAcc@1  46.88 ( 46.88)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [16][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.3935e+00 (1.4402e+00)\tAcc@1  60.16 ( 58.54)\tAcc@5  89.06 ( 87.35)\n",
            "Epoch: [16][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.5189e+00 (1.4344e+00)\tAcc@1  58.59 ( 58.91)\tAcc@5  87.50 ( 87.35)\n",
            "Epoch: [16][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.4534e+00 (1.4433e+00)\tAcc@1  60.16 ( 58.81)\tAcc@5  84.38 ( 87.21)\n",
            "Epoch: [16][120/391]\tTime  0.168 ( 0.169)\tLoss 1.4045e+00 (1.4473e+00)\tAcc@1  57.03 ( 59.05)\tAcc@5  89.84 ( 87.22)\n",
            "Epoch: [16][150/391]\tTime  0.168 ( 0.169)\tLoss 1.5320e+00 (1.4562e+00)\tAcc@1  58.59 ( 58.86)\tAcc@5  83.59 ( 87.15)\n",
            "Epoch: [16][180/391]\tTime  0.169 ( 0.169)\tLoss 1.3159e+00 (1.4570e+00)\tAcc@1  62.50 ( 58.96)\tAcc@5  92.97 ( 87.18)\n",
            "Epoch: [16][210/391]\tTime  0.167 ( 0.169)\tLoss 1.3877e+00 (1.4548e+00)\tAcc@1  64.84 ( 58.99)\tAcc@5  89.06 ( 87.16)\n",
            "Epoch: [16][240/391]\tTime  0.168 ( 0.168)\tLoss 1.4847e+00 (1.4585e+00)\tAcc@1  62.50 ( 58.90)\tAcc@5  82.03 ( 87.10)\n",
            "Epoch: [16][270/391]\tTime  0.169 ( 0.168)\tLoss 1.7218e+00 (1.4625e+00)\tAcc@1  51.56 ( 58.82)\tAcc@5  82.03 ( 86.97)\n",
            "Epoch: [16][300/391]\tTime  0.167 ( 0.168)\tLoss 1.5008e+00 (1.4683e+00)\tAcc@1  56.25 ( 58.61)\tAcc@5  85.94 ( 86.90)\n",
            "Epoch: [16][330/391]\tTime  0.168 ( 0.168)\tLoss 1.5566e+00 (1.4761e+00)\tAcc@1  52.34 ( 58.38)\tAcc@5  89.06 ( 86.80)\n",
            "Epoch: [16][360/391]\tTime  0.165 ( 0.168)\tLoss 1.4374e+00 (1.4798e+00)\tAcc@1  57.03 ( 58.23)\tAcc@5  85.94 ( 86.78)\n",
            "Epoch: [16][390/391]\tTime  0.151 ( 0.168)\tLoss 1.4470e+00 (1.4832e+00)\tAcc@1  63.75 ( 58.10)\tAcc@5  86.25 ( 86.71)\n",
            "==> Train Accuracy: Acc@1 58.098 || Acc@5 86.712\n",
            "==> Test Accuracy:  Acc@1 49.760 || Acc@5 79.430\n",
            "==> 69.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 17, lr: 0.1 -----\n",
            "Epoch: [17][  0/391]\tTime  0.270 ( 0.270)\tLoss 1.2784e+00 (1.2784e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [17][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.4202e+00 (1.3939e+00)\tAcc@1  57.81 ( 60.13)\tAcc@5  88.28 ( 88.68)\n",
            "Epoch: [17][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.5940e+00 (1.4107e+00)\tAcc@1  54.69 ( 59.40)\tAcc@5  87.50 ( 88.09)\n",
            "Epoch: [17][ 90/391]\tTime  0.168 ( 0.168)\tLoss 1.4283e+00 (1.4191e+00)\tAcc@1  60.94 ( 59.20)\tAcc@5  82.81 ( 87.69)\n",
            "Epoch: [17][120/391]\tTime  0.168 ( 0.168)\tLoss 1.3060e+00 (1.4219e+00)\tAcc@1  61.72 ( 59.38)\tAcc@5  89.06 ( 87.51)\n",
            "Epoch: [17][150/391]\tTime  0.167 ( 0.168)\tLoss 1.4471e+00 (1.4186e+00)\tAcc@1  61.72 ( 59.51)\tAcc@5  88.28 ( 87.73)\n",
            "Epoch: [17][180/391]\tTime  0.170 ( 0.168)\tLoss 1.6524e+00 (1.4354e+00)\tAcc@1  52.34 ( 59.12)\tAcc@5  83.59 ( 87.56)\n",
            "Epoch: [17][210/391]\tTime  0.167 ( 0.168)\tLoss 1.3480e+00 (1.4335e+00)\tAcc@1  55.47 ( 59.24)\tAcc@5  92.19 ( 87.69)\n",
            "Epoch: [17][240/391]\tTime  0.169 ( 0.168)\tLoss 1.6565e+00 (1.4365e+00)\tAcc@1  56.25 ( 59.18)\tAcc@5  84.38 ( 87.56)\n",
            "Epoch: [17][270/391]\tTime  0.172 ( 0.168)\tLoss 1.2826e+00 (1.4325e+00)\tAcc@1  64.84 ( 59.40)\tAcc@5  87.50 ( 87.58)\n",
            "Epoch: [17][300/391]\tTime  0.169 ( 0.168)\tLoss 1.5416e+00 (1.4348e+00)\tAcc@1  55.47 ( 59.39)\tAcc@5  85.94 ( 87.52)\n",
            "Epoch: [17][330/391]\tTime  0.167 ( 0.168)\tLoss 1.7442e+00 (1.4394e+00)\tAcc@1  53.91 ( 59.33)\tAcc@5  77.34 ( 87.41)\n",
            "Epoch: [17][360/391]\tTime  0.168 ( 0.168)\tLoss 1.4652e+00 (1.4420e+00)\tAcc@1  59.38 ( 59.24)\tAcc@5  85.16 ( 87.37)\n",
            "Epoch: [17][390/391]\tTime  0.151 ( 0.168)\tLoss 1.3862e+00 (1.4460e+00)\tAcc@1  65.00 ( 59.15)\tAcc@5  92.50 ( 87.36)\n",
            "==> Train Accuracy: Acc@1 59.146 || Acc@5 87.358\n",
            "==> Test Accuracy:  Acc@1 52.740 || Acc@5 82.250\n",
            "==> 69.83 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 18, lr: 0.1 -----\n",
            "Epoch: [18][  0/391]\tTime  0.264 ( 0.264)\tLoss 1.2835e+00 (1.2835e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [18][ 30/391]\tTime  0.166 ( 0.170)\tLoss 1.3029e+00 (1.3370e+00)\tAcc@1  67.19 ( 62.25)\tAcc@5  92.19 ( 89.34)\n",
            "Epoch: [18][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.5158e+00 (1.3218e+00)\tAcc@1  56.25 ( 62.32)\tAcc@5  84.38 ( 89.29)\n",
            "Epoch: [18][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.3318e+00 (1.3323e+00)\tAcc@1  60.16 ( 62.03)\tAcc@5  88.28 ( 89.12)\n",
            "Epoch: [18][120/391]\tTime  0.167 ( 0.168)\tLoss 1.2999e+00 (1.3511e+00)\tAcc@1  65.62 ( 61.53)\tAcc@5  86.72 ( 88.96)\n",
            "Epoch: [18][150/391]\tTime  0.167 ( 0.168)\tLoss 1.3662e+00 (1.3646e+00)\tAcc@1  62.50 ( 61.24)\tAcc@5  89.84 ( 88.73)\n",
            "Epoch: [18][180/391]\tTime  0.168 ( 0.168)\tLoss 1.4899e+00 (1.3715e+00)\tAcc@1  62.50 ( 61.09)\tAcc@5  86.72 ( 88.54)\n",
            "Epoch: [18][210/391]\tTime  0.168 ( 0.168)\tLoss 1.6530e+00 (1.3802e+00)\tAcc@1  55.47 ( 60.90)\tAcc@5  85.16 ( 88.38)\n",
            "Epoch: [18][240/391]\tTime  0.173 ( 0.168)\tLoss 1.5931e+00 (1.3889e+00)\tAcc@1  52.34 ( 60.58)\tAcc@5  86.72 ( 88.34)\n",
            "Epoch: [18][270/391]\tTime  0.168 ( 0.168)\tLoss 1.1748e+00 (1.3955e+00)\tAcc@1  64.06 ( 60.40)\tAcc@5  90.62 ( 88.14)\n",
            "Epoch: [18][300/391]\tTime  0.170 ( 0.168)\tLoss 1.4694e+00 (1.4000e+00)\tAcc@1  61.72 ( 60.40)\tAcc@5  86.72 ( 88.01)\n",
            "Epoch: [18][330/391]\tTime  0.170 ( 0.168)\tLoss 1.5976e+00 (1.4048e+00)\tAcc@1  55.47 ( 60.27)\tAcc@5  87.50 ( 87.90)\n",
            "Epoch: [18][360/391]\tTime  0.169 ( 0.168)\tLoss 1.4450e+00 (1.4105e+00)\tAcc@1  61.72 ( 60.21)\tAcc@5  87.50 ( 87.77)\n",
            "Epoch: [18][390/391]\tTime  0.150 ( 0.168)\tLoss 1.6695e+00 (1.4111e+00)\tAcc@1  57.50 ( 60.11)\tAcc@5  82.50 ( 87.76)\n",
            "==> Train Accuracy: Acc@1 60.108 || Acc@5 87.756\n",
            "==> Test Accuracy:  Acc@1 52.380 || Acc@5 82.240\n",
            "==> 69.83 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 19, lr: 0.1 -----\n",
            "Epoch: [19][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.3398e+00 (1.3398e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [19][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.2450e+00 (1.2682e+00)\tAcc@1  67.19 ( 63.21)\tAcc@5  89.06 ( 90.10)\n",
            "Epoch: [19][ 60/391]\tTime  0.167 ( 0.170)\tLoss 1.2945e+00 (1.3048e+00)\tAcc@1  62.50 ( 62.26)\tAcc@5  90.62 ( 89.49)\n",
            "Epoch: [19][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.2170e+00 (1.3228e+00)\tAcc@1  63.28 ( 61.88)\tAcc@5  92.19 ( 89.10)\n",
            "Epoch: [19][120/391]\tTime  0.169 ( 0.169)\tLoss 1.3831e+00 (1.3324e+00)\tAcc@1  62.50 ( 61.78)\tAcc@5  86.72 ( 88.87)\n",
            "Epoch: [19][150/391]\tTime  0.167 ( 0.168)\tLoss 1.2506e+00 (1.3353e+00)\tAcc@1  61.72 ( 61.77)\tAcc@5  91.41 ( 88.87)\n",
            "Epoch: [19][180/391]\tTime  0.167 ( 0.168)\tLoss 1.6593e+00 (1.3460e+00)\tAcc@1  54.69 ( 61.53)\tAcc@5  82.81 ( 88.68)\n",
            "Epoch: [19][210/391]\tTime  0.166 ( 0.168)\tLoss 1.4205e+00 (1.3557e+00)\tAcc@1  60.16 ( 61.20)\tAcc@5  88.28 ( 88.55)\n",
            "Epoch: [19][240/391]\tTime  0.166 ( 0.168)\tLoss 1.5650e+00 (1.3622e+00)\tAcc@1  57.03 ( 61.08)\tAcc@5  86.72 ( 88.42)\n",
            "Epoch: [19][270/391]\tTime  0.168 ( 0.168)\tLoss 1.4827e+00 (1.3681e+00)\tAcc@1  63.28 ( 60.99)\tAcc@5  82.03 ( 88.36)\n",
            "Epoch: [19][300/391]\tTime  0.167 ( 0.168)\tLoss 1.4991e+00 (1.3707e+00)\tAcc@1  60.16 ( 60.91)\tAcc@5  83.59 ( 88.31)\n",
            "Epoch: [19][330/391]\tTime  0.168 ( 0.168)\tLoss 1.5329e+00 (1.3748e+00)\tAcc@1  60.94 ( 60.82)\tAcc@5  85.16 ( 88.27)\n",
            "Epoch: [19][360/391]\tTime  0.168 ( 0.168)\tLoss 1.2829e+00 (1.3794e+00)\tAcc@1  60.94 ( 60.67)\tAcc@5  91.41 ( 88.19)\n",
            "Epoch: [19][390/391]\tTime  0.150 ( 0.168)\tLoss 1.5009e+00 (1.3832e+00)\tAcc@1  62.50 ( 60.67)\tAcc@5  85.00 ( 88.11)\n",
            "==> Train Accuracy: Acc@1 60.674 || Acc@5 88.114\n",
            "==> Test Accuracy:  Acc@1 47.990 || Acc@5 77.600\n",
            "==> 69.73 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 20, lr: 0.1 -----\n",
            "Epoch: [20][  0/391]\tTime  0.284 ( 0.284)\tLoss 1.2800e+00 (1.2800e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [20][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.3844e+00 (1.2865e+00)\tAcc@1  58.59 ( 62.85)\tAcc@5  85.94 ( 89.44)\n",
            "Epoch: [20][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.2286e+00 (1.3006e+00)\tAcc@1  62.50 ( 62.67)\tAcc@5  90.62 ( 89.33)\n",
            "Epoch: [20][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.3164e+00 (1.3122e+00)\tAcc@1  60.16 ( 62.72)\tAcc@5  89.06 ( 88.86)\n",
            "Epoch: [20][120/391]\tTime  0.167 ( 0.168)\tLoss 1.3360e+00 (1.3177e+00)\tAcc@1  63.28 ( 62.36)\tAcc@5  85.94 ( 89.03)\n",
            "Epoch: [20][150/391]\tTime  0.168 ( 0.168)\tLoss 1.2558e+00 (1.3190e+00)\tAcc@1  66.41 ( 62.42)\tAcc@5  90.62 ( 89.16)\n",
            "Epoch: [20][180/391]\tTime  0.166 ( 0.168)\tLoss 1.3109e+00 (1.3236e+00)\tAcc@1  64.06 ( 62.17)\tAcc@5  87.50 ( 89.06)\n",
            "Epoch: [20][210/391]\tTime  0.168 ( 0.168)\tLoss 1.5901e+00 (1.3312e+00)\tAcc@1  57.81 ( 62.00)\tAcc@5  84.38 ( 88.90)\n",
            "Epoch: [20][240/391]\tTime  0.167 ( 0.168)\tLoss 1.3166e+00 (1.3390e+00)\tAcc@1  61.72 ( 61.83)\tAcc@5  90.62 ( 88.83)\n",
            "Epoch: [20][270/391]\tTime  0.165 ( 0.168)\tLoss 1.2343e+00 (1.3390e+00)\tAcc@1  64.84 ( 61.83)\tAcc@5  92.97 ( 88.77)\n",
            "Epoch: [20][300/391]\tTime  0.167 ( 0.168)\tLoss 1.1847e+00 (1.3446e+00)\tAcc@1  68.75 ( 61.68)\tAcc@5  89.06 ( 88.70)\n",
            "Epoch: [20][330/391]\tTime  0.167 ( 0.168)\tLoss 1.1208e+00 (1.3503e+00)\tAcc@1  67.97 ( 61.59)\tAcc@5  89.84 ( 88.59)\n",
            "Epoch: [20][360/391]\tTime  0.167 ( 0.168)\tLoss 1.4533e+00 (1.3550e+00)\tAcc@1  58.59 ( 61.46)\tAcc@5  86.72 ( 88.54)\n",
            "Epoch: [20][390/391]\tTime  0.151 ( 0.168)\tLoss 1.5369e+00 (1.3579e+00)\tAcc@1  58.75 ( 61.45)\tAcc@5  85.00 ( 88.49)\n",
            "==> Train Accuracy: Acc@1 61.452 || Acc@5 88.488\n",
            "==> Test Accuracy:  Acc@1 51.290 || Acc@5 80.840\n",
            "==> 69.75 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 21, lr: 0.1 -----\n",
            "Epoch: [21][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.4625e+00 (1.4625e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [21][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.3278e+00 (1.2897e+00)\tAcc@1  65.62 ( 62.63)\tAcc@5  91.41 ( 90.12)\n",
            "Epoch: [21][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.4742e+00 (1.2606e+00)\tAcc@1  56.25 ( 63.49)\tAcc@5  85.94 ( 90.32)\n",
            "Epoch: [21][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.5926e+00 (1.2687e+00)\tAcc@1  50.00 ( 63.36)\tAcc@5  82.81 ( 90.11)\n",
            "Epoch: [21][120/391]\tTime  0.169 ( 0.169)\tLoss 1.3890e+00 (1.2782e+00)\tAcc@1  58.59 ( 63.20)\tAcc@5  89.84 ( 89.90)\n",
            "Epoch: [21][150/391]\tTime  0.163 ( 0.169)\tLoss 1.1234e+00 (1.2860e+00)\tAcc@1  66.41 ( 62.97)\tAcc@5  90.62 ( 89.86)\n",
            "Epoch: [21][180/391]\tTime  0.167 ( 0.169)\tLoss 1.3290e+00 (1.2943e+00)\tAcc@1  60.94 ( 62.89)\tAcc@5  87.50 ( 89.79)\n",
            "Epoch: [21][210/391]\tTime  0.167 ( 0.169)\tLoss 1.2802e+00 (1.3115e+00)\tAcc@1  62.50 ( 62.54)\tAcc@5  91.41 ( 89.50)\n",
            "Epoch: [21][240/391]\tTime  0.168 ( 0.168)\tLoss 1.6394e+00 (1.3143e+00)\tAcc@1  50.78 ( 62.52)\tAcc@5  82.81 ( 89.41)\n",
            "Epoch: [21][270/391]\tTime  0.168 ( 0.168)\tLoss 1.2123e+00 (1.3170e+00)\tAcc@1  71.09 ( 62.53)\tAcc@5  91.41 ( 89.30)\n",
            "Epoch: [21][300/391]\tTime  0.167 ( 0.168)\tLoss 1.3472e+00 (1.3181e+00)\tAcc@1  61.72 ( 62.50)\tAcc@5  89.84 ( 89.25)\n",
            "Epoch: [21][330/391]\tTime  0.167 ( 0.168)\tLoss 1.4140e+00 (1.3240e+00)\tAcc@1  59.38 ( 62.35)\tAcc@5  89.06 ( 89.22)\n",
            "Epoch: [21][360/391]\tTime  0.167 ( 0.168)\tLoss 1.6314e+00 (1.3311e+00)\tAcc@1  53.91 ( 62.10)\tAcc@5  85.16 ( 89.13)\n",
            "Epoch: [21][390/391]\tTime  0.150 ( 0.168)\tLoss 1.6694e+00 (1.3344e+00)\tAcc@1  51.25 ( 61.95)\tAcc@5  86.25 ( 89.07)\n",
            "==> Train Accuracy: Acc@1 61.946 || Acc@5 89.072\n",
            "==> Test Accuracy:  Acc@1 53.240 || Acc@5 81.340\n",
            "==> 69.88 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 22, lr: 0.1 -----\n",
            "Epoch: [22][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.1962e+00 (1.1962e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [22][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.2364e+00 (1.2323e+00)\tAcc@1  63.28 ( 63.84)\tAcc@5  96.88 ( 91.03)\n",
            "Epoch: [22][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.3595e+00 (1.2544e+00)\tAcc@1  65.62 ( 63.73)\tAcc@5  86.72 ( 90.27)\n",
            "Epoch: [22][ 90/391]\tTime  0.168 ( 0.168)\tLoss 1.2743e+00 (1.2713e+00)\tAcc@1  62.50 ( 63.04)\tAcc@5  92.19 ( 90.15)\n",
            "Epoch: [22][120/391]\tTime  0.168 ( 0.168)\tLoss 1.0656e+00 (1.2776e+00)\tAcc@1  66.41 ( 62.93)\tAcc@5  93.75 ( 90.01)\n",
            "Epoch: [22][150/391]\tTime  0.168 ( 0.168)\tLoss 1.4289e+00 (1.2825e+00)\tAcc@1  56.25 ( 62.85)\tAcc@5  85.94 ( 89.89)\n",
            "Epoch: [22][180/391]\tTime  0.168 ( 0.168)\tLoss 1.4217e+00 (1.2890e+00)\tAcc@1  55.47 ( 62.73)\tAcc@5  85.94 ( 89.77)\n",
            "Epoch: [22][210/391]\tTime  0.167 ( 0.168)\tLoss 1.2446e+00 (1.2909e+00)\tAcc@1  64.06 ( 62.74)\tAcc@5  86.72 ( 89.76)\n",
            "Epoch: [22][240/391]\tTime  0.168 ( 0.168)\tLoss 1.3354e+00 (1.2994e+00)\tAcc@1  57.81 ( 62.51)\tAcc@5  89.84 ( 89.60)\n",
            "Epoch: [22][270/391]\tTime  0.170 ( 0.168)\tLoss 1.5816e+00 (1.3083e+00)\tAcc@1  53.91 ( 62.36)\tAcc@5  87.50 ( 89.45)\n",
            "Epoch: [22][300/391]\tTime  0.168 ( 0.168)\tLoss 1.3647e+00 (1.3132e+00)\tAcc@1  61.72 ( 62.26)\tAcc@5  86.72 ( 89.39)\n",
            "Epoch: [22][330/391]\tTime  0.169 ( 0.168)\tLoss 1.3483e+00 (1.3160e+00)\tAcc@1  60.94 ( 62.27)\tAcc@5  91.41 ( 89.35)\n",
            "Epoch: [22][360/391]\tTime  0.167 ( 0.168)\tLoss 1.1844e+00 (1.3195e+00)\tAcc@1  71.09 ( 62.23)\tAcc@5  87.50 ( 89.23)\n",
            "Epoch: [22][390/391]\tTime  0.151 ( 0.168)\tLoss 1.2877e+00 (1.3193e+00)\tAcc@1  62.50 ( 62.20)\tAcc@5  87.50 ( 89.28)\n",
            "==> Train Accuracy: Acc@1 62.200 || Acc@5 89.276\n",
            "==> Test Accuracy:  Acc@1 51.030 || Acc@5 81.030\n",
            "==> 69.81 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 23, lr: 0.1 -----\n",
            "Epoch: [23][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.2899e+00 (1.2899e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [23][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.1214e+00 (1.1889e+00)\tAcc@1  64.06 ( 65.27)\tAcc@5  89.84 ( 91.15)\n",
            "Epoch: [23][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.0760e+00 (1.2284e+00)\tAcc@1  69.53 ( 64.57)\tAcc@5  94.53 ( 90.56)\n",
            "Epoch: [23][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.1128e+00 (1.2356e+00)\tAcc@1  68.75 ( 64.25)\tAcc@5  87.50 ( 90.67)\n",
            "Epoch: [23][120/391]\tTime  0.170 ( 0.168)\tLoss 1.3229e+00 (1.2458e+00)\tAcc@1  59.38 ( 63.88)\tAcc@5  91.41 ( 90.46)\n",
            "Epoch: [23][150/391]\tTime  0.169 ( 0.168)\tLoss 1.0054e+00 (1.2483e+00)\tAcc@1  74.22 ( 63.80)\tAcc@5  92.97 ( 90.36)\n",
            "Epoch: [23][180/391]\tTime  0.168 ( 0.168)\tLoss 1.1912e+00 (1.2583e+00)\tAcc@1  65.62 ( 63.69)\tAcc@5  94.53 ( 90.20)\n",
            "Epoch: [23][210/391]\tTime  0.169 ( 0.168)\tLoss 1.3728e+00 (1.2671e+00)\tAcc@1  63.28 ( 63.46)\tAcc@5  88.28 ( 90.03)\n",
            "Epoch: [23][240/391]\tTime  0.167 ( 0.168)\tLoss 1.1323e+00 (1.2720e+00)\tAcc@1  63.28 ( 63.31)\tAcc@5  94.53 ( 90.02)\n",
            "Epoch: [23][270/391]\tTime  0.169 ( 0.168)\tLoss 1.4118e+00 (1.2804e+00)\tAcc@1  60.94 ( 63.14)\tAcc@5  86.72 ( 89.87)\n",
            "Epoch: [23][300/391]\tTime  0.167 ( 0.168)\tLoss 1.3571e+00 (1.2867e+00)\tAcc@1  62.50 ( 62.94)\tAcc@5  90.62 ( 89.77)\n",
            "Epoch: [23][330/391]\tTime  0.168 ( 0.168)\tLoss 1.4017e+00 (1.2891e+00)\tAcc@1  61.72 ( 62.93)\tAcc@5  85.94 ( 89.71)\n",
            "Epoch: [23][360/391]\tTime  0.169 ( 0.168)\tLoss 1.5611e+00 (1.2955e+00)\tAcc@1  51.56 ( 62.77)\tAcc@5  82.81 ( 89.65)\n",
            "Epoch: [23][390/391]\tTime  0.150 ( 0.168)\tLoss 1.2439e+00 (1.2985e+00)\tAcc@1  67.50 ( 62.76)\tAcc@5  88.75 ( 89.60)\n",
            "==> Train Accuracy: Acc@1 62.760 || Acc@5 89.596\n",
            "==> Test Accuracy:  Acc@1 51.350 || Acc@5 79.070\n",
            "==> 69.89 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 24, lr: 0.1 -----\n",
            "Epoch: [24][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.2323e+00 (1.2323e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [24][ 30/391]\tTime  0.169 ( 0.172)\tLoss 1.2817e+00 (1.1919e+00)\tAcc@1  60.94 ( 65.27)\tAcc@5  87.50 ( 90.80)\n",
            "Epoch: [24][ 60/391]\tTime  0.168 ( 0.170)\tLoss 1.2029e+00 (1.1665e+00)\tAcc@1  67.19 ( 66.68)\tAcc@5  87.50 ( 91.10)\n",
            "Epoch: [24][ 90/391]\tTime  0.170 ( 0.169)\tLoss 1.1928e+00 (1.2059e+00)\tAcc@1  70.31 ( 65.72)\tAcc@5  86.72 ( 90.32)\n",
            "Epoch: [24][120/391]\tTime  0.168 ( 0.169)\tLoss 1.0199e+00 (1.2153e+00)\tAcc@1  71.09 ( 65.46)\tAcc@5  93.75 ( 90.22)\n",
            "Epoch: [24][150/391]\tTime  0.167 ( 0.168)\tLoss 1.3093e+00 (1.2209e+00)\tAcc@1  60.94 ( 65.02)\tAcc@5  89.84 ( 90.24)\n",
            "Epoch: [24][180/391]\tTime  0.172 ( 0.168)\tLoss 1.5525e+00 (1.2384e+00)\tAcc@1  53.91 ( 64.64)\tAcc@5  89.84 ( 90.11)\n",
            "Epoch: [24][210/391]\tTime  0.168 ( 0.168)\tLoss 1.3929e+00 (1.2460e+00)\tAcc@1  58.59 ( 64.32)\tAcc@5  91.41 ( 90.06)\n",
            "Epoch: [24][240/391]\tTime  0.168 ( 0.168)\tLoss 1.3487e+00 (1.2562e+00)\tAcc@1  59.38 ( 64.08)\tAcc@5  87.50 ( 89.92)\n",
            "Epoch: [24][270/391]\tTime  0.166 ( 0.168)\tLoss 1.2780e+00 (1.2556e+00)\tAcc@1  59.38 ( 64.13)\tAcc@5  91.41 ( 89.90)\n",
            "Epoch: [24][300/391]\tTime  0.168 ( 0.168)\tLoss 1.1377e+00 (1.2657e+00)\tAcc@1  64.84 ( 63.90)\tAcc@5  91.41 ( 89.76)\n",
            "Epoch: [24][330/391]\tTime  0.167 ( 0.168)\tLoss 1.1481e+00 (1.2665e+00)\tAcc@1  64.06 ( 63.83)\tAcc@5  92.97 ( 89.76)\n",
            "Epoch: [24][360/391]\tTime  0.167 ( 0.168)\tLoss 1.5309e+00 (1.2700e+00)\tAcc@1  55.47 ( 63.69)\tAcc@5  84.38 ( 89.76)\n",
            "Epoch: [24][390/391]\tTime  0.151 ( 0.168)\tLoss 1.2477e+00 (1.2752e+00)\tAcc@1  66.25 ( 63.53)\tAcc@5  88.75 ( 89.69)\n",
            "==> Train Accuracy: Acc@1 63.528 || Acc@5 89.694\n",
            "==> Test Accuracy:  Acc@1 49.840 || Acc@5 79.500\n",
            "==> 69.74 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 25, lr: 0.1 -----\n",
            "Epoch: [25][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.0781e+00 (1.0781e+00)\tAcc@1  69.53 ( 69.53)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [25][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.1733e+00 (1.2307e+00)\tAcc@1  70.31 ( 64.44)\tAcc@5  92.19 ( 90.57)\n",
            "Epoch: [25][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.1945e+00 (1.1984e+00)\tAcc@1  65.62 ( 65.20)\tAcc@5  90.62 ( 91.05)\n",
            "Epoch: [25][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.1239e+00 (1.1983e+00)\tAcc@1  67.19 ( 65.12)\tAcc@5  92.19 ( 91.02)\n",
            "Epoch: [25][120/391]\tTime  0.168 ( 0.168)\tLoss 1.2958e+00 (1.2042e+00)\tAcc@1  63.28 ( 64.82)\tAcc@5  88.28 ( 90.95)\n",
            "Epoch: [25][150/391]\tTime  0.167 ( 0.168)\tLoss 1.3321e+00 (1.2167e+00)\tAcc@1  67.97 ( 64.64)\tAcc@5  86.72 ( 90.82)\n",
            "Epoch: [25][180/391]\tTime  0.169 ( 0.168)\tLoss 1.0714e+00 (1.2255e+00)\tAcc@1  71.09 ( 64.45)\tAcc@5  92.19 ( 90.70)\n",
            "Epoch: [25][210/391]\tTime  0.167 ( 0.168)\tLoss 1.1829e+00 (1.2325e+00)\tAcc@1  66.41 ( 64.41)\tAcc@5  90.62 ( 90.60)\n",
            "Epoch: [25][240/391]\tTime  0.165 ( 0.168)\tLoss 1.2221e+00 (1.2412e+00)\tAcc@1  71.09 ( 64.21)\tAcc@5  91.41 ( 90.46)\n",
            "Epoch: [25][270/391]\tTime  0.167 ( 0.168)\tLoss 1.3602e+00 (1.2453e+00)\tAcc@1  54.69 ( 64.00)\tAcc@5  91.41 ( 90.39)\n",
            "Epoch: [25][300/391]\tTime  0.167 ( 0.168)\tLoss 1.2564e+00 (1.2551e+00)\tAcc@1  61.72 ( 63.77)\tAcc@5  91.41 ( 90.18)\n",
            "Epoch: [25][330/391]\tTime  0.168 ( 0.168)\tLoss 1.0007e+00 (1.2629e+00)\tAcc@1  76.56 ( 63.60)\tAcc@5  93.75 ( 90.04)\n",
            "Epoch: [25][360/391]\tTime  0.166 ( 0.168)\tLoss 1.1532e+00 (1.2639e+00)\tAcc@1  67.19 ( 63.62)\tAcc@5  92.97 ( 90.03)\n",
            "Epoch: [25][390/391]\tTime  0.151 ( 0.168)\tLoss 1.1819e+00 (1.2670e+00)\tAcc@1  67.50 ( 63.57)\tAcc@5  91.25 ( 89.92)\n",
            "==> Train Accuracy: Acc@1 63.570 || Acc@5 89.920\n",
            "==> Test Accuracy:  Acc@1 54.270 || Acc@5 82.420\n",
            "==> 69.77 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 26, lr: 0.1 -----\n",
            "Epoch: [26][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.0359e+00 (1.0359e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [26][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.1043e+00 (1.1439e+00)\tAcc@1  67.97 ( 66.56)\tAcc@5  90.62 ( 91.73)\n",
            "Epoch: [26][ 60/391]\tTime  0.165 ( 0.170)\tLoss 1.1347e+00 (1.1493e+00)\tAcc@1  67.97 ( 66.93)\tAcc@5  91.41 ( 91.61)\n",
            "Epoch: [26][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.1587e+00 (1.1682e+00)\tAcc@1  65.62 ( 66.23)\tAcc@5  92.97 ( 91.43)\n",
            "Epoch: [26][120/391]\tTime  0.168 ( 0.169)\tLoss 1.3017e+00 (1.1830e+00)\tAcc@1  67.19 ( 65.71)\tAcc@5  90.62 ( 91.22)\n",
            "Epoch: [26][150/391]\tTime  0.169 ( 0.169)\tLoss 1.0887e+00 (1.1821e+00)\tAcc@1  66.41 ( 65.75)\tAcc@5  92.19 ( 91.19)\n",
            "Epoch: [26][180/391]\tTime  0.168 ( 0.168)\tLoss 1.1836e+00 (1.1996e+00)\tAcc@1  62.50 ( 65.35)\tAcc@5  88.28 ( 90.85)\n",
            "Epoch: [26][210/391]\tTime  0.168 ( 0.168)\tLoss 1.2410e+00 (1.2017e+00)\tAcc@1  64.84 ( 65.27)\tAcc@5  90.62 ( 90.84)\n",
            "Epoch: [26][240/391]\tTime  0.167 ( 0.168)\tLoss 1.2397e+00 (1.2129e+00)\tAcc@1  61.72 ( 64.98)\tAcc@5  91.41 ( 90.71)\n",
            "Epoch: [26][270/391]\tTime  0.169 ( 0.168)\tLoss 1.1894e+00 (1.2211e+00)\tAcc@1  66.41 ( 64.73)\tAcc@5  91.41 ( 90.59)\n",
            "Epoch: [26][300/391]\tTime  0.166 ( 0.168)\tLoss 1.7333e+00 (1.2270e+00)\tAcc@1  51.56 ( 64.56)\tAcc@5  82.81 ( 90.49)\n",
            "Epoch: [26][330/391]\tTime  0.167 ( 0.168)\tLoss 1.1741e+00 (1.2311e+00)\tAcc@1  67.97 ( 64.51)\tAcc@5  89.84 ( 90.44)\n",
            "Epoch: [26][360/391]\tTime  0.168 ( 0.168)\tLoss 1.0517e+00 (1.2368e+00)\tAcc@1  67.97 ( 64.32)\tAcc@5  95.31 ( 90.35)\n",
            "Epoch: [26][390/391]\tTime  0.150 ( 0.168)\tLoss 1.3337e+00 (1.2400e+00)\tAcc@1  58.75 ( 64.24)\tAcc@5  88.75 ( 90.32)\n",
            "==> Train Accuracy: Acc@1 64.242 || Acc@5 90.320\n",
            "==> Test Accuracy:  Acc@1 53.240 || Acc@5 82.380\n",
            "==> 69.82 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 27, lr: 0.1 -----\n",
            "Epoch: [27][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.1277e+00 (1.1277e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [27][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.1749e+00 (1.1920e+00)\tAcc@1  68.75 ( 65.37)\tAcc@5  92.97 ( 91.41)\n",
            "Epoch: [27][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.0672e+00 (1.1897e+00)\tAcc@1  67.97 ( 65.50)\tAcc@5  93.75 ( 91.29)\n",
            "Epoch: [27][ 90/391]\tTime  0.166 ( 0.169)\tLoss 1.2036e+00 (1.1976e+00)\tAcc@1  71.09 ( 65.50)\tAcc@5  92.97 ( 91.04)\n",
            "Epoch: [27][120/391]\tTime  0.167 ( 0.169)\tLoss 1.0529e+00 (1.1987e+00)\tAcc@1  71.09 ( 65.55)\tAcc@5  92.97 ( 91.04)\n",
            "Epoch: [27][150/391]\tTime  0.168 ( 0.168)\tLoss 1.3683e+00 (1.2011e+00)\tAcc@1  62.50 ( 65.42)\tAcc@5  87.50 ( 91.04)\n",
            "Epoch: [27][180/391]\tTime  0.169 ( 0.168)\tLoss 1.2452e+00 (1.2047e+00)\tAcc@1  63.28 ( 65.35)\tAcc@5  91.41 ( 90.92)\n",
            "Epoch: [27][210/391]\tTime  0.168 ( 0.168)\tLoss 1.1355e+00 (1.2079e+00)\tAcc@1  65.62 ( 65.14)\tAcc@5  92.19 ( 90.95)\n",
            "Epoch: [27][240/391]\tTime  0.166 ( 0.168)\tLoss 1.2858e+00 (1.2215e+00)\tAcc@1  60.16 ( 64.81)\tAcc@5  89.84 ( 90.75)\n",
            "Epoch: [27][270/391]\tTime  0.169 ( 0.168)\tLoss 1.3949e+00 (1.2313e+00)\tAcc@1  64.06 ( 64.59)\tAcc@5  90.62 ( 90.58)\n",
            "Epoch: [27][300/391]\tTime  0.167 ( 0.168)\tLoss 1.3391e+00 (1.2311e+00)\tAcc@1  65.62 ( 64.62)\tAcc@5  89.06 ( 90.59)\n",
            "Epoch: [27][330/391]\tTime  0.164 ( 0.168)\tLoss 1.3709e+00 (1.2309e+00)\tAcc@1  66.41 ( 64.65)\tAcc@5  89.06 ( 90.54)\n",
            "Epoch: [27][360/391]\tTime  0.168 ( 0.168)\tLoss 1.4103e+00 (1.2376e+00)\tAcc@1  62.50 ( 64.50)\tAcc@5  90.62 ( 90.40)\n",
            "Epoch: [27][390/391]\tTime  0.151 ( 0.168)\tLoss 1.0993e+00 (1.2394e+00)\tAcc@1  70.00 ( 64.47)\tAcc@5  91.25 ( 90.39)\n",
            "==> Train Accuracy: Acc@1 64.470 || Acc@5 90.392\n",
            "==> Test Accuracy:  Acc@1 52.940 || Acc@5 81.880\n",
            "==> 69.83 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 28, lr: 0.1 -----\n",
            "Epoch: [28][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.2214e+00 (1.2214e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [28][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.2309e+00 (1.1496e+00)\tAcc@1  63.28 ( 66.86)\tAcc@5  89.84 ( 91.48)\n",
            "Epoch: [28][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.3031e+00 (1.1568e+00)\tAcc@1  64.06 ( 66.28)\tAcc@5  92.97 ( 91.59)\n",
            "Epoch: [28][ 90/391]\tTime  0.169 ( 0.168)\tLoss 9.7097e-01 (1.1689e+00)\tAcc@1  71.88 ( 66.17)\tAcc@5  93.75 ( 91.28)\n",
            "Epoch: [28][120/391]\tTime  0.168 ( 0.168)\tLoss 1.2011e+00 (1.1789e+00)\tAcc@1  67.19 ( 65.76)\tAcc@5  89.06 ( 91.17)\n",
            "Epoch: [28][150/391]\tTime  0.169 ( 0.168)\tLoss 1.1811e+00 (1.1962e+00)\tAcc@1  69.53 ( 65.41)\tAcc@5  90.62 ( 91.02)\n",
            "Epoch: [28][180/391]\tTime  0.168 ( 0.168)\tLoss 1.3542e+00 (1.2079e+00)\tAcc@1  66.41 ( 65.18)\tAcc@5  85.16 ( 90.70)\n",
            "Epoch: [28][210/391]\tTime  0.171 ( 0.168)\tLoss 1.0093e+00 (1.2141e+00)\tAcc@1  69.53 ( 64.84)\tAcc@5  89.84 ( 90.58)\n",
            "Epoch: [28][240/391]\tTime  0.172 ( 0.168)\tLoss 1.2607e+00 (1.2197e+00)\tAcc@1  64.06 ( 64.76)\tAcc@5  89.06 ( 90.47)\n",
            "Epoch: [28][270/391]\tTime  0.167 ( 0.168)\tLoss 1.0748e+00 (1.2156e+00)\tAcc@1  60.94 ( 64.89)\tAcc@5  92.19 ( 90.47)\n",
            "Epoch: [28][300/391]\tTime  0.168 ( 0.168)\tLoss 9.1505e-01 (1.2137e+00)\tAcc@1  73.44 ( 64.96)\tAcc@5  92.97 ( 90.49)\n",
            "Epoch: [28][330/391]\tTime  0.168 ( 0.168)\tLoss 1.4662e+00 (1.2173e+00)\tAcc@1  59.38 ( 64.82)\tAcc@5  87.50 ( 90.48)\n",
            "Epoch: [28][360/391]\tTime  0.172 ( 0.168)\tLoss 1.3406e+00 (1.2233e+00)\tAcc@1  65.62 ( 64.65)\tAcc@5  87.50 ( 90.39)\n",
            "Epoch: [28][390/391]\tTime  0.151 ( 0.168)\tLoss 1.4027e+00 (1.2292e+00)\tAcc@1  60.00 ( 64.57)\tAcc@5  88.75 ( 90.32)\n",
            "==> Train Accuracy: Acc@1 64.568 || Acc@5 90.320\n",
            "==> Test Accuracy:  Acc@1 48.330 || Acc@5 78.150\n",
            "==> 69.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 29, lr: 0.1 -----\n",
            "Epoch: [29][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.1132e+00 (1.1132e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [29][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.2107e+00 (1.1448e+00)\tAcc@1  63.28 ( 66.48)\tAcc@5  90.62 ( 91.66)\n",
            "Epoch: [29][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.5240e+00 (1.1554e+00)\tAcc@1  56.25 ( 66.24)\tAcc@5  86.72 ( 91.43)\n",
            "Epoch: [29][ 90/391]\tTime  0.171 ( 0.169)\tLoss 1.4767e+00 (1.1729e+00)\tAcc@1  61.72 ( 65.81)\tAcc@5  88.28 ( 91.34)\n",
            "Epoch: [29][120/391]\tTime  0.167 ( 0.168)\tLoss 1.2579e+00 (1.1817e+00)\tAcc@1  67.19 ( 65.58)\tAcc@5  89.84 ( 91.26)\n",
            "Epoch: [29][150/391]\tTime  0.167 ( 0.168)\tLoss 1.1417e+00 (1.1797e+00)\tAcc@1  66.41 ( 65.61)\tAcc@5  92.97 ( 91.27)\n",
            "Epoch: [29][180/391]\tTime  0.167 ( 0.168)\tLoss 1.1327e+00 (1.1753e+00)\tAcc@1  63.28 ( 65.64)\tAcc@5  92.97 ( 91.31)\n",
            "Epoch: [29][210/391]\tTime  0.167 ( 0.168)\tLoss 1.1755e+00 (1.1843e+00)\tAcc@1  63.28 ( 65.43)\tAcc@5  91.41 ( 91.18)\n",
            "Epoch: [29][240/391]\tTime  0.168 ( 0.168)\tLoss 1.2810e+00 (1.1939e+00)\tAcc@1  62.50 ( 65.25)\tAcc@5  89.84 ( 91.00)\n",
            "Epoch: [29][270/391]\tTime  0.169 ( 0.168)\tLoss 1.2830e+00 (1.1956e+00)\tAcc@1  62.50 ( 65.24)\tAcc@5  85.94 ( 90.91)\n",
            "Epoch: [29][300/391]\tTime  0.168 ( 0.168)\tLoss 1.1720e+00 (1.1994e+00)\tAcc@1  65.62 ( 65.17)\tAcc@5  92.19 ( 90.87)\n",
            "Epoch: [29][330/391]\tTime  0.166 ( 0.168)\tLoss 1.1518e+00 (1.2067e+00)\tAcc@1  65.62 ( 65.02)\tAcc@5  89.84 ( 90.79)\n",
            "Epoch: [29][360/391]\tTime  0.168 ( 0.168)\tLoss 1.3580e+00 (1.2130e+00)\tAcc@1  63.28 ( 64.82)\tAcc@5  85.94 ( 90.68)\n",
            "Epoch: [29][390/391]\tTime  0.152 ( 0.168)\tLoss 1.0740e+00 (1.2191e+00)\tAcc@1  67.50 ( 64.60)\tAcc@5  90.00 ( 90.58)\n",
            "==> Train Accuracy: Acc@1 64.598 || Acc@5 90.582\n",
            "==> Test Accuracy:  Acc@1 55.820 || Acc@5 83.780\n",
            "==> 69.73 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 30, lr: 0.1 -----\n",
            "Epoch: [30][  0/391]\tTime  0.294 ( 0.294)\tLoss 1.1904e+00 (1.1904e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [30][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.0837e+00 (1.1138e+00)\tAcc@1  65.62 ( 67.59)\tAcc@5  92.19 ( 91.96)\n",
            "Epoch: [30][ 60/391]\tTime  0.168 ( 0.170)\tLoss 1.2670e+00 (1.1171e+00)\tAcc@1  67.97 ( 67.55)\tAcc@5  88.28 ( 91.94)\n",
            "Epoch: [30][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.1241e+00 (1.1421e+00)\tAcc@1  68.75 ( 66.75)\tAcc@5  91.41 ( 91.43)\n",
            "Epoch: [30][120/391]\tTime  0.172 ( 0.169)\tLoss 9.2289e-01 (1.1512e+00)\tAcc@1  72.66 ( 66.54)\tAcc@5  94.53 ( 91.36)\n",
            "Epoch: [30][150/391]\tTime  0.167 ( 0.168)\tLoss 1.2676e+00 (1.1572e+00)\tAcc@1  60.16 ( 66.30)\tAcc@5  89.06 ( 91.32)\n",
            "Epoch: [30][180/391]\tTime  0.167 ( 0.168)\tLoss 1.2244e+00 (1.1638e+00)\tAcc@1  64.84 ( 66.10)\tAcc@5  91.41 ( 91.13)\n",
            "Epoch: [30][210/391]\tTime  0.167 ( 0.168)\tLoss 1.2771e+00 (1.1765e+00)\tAcc@1  65.62 ( 65.70)\tAcc@5  88.28 ( 91.04)\n",
            "Epoch: [30][240/391]\tTime  0.169 ( 0.168)\tLoss 1.3294e+00 (1.1821e+00)\tAcc@1  63.28 ( 65.56)\tAcc@5  88.28 ( 90.99)\n",
            "Epoch: [30][270/391]\tTime  0.167 ( 0.168)\tLoss 1.2783e+00 (1.1848e+00)\tAcc@1  60.94 ( 65.50)\tAcc@5  86.72 ( 90.96)\n",
            "Epoch: [30][300/391]\tTime  0.167 ( 0.168)\tLoss 9.5114e-01 (1.1895e+00)\tAcc@1  72.66 ( 65.44)\tAcc@5  91.41 ( 90.89)\n",
            "Epoch: [30][330/391]\tTime  0.169 ( 0.168)\tLoss 1.2827e+00 (1.1943e+00)\tAcc@1  67.19 ( 65.33)\tAcc@5  87.50 ( 90.83)\n",
            "Epoch: [30][360/391]\tTime  0.169 ( 0.168)\tLoss 1.2018e+00 (1.1959e+00)\tAcc@1  66.41 ( 65.33)\tAcc@5  89.84 ( 90.80)\n",
            "Epoch: [30][390/391]\tTime  0.151 ( 0.168)\tLoss 1.3115e+00 (1.1980e+00)\tAcc@1  60.00 ( 65.26)\tAcc@5  91.25 ( 90.79)\n",
            "==> Train Accuracy: Acc@1 65.262 || Acc@5 90.794\n",
            "==> Test Accuracy:  Acc@1 52.580 || Acc@5 81.170\n",
            "==> 69.81 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 31, lr: 0.1 -----\n",
            "Epoch: [31][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.2149e+00 (1.2149e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [31][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.1688e+00 (1.1209e+00)\tAcc@1  68.75 ( 66.91)\tAcc@5  89.06 ( 92.26)\n",
            "Epoch: [31][ 60/391]\tTime  0.167 ( 0.170)\tLoss 9.6212e-01 (1.1106e+00)\tAcc@1  71.88 ( 67.30)\tAcc@5  94.53 ( 92.44)\n",
            "Epoch: [31][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.0609e+00 (1.1293e+00)\tAcc@1  70.31 ( 67.14)\tAcc@5  92.97 ( 92.20)\n",
            "Epoch: [31][120/391]\tTime  0.168 ( 0.169)\tLoss 1.0673e+00 (1.1360e+00)\tAcc@1  64.06 ( 66.79)\tAcc@5  95.31 ( 91.99)\n",
            "Epoch: [31][150/391]\tTime  0.163 ( 0.169)\tLoss 9.5206e-01 (1.1426e+00)\tAcc@1  73.44 ( 66.64)\tAcc@5  94.53 ( 91.88)\n",
            "Epoch: [31][180/391]\tTime  0.167 ( 0.168)\tLoss 1.3719e+00 (1.1577e+00)\tAcc@1  60.16 ( 66.33)\tAcc@5  89.06 ( 91.61)\n",
            "Epoch: [31][210/391]\tTime  0.168 ( 0.168)\tLoss 1.1079e+00 (1.1679e+00)\tAcc@1  71.88 ( 66.08)\tAcc@5  89.06 ( 91.36)\n",
            "Epoch: [31][240/391]\tTime  0.168 ( 0.168)\tLoss 1.1943e+00 (1.1691e+00)\tAcc@1  64.84 ( 65.98)\tAcc@5  89.84 ( 91.38)\n",
            "Epoch: [31][270/391]\tTime  0.168 ( 0.168)\tLoss 1.2211e+00 (1.1806e+00)\tAcc@1  60.94 ( 65.62)\tAcc@5  92.97 ( 91.24)\n",
            "Epoch: [31][300/391]\tTime  0.166 ( 0.168)\tLoss 1.3048e+00 (1.1866e+00)\tAcc@1  62.50 ( 65.49)\tAcc@5  89.06 ( 91.16)\n",
            "Epoch: [31][330/391]\tTime  0.167 ( 0.168)\tLoss 1.3000e+00 (1.1870e+00)\tAcc@1  66.41 ( 65.54)\tAcc@5  88.28 ( 91.14)\n",
            "Epoch: [31][360/391]\tTime  0.171 ( 0.168)\tLoss 1.4924e+00 (1.1942e+00)\tAcc@1  57.03 ( 65.36)\tAcc@5  80.47 ( 91.03)\n",
            "Epoch: [31][390/391]\tTime  0.153 ( 0.168)\tLoss 1.1984e+00 (1.2001e+00)\tAcc@1  66.25 ( 65.24)\tAcc@5  95.00 ( 90.93)\n",
            "==> Train Accuracy: Acc@1 65.236 || Acc@5 90.928\n",
            "==> Test Accuracy:  Acc@1 57.200 || Acc@5 84.180\n",
            "==> 69.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 32, lr: 0.1 -----\n",
            "Epoch: [32][  0/391]\tTime  0.272 ( 0.272)\tLoss 8.9852e-01 (8.9852e-01)\tAcc@1  76.56 ( 76.56)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [32][ 30/391]\tTime  0.169 ( 0.171)\tLoss 9.9363e-01 (1.0348e+00)\tAcc@1  70.31 ( 69.51)\tAcc@5  93.75 ( 93.70)\n",
            "Epoch: [32][ 60/391]\tTime  0.169 ( 0.169)\tLoss 1.3278e+00 (1.0590e+00)\tAcc@1  59.38 ( 68.83)\tAcc@5  93.75 ( 93.15)\n",
            "Epoch: [32][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.1376e+00 (1.0690e+00)\tAcc@1  66.41 ( 68.37)\tAcc@5  90.62 ( 93.00)\n",
            "Epoch: [32][120/391]\tTime  0.168 ( 0.169)\tLoss 1.3027e+00 (1.0763e+00)\tAcc@1  57.03 ( 68.22)\tAcc@5  91.41 ( 92.81)\n",
            "Epoch: [32][150/391]\tTime  0.167 ( 0.168)\tLoss 1.2025e+00 (1.1111e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  89.84 ( 92.25)\n",
            "Epoch: [32][180/391]\tTime  0.169 ( 0.168)\tLoss 1.1306e+00 (1.1306e+00)\tAcc@1  68.75 ( 66.82)\tAcc@5  93.75 ( 91.95)\n",
            "Epoch: [32][210/391]\tTime  0.168 ( 0.168)\tLoss 1.1849e+00 (1.1479e+00)\tAcc@1  61.72 ( 66.33)\tAcc@5  89.06 ( 91.73)\n",
            "Epoch: [32][240/391]\tTime  0.167 ( 0.168)\tLoss 1.2174e+00 (1.1570e+00)\tAcc@1  68.75 ( 66.19)\tAcc@5  89.84 ( 91.58)\n",
            "Epoch: [32][270/391]\tTime  0.170 ( 0.168)\tLoss 1.0329e+00 (1.1644e+00)\tAcc@1  68.75 ( 66.02)\tAcc@5  96.09 ( 91.49)\n",
            "Epoch: [32][300/391]\tTime  0.166 ( 0.168)\tLoss 1.2038e+00 (1.1721e+00)\tAcc@1  73.44 ( 65.90)\tAcc@5  86.72 ( 91.33)\n",
            "Epoch: [32][330/391]\tTime  0.168 ( 0.168)\tLoss 1.1175e+00 (1.1728e+00)\tAcc@1  68.75 ( 65.94)\tAcc@5  92.19 ( 91.29)\n",
            "Epoch: [32][360/391]\tTime  0.168 ( 0.168)\tLoss 1.2159e+00 (1.1785e+00)\tAcc@1  62.50 ( 65.78)\tAcc@5  89.06 ( 91.16)\n",
            "Epoch: [32][390/391]\tTime  0.150 ( 0.168)\tLoss 1.3639e+00 (1.1823e+00)\tAcc@1  56.25 ( 65.72)\tAcc@5  88.75 ( 91.08)\n",
            "==> Train Accuracy: Acc@1 65.716 || Acc@5 91.082\n",
            "==> Test Accuracy:  Acc@1 54.830 || Acc@5 82.810\n",
            "==> 69.76 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 33, lr: 0.1 -----\n",
            "Epoch: [33][  0/391]\tTime  0.287 ( 0.287)\tLoss 9.0038e-01 (9.0038e-01)\tAcc@1  66.41 ( 66.41)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [33][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.0682e+00 (1.1059e+00)\tAcc@1  67.97 ( 67.59)\tAcc@5  92.19 ( 91.76)\n",
            "Epoch: [33][ 60/391]\tTime  0.169 ( 0.169)\tLoss 1.1128e+00 (1.0852e+00)\tAcc@1  64.84 ( 68.22)\tAcc@5  93.75 ( 92.25)\n",
            "Epoch: [33][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.2249e+00 (1.0980e+00)\tAcc@1  60.94 ( 67.87)\tAcc@5  93.75 ( 92.26)\n",
            "Epoch: [33][120/391]\tTime  0.167 ( 0.169)\tLoss 8.7941e-01 (1.1069e+00)\tAcc@1  75.00 ( 67.79)\tAcc@5  95.31 ( 92.10)\n",
            "Epoch: [33][150/391]\tTime  0.168 ( 0.169)\tLoss 1.0774e+00 (1.1275e+00)\tAcc@1  69.53 ( 67.22)\tAcc@5  90.62 ( 91.70)\n",
            "Epoch: [33][180/391]\tTime  0.169 ( 0.168)\tLoss 1.0238e+00 (1.1339e+00)\tAcc@1  67.97 ( 66.76)\tAcc@5  94.53 ( 91.68)\n",
            "Epoch: [33][210/391]\tTime  0.167 ( 0.168)\tLoss 1.1790e+00 (1.1408e+00)\tAcc@1  61.72 ( 66.65)\tAcc@5  93.75 ( 91.52)\n",
            "Epoch: [33][240/391]\tTime  0.168 ( 0.168)\tLoss 1.1784e+00 (1.1507e+00)\tAcc@1  62.50 ( 66.47)\tAcc@5  93.75 ( 91.32)\n",
            "Epoch: [33][270/391]\tTime  0.169 ( 0.168)\tLoss 1.3375e+00 (1.1572e+00)\tAcc@1  63.28 ( 66.33)\tAcc@5  88.28 ( 91.31)\n",
            "Epoch: [33][300/391]\tTime  0.166 ( 0.168)\tLoss 1.1328e+00 (1.1605e+00)\tAcc@1  64.84 ( 66.24)\tAcc@5  92.19 ( 91.29)\n",
            "Epoch: [33][330/391]\tTime  0.168 ( 0.168)\tLoss 1.2930e+00 (1.1620e+00)\tAcc@1  57.81 ( 66.16)\tAcc@5  88.28 ( 91.27)\n",
            "Epoch: [33][360/391]\tTime  0.168 ( 0.168)\tLoss 1.1727e+00 (1.1667e+00)\tAcc@1  67.19 ( 66.03)\tAcc@5  94.53 ( 91.23)\n",
            "Epoch: [33][390/391]\tTime  0.150 ( 0.168)\tLoss 1.3040e+00 (1.1762e+00)\tAcc@1  57.50 ( 65.76)\tAcc@5  88.75 ( 91.13)\n",
            "==> Train Accuracy: Acc@1 65.764 || Acc@5 91.128\n",
            "==> Test Accuracy:  Acc@1 54.800 || Acc@5 82.740\n",
            "==> 69.85 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 34, lr: 0.1 -----\n",
            "Epoch: [34][  0/391]\tTime  0.296 ( 0.296)\tLoss 1.1334e+00 (1.1334e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [34][ 30/391]\tTime  0.170 ( 0.171)\tLoss 1.0056e+00 (1.0383e+00)\tAcc@1  67.19 ( 70.21)\tAcc@5  95.31 ( 93.52)\n",
            "Epoch: [34][ 60/391]\tTime  0.166 ( 0.169)\tLoss 1.1708e+00 (1.0639e+00)\tAcc@1  64.84 ( 69.04)\tAcc@5  90.62 ( 93.01)\n",
            "Epoch: [34][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.0749e+00 (1.0760e+00)\tAcc@1  68.75 ( 68.98)\tAcc@5  93.75 ( 92.84)\n",
            "Epoch: [34][120/391]\tTime  0.168 ( 0.168)\tLoss 1.1388e+00 (1.0865e+00)\tAcc@1  66.41 ( 68.63)\tAcc@5  90.62 ( 92.62)\n",
            "Epoch: [34][150/391]\tTime  0.166 ( 0.168)\tLoss 1.0858e+00 (1.1023e+00)\tAcc@1  67.97 ( 68.33)\tAcc@5  92.19 ( 92.32)\n",
            "Epoch: [34][180/391]\tTime  0.165 ( 0.168)\tLoss 1.3769e+00 (1.1173e+00)\tAcc@1  57.81 ( 67.69)\tAcc@5  89.84 ( 92.11)\n",
            "Epoch: [34][210/391]\tTime  0.168 ( 0.168)\tLoss 1.0072e+00 (1.1296e+00)\tAcc@1  71.88 ( 67.48)\tAcc@5  92.19 ( 91.85)\n",
            "Epoch: [34][240/391]\tTime  0.168 ( 0.168)\tLoss 1.0681e+00 (1.1400e+00)\tAcc@1  65.62 ( 67.20)\tAcc@5  96.09 ( 91.77)\n",
            "Epoch: [34][270/391]\tTime  0.169 ( 0.168)\tLoss 1.2527e+00 (1.1462e+00)\tAcc@1  61.72 ( 67.10)\tAcc@5  89.06 ( 91.67)\n",
            "Epoch: [34][300/391]\tTime  0.174 ( 0.168)\tLoss 1.3190e+00 (1.1559e+00)\tAcc@1  64.06 ( 66.88)\tAcc@5  88.28 ( 91.50)\n",
            "Epoch: [34][330/391]\tTime  0.168 ( 0.168)\tLoss 1.1551e+00 (1.1636e+00)\tAcc@1  62.50 ( 66.59)\tAcc@5  91.41 ( 91.38)\n",
            "Epoch: [34][360/391]\tTime  0.167 ( 0.168)\tLoss 1.2102e+00 (1.1657e+00)\tAcc@1  65.62 ( 66.49)\tAcc@5  90.62 ( 91.32)\n",
            "Epoch: [34][390/391]\tTime  0.153 ( 0.168)\tLoss 1.2066e+00 (1.1676e+00)\tAcc@1  66.25 ( 66.46)\tAcc@5  91.25 ( 91.30)\n",
            "==> Train Accuracy: Acc@1 66.458 || Acc@5 91.304\n",
            "==> Test Accuracy:  Acc@1 52.070 || Acc@5 80.850\n",
            "==> 69.76 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 35, lr: 0.1 -----\n",
            "Epoch: [35][  0/391]\tTime  0.269 ( 0.269)\tLoss 9.1811e-01 (9.1811e-01)\tAcc@1  71.09 ( 71.09)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [35][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.0484e+00 (1.0667e+00)\tAcc@1  69.53 ( 68.17)\tAcc@5  92.19 ( 92.89)\n",
            "Epoch: [35][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.0779e+00 (1.0746e+00)\tAcc@1  71.88 ( 68.20)\tAcc@5  90.62 ( 92.51)\n",
            "Epoch: [35][ 90/391]\tTime  0.170 ( 0.168)\tLoss 1.3176e+00 (1.0928e+00)\tAcc@1  64.06 ( 67.88)\tAcc@5  86.72 ( 92.26)\n",
            "Epoch: [35][120/391]\tTime  0.166 ( 0.168)\tLoss 1.3093e+00 (1.1007e+00)\tAcc@1  67.19 ( 67.72)\tAcc@5  88.28 ( 92.20)\n",
            "Epoch: [35][150/391]\tTime  0.168 ( 0.168)\tLoss 1.1397e+00 (1.1094e+00)\tAcc@1  64.84 ( 67.47)\tAcc@5  89.84 ( 92.05)\n",
            "Epoch: [35][180/391]\tTime  0.168 ( 0.168)\tLoss 1.0079e+00 (1.1116e+00)\tAcc@1  66.41 ( 67.36)\tAcc@5  94.53 ( 92.07)\n",
            "Epoch: [35][210/391]\tTime  0.168 ( 0.168)\tLoss 1.6145e+00 (1.1249e+00)\tAcc@1  56.25 ( 66.96)\tAcc@5  82.03 ( 91.87)\n",
            "Epoch: [35][240/391]\tTime  0.168 ( 0.168)\tLoss 1.0856e+00 (1.1301e+00)\tAcc@1  67.19 ( 66.87)\tAcc@5  89.06 ( 91.72)\n",
            "Epoch: [35][270/391]\tTime  0.166 ( 0.168)\tLoss 1.2312e+00 (1.1404e+00)\tAcc@1  63.28 ( 66.65)\tAcc@5  90.62 ( 91.51)\n",
            "Epoch: [35][300/391]\tTime  0.169 ( 0.168)\tLoss 1.0422e+00 (1.1457e+00)\tAcc@1  70.31 ( 66.60)\tAcc@5  92.97 ( 91.45)\n",
            "Epoch: [35][330/391]\tTime  0.169 ( 0.168)\tLoss 1.1308e+00 (1.1508e+00)\tAcc@1  63.28 ( 66.38)\tAcc@5  91.41 ( 91.43)\n",
            "Epoch: [35][360/391]\tTime  0.169 ( 0.168)\tLoss 1.3343e+00 (1.1568e+00)\tAcc@1  57.81 ( 66.25)\tAcc@5  90.62 ( 91.37)\n",
            "Epoch: [35][390/391]\tTime  0.152 ( 0.168)\tLoss 1.4053e+00 (1.1583e+00)\tAcc@1  58.75 ( 66.21)\tAcc@5  93.75 ( 91.37)\n",
            "==> Train Accuracy: Acc@1 66.206 || Acc@5 91.366\n",
            "==> Test Accuracy:  Acc@1 55.390 || Acc@5 83.850\n",
            "==> 69.83 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 36, lr: 0.1 -----\n",
            "Epoch: [36][  0/391]\tTime  0.275 ( 0.275)\tLoss 1.0456e+00 (1.0456e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [36][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.0370e+00 (1.0742e+00)\tAcc@1  68.75 ( 69.13)\tAcc@5  92.97 ( 91.99)\n",
            "Epoch: [36][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.2294e+00 (1.0829e+00)\tAcc@1  65.62 ( 68.95)\tAcc@5  92.97 ( 92.28)\n",
            "Epoch: [36][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.0496e+00 (1.0816e+00)\tAcc@1  70.31 ( 68.70)\tAcc@5  93.75 ( 92.33)\n",
            "Epoch: [36][120/391]\tTime  0.167 ( 0.168)\tLoss 7.7974e-01 (1.0911e+00)\tAcc@1  78.91 ( 68.36)\tAcc@5  97.66 ( 92.17)\n",
            "Epoch: [36][150/391]\tTime  0.167 ( 0.168)\tLoss 1.2831e+00 (1.0995e+00)\tAcc@1  59.38 ( 68.10)\tAcc@5  90.62 ( 92.11)\n",
            "Epoch: [36][180/391]\tTime  0.167 ( 0.168)\tLoss 1.4134e+00 (1.1166e+00)\tAcc@1  60.94 ( 67.65)\tAcc@5  86.72 ( 91.87)\n",
            "Epoch: [36][210/391]\tTime  0.166 ( 0.168)\tLoss 1.1722e+00 (1.1246e+00)\tAcc@1  63.28 ( 67.42)\tAcc@5  89.84 ( 91.75)\n",
            "Epoch: [36][240/391]\tTime  0.168 ( 0.168)\tLoss 1.1840e+00 (1.1341e+00)\tAcc@1  65.62 ( 67.19)\tAcc@5  89.06 ( 91.67)\n",
            "Epoch: [36][270/391]\tTime  0.168 ( 0.168)\tLoss 1.3823e+00 (1.1409e+00)\tAcc@1  61.72 ( 67.04)\tAcc@5  85.94 ( 91.58)\n",
            "Epoch: [36][300/391]\tTime  0.166 ( 0.168)\tLoss 1.2155e+00 (1.1488e+00)\tAcc@1  65.62 ( 66.74)\tAcc@5  89.06 ( 91.52)\n",
            "Epoch: [36][330/391]\tTime  0.167 ( 0.168)\tLoss 1.1942e+00 (1.1536e+00)\tAcc@1  67.97 ( 66.63)\tAcc@5  91.41 ( 91.51)\n",
            "Epoch: [36][360/391]\tTime  0.167 ( 0.168)\tLoss 1.0403e+00 (1.1560e+00)\tAcc@1  74.22 ( 66.55)\tAcc@5  91.41 ( 91.48)\n",
            "Epoch: [36][390/391]\tTime  0.151 ( 0.168)\tLoss 1.1658e+00 (1.1614e+00)\tAcc@1  65.00 ( 66.46)\tAcc@5  93.75 ( 91.39)\n",
            "==> Train Accuracy: Acc@1 66.462 || Acc@5 91.388\n",
            "==> Test Accuracy:  Acc@1 59.970 || Acc@5 86.990\n",
            "==> 69.71 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 37, lr: 0.1 -----\n",
            "Epoch: [37][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.0267e+00 (1.0267e+00)\tAcc@1  72.66 ( 72.66)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [37][ 30/391]\tTime  0.168 ( 0.171)\tLoss 9.6772e-01 (9.9052e-01)\tAcc@1  65.62 ( 70.64)\tAcc@5  97.66 ( 93.45)\n",
            "Epoch: [37][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.0057e+00 (1.0229e+00)\tAcc@1  71.09 ( 69.72)\tAcc@5  92.97 ( 93.03)\n",
            "Epoch: [37][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.1357e+00 (1.0538e+00)\tAcc@1  68.75 ( 69.14)\tAcc@5  89.84 ( 92.64)\n",
            "Epoch: [37][120/391]\tTime  0.168 ( 0.169)\tLoss 1.1825e+00 (1.0845e+00)\tAcc@1  65.62 ( 68.30)\tAcc@5  89.84 ( 92.20)\n",
            "Epoch: [37][150/391]\tTime  0.167 ( 0.168)\tLoss 1.3098e+00 (1.0897e+00)\tAcc@1  64.84 ( 68.27)\tAcc@5  87.50 ( 92.16)\n",
            "Epoch: [37][180/391]\tTime  0.168 ( 0.168)\tLoss 1.1569e+00 (1.1050e+00)\tAcc@1  67.97 ( 67.77)\tAcc@5  92.97 ( 92.07)\n",
            "Epoch: [37][210/391]\tTime  0.167 ( 0.168)\tLoss 1.0790e+00 (1.1182e+00)\tAcc@1  71.09 ( 67.39)\tAcc@5  92.19 ( 91.97)\n",
            "Epoch: [37][240/391]\tTime  0.168 ( 0.168)\tLoss 1.4637e+00 (1.1259e+00)\tAcc@1  61.72 ( 67.19)\tAcc@5  83.59 ( 91.95)\n",
            "Epoch: [37][270/391]\tTime  0.168 ( 0.168)\tLoss 1.3840e+00 (1.1344e+00)\tAcc@1  60.16 ( 67.01)\tAcc@5  86.72 ( 91.86)\n",
            "Epoch: [37][300/391]\tTime  0.168 ( 0.168)\tLoss 1.0697e+00 (1.1344e+00)\tAcc@1  69.53 ( 67.03)\tAcc@5  89.06 ( 91.83)\n",
            "Epoch: [37][330/391]\tTime  0.169 ( 0.168)\tLoss 1.2163e+00 (1.1389e+00)\tAcc@1  67.19 ( 66.97)\tAcc@5  91.41 ( 91.79)\n",
            "Epoch: [37][360/391]\tTime  0.168 ( 0.168)\tLoss 1.3548e+00 (1.1440e+00)\tAcc@1  62.50 ( 66.86)\tAcc@5  86.72 ( 91.68)\n",
            "Epoch: [37][390/391]\tTime  0.151 ( 0.168)\tLoss 1.3097e+00 (1.1473e+00)\tAcc@1  58.75 ( 66.82)\tAcc@5  87.50 ( 91.59)\n",
            "==> Train Accuracy: Acc@1 66.824 || Acc@5 91.592\n",
            "==> Test Accuracy:  Acc@1 55.980 || Acc@5 84.240\n",
            "==> 69.76 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 38, lr: 0.1 -----\n",
            "Epoch: [38][  0/391]\tTime  0.282 ( 0.282)\tLoss 8.6342e-01 (8.6342e-01)\tAcc@1  72.66 ( 72.66)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [38][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.0566e+00 (1.0527e+00)\tAcc@1  67.97 ( 68.95)\tAcc@5  96.09 ( 92.74)\n",
            "Epoch: [38][ 60/391]\tTime  0.168 ( 0.170)\tLoss 9.6905e-01 (1.0645e+00)\tAcc@1  72.66 ( 68.51)\tAcc@5  89.06 ( 92.73)\n",
            "Epoch: [38][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.4060e+00 (1.0823e+00)\tAcc@1  63.28 ( 68.17)\tAcc@5  89.84 ( 92.71)\n",
            "Epoch: [38][120/391]\tTime  0.169 ( 0.169)\tLoss 1.1187e+00 (1.0972e+00)\tAcc@1  67.19 ( 67.65)\tAcc@5  93.75 ( 92.57)\n",
            "Epoch: [38][150/391]\tTime  0.168 ( 0.169)\tLoss 1.1307e+00 (1.1046e+00)\tAcc@1  68.75 ( 67.38)\tAcc@5  91.41 ( 92.53)\n",
            "Epoch: [38][180/391]\tTime  0.168 ( 0.168)\tLoss 1.1033e+00 (1.1127e+00)\tAcc@1  67.19 ( 67.18)\tAcc@5  90.62 ( 92.34)\n",
            "Epoch: [38][210/391]\tTime  0.168 ( 0.168)\tLoss 1.2796e+00 (1.1267e+00)\tAcc@1  61.72 ( 66.82)\tAcc@5  89.84 ( 92.15)\n",
            "Epoch: [38][240/391]\tTime  0.170 ( 0.168)\tLoss 9.7190e-01 (1.1296e+00)\tAcc@1  69.53 ( 66.91)\tAcc@5  94.53 ( 92.10)\n",
            "Epoch: [38][270/391]\tTime  0.167 ( 0.168)\tLoss 1.2148e+00 (1.1320e+00)\tAcc@1  66.41 ( 66.89)\tAcc@5  89.84 ( 91.97)\n",
            "Epoch: [38][300/391]\tTime  0.166 ( 0.168)\tLoss 1.2281e+00 (1.1357e+00)\tAcc@1  66.41 ( 66.78)\tAcc@5  89.84 ( 91.82)\n",
            "Epoch: [38][330/391]\tTime  0.167 ( 0.168)\tLoss 1.1761e+00 (1.1357e+00)\tAcc@1  68.75 ( 66.87)\tAcc@5  89.06 ( 91.72)\n",
            "Epoch: [38][360/391]\tTime  0.170 ( 0.168)\tLoss 1.1294e+00 (1.1364e+00)\tAcc@1  67.97 ( 66.83)\tAcc@5  91.41 ( 91.73)\n",
            "Epoch: [38][390/391]\tTime  0.150 ( 0.168)\tLoss 1.2584e+00 (1.1415e+00)\tAcc@1  65.00 ( 66.73)\tAcc@5  95.00 ( 91.69)\n",
            "==> Train Accuracy: Acc@1 66.734 || Acc@5 91.686\n",
            "==> Test Accuracy:  Acc@1 57.520 || Acc@5 84.570\n",
            "==> 69.75 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 39, lr: 0.1 -----\n",
            "Epoch: [39][  0/391]\tTime  0.289 ( 0.289)\tLoss 1.1408e+00 (1.1408e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [39][ 30/391]\tTime  0.167 ( 0.170)\tLoss 9.6364e-01 (1.0467e+00)\tAcc@1  71.88 ( 69.76)\tAcc@5  94.53 ( 93.12)\n",
            "Epoch: [39][ 60/391]\tTime  0.166 ( 0.169)\tLoss 1.1547e+00 (1.0734e+00)\tAcc@1  65.62 ( 68.38)\tAcc@5  92.97 ( 92.80)\n",
            "Epoch: [39][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.1957e+00 (1.0937e+00)\tAcc@1  67.19 ( 68.21)\tAcc@5  89.06 ( 92.37)\n",
            "Epoch: [39][120/391]\tTime  0.167 ( 0.168)\tLoss 1.0362e+00 (1.1011e+00)\tAcc@1  68.75 ( 67.90)\tAcc@5  95.31 ( 92.34)\n",
            "Epoch: [39][150/391]\tTime  0.168 ( 0.168)\tLoss 1.0665e+00 (1.1092e+00)\tAcc@1  70.31 ( 67.59)\tAcc@5  93.75 ( 92.26)\n",
            "Epoch: [39][180/391]\tTime  0.170 ( 0.168)\tLoss 1.2216e+00 (1.1157e+00)\tAcc@1  60.16 ( 67.32)\tAcc@5  92.97 ( 92.22)\n",
            "Epoch: [39][210/391]\tTime  0.168 ( 0.168)\tLoss 8.4812e-01 (1.1239e+00)\tAcc@1  73.44 ( 67.09)\tAcc@5  94.53 ( 92.09)\n",
            "Epoch: [39][240/391]\tTime  0.167 ( 0.168)\tLoss 1.1196e+00 (1.1287e+00)\tAcc@1  67.19 ( 66.92)\tAcc@5  92.19 ( 92.06)\n",
            "Epoch: [39][270/391]\tTime  0.168 ( 0.168)\tLoss 1.0074e+00 (1.1323e+00)\tAcc@1  73.44 ( 66.80)\tAcc@5  92.97 ( 91.99)\n",
            "Epoch: [39][300/391]\tTime  0.164 ( 0.168)\tLoss 1.1198e+00 (1.1348e+00)\tAcc@1  67.97 ( 66.74)\tAcc@5  94.53 ( 91.94)\n",
            "Epoch: [39][330/391]\tTime  0.167 ( 0.168)\tLoss 1.0171e+00 (1.1376e+00)\tAcc@1  68.75 ( 66.75)\tAcc@5  91.41 ( 91.84)\n",
            "Epoch: [39][360/391]\tTime  0.166 ( 0.168)\tLoss 9.9568e-01 (1.1399e+00)\tAcc@1  68.75 ( 66.67)\tAcc@5  92.19 ( 91.83)\n",
            "Epoch: [39][390/391]\tTime  0.151 ( 0.168)\tLoss 1.1445e+00 (1.1458e+00)\tAcc@1  67.50 ( 66.50)\tAcc@5  93.75 ( 91.76)\n",
            "==> Train Accuracy: Acc@1 66.504 || Acc@5 91.758\n",
            "==> Test Accuracy:  Acc@1 54.450 || Acc@5 82.880\n",
            "==> 69.70 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 40, lr: 0.1 -----\n",
            "Epoch: [40][  0/391]\tTime  0.294 ( 0.294)\tLoss 1.1815e+00 (1.1815e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [40][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.0906e+00 (1.0605e+00)\tAcc@1  63.28 ( 68.85)\tAcc@5  92.19 ( 93.09)\n",
            "Epoch: [40][ 60/391]\tTime  0.168 ( 0.169)\tLoss 8.7496e-01 (1.0670e+00)\tAcc@1  77.34 ( 68.62)\tAcc@5  94.53 ( 92.85)\n",
            "Epoch: [40][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.0462e+00 (1.0781e+00)\tAcc@1  67.19 ( 68.55)\tAcc@5  92.19 ( 92.63)\n",
            "Epoch: [40][120/391]\tTime  0.168 ( 0.169)\tLoss 8.8343e-01 (1.0744e+00)\tAcc@1  75.78 ( 68.69)\tAcc@5  94.53 ( 92.60)\n",
            "Epoch: [40][150/391]\tTime  0.168 ( 0.168)\tLoss 1.0894e+00 (1.0784e+00)\tAcc@1  68.75 ( 68.60)\tAcc@5  92.19 ( 92.62)\n",
            "Epoch: [40][180/391]\tTime  0.167 ( 0.168)\tLoss 1.2050e+00 (1.0826e+00)\tAcc@1  62.50 ( 68.48)\tAcc@5  92.19 ( 92.54)\n",
            "Epoch: [40][210/391]\tTime  0.165 ( 0.168)\tLoss 1.0535e+00 (1.0893e+00)\tAcc@1  68.75 ( 68.37)\tAcc@5  94.53 ( 92.44)\n",
            "Epoch: [40][240/391]\tTime  0.167 ( 0.168)\tLoss 1.2693e+00 (1.0936e+00)\tAcc@1  65.62 ( 68.31)\tAcc@5  90.62 ( 92.45)\n",
            "Epoch: [40][270/391]\tTime  0.166 ( 0.168)\tLoss 1.2888e+00 (1.1063e+00)\tAcc@1  67.19 ( 67.99)\tAcc@5  89.06 ( 92.27)\n",
            "Epoch: [40][300/391]\tTime  0.169 ( 0.168)\tLoss 1.2126e+00 (1.1142e+00)\tAcc@1  64.06 ( 67.70)\tAcc@5  88.28 ( 92.12)\n",
            "Epoch: [40][330/391]\tTime  0.168 ( 0.168)\tLoss 1.1247e+00 (1.1210e+00)\tAcc@1  68.75 ( 67.48)\tAcc@5  93.75 ( 91.97)\n",
            "Epoch: [40][360/391]\tTime  0.168 ( 0.168)\tLoss 1.1344e+00 (1.1236e+00)\tAcc@1  66.41 ( 67.39)\tAcc@5  89.84 ( 91.96)\n",
            "Epoch: [40][390/391]\tTime  0.149 ( 0.168)\tLoss 1.0018e+00 (1.1284e+00)\tAcc@1  72.50 ( 67.24)\tAcc@5  93.75 ( 91.88)\n",
            "==> Train Accuracy: Acc@1 67.240 || Acc@5 91.882\n",
            "==> Test Accuracy:  Acc@1 59.370 || Acc@5 85.960\n",
            "==> 69.80 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 41, lr: 0.1 -----\n",
            "Epoch: [41][  0/391]\tTime  0.280 ( 0.280)\tLoss 9.0534e-01 (9.0534e-01)\tAcc@1  71.88 ( 71.88)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [41][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.1790e+00 (1.0172e+00)\tAcc@1  65.62 ( 70.59)\tAcc@5  92.97 ( 93.42)\n",
            "Epoch: [41][ 60/391]\tTime  0.168 ( 0.169)\tLoss 9.5619e-01 (1.0535e+00)\tAcc@1  75.78 ( 69.54)\tAcc@5  92.19 ( 92.99)\n",
            "Epoch: [41][ 90/391]\tTime  0.167 ( 0.168)\tLoss 9.5444e-01 (1.0525e+00)\tAcc@1  70.31 ( 69.43)\tAcc@5  94.53 ( 93.10)\n",
            "Epoch: [41][120/391]\tTime  0.167 ( 0.168)\tLoss 1.1661e+00 (1.0756e+00)\tAcc@1  64.06 ( 68.52)\tAcc@5  92.19 ( 92.81)\n",
            "Epoch: [41][150/391]\tTime  0.168 ( 0.168)\tLoss 1.2810e+00 (1.0890e+00)\tAcc@1  64.84 ( 68.21)\tAcc@5  85.16 ( 92.52)\n",
            "Epoch: [41][180/391]\tTime  0.168 ( 0.168)\tLoss 1.0593e+00 (1.0966e+00)\tAcc@1  69.53 ( 67.95)\tAcc@5  92.97 ( 92.37)\n",
            "Epoch: [41][210/391]\tTime  0.168 ( 0.168)\tLoss 1.0675e+00 (1.0976e+00)\tAcc@1  70.31 ( 67.97)\tAcc@5  88.28 ( 92.22)\n",
            "Epoch: [41][240/391]\tTime  0.168 ( 0.168)\tLoss 1.1405e+00 (1.1023e+00)\tAcc@1  68.75 ( 67.89)\tAcc@5  91.41 ( 92.13)\n",
            "Epoch: [41][270/391]\tTime  0.167 ( 0.168)\tLoss 1.0693e+00 (1.1090e+00)\tAcc@1  69.53 ( 67.76)\tAcc@5  92.97 ( 92.04)\n",
            "Epoch: [41][300/391]\tTime  0.164 ( 0.168)\tLoss 1.0300e+00 (1.1171e+00)\tAcc@1  70.31 ( 67.62)\tAcc@5  92.97 ( 91.97)\n",
            "Epoch: [41][330/391]\tTime  0.168 ( 0.168)\tLoss 1.1166e+00 (1.1155e+00)\tAcc@1  66.41 ( 67.60)\tAcc@5  90.62 ( 91.97)\n",
            "Epoch: [41][360/391]\tTime  0.165 ( 0.168)\tLoss 1.0524e+00 (1.1196e+00)\tAcc@1  66.41 ( 67.46)\tAcc@5  90.62 ( 91.89)\n",
            "Epoch: [41][390/391]\tTime  0.150 ( 0.168)\tLoss 1.4022e+00 (1.1254e+00)\tAcc@1  58.75 ( 67.36)\tAcc@5  90.00 ( 91.82)\n",
            "==> Train Accuracy: Acc@1 67.358 || Acc@5 91.818\n",
            "==> Test Accuracy:  Acc@1 57.910 || Acc@5 85.580\n",
            "==> 69.74 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 42, lr: 0.1 -----\n",
            "Epoch: [42][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.0812e+00 (1.0812e+00)\tAcc@1  74.22 ( 74.22)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [42][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.1126e+00 (1.0322e+00)\tAcc@1  65.62 ( 69.25)\tAcc@5  92.19 ( 93.72)\n",
            "Epoch: [42][ 60/391]\tTime  0.168 ( 0.169)\tLoss 9.5117e-01 (1.0490e+00)\tAcc@1  67.97 ( 68.93)\tAcc@5  96.88 ( 93.61)\n",
            "Epoch: [42][ 90/391]\tTime  0.168 ( 0.168)\tLoss 8.5534e-01 (1.0746e+00)\tAcc@1  76.56 ( 68.87)\tAcc@5  95.31 ( 93.11)\n",
            "Epoch: [42][120/391]\tTime  0.168 ( 0.168)\tLoss 8.0546e-01 (1.0728e+00)\tAcc@1  75.78 ( 68.80)\tAcc@5  95.31 ( 92.84)\n",
            "Epoch: [42][150/391]\tTime  0.166 ( 0.168)\tLoss 9.6342e-01 (1.0895e+00)\tAcc@1  73.44 ( 68.25)\tAcc@5  96.88 ( 92.66)\n",
            "Epoch: [42][180/391]\tTime  0.166 ( 0.168)\tLoss 1.3713e+00 (1.0953e+00)\tAcc@1  60.16 ( 67.97)\tAcc@5  91.41 ( 92.58)\n",
            "Epoch: [42][210/391]\tTime  0.166 ( 0.168)\tLoss 1.1528e+00 (1.0969e+00)\tAcc@1  70.31 ( 68.00)\tAcc@5  92.97 ( 92.56)\n",
            "Epoch: [42][240/391]\tTime  0.169 ( 0.168)\tLoss 1.1250e+00 (1.0995e+00)\tAcc@1  68.75 ( 67.95)\tAcc@5  92.97 ( 92.48)\n",
            "Epoch: [42][270/391]\tTime  0.169 ( 0.168)\tLoss 1.1570e+00 (1.1099e+00)\tAcc@1  67.19 ( 67.65)\tAcc@5  89.06 ( 92.29)\n",
            "Epoch: [42][300/391]\tTime  0.168 ( 0.168)\tLoss 9.9730e-01 (1.1124e+00)\tAcc@1  72.66 ( 67.61)\tAcc@5  91.41 ( 92.23)\n",
            "Epoch: [42][330/391]\tTime  0.168 ( 0.168)\tLoss 1.2901e+00 (1.1148e+00)\tAcc@1  63.28 ( 67.58)\tAcc@5  90.62 ( 92.14)\n",
            "Epoch: [42][360/391]\tTime  0.169 ( 0.168)\tLoss 1.0932e+00 (1.1222e+00)\tAcc@1  73.44 ( 67.36)\tAcc@5  92.97 ( 92.06)\n",
            "Epoch: [42][390/391]\tTime  0.152 ( 0.168)\tLoss 1.3349e+00 (1.1221e+00)\tAcc@1  57.50 ( 67.36)\tAcc@5  86.25 ( 92.06)\n",
            "==> Train Accuracy: Acc@1 67.356 || Acc@5 92.064\n",
            "==> Test Accuracy:  Acc@1 55.730 || Acc@5 83.680\n",
            "==> 69.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 43, lr: 0.1 -----\n",
            "Epoch: [43][  0/391]\tTime  0.300 ( 0.300)\tLoss 1.2135e+00 (1.2135e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [43][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.1184e+00 (1.0278e+00)\tAcc@1  69.53 ( 69.53)\tAcc@5  91.41 ( 93.32)\n",
            "Epoch: [43][ 60/391]\tTime  0.167 ( 0.169)\tLoss 9.0415e-01 (1.0375e+00)\tAcc@1  74.22 ( 69.34)\tAcc@5  96.09 ( 93.24)\n",
            "Epoch: [43][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.2005e+00 (1.0498e+00)\tAcc@1  64.06 ( 69.32)\tAcc@5  89.06 ( 92.84)\n",
            "Epoch: [43][120/391]\tTime  0.167 ( 0.169)\tLoss 1.0427e+00 (1.0570e+00)\tAcc@1  68.75 ( 69.12)\tAcc@5  92.19 ( 92.65)\n",
            "Epoch: [43][150/391]\tTime  0.169 ( 0.168)\tLoss 9.9126e-01 (1.0625e+00)\tAcc@1  74.22 ( 69.23)\tAcc@5  93.75 ( 92.48)\n",
            "Epoch: [43][180/391]\tTime  0.167 ( 0.168)\tLoss 1.2154e+00 (1.0698e+00)\tAcc@1  62.50 ( 69.09)\tAcc@5  89.06 ( 92.36)\n",
            "Epoch: [43][210/391]\tTime  0.169 ( 0.168)\tLoss 1.0614e+00 (1.0784e+00)\tAcc@1  72.66 ( 68.79)\tAcc@5  89.06 ( 92.32)\n",
            "Epoch: [43][240/391]\tTime  0.168 ( 0.168)\tLoss 1.3946e+00 (1.0895e+00)\tAcc@1  56.25 ( 68.37)\tAcc@5  87.50 ( 92.23)\n",
            "Epoch: [43][270/391]\tTime  0.166 ( 0.168)\tLoss 1.1861e+00 (1.0949e+00)\tAcc@1  67.97 ( 68.20)\tAcc@5  91.41 ( 92.21)\n",
            "Epoch: [43][300/391]\tTime  0.167 ( 0.168)\tLoss 1.0692e+00 (1.1030e+00)\tAcc@1  68.75 ( 67.99)\tAcc@5  94.53 ( 92.15)\n",
            "Epoch: [43][330/391]\tTime  0.167 ( 0.168)\tLoss 1.2416e+00 (1.1050e+00)\tAcc@1  59.38 ( 67.97)\tAcc@5  92.19 ( 92.13)\n",
            "Epoch: [43][360/391]\tTime  0.168 ( 0.168)\tLoss 1.4453e+00 (1.1117e+00)\tAcc@1  63.28 ( 67.79)\tAcc@5  86.72 ( 92.01)\n",
            "Epoch: [43][390/391]\tTime  0.151 ( 0.168)\tLoss 1.4133e+00 (1.1164e+00)\tAcc@1  56.25 ( 67.63)\tAcc@5  86.25 ( 91.93)\n",
            "==> Train Accuracy: Acc@1 67.628 || Acc@5 91.928\n",
            "==> Test Accuracy:  Acc@1 48.700 || Acc@5 77.360\n",
            "==> 69.74 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 44, lr: 0.1 -----\n",
            "Epoch: [44][  0/391]\tTime  0.311 ( 0.311)\tLoss 1.0732e+00 (1.0732e+00)\tAcc@1  72.66 ( 72.66)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [44][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.0968e+00 (1.1075e+00)\tAcc@1  67.19 ( 67.82)\tAcc@5  92.19 ( 92.04)\n",
            "Epoch: [44][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.2792e+00 (1.0762e+00)\tAcc@1  58.59 ( 68.44)\tAcc@5  91.41 ( 92.42)\n",
            "Epoch: [44][ 90/391]\tTime  0.166 ( 0.169)\tLoss 7.5384e-01 (1.0625e+00)\tAcc@1  80.47 ( 68.82)\tAcc@5  96.09 ( 92.63)\n",
            "Epoch: [44][120/391]\tTime  0.167 ( 0.169)\tLoss 1.2878e+00 (1.0616e+00)\tAcc@1  62.50 ( 68.92)\tAcc@5  92.19 ( 92.75)\n",
            "Epoch: [44][150/391]\tTime  0.168 ( 0.168)\tLoss 1.1072e+00 (1.0700e+00)\tAcc@1  64.84 ( 68.78)\tAcc@5  94.53 ( 92.69)\n",
            "Epoch: [44][180/391]\tTime  0.169 ( 0.168)\tLoss 1.0539e+00 (1.0791e+00)\tAcc@1  66.41 ( 68.57)\tAcc@5  92.97 ( 92.60)\n",
            "Epoch: [44][210/391]\tTime  0.163 ( 0.168)\tLoss 1.1514e+00 (1.0837e+00)\tAcc@1  67.19 ( 68.45)\tAcc@5  90.62 ( 92.56)\n",
            "Epoch: [44][240/391]\tTime  0.168 ( 0.168)\tLoss 1.1939e+00 (1.0956e+00)\tAcc@1  63.28 ( 68.04)\tAcc@5  89.06 ( 92.45)\n",
            "Epoch: [44][270/391]\tTime  0.166 ( 0.168)\tLoss 1.3196e+00 (1.0997e+00)\tAcc@1  64.06 ( 67.95)\tAcc@5  86.72 ( 92.37)\n",
            "Epoch: [44][300/391]\tTime  0.169 ( 0.168)\tLoss 1.1136e+00 (1.1045e+00)\tAcc@1  70.31 ( 67.81)\tAcc@5  89.84 ( 92.29)\n",
            "Epoch: [44][330/391]\tTime  0.168 ( 0.168)\tLoss 1.0224e+00 (1.1069e+00)\tAcc@1  70.31 ( 67.74)\tAcc@5  94.53 ( 92.22)\n",
            "Epoch: [44][360/391]\tTime  0.168 ( 0.168)\tLoss 1.0061e+00 (1.1115e+00)\tAcc@1  70.31 ( 67.58)\tAcc@5  94.53 ( 92.20)\n",
            "Epoch: [44][390/391]\tTime  0.150 ( 0.168)\tLoss 1.2710e+00 (1.1144e+00)\tAcc@1  65.00 ( 67.52)\tAcc@5  88.75 ( 92.13)\n",
            "==> Train Accuracy: Acc@1 67.518 || Acc@5 92.132\n",
            "==> Test Accuracy:  Acc@1 57.520 || Acc@5 84.460\n",
            "==> 69.74 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 45, lr: 0.1 -----\n",
            "Epoch: [45][  0/391]\tTime  0.270 ( 0.270)\tLoss 9.1805e-01 (9.1805e-01)\tAcc@1  70.31 ( 70.31)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [45][ 30/391]\tTime  0.168 ( 0.171)\tLoss 7.7965e-01 (9.9991e-01)\tAcc@1  78.12 ( 70.56)\tAcc@5  97.66 ( 93.25)\n",
            "Epoch: [45][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.0942e+00 (1.0092e+00)\tAcc@1  68.75 ( 70.31)\tAcc@5  92.19 ( 93.49)\n",
            "Epoch: [45][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.0440e+00 (1.0489e+00)\tAcc@1  66.41 ( 69.15)\tAcc@5  92.19 ( 93.05)\n",
            "Epoch: [45][120/391]\tTime  0.169 ( 0.169)\tLoss 1.1063e+00 (1.0579e+00)\tAcc@1  68.75 ( 68.93)\tAcc@5  90.62 ( 92.71)\n",
            "Epoch: [45][150/391]\tTime  0.169 ( 0.169)\tLoss 1.1695e+00 (1.0643e+00)\tAcc@1  65.62 ( 68.78)\tAcc@5  92.19 ( 92.53)\n",
            "Epoch: [45][180/391]\tTime  0.169 ( 0.168)\tLoss 1.1107e+00 (1.0769e+00)\tAcc@1  64.06 ( 68.44)\tAcc@5  92.19 ( 92.38)\n",
            "Epoch: [45][210/391]\tTime  0.168 ( 0.168)\tLoss 1.1124e+00 (1.0842e+00)\tAcc@1  70.31 ( 68.30)\tAcc@5  93.75 ( 92.30)\n",
            "Epoch: [45][240/391]\tTime  0.168 ( 0.168)\tLoss 1.2528e+00 (1.0864e+00)\tAcc@1  64.06 ( 68.27)\tAcc@5  91.41 ( 92.31)\n",
            "Epoch: [45][270/391]\tTime  0.168 ( 0.168)\tLoss 1.1952e+00 (1.0897e+00)\tAcc@1  65.62 ( 68.20)\tAcc@5  91.41 ( 92.34)\n",
            "Epoch: [45][300/391]\tTime  0.167 ( 0.168)\tLoss 1.0101e+00 (1.0982e+00)\tAcc@1  68.75 ( 68.00)\tAcc@5  94.53 ( 92.21)\n",
            "Epoch: [45][330/391]\tTime  0.167 ( 0.168)\tLoss 1.2426e+00 (1.1044e+00)\tAcc@1  63.28 ( 67.79)\tAcc@5  90.62 ( 92.14)\n",
            "Epoch: [45][360/391]\tTime  0.168 ( 0.168)\tLoss 1.2382e+00 (1.1095e+00)\tAcc@1  63.28 ( 67.65)\tAcc@5  93.75 ( 92.14)\n",
            "Epoch: [45][390/391]\tTime  0.152 ( 0.168)\tLoss 1.3166e+00 (1.1149e+00)\tAcc@1  68.75 ( 67.50)\tAcc@5  88.75 ( 92.08)\n",
            "==> Train Accuracy: Acc@1 67.504 || Acc@5 92.078\n",
            "==> Test Accuracy:  Acc@1 55.970 || Acc@5 83.750\n",
            "==> 69.84 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 46, lr: 0.1 -----\n",
            "Epoch: [46][  0/391]\tTime  0.286 ( 0.286)\tLoss 9.2778e-01 (9.2778e-01)\tAcc@1  74.22 ( 74.22)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [46][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.0013e+00 (1.0233e+00)\tAcc@1  73.44 ( 71.12)\tAcc@5  93.75 ( 92.87)\n",
            "Epoch: [46][ 60/391]\tTime  0.168 ( 0.169)\tLoss 9.3574e-01 (1.0016e+00)\tAcc@1  71.88 ( 71.03)\tAcc@5  94.53 ( 93.48)\n",
            "Epoch: [46][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.0580e+00 (1.0198e+00)\tAcc@1  71.88 ( 70.47)\tAcc@5  92.97 ( 93.22)\n",
            "Epoch: [46][120/391]\tTime  0.168 ( 0.168)\tLoss 1.2317e+00 (1.0469e+00)\tAcc@1  62.50 ( 69.60)\tAcc@5  92.97 ( 93.05)\n",
            "Epoch: [46][150/391]\tTime  0.168 ( 0.168)\tLoss 1.1619e+00 (1.0461e+00)\tAcc@1  64.84 ( 69.62)\tAcc@5  96.09 ( 93.10)\n",
            "Epoch: [46][180/391]\tTime  0.168 ( 0.168)\tLoss 9.1640e-01 (1.0574e+00)\tAcc@1  76.56 ( 69.15)\tAcc@5  93.75 ( 93.00)\n",
            "Epoch: [46][210/391]\tTime  0.168 ( 0.168)\tLoss 1.2389e+00 (1.0708e+00)\tAcc@1  64.06 ( 68.70)\tAcc@5  92.97 ( 92.78)\n",
            "Epoch: [46][240/391]\tTime  0.166 ( 0.168)\tLoss 8.9853e-01 (1.0789e+00)\tAcc@1  74.22 ( 68.56)\tAcc@5  92.97 ( 92.60)\n",
            "Epoch: [46][270/391]\tTime  0.168 ( 0.168)\tLoss 1.1351e+00 (1.0849e+00)\tAcc@1  63.28 ( 68.36)\tAcc@5  93.75 ( 92.48)\n",
            "Epoch: [46][300/391]\tTime  0.168 ( 0.168)\tLoss 9.9056e-01 (1.0922e+00)\tAcc@1  70.31 ( 68.20)\tAcc@5  93.75 ( 92.37)\n",
            "Epoch: [46][330/391]\tTime  0.167 ( 0.168)\tLoss 1.2251e+00 (1.0958e+00)\tAcc@1  67.19 ( 68.07)\tAcc@5  87.50 ( 92.26)\n",
            "Epoch: [46][360/391]\tTime  0.167 ( 0.168)\tLoss 1.0807e+00 (1.1017e+00)\tAcc@1  68.75 ( 67.91)\tAcc@5  94.53 ( 92.21)\n",
            "Epoch: [46][390/391]\tTime  0.151 ( 0.168)\tLoss 1.4315e+00 (1.1085e+00)\tAcc@1  60.00 ( 67.75)\tAcc@5  85.00 ( 92.13)\n",
            "==> Train Accuracy: Acc@1 67.752 || Acc@5 92.130\n",
            "==> Test Accuracy:  Acc@1 58.790 || Acc@5 85.370\n",
            "==> 69.77 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 47, lr: 0.1 -----\n",
            "Epoch: [47][  0/391]\tTime  0.294 ( 0.294)\tLoss 1.0590e+00 (1.0590e+00)\tAcc@1  74.22 ( 74.22)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [47][ 30/391]\tTime  0.166 ( 0.171)\tLoss 1.1607e+00 (1.0330e+00)\tAcc@1  66.41 ( 69.61)\tAcc@5  90.62 ( 93.25)\n",
            "Epoch: [47][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.1964e+00 (1.0516e+00)\tAcc@1  66.41 ( 69.11)\tAcc@5  91.41 ( 93.08)\n",
            "Epoch: [47][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.1687e+00 (1.0354e+00)\tAcc@1  65.62 ( 69.51)\tAcc@5  90.62 ( 93.23)\n",
            "Epoch: [47][120/391]\tTime  0.166 ( 0.168)\tLoss 1.2572e+00 (1.0433e+00)\tAcc@1  58.59 ( 69.31)\tAcc@5  92.19 ( 93.12)\n",
            "Epoch: [47][150/391]\tTime  0.166 ( 0.168)\tLoss 1.1172e+00 (1.0487e+00)\tAcc@1  65.62 ( 69.03)\tAcc@5  94.53 ( 93.07)\n",
            "Epoch: [47][180/391]\tTime  0.168 ( 0.168)\tLoss 1.0622e+00 (1.0621e+00)\tAcc@1  69.53 ( 68.75)\tAcc@5  94.53 ( 92.96)\n",
            "Epoch: [47][210/391]\tTime  0.168 ( 0.168)\tLoss 1.0859e+00 (1.0688e+00)\tAcc@1  71.88 ( 68.68)\tAcc@5  92.97 ( 92.87)\n",
            "Epoch: [47][240/391]\tTime  0.169 ( 0.168)\tLoss 1.3026e+00 (1.0777e+00)\tAcc@1  64.06 ( 68.42)\tAcc@5  89.06 ( 92.70)\n",
            "Epoch: [47][270/391]\tTime  0.167 ( 0.168)\tLoss 9.6295e-01 (1.0846e+00)\tAcc@1  76.56 ( 68.29)\tAcc@5  92.97 ( 92.56)\n",
            "Epoch: [47][300/391]\tTime  0.168 ( 0.168)\tLoss 1.1402e+00 (1.0966e+00)\tAcc@1  65.62 ( 68.03)\tAcc@5  95.31 ( 92.42)\n",
            "Epoch: [47][330/391]\tTime  0.169 ( 0.168)\tLoss 1.1889e+00 (1.1011e+00)\tAcc@1  63.28 ( 67.89)\tAcc@5  94.53 ( 92.34)\n",
            "Epoch: [47][360/391]\tTime  0.168 ( 0.168)\tLoss 1.0931e+00 (1.0989e+00)\tAcc@1  66.41 ( 67.92)\tAcc@5  92.19 ( 92.37)\n",
            "Epoch: [47][390/391]\tTime  0.149 ( 0.168)\tLoss 1.3172e+00 (1.1046e+00)\tAcc@1  60.00 ( 67.84)\tAcc@5  88.75 ( 92.28)\n",
            "==> Train Accuracy: Acc@1 67.842 || Acc@5 92.280\n",
            "==> Test Accuracy:  Acc@1 58.320 || Acc@5 85.610\n",
            "==> 69.81 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 48, lr: 0.1 -----\n",
            "Epoch: [48][  0/391]\tTime  0.276 ( 0.276)\tLoss 7.9159e-01 (7.9159e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [48][ 30/391]\tTime  0.169 ( 0.171)\tLoss 7.3438e-01 (9.5006e-01)\tAcc@1  81.25 ( 72.48)\tAcc@5  96.88 ( 94.15)\n",
            "Epoch: [48][ 60/391]\tTime  0.168 ( 0.170)\tLoss 1.2931e+00 (9.8125e-01)\tAcc@1  60.16 ( 71.38)\tAcc@5  91.41 ( 93.84)\n",
            "Epoch: [48][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.2075e+00 (1.0082e+00)\tAcc@1  71.88 ( 70.84)\tAcc@5  89.84 ( 93.37)\n",
            "Epoch: [48][120/391]\tTime  0.169 ( 0.169)\tLoss 1.1964e+00 (1.0188e+00)\tAcc@1  64.06 ( 70.62)\tAcc@5  93.75 ( 93.14)\n",
            "Epoch: [48][150/391]\tTime  0.167 ( 0.168)\tLoss 1.1303e+00 (1.0405e+00)\tAcc@1  71.09 ( 70.10)\tAcc@5  92.97 ( 92.91)\n",
            "Epoch: [48][180/391]\tTime  0.168 ( 0.168)\tLoss 9.8889e-01 (1.0505e+00)\tAcc@1  67.97 ( 69.79)\tAcc@5  96.09 ( 92.72)\n",
            "Epoch: [48][210/391]\tTime  0.168 ( 0.168)\tLoss 1.0849e+00 (1.0618e+00)\tAcc@1  69.53 ( 69.40)\tAcc@5  89.84 ( 92.58)\n",
            "Epoch: [48][240/391]\tTime  0.167 ( 0.168)\tLoss 1.1518e+00 (1.0683e+00)\tAcc@1  66.41 ( 69.16)\tAcc@5  92.19 ( 92.51)\n",
            "Epoch: [48][270/391]\tTime  0.166 ( 0.168)\tLoss 9.9834e-01 (1.0733e+00)\tAcc@1  70.31 ( 68.95)\tAcc@5  94.53 ( 92.46)\n",
            "Epoch: [48][300/391]\tTime  0.167 ( 0.168)\tLoss 1.2009e+00 (1.0817e+00)\tAcc@1  67.97 ( 68.76)\tAcc@5  89.84 ( 92.32)\n",
            "Epoch: [48][330/391]\tTime  0.167 ( 0.168)\tLoss 1.0632e+00 (1.0853e+00)\tAcc@1  67.97 ( 68.65)\tAcc@5  92.97 ( 92.31)\n",
            "Epoch: [48][360/391]\tTime  0.166 ( 0.168)\tLoss 1.0771e+00 (1.0913e+00)\tAcc@1  68.75 ( 68.54)\tAcc@5  91.41 ( 92.18)\n",
            "Epoch: [48][390/391]\tTime  0.151 ( 0.168)\tLoss 1.3334e+00 (1.0985e+00)\tAcc@1  65.00 ( 68.34)\tAcc@5  87.50 ( 92.07)\n",
            "==> Train Accuracy: Acc@1 68.342 || Acc@5 92.070\n",
            "==> Test Accuracy:  Acc@1 55.620 || Acc@5 84.240\n",
            "==> 69.73 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 49, lr: 0.1 -----\n",
            "Epoch: [49][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.1371e+00 (1.1371e+00)\tAcc@1  69.53 ( 69.53)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [49][ 30/391]\tTime  0.168 ( 0.170)\tLoss 1.1348e+00 (1.0018e+00)\tAcc@1  65.62 ( 71.09)\tAcc@5  93.75 ( 93.52)\n",
            "Epoch: [49][ 60/391]\tTime  0.167 ( 0.169)\tLoss 8.8063e-01 (9.9172e-01)\tAcc@1  77.34 ( 71.50)\tAcc@5  96.88 ( 93.52)\n",
            "Epoch: [49][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.0511e+00 (1.0033e+00)\tAcc@1  69.53 ( 70.88)\tAcc@5  92.19 ( 93.47)\n",
            "Epoch: [49][120/391]\tTime  0.169 ( 0.168)\tLoss 1.1932e+00 (1.0228e+00)\tAcc@1  69.53 ( 70.46)\tAcc@5  89.06 ( 93.07)\n",
            "Epoch: [49][150/391]\tTime  0.166 ( 0.168)\tLoss 1.0843e+00 (1.0287e+00)\tAcc@1  68.75 ( 70.04)\tAcc@5  92.97 ( 92.98)\n",
            "Epoch: [49][180/391]\tTime  0.167 ( 0.168)\tLoss 1.2195e+00 (1.0340e+00)\tAcc@1  67.19 ( 69.85)\tAcc@5  89.84 ( 92.98)\n",
            "Epoch: [49][210/391]\tTime  0.165 ( 0.168)\tLoss 9.3751e-01 (1.0439e+00)\tAcc@1  75.00 ( 69.68)\tAcc@5  90.62 ( 92.80)\n",
            "Epoch: [49][240/391]\tTime  0.167 ( 0.168)\tLoss 1.0057e+00 (1.0529e+00)\tAcc@1  67.97 ( 69.42)\tAcc@5  92.97 ( 92.68)\n",
            "Epoch: [49][270/391]\tTime  0.160 ( 0.168)\tLoss 9.4651e-01 (1.0576e+00)\tAcc@1  71.88 ( 69.29)\tAcc@5  92.19 ( 92.61)\n",
            "Epoch: [49][300/391]\tTime  0.167 ( 0.168)\tLoss 1.2721e+00 (1.0598e+00)\tAcc@1  64.06 ( 69.20)\tAcc@5  86.72 ( 92.59)\n",
            "Epoch: [49][330/391]\tTime  0.169 ( 0.168)\tLoss 1.0755e+00 (1.0664e+00)\tAcc@1  77.34 ( 69.03)\tAcc@5  92.97 ( 92.50)\n",
            "Epoch: [49][360/391]\tTime  0.173 ( 0.168)\tLoss 1.1020e+00 (1.0768e+00)\tAcc@1  64.84 ( 68.74)\tAcc@5  92.19 ( 92.43)\n",
            "Epoch: [49][390/391]\tTime  0.151 ( 0.168)\tLoss 1.2476e+00 (1.0854e+00)\tAcc@1  61.25 ( 68.53)\tAcc@5  93.75 ( 92.32)\n",
            "==> Train Accuracy: Acc@1 68.528 || Acc@5 92.322\n",
            "==> Test Accuracy:  Acc@1 56.870 || Acc@5 84.760\n",
            "==> 69.69 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 50, lr: 0.1 -----\n",
            "Epoch: [50][  0/391]\tTime  0.300 ( 0.300)\tLoss 1.0341e+00 (1.0341e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [50][ 30/391]\tTime  0.167 ( 0.171)\tLoss 8.6010e-01 (9.7889e-01)\tAcc@1  71.88 ( 71.19)\tAcc@5  95.31 ( 93.35)\n",
            "Epoch: [50][ 60/391]\tTime  0.168 ( 0.169)\tLoss 9.4235e-01 (9.8560e-01)\tAcc@1  71.88 ( 71.07)\tAcc@5  94.53 ( 93.29)\n",
            "Epoch: [50][ 90/391]\tTime  0.164 ( 0.169)\tLoss 8.9592e-01 (9.9279e-01)\tAcc@1  75.78 ( 70.90)\tAcc@5  92.97 ( 93.47)\n",
            "Epoch: [50][120/391]\tTime  0.168 ( 0.169)\tLoss 1.0900e+00 (9.9058e-01)\tAcc@1  68.75 ( 70.81)\tAcc@5  88.28 ( 93.52)\n",
            "Epoch: [50][150/391]\tTime  0.167 ( 0.169)\tLoss 9.7241e-01 (1.0021e+00)\tAcc@1  73.44 ( 70.61)\tAcc@5  92.97 ( 93.38)\n",
            "Epoch: [50][180/391]\tTime  0.168 ( 0.169)\tLoss 1.3387e+00 (1.0164e+00)\tAcc@1  57.81 ( 70.17)\tAcc@5  90.62 ( 93.32)\n",
            "Epoch: [50][210/391]\tTime  0.167 ( 0.168)\tLoss 1.2084e+00 (1.0315e+00)\tAcc@1  64.06 ( 69.80)\tAcc@5  89.06 ( 93.13)\n",
            "Epoch: [50][240/391]\tTime  0.168 ( 0.168)\tLoss 1.0699e+00 (1.0436e+00)\tAcc@1  68.75 ( 69.39)\tAcc@5  93.75 ( 92.98)\n",
            "Epoch: [50][270/391]\tTime  0.167 ( 0.168)\tLoss 1.0364e+00 (1.0521e+00)\tAcc@1  74.22 ( 69.12)\tAcc@5  95.31 ( 92.89)\n",
            "Epoch: [50][300/391]\tTime  0.168 ( 0.168)\tLoss 9.7696e-01 (1.0612e+00)\tAcc@1  70.31 ( 68.89)\tAcc@5  95.31 ( 92.80)\n",
            "Epoch: [50][330/391]\tTime  0.166 ( 0.168)\tLoss 1.2098e+00 (1.0707e+00)\tAcc@1  64.06 ( 68.71)\tAcc@5  91.41 ( 92.66)\n",
            "Epoch: [50][360/391]\tTime  0.168 ( 0.168)\tLoss 1.0304e+00 (1.0786e+00)\tAcc@1  71.88 ( 68.49)\tAcc@5  94.53 ( 92.51)\n",
            "Epoch: [50][390/391]\tTime  0.150 ( 0.168)\tLoss 1.2199e+00 (1.0838e+00)\tAcc@1  65.00 ( 68.40)\tAcc@5  86.25 ( 92.46)\n",
            "==> Train Accuracy: Acc@1 68.396 || Acc@5 92.460\n",
            "==> Test Accuracy:  Acc@1 57.650 || Acc@5 85.460\n",
            "==> 69.85 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 51, lr: 0.1 -----\n",
            "Epoch: [51][  0/391]\tTime  0.299 ( 0.299)\tLoss 8.3234e-01 (8.3234e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [51][ 30/391]\tTime  0.165 ( 0.171)\tLoss 8.1927e-01 (9.5519e-01)\tAcc@1  75.00 ( 71.62)\tAcc@5  96.88 ( 94.05)\n",
            "Epoch: [51][ 60/391]\tTime  0.172 ( 0.169)\tLoss 1.0085e+00 (9.6058e-01)\tAcc@1  69.53 ( 71.75)\tAcc@5  94.53 ( 93.97)\n",
            "Epoch: [51][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.2303e+00 (9.8136e-01)\tAcc@1  61.72 ( 71.04)\tAcc@5  91.41 ( 93.63)\n",
            "Epoch: [51][120/391]\tTime  0.167 ( 0.168)\tLoss 1.1517e+00 (9.8655e-01)\tAcc@1  69.53 ( 71.00)\tAcc@5  92.19 ( 93.60)\n",
            "Epoch: [51][150/391]\tTime  0.168 ( 0.168)\tLoss 1.1168e+00 (1.0041e+00)\tAcc@1  65.62 ( 70.40)\tAcc@5  92.19 ( 93.39)\n",
            "Epoch: [51][180/391]\tTime  0.168 ( 0.168)\tLoss 1.1723e+00 (1.0178e+00)\tAcc@1  68.75 ( 69.98)\tAcc@5  92.19 ( 93.25)\n",
            "Epoch: [51][210/391]\tTime  0.169 ( 0.168)\tLoss 1.2446e+00 (1.0358e+00)\tAcc@1  64.84 ( 69.50)\tAcc@5  89.84 ( 93.00)\n",
            "Epoch: [51][240/391]\tTime  0.168 ( 0.168)\tLoss 1.2624e+00 (1.0471e+00)\tAcc@1  60.94 ( 69.11)\tAcc@5  91.41 ( 92.94)\n",
            "Epoch: [51][270/391]\tTime  0.167 ( 0.168)\tLoss 1.1195e+00 (1.0555e+00)\tAcc@1  68.75 ( 69.01)\tAcc@5  89.84 ( 92.84)\n",
            "Epoch: [51][300/391]\tTime  0.167 ( 0.168)\tLoss 1.1925e+00 (1.0630e+00)\tAcc@1  64.84 ( 68.85)\tAcc@5  93.75 ( 92.74)\n",
            "Epoch: [51][330/391]\tTime  0.166 ( 0.168)\tLoss 1.3499e+00 (1.0711e+00)\tAcc@1  67.19 ( 68.64)\tAcc@5  86.72 ( 92.64)\n",
            "Epoch: [51][360/391]\tTime  0.167 ( 0.168)\tLoss 9.6060e-01 (1.0778e+00)\tAcc@1  72.66 ( 68.48)\tAcc@5  93.75 ( 92.51)\n",
            "Epoch: [51][390/391]\tTime  0.152 ( 0.168)\tLoss 1.4163e+00 (1.0811e+00)\tAcc@1  63.75 ( 68.41)\tAcc@5  83.75 ( 92.45)\n",
            "==> Train Accuracy: Acc@1 68.412 || Acc@5 92.454\n",
            "==> Test Accuracy:  Acc@1 57.380 || Acc@5 84.580\n",
            "==> 69.79 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 52, lr: 0.1 -----\n",
            "Epoch: [52][  0/391]\tTime  0.284 ( 0.284)\tLoss 9.7138e-01 (9.7138e-01)\tAcc@1  68.75 ( 68.75)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [52][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.0489e+00 (1.0055e+00)\tAcc@1  69.53 ( 69.91)\tAcc@5  95.31 ( 93.90)\n",
            "Epoch: [52][ 60/391]\tTime  0.165 ( 0.169)\tLoss 9.1923e-01 (1.0168e+00)\tAcc@1  75.00 ( 70.09)\tAcc@5  91.41 ( 93.55)\n",
            "Epoch: [52][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.1291e+00 (1.0165e+00)\tAcc@1  65.62 ( 70.22)\tAcc@5  91.41 ( 93.31)\n",
            "Epoch: [52][120/391]\tTime  0.170 ( 0.168)\tLoss 1.1359e+00 (1.0249e+00)\tAcc@1  67.97 ( 69.96)\tAcc@5  92.97 ( 93.29)\n",
            "Epoch: [52][150/391]\tTime  0.168 ( 0.168)\tLoss 1.1152e+00 (1.0320e+00)\tAcc@1  67.97 ( 69.84)\tAcc@5  89.84 ( 93.22)\n",
            "Epoch: [52][180/391]\tTime  0.167 ( 0.168)\tLoss 1.1604e+00 (1.0421e+00)\tAcc@1  64.84 ( 69.57)\tAcc@5  91.41 ( 93.08)\n",
            "Epoch: [52][210/391]\tTime  0.168 ( 0.168)\tLoss 9.7165e-01 (1.0502e+00)\tAcc@1  71.09 ( 69.36)\tAcc@5  95.31 ( 92.92)\n",
            "Epoch: [52][240/391]\tTime  0.168 ( 0.168)\tLoss 1.3105e+00 (1.0585e+00)\tAcc@1  63.28 ( 69.12)\tAcc@5  87.50 ( 92.76)\n",
            "Epoch: [52][270/391]\tTime  0.168 ( 0.168)\tLoss 1.0682e+00 (1.0588e+00)\tAcc@1  72.66 ( 69.10)\tAcc@5  92.19 ( 92.77)\n",
            "Epoch: [52][300/391]\tTime  0.169 ( 0.168)\tLoss 1.2650e+00 (1.0631e+00)\tAcc@1  61.72 ( 69.00)\tAcc@5  89.84 ( 92.69)\n",
            "Epoch: [52][330/391]\tTime  0.169 ( 0.168)\tLoss 1.0524e+00 (1.0680e+00)\tAcc@1  67.19 ( 68.86)\tAcc@5  92.97 ( 92.64)\n",
            "Epoch: [52][360/391]\tTime  0.167 ( 0.168)\tLoss 1.1454e+00 (1.0730e+00)\tAcc@1  65.62 ( 68.75)\tAcc@5  91.41 ( 92.59)\n",
            "Epoch: [52][390/391]\tTime  0.151 ( 0.168)\tLoss 1.1540e+00 (1.0791e+00)\tAcc@1  66.25 ( 68.52)\tAcc@5  95.00 ( 92.52)\n",
            "==> Train Accuracy: Acc@1 68.516 || Acc@5 92.522\n",
            "==> Test Accuracy:  Acc@1 56.450 || Acc@5 84.590\n",
            "==> 69.77 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 53, lr: 0.1 -----\n",
            "Epoch: [53][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.0301e+00 (1.0301e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [53][ 30/391]\tTime  0.171 ( 0.171)\tLoss 1.0426e+00 (1.0038e+00)\tAcc@1  66.41 ( 68.72)\tAcc@5  92.97 ( 93.85)\n",
            "Epoch: [53][ 60/391]\tTime  0.167 ( 0.169)\tLoss 7.4218e-01 (9.7174e-01)\tAcc@1  81.25 ( 70.67)\tAcc@5  97.66 ( 93.97)\n",
            "Epoch: [53][ 90/391]\tTime  0.168 ( 0.169)\tLoss 7.9110e-01 (9.8226e-01)\tAcc@1  79.69 ( 70.61)\tAcc@5  96.09 ( 93.80)\n",
            "Epoch: [53][120/391]\tTime  0.167 ( 0.168)\tLoss 9.6995e-01 (9.9165e-01)\tAcc@1  73.44 ( 70.38)\tAcc@5  92.19 ( 93.61)\n",
            "Epoch: [53][150/391]\tTime  0.168 ( 0.168)\tLoss 1.3457e+00 (1.0116e+00)\tAcc@1  61.72 ( 70.00)\tAcc@5  89.06 ( 93.44)\n",
            "Epoch: [53][180/391]\tTime  0.167 ( 0.168)\tLoss 9.0673e-01 (1.0264e+00)\tAcc@1  73.44 ( 69.71)\tAcc@5  92.19 ( 93.18)\n",
            "Epoch: [53][210/391]\tTime  0.166 ( 0.168)\tLoss 8.8151e-01 (1.0391e+00)\tAcc@1  75.78 ( 69.41)\tAcc@5  92.97 ( 92.96)\n",
            "Epoch: [53][240/391]\tTime  0.168 ( 0.168)\tLoss 8.1684e-01 (1.0507e+00)\tAcc@1  72.66 ( 69.19)\tAcc@5  95.31 ( 92.86)\n",
            "Epoch: [53][270/391]\tTime  0.169 ( 0.168)\tLoss 1.4298e+00 (1.0640e+00)\tAcc@1  57.81 ( 68.97)\tAcc@5  92.19 ( 92.70)\n",
            "Epoch: [53][300/391]\tTime  0.168 ( 0.168)\tLoss 1.2417e+00 (1.0733e+00)\tAcc@1  65.62 ( 68.76)\tAcc@5  87.50 ( 92.56)\n",
            "Epoch: [53][330/391]\tTime  0.168 ( 0.168)\tLoss 1.1703e+00 (1.0763e+00)\tAcc@1  70.31 ( 68.73)\tAcc@5  91.41 ( 92.50)\n",
            "Epoch: [53][360/391]\tTime  0.169 ( 0.168)\tLoss 9.5757e-01 (1.0804e+00)\tAcc@1  66.41 ( 68.58)\tAcc@5  94.53 ( 92.50)\n",
            "Epoch: [53][390/391]\tTime  0.149 ( 0.168)\tLoss 1.1480e+00 (1.0805e+00)\tAcc@1  66.25 ( 68.58)\tAcc@5  91.25 ( 92.49)\n",
            "==> Train Accuracy: Acc@1 68.584 || Acc@5 92.488\n",
            "==> Test Accuracy:  Acc@1 56.290 || Acc@5 83.820\n",
            "==> 69.68 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 54, lr: 0.1 -----\n",
            "Epoch: [54][  0/391]\tTime  0.286 ( 0.286)\tLoss 1.0066e+00 (1.0066e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [54][ 30/391]\tTime  0.169 ( 0.171)\tLoss 9.6927e-01 (9.3724e-01)\tAcc@1  71.09 ( 72.63)\tAcc@5  91.41 ( 94.00)\n",
            "Epoch: [54][ 60/391]\tTime  0.167 ( 0.169)\tLoss 7.9216e-01 (9.5645e-01)\tAcc@1  76.56 ( 72.44)\tAcc@5  98.44 ( 93.80)\n",
            "Epoch: [54][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.0288e+00 (9.7482e-01)\tAcc@1  71.88 ( 71.74)\tAcc@5  92.97 ( 93.65)\n",
            "Epoch: [54][120/391]\tTime  0.167 ( 0.168)\tLoss 7.2001e-01 (9.9005e-01)\tAcc@1  76.56 ( 71.29)\tAcc@5  95.31 ( 93.39)\n",
            "Epoch: [54][150/391]\tTime  0.165 ( 0.168)\tLoss 1.2243e+00 (1.0012e+00)\tAcc@1  61.72 ( 70.90)\tAcc@5  89.06 ( 93.32)\n",
            "Epoch: [54][180/391]\tTime  0.167 ( 0.168)\tLoss 1.1247e+00 (1.0179e+00)\tAcc@1  66.41 ( 70.39)\tAcc@5  89.06 ( 93.10)\n",
            "Epoch: [54][210/391]\tTime  0.167 ( 0.168)\tLoss 8.6697e-01 (1.0284e+00)\tAcc@1  71.88 ( 70.02)\tAcc@5  95.31 ( 92.99)\n",
            "Epoch: [54][240/391]\tTime  0.166 ( 0.168)\tLoss 1.2391e+00 (1.0382e+00)\tAcc@1  64.84 ( 69.73)\tAcc@5  89.06 ( 92.89)\n",
            "Epoch: [54][270/391]\tTime  0.169 ( 0.168)\tLoss 9.4448e-01 (1.0490e+00)\tAcc@1  74.22 ( 69.41)\tAcc@5  92.97 ( 92.76)\n",
            "Epoch: [54][300/391]\tTime  0.171 ( 0.168)\tLoss 1.1452e+00 (1.0622e+00)\tAcc@1  67.97 ( 69.12)\tAcc@5  93.75 ( 92.63)\n",
            "Epoch: [54][330/391]\tTime  0.167 ( 0.168)\tLoss 1.0245e+00 (1.0648e+00)\tAcc@1  73.44 ( 69.08)\tAcc@5  93.75 ( 92.62)\n",
            "Epoch: [54][360/391]\tTime  0.167 ( 0.168)\tLoss 1.1142e+00 (1.0694e+00)\tAcc@1  64.84 ( 68.93)\tAcc@5  89.84 ( 92.57)\n",
            "Epoch: [54][390/391]\tTime  0.151 ( 0.168)\tLoss 1.1669e+00 (1.0741e+00)\tAcc@1  66.25 ( 68.81)\tAcc@5  91.25 ( 92.53)\n",
            "==> Train Accuracy: Acc@1 68.806 || Acc@5 92.530\n",
            "==> Test Accuracy:  Acc@1 56.890 || Acc@5 83.900\n",
            "==> 69.72 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 55, lr: 0.1 -----\n",
            "Epoch: [55][  0/391]\tTime  0.275 ( 0.275)\tLoss 9.9805e-01 (9.9805e-01)\tAcc@1  69.53 ( 69.53)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [55][ 30/391]\tTime  0.168 ( 0.171)\tLoss 8.9687e-01 (9.7184e-01)\tAcc@1  70.31 ( 71.17)\tAcc@5  95.31 ( 93.75)\n",
            "Epoch: [55][ 60/391]\tTime  0.167 ( 0.170)\tLoss 1.1034e+00 (9.8707e-01)\tAcc@1  66.41 ( 71.13)\tAcc@5  92.97 ( 93.16)\n",
            "Epoch: [55][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.0415e+00 (9.9986e-01)\tAcc@1  70.31 ( 70.76)\tAcc@5  90.62 ( 92.93)\n",
            "Epoch: [55][120/391]\tTime  0.167 ( 0.169)\tLoss 1.1964e+00 (1.0184e+00)\tAcc@1  68.75 ( 70.27)\tAcc@5  89.84 ( 92.88)\n",
            "Epoch: [55][150/391]\tTime  0.168 ( 0.169)\tLoss 1.0853e+00 (1.0252e+00)\tAcc@1  67.19 ( 70.13)\tAcc@5  92.19 ( 92.75)\n",
            "Epoch: [55][180/391]\tTime  0.166 ( 0.169)\tLoss 1.3555e+00 (1.0377e+00)\tAcc@1  62.50 ( 69.63)\tAcc@5  86.72 ( 92.75)\n",
            "Epoch: [55][210/391]\tTime  0.167 ( 0.168)\tLoss 1.1896e+00 (1.0489e+00)\tAcc@1  66.41 ( 69.28)\tAcc@5  92.97 ( 92.67)\n",
            "Epoch: [55][240/391]\tTime  0.168 ( 0.168)\tLoss 1.2319e+00 (1.0624e+00)\tAcc@1  64.84 ( 68.89)\tAcc@5  94.53 ( 92.58)\n",
            "Epoch: [55][270/391]\tTime  0.167 ( 0.168)\tLoss 1.3067e+00 (1.0661e+00)\tAcc@1  60.94 ( 68.78)\tAcc@5  91.41 ( 92.54)\n",
            "Epoch: [55][300/391]\tTime  0.166 ( 0.168)\tLoss 1.2844e+00 (1.0701e+00)\tAcc@1  57.03 ( 68.71)\tAcc@5  89.06 ( 92.44)\n",
            "Epoch: [55][330/391]\tTime  0.168 ( 0.168)\tLoss 9.8019e-01 (1.0717e+00)\tAcc@1  68.75 ( 68.65)\tAcc@5  95.31 ( 92.51)\n",
            "Epoch: [55][360/391]\tTime  0.168 ( 0.168)\tLoss 1.1886e+00 (1.0724e+00)\tAcc@1  67.19 ( 68.65)\tAcc@5  89.84 ( 92.49)\n",
            "Epoch: [55][390/391]\tTime  0.149 ( 0.168)\tLoss 8.8455e-01 (1.0809e+00)\tAcc@1  65.00 ( 68.42)\tAcc@5  96.25 ( 92.42)\n",
            "==> Train Accuracy: Acc@1 68.420 || Acc@5 92.420\n",
            "==> Test Accuracy:  Acc@1 53.490 || Acc@5 81.080\n",
            "==> 69.80 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 56, lr: 0.1 -----\n",
            "Epoch: [56][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.0590e+00 (1.0590e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [56][ 30/391]\tTime  0.165 ( 0.171)\tLoss 9.0456e-01 (9.8170e-01)\tAcc@1  71.88 ( 70.39)\tAcc@5  93.75 ( 93.98)\n",
            "Epoch: [56][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.0601e+00 (1.0020e+00)\tAcc@1  72.66 ( 70.13)\tAcc@5  92.19 ( 93.69)\n",
            "Epoch: [56][ 90/391]\tTime  0.167 ( 0.169)\tLoss 9.2663e-01 (1.0100e+00)\tAcc@1  71.88 ( 70.24)\tAcc@5  93.75 ( 93.46)\n",
            "Epoch: [56][120/391]\tTime  0.169 ( 0.168)\tLoss 9.6646e-01 (1.0146e+00)\tAcc@1  71.09 ( 70.16)\tAcc@5  94.53 ( 93.35)\n",
            "Epoch: [56][150/391]\tTime  0.166 ( 0.168)\tLoss 1.2278e+00 (1.0216e+00)\tAcc@1  61.72 ( 70.15)\tAcc@5  90.62 ( 93.25)\n",
            "Epoch: [56][180/391]\tTime  0.168 ( 0.168)\tLoss 1.0238e+00 (1.0303e+00)\tAcc@1  68.75 ( 69.83)\tAcc@5  91.41 ( 93.06)\n",
            "Epoch: [56][210/391]\tTime  0.168 ( 0.168)\tLoss 9.9301e-01 (1.0398e+00)\tAcc@1  71.09 ( 69.45)\tAcc@5  94.53 ( 92.96)\n",
            "Epoch: [56][240/391]\tTime  0.167 ( 0.168)\tLoss 1.0567e+00 (1.0475e+00)\tAcc@1  69.53 ( 69.29)\tAcc@5  93.75 ( 92.84)\n",
            "Epoch: [56][270/391]\tTime  0.167 ( 0.168)\tLoss 8.7805e-01 (1.0553e+00)\tAcc@1  77.34 ( 69.07)\tAcc@5  92.97 ( 92.73)\n",
            "Epoch: [56][300/391]\tTime  0.168 ( 0.168)\tLoss 1.1175e+00 (1.0586e+00)\tAcc@1  67.19 ( 69.03)\tAcc@5  92.19 ( 92.65)\n",
            "Epoch: [56][330/391]\tTime  0.168 ( 0.168)\tLoss 1.0346e+00 (1.0636e+00)\tAcc@1  73.44 ( 68.92)\tAcc@5  92.19 ( 92.54)\n",
            "Epoch: [56][360/391]\tTime  0.167 ( 0.168)\tLoss 1.2416e+00 (1.0698e+00)\tAcc@1  53.91 ( 68.77)\tAcc@5  92.19 ( 92.48)\n",
            "Epoch: [56][390/391]\tTime  0.149 ( 0.168)\tLoss 9.0710e-01 (1.0750e+00)\tAcc@1  68.75 ( 68.66)\tAcc@5  97.50 ( 92.39)\n",
            "==> Train Accuracy: Acc@1 68.662 || Acc@5 92.394\n",
            "==> Test Accuracy:  Acc@1 53.650 || Acc@5 82.600\n",
            "==> 69.71 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 57, lr: 0.1 -----\n",
            "Epoch: [57][  0/391]\tTime  0.271 ( 0.271)\tLoss 8.8734e-01 (8.8734e-01)\tAcc@1  69.53 ( 69.53)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [57][ 30/391]\tTime  0.167 ( 0.170)\tLoss 9.9011e-01 (9.7743e-01)\tAcc@1  71.09 ( 72.00)\tAcc@5  95.31 ( 93.93)\n",
            "Epoch: [57][ 60/391]\tTime  0.172 ( 0.169)\tLoss 9.1087e-01 (9.7230e-01)\tAcc@1  73.44 ( 71.55)\tAcc@5  92.97 ( 94.01)\n",
            "Epoch: [57][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.1217e+00 (1.0005e+00)\tAcc@1  63.28 ( 70.82)\tAcc@5  92.97 ( 93.52)\n",
            "Epoch: [57][120/391]\tTime  0.168 ( 0.168)\tLoss 1.1642e+00 (1.0159e+00)\tAcc@1  71.09 ( 70.38)\tAcc@5  91.41 ( 93.26)\n",
            "Epoch: [57][150/391]\tTime  0.173 ( 0.168)\tLoss 1.4687e+00 (1.0275e+00)\tAcc@1  60.94 ( 69.99)\tAcc@5  86.72 ( 93.08)\n",
            "Epoch: [57][180/391]\tTime  0.169 ( 0.168)\tLoss 1.2306e+00 (1.0379e+00)\tAcc@1  63.28 ( 69.64)\tAcc@5  91.41 ( 93.04)\n",
            "Epoch: [57][210/391]\tTime  0.170 ( 0.168)\tLoss 9.9719e-01 (1.0421e+00)\tAcc@1  71.88 ( 69.52)\tAcc@5  92.97 ( 92.94)\n",
            "Epoch: [57][240/391]\tTime  0.165 ( 0.168)\tLoss 1.1271e+00 (1.0497e+00)\tAcc@1  68.75 ( 69.25)\tAcc@5  89.84 ( 92.89)\n",
            "Epoch: [57][270/391]\tTime  0.169 ( 0.168)\tLoss 1.1660e+00 (1.0557e+00)\tAcc@1  61.72 ( 69.07)\tAcc@5  92.19 ( 92.85)\n",
            "Epoch: [57][300/391]\tTime  0.167 ( 0.168)\tLoss 1.0564e+00 (1.0561e+00)\tAcc@1  69.53 ( 69.04)\tAcc@5  92.97 ( 92.83)\n",
            "Epoch: [57][330/391]\tTime  0.169 ( 0.168)\tLoss 1.1029e+00 (1.0595e+00)\tAcc@1  68.75 ( 68.97)\tAcc@5  90.62 ( 92.78)\n",
            "Epoch: [57][360/391]\tTime  0.167 ( 0.168)\tLoss 1.2587e+00 (1.0632e+00)\tAcc@1  63.28 ( 68.84)\tAcc@5  90.62 ( 92.68)\n",
            "Epoch: [57][390/391]\tTime  0.149 ( 0.168)\tLoss 1.1896e+00 (1.0689e+00)\tAcc@1  70.00 ( 68.71)\tAcc@5  92.50 ( 92.62)\n",
            "==> Train Accuracy: Acc@1 68.708 || Acc@5 92.620\n",
            "==> Test Accuracy:  Acc@1 54.580 || Acc@5 82.960\n",
            "==> 69.83 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 58, lr: 0.1 -----\n",
            "Epoch: [58][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.1151e+00 (1.1151e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [58][ 30/391]\tTime  0.166 ( 0.170)\tLoss 1.1878e+00 (1.0170e+00)\tAcc@1  63.28 ( 70.06)\tAcc@5  91.41 ( 93.15)\n",
            "Epoch: [58][ 60/391]\tTime  0.167 ( 0.169)\tLoss 9.5673e-01 (1.0007e+00)\tAcc@1  73.44 ( 70.68)\tAcc@5  93.75 ( 93.11)\n",
            "Epoch: [58][ 90/391]\tTime  0.168 ( 0.168)\tLoss 1.0203e+00 (1.0155e+00)\tAcc@1  72.66 ( 70.38)\tAcc@5  90.62 ( 93.04)\n",
            "Epoch: [58][120/391]\tTime  0.167 ( 0.168)\tLoss 1.1527e+00 (1.0291e+00)\tAcc@1  66.41 ( 70.03)\tAcc@5  89.06 ( 92.83)\n",
            "Epoch: [58][150/391]\tTime  0.167 ( 0.168)\tLoss 1.0481e+00 (1.0306e+00)\tAcc@1  70.31 ( 70.00)\tAcc@5  92.19 ( 92.79)\n",
            "Epoch: [58][180/391]\tTime  0.167 ( 0.168)\tLoss 9.8959e-01 (1.0366e+00)\tAcc@1  74.22 ( 69.84)\tAcc@5  91.41 ( 92.76)\n",
            "Epoch: [58][210/391]\tTime  0.167 ( 0.168)\tLoss 1.1838e+00 (1.0378e+00)\tAcc@1  65.62 ( 69.73)\tAcc@5  93.75 ( 92.82)\n",
            "Epoch: [58][240/391]\tTime  0.169 ( 0.168)\tLoss 9.1800e-01 (1.0455e+00)\tAcc@1  71.88 ( 69.52)\tAcc@5  93.75 ( 92.74)\n",
            "Epoch: [58][270/391]\tTime  0.168 ( 0.168)\tLoss 1.0068e+00 (1.0505e+00)\tAcc@1  68.75 ( 69.35)\tAcc@5  96.88 ( 92.69)\n",
            "Epoch: [58][300/391]\tTime  0.167 ( 0.168)\tLoss 7.9651e-01 (1.0569e+00)\tAcc@1  80.47 ( 69.17)\tAcc@5  95.31 ( 92.62)\n",
            "Epoch: [58][330/391]\tTime  0.168 ( 0.168)\tLoss 1.0976e+00 (1.0609e+00)\tAcc@1  69.53 ( 69.06)\tAcc@5  91.41 ( 92.57)\n",
            "Epoch: [58][360/391]\tTime  0.168 ( 0.168)\tLoss 1.0097e+00 (1.0653e+00)\tAcc@1  74.22 ( 68.96)\tAcc@5  95.31 ( 92.55)\n",
            "Epoch: [58][390/391]\tTime  0.151 ( 0.168)\tLoss 1.1982e+00 (1.0718e+00)\tAcc@1  67.50 ( 68.81)\tAcc@5  92.50 ( 92.43)\n",
            "==> Train Accuracy: Acc@1 68.810 || Acc@5 92.426\n",
            "==> Test Accuracy:  Acc@1 57.770 || Acc@5 85.950\n",
            "==> 69.72 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 59, lr: 0.1 -----\n",
            "Epoch: [59][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.0380e+00 (1.0380e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [59][ 30/391]\tTime  0.169 ( 0.171)\tLoss 9.2455e-01 (9.8460e-01)\tAcc@1  71.88 ( 71.42)\tAcc@5  93.75 ( 93.88)\n",
            "Epoch: [59][ 60/391]\tTime  0.166 ( 0.169)\tLoss 1.2173e+00 (9.7719e-01)\tAcc@1  62.50 ( 71.06)\tAcc@5  89.84 ( 93.69)\n",
            "Epoch: [59][ 90/391]\tTime  0.167 ( 0.168)\tLoss 8.7278e-01 (1.0071e+00)\tAcc@1  75.78 ( 70.27)\tAcc@5  95.31 ( 93.28)\n",
            "Epoch: [59][120/391]\tTime  0.166 ( 0.168)\tLoss 1.0855e+00 (1.0131e+00)\tAcc@1  72.66 ( 70.20)\tAcc@5  92.97 ( 93.33)\n",
            "Epoch: [59][150/391]\tTime  0.168 ( 0.168)\tLoss 1.0842e+00 (1.0212e+00)\tAcc@1  67.97 ( 70.08)\tAcc@5  91.41 ( 93.24)\n",
            "Epoch: [59][180/391]\tTime  0.171 ( 0.168)\tLoss 8.9463e-01 (1.0256e+00)\tAcc@1  73.44 ( 69.95)\tAcc@5  96.88 ( 93.16)\n",
            "Epoch: [59][210/391]\tTime  0.168 ( 0.168)\tLoss 1.0499e+00 (1.0345e+00)\tAcc@1  66.41 ( 69.49)\tAcc@5  93.75 ( 93.11)\n",
            "Epoch: [59][240/391]\tTime  0.168 ( 0.168)\tLoss 1.0527e+00 (1.0411e+00)\tAcc@1  75.00 ( 69.46)\tAcc@5  91.41 ( 93.00)\n",
            "Epoch: [59][270/391]\tTime  0.163 ( 0.168)\tLoss 1.0741e+00 (1.0490e+00)\tAcc@1  67.97 ( 69.27)\tAcc@5  92.19 ( 92.87)\n",
            "Epoch: [59][300/391]\tTime  0.168 ( 0.168)\tLoss 1.1092e+00 (1.0497e+00)\tAcc@1  65.62 ( 69.28)\tAcc@5  94.53 ( 92.89)\n",
            "Epoch: [59][330/391]\tTime  0.169 ( 0.168)\tLoss 9.8300e-01 (1.0541e+00)\tAcc@1  74.22 ( 69.10)\tAcc@5  92.19 ( 92.91)\n",
            "Epoch: [59][360/391]\tTime  0.169 ( 0.168)\tLoss 1.2633e+00 (1.0574e+00)\tAcc@1  63.28 ( 68.98)\tAcc@5  89.06 ( 92.89)\n",
            "Epoch: [59][390/391]\tTime  0.154 ( 0.168)\tLoss 1.2844e+00 (1.0638e+00)\tAcc@1  68.75 ( 68.89)\tAcc@5  93.75 ( 92.78)\n",
            "==> Train Accuracy: Acc@1 68.894 || Acc@5 92.782\n",
            "==> Test Accuracy:  Acc@1 59.070 || Acc@5 85.870\n",
            "==> 69.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 60, lr: 0.020000000000000004 -----\n",
            "Epoch: [60][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.1566e+00 (1.1566e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [60][ 30/391]\tTime  0.166 ( 0.171)\tLoss 6.0890e-01 (8.2749e-01)\tAcc@1  80.47 ( 75.45)\tAcc@5  98.44 ( 95.69)\n",
            "Epoch: [60][ 60/391]\tTime  0.172 ( 0.169)\tLoss 5.4589e-01 (7.5226e-01)\tAcc@1  84.38 ( 77.89)\tAcc@5  98.44 ( 96.23)\n",
            "Epoch: [60][ 90/391]\tTime  0.167 ( 0.169)\tLoss 6.4640e-01 (7.1961e-01)\tAcc@1  79.69 ( 79.06)\tAcc@5  98.44 ( 96.45)\n",
            "Epoch: [60][120/391]\tTime  0.163 ( 0.168)\tLoss 6.5867e-01 (6.9069e-01)\tAcc@1  81.25 ( 79.71)\tAcc@5  94.53 ( 96.62)\n",
            "Epoch: [60][150/391]\tTime  0.168 ( 0.168)\tLoss 6.9876e-01 (6.7197e-01)\tAcc@1  79.69 ( 80.29)\tAcc@5  96.09 ( 96.74)\n",
            "Epoch: [60][180/391]\tTime  0.167 ( 0.168)\tLoss 5.3261e-01 (6.5400e-01)\tAcc@1  82.81 ( 80.80)\tAcc@5  96.88 ( 96.84)\n",
            "Epoch: [60][210/391]\tTime  0.168 ( 0.168)\tLoss 6.1796e-01 (6.4269e-01)\tAcc@1  82.03 ( 81.04)\tAcc@5  96.09 ( 96.93)\n",
            "Epoch: [60][240/391]\tTime  0.167 ( 0.168)\tLoss 5.9950e-01 (6.3008e-01)\tAcc@1  78.91 ( 81.41)\tAcc@5  97.66 ( 97.02)\n",
            "Epoch: [60][270/391]\tTime  0.169 ( 0.168)\tLoss 5.6119e-01 (6.2257e-01)\tAcc@1  83.59 ( 81.62)\tAcc@5  97.66 ( 97.10)\n",
            "Epoch: [60][300/391]\tTime  0.167 ( 0.168)\tLoss 4.9418e-01 (6.1447e-01)\tAcc@1  86.72 ( 81.74)\tAcc@5  99.22 ( 97.20)\n",
            "Epoch: [60][330/391]\tTime  0.167 ( 0.168)\tLoss 5.5079e-01 (6.1216e-01)\tAcc@1  85.16 ( 81.77)\tAcc@5  97.66 ( 97.21)\n",
            "Epoch: [60][360/391]\tTime  0.166 ( 0.168)\tLoss 4.5258e-01 (6.0772e-01)\tAcc@1  85.16 ( 81.88)\tAcc@5  97.66 ( 97.24)\n",
            "Epoch: [60][390/391]\tTime  0.151 ( 0.168)\tLoss 4.6482e-01 (5.9942e-01)\tAcc@1  87.50 ( 82.14)\tAcc@5  97.50 ( 97.32)\n",
            "==> Train Accuracy: Acc@1 82.142 || Acc@5 97.320\n",
            "==> Test Accuracy:  Acc@1 72.650 || Acc@5 93.030\n",
            "==> 69.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 61, lr: 0.020000000000000004 -----\n",
            "Epoch: [61][  0/391]\tTime  0.301 ( 0.301)\tLoss 4.0316e-01 (4.0316e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [61][ 30/391]\tTime  0.168 ( 0.171)\tLoss 3.4271e-01 (4.5058e-01)\tAcc@1  88.28 ( 86.34)\tAcc@5 100.00 ( 98.44)\n",
            "Epoch: [61][ 60/391]\tTime  0.169 ( 0.169)\tLoss 4.5987e-01 (4.3514e-01)\tAcc@1  85.16 ( 86.80)\tAcc@5  98.44 ( 98.50)\n",
            "Epoch: [61][ 90/391]\tTime  0.174 ( 0.169)\tLoss 3.8148e-01 (4.3125e-01)\tAcc@1  89.06 ( 87.11)\tAcc@5  97.66 ( 98.54)\n",
            "Epoch: [61][120/391]\tTime  0.167 ( 0.168)\tLoss 5.3926e-01 (4.2860e-01)\tAcc@1  81.25 ( 87.28)\tAcc@5  98.44 ( 98.59)\n",
            "Epoch: [61][150/391]\tTime  0.168 ( 0.168)\tLoss 4.7629e-01 (4.3107e-01)\tAcc@1  85.94 ( 87.22)\tAcc@5  97.66 ( 98.57)\n",
            "Epoch: [61][180/391]\tTime  0.168 ( 0.168)\tLoss 5.4727e-01 (4.3162e-01)\tAcc@1  85.94 ( 87.18)\tAcc@5  96.88 ( 98.55)\n",
            "Epoch: [61][210/391]\tTime  0.167 ( 0.168)\tLoss 3.8361e-01 (4.3266e-01)\tAcc@1  88.28 ( 87.10)\tAcc@5  98.44 ( 98.55)\n",
            "Epoch: [61][240/391]\tTime  0.168 ( 0.168)\tLoss 3.8086e-01 (4.3418e-01)\tAcc@1  89.06 ( 87.00)\tAcc@5  99.22 ( 98.51)\n",
            "Epoch: [61][270/391]\tTime  0.169 ( 0.168)\tLoss 4.5534e-01 (4.3407e-01)\tAcc@1  87.50 ( 87.02)\tAcc@5  98.44 ( 98.48)\n",
            "Epoch: [61][300/391]\tTime  0.165 ( 0.168)\tLoss 4.0176e-01 (4.3239e-01)\tAcc@1  85.94 ( 87.04)\tAcc@5 100.00 ( 98.52)\n",
            "Epoch: [61][330/391]\tTime  0.170 ( 0.168)\tLoss 4.4729e-01 (4.3277e-01)\tAcc@1  88.28 ( 87.01)\tAcc@5  98.44 ( 98.52)\n",
            "Epoch: [61][360/391]\tTime  0.169 ( 0.168)\tLoss 3.0488e-01 (4.3462e-01)\tAcc@1  89.06 ( 86.96)\tAcc@5  99.22 ( 98.49)\n",
            "Epoch: [61][390/391]\tTime  0.148 ( 0.168)\tLoss 5.6892e-01 (4.3669e-01)\tAcc@1  87.50 ( 86.91)\tAcc@5  95.00 ( 98.45)\n",
            "==> Train Accuracy: Acc@1 86.914 || Acc@5 98.454\n",
            "==> Test Accuracy:  Acc@1 72.500 || Acc@5 93.110\n",
            "==> 69.66 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 62, lr: 0.020000000000000004 -----\n",
            "Epoch: [62][  0/391]\tTime  0.284 ( 0.284)\tLoss 3.6413e-01 (3.6413e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [62][ 30/391]\tTime  0.168 ( 0.171)\tLoss 3.1705e-01 (3.4153e-01)\tAcc@1  90.62 ( 90.10)\tAcc@5  98.44 ( 99.17)\n",
            "Epoch: [62][ 60/391]\tTime  0.169 ( 0.170)\tLoss 2.9758e-01 (3.3859e-01)\tAcc@1  92.97 ( 90.07)\tAcc@5 100.00 ( 99.26)\n",
            "Epoch: [62][ 90/391]\tTime  0.166 ( 0.169)\tLoss 3.1737e-01 (3.4732e-01)\tAcc@1  89.06 ( 89.71)\tAcc@5 100.00 ( 99.21)\n",
            "Epoch: [62][120/391]\tTime  0.168 ( 0.169)\tLoss 3.4285e-01 (3.4897e-01)\tAcc@1  86.72 ( 89.61)\tAcc@5 100.00 ( 99.16)\n",
            "Epoch: [62][150/391]\tTime  0.169 ( 0.169)\tLoss 3.3742e-01 (3.5175e-01)\tAcc@1  93.75 ( 89.60)\tAcc@5  99.22 ( 99.14)\n",
            "Epoch: [62][180/391]\tTime  0.168 ( 0.169)\tLoss 3.2865e-01 (3.5386e-01)\tAcc@1  90.62 ( 89.52)\tAcc@5 100.00 ( 99.12)\n",
            "Epoch: [62][210/391]\tTime  0.167 ( 0.168)\tLoss 3.2335e-01 (3.5904e-01)\tAcc@1  89.84 ( 89.29)\tAcc@5  98.44 ( 99.08)\n",
            "Epoch: [62][240/391]\tTime  0.167 ( 0.168)\tLoss 2.4839e-01 (3.6178e-01)\tAcc@1  92.19 ( 89.09)\tAcc@5  99.22 ( 99.08)\n",
            "Epoch: [62][270/391]\tTime  0.167 ( 0.168)\tLoss 4.6797e-01 (3.6196e-01)\tAcc@1  83.59 ( 89.04)\tAcc@5 100.00 ( 99.08)\n",
            "Epoch: [62][300/391]\tTime  0.166 ( 0.168)\tLoss 3.9012e-01 (3.6540e-01)\tAcc@1  86.72 ( 88.87)\tAcc@5 100.00 ( 99.06)\n",
            "Epoch: [62][330/391]\tTime  0.169 ( 0.168)\tLoss 2.3171e-01 (3.6635e-01)\tAcc@1  92.97 ( 88.87)\tAcc@5 100.00 ( 99.04)\n",
            "Epoch: [62][360/391]\tTime  0.167 ( 0.168)\tLoss 4.1249e-01 (3.6785e-01)\tAcc@1  89.06 ( 88.81)\tAcc@5  98.44 ( 99.02)\n",
            "Epoch: [62][390/391]\tTime  0.150 ( 0.168)\tLoss 3.4733e-01 (3.6843e-01)\tAcc@1  91.25 ( 88.76)\tAcc@5  98.75 ( 99.03)\n",
            "==> Train Accuracy: Acc@1 88.762 || Acc@5 99.028\n",
            "==> Test Accuracy:  Acc@1 72.840 || Acc@5 93.060\n",
            "==> 69.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 63, lr: 0.020000000000000004 -----\n",
            "Epoch: [63][  0/391]\tTime  0.285 ( 0.285)\tLoss 3.5576e-01 (3.5576e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [63][ 30/391]\tTime  0.166 ( 0.170)\tLoss 3.4554e-01 (2.9861e-01)\tAcc@1  88.28 ( 90.88)\tAcc@5 100.00 ( 99.45)\n",
            "Epoch: [63][ 60/391]\tTime  0.168 ( 0.169)\tLoss 3.7640e-01 (3.0131e-01)\tAcc@1  90.62 ( 91.14)\tAcc@5  99.22 ( 99.30)\n",
            "Epoch: [63][ 90/391]\tTime  0.168 ( 0.168)\tLoss 3.8464e-01 (3.0598e-01)\tAcc@1  89.06 ( 90.98)\tAcc@5  98.44 ( 99.30)\n",
            "Epoch: [63][120/391]\tTime  0.166 ( 0.168)\tLoss 3.2065e-01 (3.0835e-01)\tAcc@1  88.28 ( 90.69)\tAcc@5  98.44 ( 99.30)\n",
            "Epoch: [63][150/391]\tTime  0.168 ( 0.168)\tLoss 3.6069e-01 (3.1079e-01)\tAcc@1  87.50 ( 90.60)\tAcc@5 100.00 ( 99.30)\n",
            "Epoch: [63][180/391]\tTime  0.168 ( 0.168)\tLoss 2.7943e-01 (3.0833e-01)\tAcc@1  92.97 ( 90.69)\tAcc@5  98.44 ( 99.33)\n",
            "Epoch: [63][210/391]\tTime  0.167 ( 0.168)\tLoss 2.7711e-01 (3.0844e-01)\tAcc@1  92.19 ( 90.61)\tAcc@5  99.22 ( 99.33)\n",
            "Epoch: [63][240/391]\tTime  0.168 ( 0.168)\tLoss 1.6946e-01 (3.0979e-01)\tAcc@1  95.31 ( 90.58)\tAcc@5 100.00 ( 99.33)\n",
            "Epoch: [63][270/391]\tTime  0.168 ( 0.168)\tLoss 3.2908e-01 (3.1179e-01)\tAcc@1  89.84 ( 90.53)\tAcc@5  99.22 ( 99.30)\n",
            "Epoch: [63][300/391]\tTime  0.169 ( 0.168)\tLoss 3.4546e-01 (3.1306e-01)\tAcc@1  89.06 ( 90.51)\tAcc@5  98.44 ( 99.27)\n",
            "Epoch: [63][330/391]\tTime  0.166 ( 0.168)\tLoss 2.9070e-01 (3.1636e-01)\tAcc@1  91.41 ( 90.39)\tAcc@5  99.22 ( 99.27)\n",
            "Epoch: [63][360/391]\tTime  0.168 ( 0.168)\tLoss 3.4551e-01 (3.1761e-01)\tAcc@1  87.50 ( 90.30)\tAcc@5  98.44 ( 99.26)\n",
            "Epoch: [63][390/391]\tTime  0.150 ( 0.168)\tLoss 3.2862e-01 (3.1763e-01)\tAcc@1  88.75 ( 90.31)\tAcc@5 100.00 ( 99.26)\n",
            "==> Train Accuracy: Acc@1 90.312 || Acc@5 99.264\n",
            "==> Test Accuracy:  Acc@1 72.950 || Acc@5 92.950\n",
            "==> 69.70 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 64, lr: 0.020000000000000004 -----\n",
            "Epoch: [64][  0/391]\tTime  0.277 ( 0.277)\tLoss 2.0347e-01 (2.0347e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [64][ 30/391]\tTime  0.168 ( 0.170)\tLoss 2.2349e-01 (2.6988e-01)\tAcc@1  91.41 ( 92.14)\tAcc@5  99.22 ( 99.45)\n",
            "Epoch: [64][ 60/391]\tTime  0.167 ( 0.169)\tLoss 2.1726e-01 (2.6631e-01)\tAcc@1  95.31 ( 92.25)\tAcc@5 100.00 ( 99.49)\n",
            "Epoch: [64][ 90/391]\tTime  0.168 ( 0.168)\tLoss 3.5926e-01 (2.6669e-01)\tAcc@1  87.50 ( 92.33)\tAcc@5  98.44 ( 99.45)\n",
            "Epoch: [64][120/391]\tTime  0.168 ( 0.168)\tLoss 3.6110e-01 (2.6292e-01)\tAcc@1  87.50 ( 92.43)\tAcc@5  99.22 ( 99.50)\n",
            "Epoch: [64][150/391]\tTime  0.169 ( 0.168)\tLoss 2.4631e-01 (2.6522e-01)\tAcc@1  95.31 ( 92.28)\tAcc@5 100.00 ( 99.53)\n",
            "Epoch: [64][180/391]\tTime  0.168 ( 0.168)\tLoss 2.6527e-01 (2.6877e-01)\tAcc@1  91.41 ( 92.10)\tAcc@5 100.00 ( 99.50)\n",
            "Epoch: [64][210/391]\tTime  0.167 ( 0.168)\tLoss 2.1788e-01 (2.7199e-01)\tAcc@1  91.41 ( 91.94)\tAcc@5 100.00 ( 99.51)\n",
            "Epoch: [64][240/391]\tTime  0.169 ( 0.168)\tLoss 2.6961e-01 (2.7276e-01)\tAcc@1  92.19 ( 91.91)\tAcc@5 100.00 ( 99.51)\n",
            "Epoch: [64][270/391]\tTime  0.166 ( 0.168)\tLoss 2.6304e-01 (2.7516e-01)\tAcc@1  89.84 ( 91.82)\tAcc@5 100.00 ( 99.50)\n",
            "Epoch: [64][300/391]\tTime  0.168 ( 0.168)\tLoss 2.8806e-01 (2.7674e-01)\tAcc@1  93.75 ( 91.75)\tAcc@5 100.00 ( 99.52)\n",
            "Epoch: [64][330/391]\tTime  0.170 ( 0.168)\tLoss 3.3140e-01 (2.7924e-01)\tAcc@1  87.50 ( 91.61)\tAcc@5 100.00 ( 99.49)\n",
            "Epoch: [64][360/391]\tTime  0.168 ( 0.168)\tLoss 3.8778e-01 (2.8198e-01)\tAcc@1  88.28 ( 91.51)\tAcc@5  98.44 ( 99.48)\n",
            "Epoch: [64][390/391]\tTime  0.149 ( 0.168)\tLoss 4.5901e-01 (2.8581e-01)\tAcc@1  87.50 ( 91.36)\tAcc@5  96.25 ( 99.44)\n",
            "==> Train Accuracy: Acc@1 91.358 || Acc@5 99.442\n",
            "==> Test Accuracy:  Acc@1 71.190 || Acc@5 92.440\n",
            "==> 69.82 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 65, lr: 0.020000000000000004 -----\n",
            "Epoch: [65][  0/391]\tTime  0.287 ( 0.287)\tLoss 2.2690e-01 (2.2690e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [65][ 30/391]\tTime  0.167 ( 0.171)\tLoss 2.6735e-01 (2.4365e-01)\tAcc@1  91.41 ( 93.04)\tAcc@5  99.22 ( 99.57)\n",
            "Epoch: [65][ 60/391]\tTime  0.167 ( 0.169)\tLoss 2.5551e-01 (2.3850e-01)\tAcc@1  90.62 ( 93.15)\tAcc@5  98.44 ( 99.60)\n",
            "Epoch: [65][ 90/391]\tTime  0.167 ( 0.168)\tLoss 3.1497e-01 (2.4136e-01)\tAcc@1  90.62 ( 93.10)\tAcc@5 100.00 ( 99.57)\n",
            "Epoch: [65][120/391]\tTime  0.169 ( 0.168)\tLoss 1.7700e-01 (2.4315e-01)\tAcc@1  94.53 ( 93.02)\tAcc@5 100.00 ( 99.61)\n",
            "Epoch: [65][150/391]\tTime  0.165 ( 0.168)\tLoss 2.3621e-01 (2.4545e-01)\tAcc@1  92.97 ( 92.85)\tAcc@5  99.22 ( 99.60)\n",
            "Epoch: [65][180/391]\tTime  0.167 ( 0.168)\tLoss 2.5133e-01 (2.4745e-01)\tAcc@1  92.97 ( 92.74)\tAcc@5  99.22 ( 99.61)\n",
            "Epoch: [65][210/391]\tTime  0.168 ( 0.168)\tLoss 2.1612e-01 (2.4745e-01)\tAcc@1  95.31 ( 92.66)\tAcc@5 100.00 ( 99.63)\n",
            "Epoch: [65][240/391]\tTime  0.166 ( 0.168)\tLoss 3.2606e-01 (2.5139e-01)\tAcc@1  89.84 ( 92.51)\tAcc@5  99.22 ( 99.62)\n",
            "Epoch: [65][270/391]\tTime  0.168 ( 0.168)\tLoss 1.4865e-01 (2.5246e-01)\tAcc@1  96.88 ( 92.45)\tAcc@5 100.00 ( 99.62)\n",
            "Epoch: [65][300/391]\tTime  0.168 ( 0.168)\tLoss 2.4654e-01 (2.5420e-01)\tAcc@1  92.97 ( 92.33)\tAcc@5  99.22 ( 99.60)\n",
            "Epoch: [65][330/391]\tTime  0.166 ( 0.167)\tLoss 1.8013e-01 (2.5585e-01)\tAcc@1  95.31 ( 92.26)\tAcc@5 100.00 ( 99.60)\n",
            "Epoch: [65][360/391]\tTime  0.169 ( 0.167)\tLoss 3.4993e-01 (2.6018e-01)\tAcc@1  89.06 ( 92.14)\tAcc@5  99.22 ( 99.58)\n",
            "Epoch: [65][390/391]\tTime  0.151 ( 0.167)\tLoss 3.1686e-01 (2.6206e-01)\tAcc@1  88.75 ( 92.03)\tAcc@5  98.75 ( 99.58)\n",
            "==> Train Accuracy: Acc@1 92.034 || Acc@5 99.578\n",
            "==> Test Accuracy:  Acc@1 71.430 || Acc@5 92.260\n",
            "==> 69.61 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 66, lr: 0.020000000000000004 -----\n",
            "Epoch: [66][  0/391]\tTime  0.299 ( 0.299)\tLoss 2.3230e-01 (2.3230e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [66][ 30/391]\tTime  0.168 ( 0.171)\tLoss 2.1242e-01 (2.2555e-01)\tAcc@1  94.53 ( 93.52)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [66][ 60/391]\tTime  0.166 ( 0.169)\tLoss 2.4463e-01 (2.2541e-01)\tAcc@1  92.19 ( 93.65)\tAcc@5 100.00 ( 99.67)\n",
            "Epoch: [66][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.4257e-01 (2.2120e-01)\tAcc@1  95.31 ( 93.72)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [66][120/391]\tTime  0.168 ( 0.168)\tLoss 1.4438e-01 (2.2391e-01)\tAcc@1  98.44 ( 93.45)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [66][150/391]\tTime  0.169 ( 0.168)\tLoss 2.6685e-01 (2.2623e-01)\tAcc@1  91.41 ( 93.29)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [66][180/391]\tTime  0.167 ( 0.168)\tLoss 2.1847e-01 (2.2813e-01)\tAcc@1  95.31 ( 93.15)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [66][210/391]\tTime  0.169 ( 0.168)\tLoss 2.0421e-01 (2.2974e-01)\tAcc@1  92.97 ( 93.05)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [66][240/391]\tTime  0.167 ( 0.168)\tLoss 3.3889e-01 (2.3070e-01)\tAcc@1  89.06 ( 93.04)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [66][270/391]\tTime  0.169 ( 0.168)\tLoss 3.1056e-01 (2.3417e-01)\tAcc@1  89.84 ( 92.93)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [66][300/391]\tTime  0.168 ( 0.168)\tLoss 1.8782e-01 (2.3758e-01)\tAcc@1  96.09 ( 92.84)\tAcc@5 100.00 ( 99.69)\n",
            "Epoch: [66][330/391]\tTime  0.167 ( 0.168)\tLoss 2.4950e-01 (2.3855e-01)\tAcc@1  92.19 ( 92.80)\tAcc@5 100.00 ( 99.69)\n",
            "Epoch: [66][360/391]\tTime  0.168 ( 0.168)\tLoss 2.7519e-01 (2.4044e-01)\tAcc@1  93.75 ( 92.77)\tAcc@5  98.44 ( 99.68)\n",
            "Epoch: [66][390/391]\tTime  0.151 ( 0.168)\tLoss 4.5436e-01 (2.4254e-01)\tAcc@1  82.50 ( 92.72)\tAcc@5  98.75 ( 99.67)\n",
            "==> Train Accuracy: Acc@1 92.716 || Acc@5 99.670\n",
            "==> Test Accuracy:  Acc@1 72.340 || Acc@5 92.760\n",
            "==> 69.72 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 67, lr: 0.020000000000000004 -----\n",
            "Epoch: [67][  0/391]\tTime  0.288 ( 0.288)\tLoss 1.7468e-01 (1.7468e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [67][ 30/391]\tTime  0.168 ( 0.171)\tLoss 2.2968e-01 (1.9814e-01)\tAcc@1  92.97 ( 94.58)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [67][ 60/391]\tTime  0.169 ( 0.170)\tLoss 1.7071e-01 (1.9589e-01)\tAcc@1  96.88 ( 94.52)\tAcc@5  99.22 ( 99.83)\n",
            "Epoch: [67][ 90/391]\tTime  0.168 ( 0.169)\tLoss 2.1920e-01 (2.0597e-01)\tAcc@1  94.53 ( 93.92)\tAcc@5  99.22 ( 99.79)\n",
            "Epoch: [67][120/391]\tTime  0.167 ( 0.169)\tLoss 2.1554e-01 (2.1349e-01)\tAcc@1  91.41 ( 93.60)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [67][150/391]\tTime  0.168 ( 0.168)\tLoss 2.1933e-01 (2.1593e-01)\tAcc@1  93.75 ( 93.49)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [67][180/391]\tTime  0.165 ( 0.168)\tLoss 2.7047e-01 (2.1941e-01)\tAcc@1  92.97 ( 93.34)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [67][210/391]\tTime  0.168 ( 0.168)\tLoss 1.9173e-01 (2.2501e-01)\tAcc@1  95.31 ( 93.17)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [67][240/391]\tTime  0.168 ( 0.168)\tLoss 2.4873e-01 (2.2835e-01)\tAcc@1  91.41 ( 93.05)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [67][270/391]\tTime  0.168 ( 0.168)\tLoss 1.6997e-01 (2.3202e-01)\tAcc@1  95.31 ( 92.92)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [67][300/391]\tTime  0.168 ( 0.168)\tLoss 2.7759e-01 (2.3441e-01)\tAcc@1  88.28 ( 92.86)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [67][330/391]\tTime  0.167 ( 0.168)\tLoss 2.2621e-01 (2.3700e-01)\tAcc@1  91.41 ( 92.78)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [67][360/391]\tTime  0.167 ( 0.168)\tLoss 2.1740e-01 (2.3974e-01)\tAcc@1  93.75 ( 92.71)\tAcc@5  99.22 ( 99.70)\n",
            "Epoch: [67][390/391]\tTime  0.150 ( 0.168)\tLoss 2.6542e-01 (2.4107e-01)\tAcc@1  90.00 ( 92.64)\tAcc@5 100.00 ( 99.69)\n",
            "==> Train Accuracy: Acc@1 92.640 || Acc@5 99.688\n",
            "==> Test Accuracy:  Acc@1 71.080 || Acc@5 91.910\n",
            "==> 69.69 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 68, lr: 0.020000000000000004 -----\n",
            "Epoch: [68][  0/391]\tTime  0.286 ( 0.286)\tLoss 3.1175e-01 (3.1175e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [68][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.5183e-01 (2.0309e-01)\tAcc@1  96.88 ( 94.10)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [68][ 60/391]\tTime  0.167 ( 0.169)\tLoss 2.4026e-01 (2.1113e-01)\tAcc@1  92.97 ( 93.75)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [68][ 90/391]\tTime  0.168 ( 0.169)\tLoss 2.8156e-01 (2.1113e-01)\tAcc@1  91.41 ( 93.66)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [68][120/391]\tTime  0.168 ( 0.168)\tLoss 1.7142e-01 (2.1190e-01)\tAcc@1  95.31 ( 93.76)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [68][150/391]\tTime  0.169 ( 0.168)\tLoss 2.3793e-01 (2.1761e-01)\tAcc@1  92.97 ( 93.57)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [68][180/391]\tTime  0.168 ( 0.168)\tLoss 1.6576e-01 (2.1935e-01)\tAcc@1  96.09 ( 93.47)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [68][210/391]\tTime  0.169 ( 0.168)\tLoss 3.6429e-01 (2.2092e-01)\tAcc@1  89.84 ( 93.44)\tAcc@5  98.44 ( 99.76)\n",
            "Epoch: [68][240/391]\tTime  0.168 ( 0.168)\tLoss 2.1839e-01 (2.2295e-01)\tAcc@1  95.31 ( 93.33)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [68][270/391]\tTime  0.166 ( 0.168)\tLoss 2.8300e-01 (2.2563e-01)\tAcc@1  91.41 ( 93.24)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [68][300/391]\tTime  0.168 ( 0.168)\tLoss 2.8388e-01 (2.2837e-01)\tAcc@1  92.19 ( 93.14)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [68][330/391]\tTime  0.169 ( 0.168)\tLoss 2.3393e-01 (2.3044e-01)\tAcc@1  91.41 ( 93.10)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [68][360/391]\tTime  0.167 ( 0.168)\tLoss 2.4730e-01 (2.3120e-01)\tAcc@1  92.19 ( 93.07)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [68][390/391]\tTime  0.150 ( 0.168)\tLoss 2.6254e-01 (2.3353e-01)\tAcc@1  91.25 ( 92.96)\tAcc@5 100.00 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.960 || Acc@5 99.716\n",
            "==> Test Accuracy:  Acc@1 70.930 || Acc@5 92.090\n",
            "==> 69.70 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 69, lr: 0.020000000000000004 -----\n",
            "Epoch: [69][  0/391]\tTime  0.298 ( 0.298)\tLoss 2.2002e-01 (2.2002e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [69][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.4981e-01 (1.9139e-01)\tAcc@1  96.88 ( 94.56)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [69][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.8508e-01 (1.9603e-01)\tAcc@1  93.75 ( 94.35)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [69][ 90/391]\tTime  0.168 ( 0.169)\tLoss 2.6587e-01 (1.9948e-01)\tAcc@1  91.41 ( 94.18)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [69][120/391]\tTime  0.167 ( 0.169)\tLoss 2.7019e-01 (2.0108e-01)\tAcc@1  89.06 ( 94.08)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [69][150/391]\tTime  0.167 ( 0.168)\tLoss 3.0435e-01 (2.0100e-01)\tAcc@1  85.94 ( 94.04)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [69][180/391]\tTime  0.168 ( 0.168)\tLoss 2.4821e-01 (2.0717e-01)\tAcc@1  89.06 ( 93.78)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [69][210/391]\tTime  0.166 ( 0.168)\tLoss 2.1311e-01 (2.0824e-01)\tAcc@1  93.75 ( 93.72)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [69][240/391]\tTime  0.169 ( 0.168)\tLoss 1.9061e-01 (2.1117e-01)\tAcc@1  92.19 ( 93.62)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [69][270/391]\tTime  0.168 ( 0.168)\tLoss 2.2006e-01 (2.1465e-01)\tAcc@1  92.97 ( 93.47)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [69][300/391]\tTime  0.168 ( 0.168)\tLoss 1.9148e-01 (2.1721e-01)\tAcc@1  94.53 ( 93.39)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [69][330/391]\tTime  0.165 ( 0.168)\tLoss 1.6977e-01 (2.2056e-01)\tAcc@1  95.31 ( 93.31)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [69][360/391]\tTime  0.166 ( 0.168)\tLoss 2.5719e-01 (2.2445e-01)\tAcc@1  90.62 ( 93.16)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [69][390/391]\tTime  0.151 ( 0.168)\tLoss 1.9265e-01 (2.2577e-01)\tAcc@1  96.25 ( 93.08)\tAcc@5 100.00 ( 99.76)\n",
            "==> Train Accuracy: Acc@1 93.082 || Acc@5 99.756\n",
            "==> Test Accuracy:  Acc@1 70.780 || Acc@5 91.540\n",
            "==> 69.73 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 70, lr: 0.020000000000000004 -----\n",
            "Epoch: [70][  0/391]\tTime  0.300 ( 0.300)\tLoss 1.8210e-01 (1.8210e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [70][ 30/391]\tTime  0.166 ( 0.171)\tLoss 1.7981e-01 (1.9185e-01)\tAcc@1  92.97 ( 94.61)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [70][ 60/391]\tTime  0.166 ( 0.169)\tLoss 2.5990e-01 (1.9212e-01)\tAcc@1  91.41 ( 94.58)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [70][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.9357e-01 (1.9698e-01)\tAcc@1  96.09 ( 94.32)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [70][120/391]\tTime  0.166 ( 0.168)\tLoss 1.7961e-01 (1.9913e-01)\tAcc@1  94.53 ( 94.22)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [70][150/391]\tTime  0.165 ( 0.168)\tLoss 2.8860e-01 (2.0185e-01)\tAcc@1  89.06 ( 94.06)\tAcc@5  99.22 ( 99.83)\n",
            "Epoch: [70][180/391]\tTime  0.167 ( 0.168)\tLoss 1.6510e-01 (2.0458e-01)\tAcc@1  94.53 ( 93.92)\tAcc@5  99.22 ( 99.83)\n",
            "Epoch: [70][210/391]\tTime  0.169 ( 0.168)\tLoss 3.3634e-01 (2.1024e-01)\tAcc@1  88.28 ( 93.75)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [70][240/391]\tTime  0.169 ( 0.168)\tLoss 2.9596e-01 (2.1393e-01)\tAcc@1  91.41 ( 93.68)\tAcc@5  98.44 ( 99.77)\n",
            "Epoch: [70][270/391]\tTime  0.167 ( 0.168)\tLoss 2.0615e-01 (2.1774e-01)\tAcc@1  95.31 ( 93.54)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [70][300/391]\tTime  0.167 ( 0.168)\tLoss 2.4838e-01 (2.2228e-01)\tAcc@1  92.97 ( 93.34)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [70][330/391]\tTime  0.168 ( 0.168)\tLoss 2.7132e-01 (2.2513e-01)\tAcc@1  90.62 ( 93.23)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [70][360/391]\tTime  0.166 ( 0.168)\tLoss 2.9672e-01 (2.2856e-01)\tAcc@1  88.28 ( 93.09)\tAcc@5  99.22 ( 99.71)\n",
            "Epoch: [70][390/391]\tTime  0.150 ( 0.168)\tLoss 2.9332e-01 (2.3276e-01)\tAcc@1  88.75 ( 92.96)\tAcc@5 100.00 ( 99.71)\n",
            "==> Train Accuracy: Acc@1 92.964 || Acc@5 99.708\n",
            "==> Test Accuracy:  Acc@1 70.410 || Acc@5 91.510\n",
            "==> 69.76 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 71, lr: 0.020000000000000004 -----\n",
            "Epoch: [71][  0/391]\tTime  0.300 ( 0.300)\tLoss 2.6025e-01 (2.6025e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [71][ 30/391]\tTime  0.166 ( 0.171)\tLoss 1.8536e-01 (2.0433e-01)\tAcc@1  94.53 ( 94.23)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [71][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.4611e-01 (1.9885e-01)\tAcc@1  95.31 ( 94.15)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [71][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.4575e-01 (1.9933e-01)\tAcc@1  96.09 ( 94.22)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [71][120/391]\tTime  0.165 ( 0.168)\tLoss 2.6508e-01 (1.9936e-01)\tAcc@1  89.84 ( 94.12)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [71][150/391]\tTime  0.167 ( 0.168)\tLoss 1.2404e-01 (1.9945e-01)\tAcc@1  96.88 ( 94.04)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [71][180/391]\tTime  0.166 ( 0.168)\tLoss 2.1209e-01 (2.0397e-01)\tAcc@1  92.19 ( 93.92)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [71][210/391]\tTime  0.168 ( 0.168)\tLoss 1.7025e-01 (2.0682e-01)\tAcc@1  96.09 ( 93.78)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [71][240/391]\tTime  0.167 ( 0.168)\tLoss 2.4525e-01 (2.0929e-01)\tAcc@1  95.31 ( 93.66)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [71][270/391]\tTime  0.168 ( 0.168)\tLoss 2.6851e-01 (2.1339e-01)\tAcc@1  92.97 ( 93.48)\tAcc@5  99.22 ( 99.82)\n",
            "Epoch: [71][300/391]\tTime  0.169 ( 0.168)\tLoss 2.4084e-01 (2.1722e-01)\tAcc@1  91.41 ( 93.33)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [71][330/391]\tTime  0.168 ( 0.168)\tLoss 2.3214e-01 (2.2012e-01)\tAcc@1  95.31 ( 93.24)\tAcc@5  99.22 ( 99.79)\n",
            "Epoch: [71][360/391]\tTime  0.169 ( 0.168)\tLoss 3.3179e-01 (2.2559e-01)\tAcc@1  88.28 ( 93.04)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [71][390/391]\tTime  0.151 ( 0.168)\tLoss 3.7471e-01 (2.3020e-01)\tAcc@1  87.50 ( 92.89)\tAcc@5  98.75 ( 99.77)\n",
            "==> Train Accuracy: Acc@1 92.894 || Acc@5 99.766\n",
            "==> Test Accuracy:  Acc@1 70.080 || Acc@5 91.460\n",
            "==> 69.76 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 72, lr: 0.020000000000000004 -----\n",
            "Epoch: [72][  0/391]\tTime  0.291 ( 0.291)\tLoss 2.0868e-01 (2.0868e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [72][ 30/391]\tTime  0.169 ( 0.170)\tLoss 2.1604e-01 (2.0093e-01)\tAcc@1  93.75 ( 94.51)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [72][ 60/391]\tTime  0.167 ( 0.169)\tLoss 2.2461e-01 (2.0425e-01)\tAcc@1  91.41 ( 94.08)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [72][ 90/391]\tTime  0.167 ( 0.168)\tLoss 2.2023e-01 (2.0525e-01)\tAcc@1  95.31 ( 93.81)\tAcc@5  99.22 ( 99.81)\n",
            "Epoch: [72][120/391]\tTime  0.168 ( 0.168)\tLoss 1.2316e-01 (2.0568e-01)\tAcc@1  96.88 ( 93.71)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [72][150/391]\tTime  0.168 ( 0.168)\tLoss 2.6881e-01 (2.0822e-01)\tAcc@1  92.19 ( 93.64)\tAcc@5  99.22 ( 99.80)\n",
            "Epoch: [72][180/391]\tTime  0.164 ( 0.168)\tLoss 2.7491e-01 (2.1223e-01)\tAcc@1  92.97 ( 93.53)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [72][210/391]\tTime  0.167 ( 0.168)\tLoss 2.3937e-01 (2.1468e-01)\tAcc@1  93.75 ( 93.48)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [72][240/391]\tTime  0.166 ( 0.168)\tLoss 2.4277e-01 (2.1883e-01)\tAcc@1  94.53 ( 93.34)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [72][270/391]\tTime  0.166 ( 0.168)\tLoss 2.3020e-01 (2.2261e-01)\tAcc@1  93.75 ( 93.23)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [72][300/391]\tTime  0.168 ( 0.168)\tLoss 3.1738e-01 (2.2845e-01)\tAcc@1  91.41 ( 93.03)\tAcc@5  98.44 ( 99.75)\n",
            "Epoch: [72][330/391]\tTime  0.168 ( 0.167)\tLoss 1.8236e-01 (2.3279e-01)\tAcc@1  96.09 ( 92.91)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [72][360/391]\tTime  0.170 ( 0.168)\tLoss 3.3831e-01 (2.3734e-01)\tAcc@1  91.41 ( 92.72)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [72][390/391]\tTime  0.151 ( 0.167)\tLoss 2.7882e-01 (2.4202e-01)\tAcc@1  91.25 ( 92.59)\tAcc@5 100.00 ( 99.71)\n",
            "==> Train Accuracy: Acc@1 92.594 || Acc@5 99.706\n",
            "==> Test Accuracy:  Acc@1 68.850 || Acc@5 91.110\n",
            "==> 69.65 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 73, lr: 0.020000000000000004 -----\n",
            "Epoch: [73][  0/391]\tTime  0.298 ( 0.298)\tLoss 2.5072e-01 (2.5072e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [73][ 30/391]\tTime  0.169 ( 0.171)\tLoss 2.0167e-01 (2.1212e-01)\tAcc@1  93.75 ( 94.10)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [73][ 60/391]\tTime  0.167 ( 0.169)\tLoss 2.2000e-01 (1.9693e-01)\tAcc@1  93.75 ( 94.47)\tAcc@5  99.22 ( 99.85)\n",
            "Epoch: [73][ 90/391]\tTime  0.168 ( 0.169)\tLoss 2.0993e-01 (1.9752e-01)\tAcc@1  93.75 ( 94.25)\tAcc@5 100.00 ( 99.84)\n",
            "Epoch: [73][120/391]\tTime  0.168 ( 0.168)\tLoss 2.5242e-01 (2.0249e-01)\tAcc@1  92.19 ( 94.00)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [73][150/391]\tTime  0.168 ( 0.168)\tLoss 2.4112e-01 (2.0964e-01)\tAcc@1  92.97 ( 93.70)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [73][180/391]\tTime  0.170 ( 0.168)\tLoss 2.0031e-01 (2.1398e-01)\tAcc@1  94.53 ( 93.52)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [73][210/391]\tTime  0.169 ( 0.168)\tLoss 2.5579e-01 (2.1673e-01)\tAcc@1  95.31 ( 93.38)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [73][240/391]\tTime  0.169 ( 0.168)\tLoss 2.1392e-01 (2.2092e-01)\tAcc@1  92.19 ( 93.22)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [73][270/391]\tTime  0.167 ( 0.168)\tLoss 3.2291e-01 (2.2653e-01)\tAcc@1  92.97 ( 93.05)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [73][300/391]\tTime  0.167 ( 0.168)\tLoss 3.8545e-01 (2.3026e-01)\tAcc@1  89.84 ( 92.98)\tAcc@5  99.22 ( 99.79)\n",
            "Epoch: [73][330/391]\tTime  0.167 ( 0.168)\tLoss 2.7421e-01 (2.3381e-01)\tAcc@1  91.41 ( 92.87)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [73][360/391]\tTime  0.168 ( 0.168)\tLoss 1.5082e-01 (2.3581e-01)\tAcc@1  94.53 ( 92.80)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [73][390/391]\tTime  0.152 ( 0.168)\tLoss 3.5382e-01 (2.3811e-01)\tAcc@1  87.50 ( 92.72)\tAcc@5 100.00 ( 99.76)\n",
            "==> Train Accuracy: Acc@1 92.720 || Acc@5 99.764\n",
            "==> Test Accuracy:  Acc@1 69.350 || Acc@5 90.880\n",
            "==> 69.71 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 74, lr: 0.020000000000000004 -----\n",
            "Epoch: [74][  0/391]\tTime  0.282 ( 0.282)\tLoss 2.4247e-01 (2.4247e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [74][ 30/391]\tTime  0.166 ( 0.171)\tLoss 2.8668e-01 (2.2878e-01)\tAcc@1  90.62 ( 93.47)\tAcc@5 100.00 ( 99.67)\n",
            "Epoch: [74][ 60/391]\tTime  0.169 ( 0.169)\tLoss 1.3102e-01 (2.1803e-01)\tAcc@1  96.88 ( 93.60)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [74][ 90/391]\tTime  0.168 ( 0.169)\tLoss 2.2759e-01 (2.1518e-01)\tAcc@1  93.75 ( 93.63)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [74][120/391]\tTime  0.168 ( 0.169)\tLoss 2.1558e-01 (2.1327e-01)\tAcc@1  95.31 ( 93.65)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [74][150/391]\tTime  0.168 ( 0.168)\tLoss 2.7743e-01 (2.2057e-01)\tAcc@1  90.62 ( 93.28)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [74][180/391]\tTime  0.166 ( 0.168)\tLoss 3.5715e-01 (2.2547e-01)\tAcc@1  89.84 ( 93.13)\tAcc@5  98.44 ( 99.75)\n",
            "Epoch: [74][210/391]\tTime  0.165 ( 0.168)\tLoss 2.7637e-01 (2.2907e-01)\tAcc@1  90.62 ( 93.03)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [74][240/391]\tTime  0.169 ( 0.168)\tLoss 2.7391e-01 (2.3536e-01)\tAcc@1  89.84 ( 92.78)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [74][270/391]\tTime  0.168 ( 0.168)\tLoss 3.0316e-01 (2.3830e-01)\tAcc@1  93.75 ( 92.70)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [74][300/391]\tTime  0.166 ( 0.168)\tLoss 4.2739e-01 (2.4380e-01)\tAcc@1  86.72 ( 92.51)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [74][330/391]\tTime  0.167 ( 0.168)\tLoss 2.7601e-01 (2.4613e-01)\tAcc@1  90.62 ( 92.50)\tAcc@5 100.00 ( 99.69)\n",
            "Epoch: [74][360/391]\tTime  0.167 ( 0.168)\tLoss 4.8628e-01 (2.4935e-01)\tAcc@1  83.59 ( 92.42)\tAcc@5  98.44 ( 99.67)\n",
            "Epoch: [74][390/391]\tTime  0.151 ( 0.168)\tLoss 3.1309e-01 (2.5351e-01)\tAcc@1  90.00 ( 92.25)\tAcc@5 100.00 ( 99.66)\n",
            "==> Train Accuracy: Acc@1 92.250 || Acc@5 99.664\n",
            "==> Test Accuracy:  Acc@1 69.660 || Acc@5 90.950\n",
            "==> 69.75 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 75, lr: 0.020000000000000004 -----\n",
            "Epoch: [75][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.4580e-01 (1.4580e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [75][ 30/391]\tTime  0.168 ( 0.170)\tLoss 1.3699e-01 (2.1199e-01)\tAcc@1  97.66 ( 93.88)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [75][ 60/391]\tTime  0.167 ( 0.169)\tLoss 2.2655e-01 (2.2179e-01)\tAcc@1  93.75 ( 93.25)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [75][ 90/391]\tTime  0.165 ( 0.168)\tLoss 2.0418e-01 (2.2133e-01)\tAcc@1  94.53 ( 93.24)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [75][120/391]\tTime  0.166 ( 0.168)\tLoss 2.1753e-01 (2.2174e-01)\tAcc@1  92.97 ( 93.22)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [75][150/391]\tTime  0.168 ( 0.168)\tLoss 2.2256e-01 (2.2201e-01)\tAcc@1  94.53 ( 93.20)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [75][180/391]\tTime  0.166 ( 0.168)\tLoss 2.7955e-01 (2.2357e-01)\tAcc@1  89.84 ( 93.14)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [75][210/391]\tTime  0.167 ( 0.168)\tLoss 2.2810e-01 (2.2751e-01)\tAcc@1  94.53 ( 92.95)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [75][240/391]\tTime  0.168 ( 0.168)\tLoss 2.7878e-01 (2.3323e-01)\tAcc@1  89.84 ( 92.79)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [75][270/391]\tTime  0.167 ( 0.168)\tLoss 2.7009e-01 (2.3541e-01)\tAcc@1  90.62 ( 92.72)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [75][300/391]\tTime  0.172 ( 0.168)\tLoss 2.7489e-01 (2.4047e-01)\tAcc@1  92.97 ( 92.59)\tAcc@5  98.44 ( 99.75)\n",
            "Epoch: [75][330/391]\tTime  0.169 ( 0.168)\tLoss 3.6726e-01 (2.4306e-01)\tAcc@1  89.06 ( 92.50)\tAcc@5  98.44 ( 99.74)\n",
            "Epoch: [75][360/391]\tTime  0.168 ( 0.168)\tLoss 2.5989e-01 (2.4819e-01)\tAcc@1  92.97 ( 92.31)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [75][390/391]\tTime  0.150 ( 0.167)\tLoss 4.4421e-01 (2.5222e-01)\tAcc@1  85.00 ( 92.17)\tAcc@5 100.00 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.166 || Acc@5 99.724\n",
            "==> Test Accuracy:  Acc@1 67.670 || Acc@5 90.430\n",
            "==> 69.60 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 76, lr: 0.020000000000000004 -----\n",
            "Epoch: [76][  0/391]\tTime  0.318 ( 0.318)\tLoss 1.8772e-01 (1.8772e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [76][ 30/391]\tTime  0.166 ( 0.171)\tLoss 2.3705e-01 (2.1865e-01)\tAcc@1  92.19 ( 93.52)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [76][ 60/391]\tTime  0.170 ( 0.169)\tLoss 2.2198e-01 (2.1718e-01)\tAcc@1  94.53 ( 93.53)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [76][ 90/391]\tTime  0.165 ( 0.168)\tLoss 1.4759e-01 (2.1959e-01)\tAcc@1  94.53 ( 93.31)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [76][120/391]\tTime  0.167 ( 0.168)\tLoss 2.8347e-01 (2.2254e-01)\tAcc@1  93.75 ( 93.28)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [76][150/391]\tTime  0.166 ( 0.168)\tLoss 2.1646e-01 (2.2688e-01)\tAcc@1  93.75 ( 93.15)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [76][180/391]\tTime  0.169 ( 0.168)\tLoss 1.9378e-01 (2.2976e-01)\tAcc@1  94.53 ( 93.15)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [76][210/391]\tTime  0.170 ( 0.168)\tLoss 2.8744e-01 (2.3189e-01)\tAcc@1  89.06 ( 93.06)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [76][240/391]\tTime  0.167 ( 0.168)\tLoss 2.6042e-01 (2.3563e-01)\tAcc@1  92.19 ( 92.93)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [76][270/391]\tTime  0.169 ( 0.168)\tLoss 2.5491e-01 (2.4114e-01)\tAcc@1  92.19 ( 92.76)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [76][300/391]\tTime  0.169 ( 0.168)\tLoss 2.6200e-01 (2.4557e-01)\tAcc@1  91.41 ( 92.59)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [76][330/391]\tTime  0.167 ( 0.168)\tLoss 2.8505e-01 (2.5260e-01)\tAcc@1  92.19 ( 92.34)\tAcc@5  99.22 ( 99.70)\n",
            "Epoch: [76][360/391]\tTime  0.167 ( 0.168)\tLoss 3.4396e-01 (2.5693e-01)\tAcc@1  89.84 ( 92.24)\tAcc@5 100.00 ( 99.69)\n",
            "Epoch: [76][390/391]\tTime  0.149 ( 0.168)\tLoss 3.2454e-01 (2.6136e-01)\tAcc@1  87.50 ( 92.04)\tAcc@5  98.75 ( 99.68)\n",
            "==> Train Accuracy: Acc@1 92.040 || Acc@5 99.676\n",
            "==> Test Accuracy:  Acc@1 68.590 || Acc@5 90.700\n",
            "==> 69.81 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 77, lr: 0.020000000000000004 -----\n",
            "Epoch: [77][  0/391]\tTime  0.295 ( 0.295)\tLoss 2.3801e-01 (2.3801e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [77][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.5757e-01 (2.2293e-01)\tAcc@1  95.31 ( 93.32)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [77][ 60/391]\tTime  0.168 ( 0.169)\tLoss 2.5287e-01 (2.2744e-01)\tAcc@1  92.19 ( 93.10)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [77][ 90/391]\tTime  0.168 ( 0.168)\tLoss 1.8415e-01 (2.2239e-01)\tAcc@1  95.31 ( 93.32)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [77][120/391]\tTime  0.166 ( 0.168)\tLoss 2.3620e-01 (2.2583e-01)\tAcc@1  92.97 ( 93.09)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [77][150/391]\tTime  0.168 ( 0.168)\tLoss 3.0867e-01 (2.2859e-01)\tAcc@1  89.84 ( 93.04)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [77][180/391]\tTime  0.166 ( 0.168)\tLoss 3.1096e-01 (2.3333e-01)\tAcc@1  92.97 ( 92.91)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [77][210/391]\tTime  0.167 ( 0.168)\tLoss 2.6772e-01 (2.3646e-01)\tAcc@1  92.19 ( 92.81)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [77][240/391]\tTime  0.167 ( 0.168)\tLoss 2.8020e-01 (2.3792e-01)\tAcc@1  91.41 ( 92.68)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [77][270/391]\tTime  0.167 ( 0.168)\tLoss 2.6716e-01 (2.4114e-01)\tAcc@1  92.19 ( 92.61)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [77][300/391]\tTime  0.167 ( 0.168)\tLoss 2.3646e-01 (2.4492e-01)\tAcc@1  91.41 ( 92.45)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [77][330/391]\tTime  0.167 ( 0.168)\tLoss 2.0591e-01 (2.4847e-01)\tAcc@1  96.09 ( 92.36)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [77][360/391]\tTime  0.170 ( 0.168)\tLoss 2.5529e-01 (2.5242e-01)\tAcc@1  92.19 ( 92.22)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [77][390/391]\tTime  0.152 ( 0.167)\tLoss 2.7987e-01 (2.5621e-01)\tAcc@1  91.25 ( 92.11)\tAcc@5 100.00 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.112 || Acc@5 99.724\n",
            "==> Test Accuracy:  Acc@1 69.450 || Acc@5 91.200\n",
            "==> 69.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 78, lr: 0.020000000000000004 -----\n",
            "Epoch: [78][  0/391]\tTime  0.287 ( 0.287)\tLoss 2.6527e-01 (2.6527e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [78][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.9668e-01 (2.3068e-01)\tAcc@1  96.09 ( 92.92)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [78][ 60/391]\tTime  0.168 ( 0.169)\tLoss 2.8105e-01 (2.3149e-01)\tAcc@1  89.06 ( 93.08)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [78][ 90/391]\tTime  0.166 ( 0.168)\tLoss 3.2002e-01 (2.2779e-01)\tAcc@1  88.28 ( 93.33)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [78][120/391]\tTime  0.168 ( 0.168)\tLoss 2.3461e-01 (2.2590e-01)\tAcc@1  94.53 ( 93.23)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [78][150/391]\tTime  0.166 ( 0.168)\tLoss 2.8183e-01 (2.2863e-01)\tAcc@1  90.62 ( 93.07)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [78][180/391]\tTime  0.168 ( 0.168)\tLoss 2.8422e-01 (2.3596e-01)\tAcc@1  88.28 ( 92.79)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [78][210/391]\tTime  0.167 ( 0.168)\tLoss 2.5485e-01 (2.3797e-01)\tAcc@1  91.41 ( 92.73)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [78][240/391]\tTime  0.167 ( 0.168)\tLoss 3.4498e-01 (2.3916e-01)\tAcc@1  89.06 ( 92.69)\tAcc@5  97.66 ( 99.73)\n",
            "Epoch: [78][270/391]\tTime  0.168 ( 0.168)\tLoss 4.2215e-01 (2.4354e-01)\tAcc@1  87.50 ( 92.52)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [78][300/391]\tTime  0.167 ( 0.168)\tLoss 2.4061e-01 (2.4429e-01)\tAcc@1  90.62 ( 92.45)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [78][330/391]\tTime  0.169 ( 0.168)\tLoss 3.2891e-01 (2.4858e-01)\tAcc@1  89.06 ( 92.30)\tAcc@5  98.44 ( 99.72)\n",
            "Epoch: [78][360/391]\tTime  0.167 ( 0.168)\tLoss 4.0136e-01 (2.5120e-01)\tAcc@1  86.72 ( 92.20)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [78][390/391]\tTime  0.150 ( 0.168)\tLoss 4.6145e-01 (2.5515e-01)\tAcc@1  82.50 ( 92.08)\tAcc@5 100.00 ( 99.71)\n",
            "==> Train Accuracy: Acc@1 92.076 || Acc@5 99.712\n",
            "==> Test Accuracy:  Acc@1 69.570 || Acc@5 90.760\n",
            "==> 69.65 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 79, lr: 0.020000000000000004 -----\n",
            "Epoch: [79][  0/391]\tTime  0.290 ( 0.290)\tLoss 2.8350e-01 (2.8350e-01)\tAcc@1  91.41 ( 91.41)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [79][ 30/391]\tTime  0.169 ( 0.172)\tLoss 1.8034e-01 (2.4240e-01)\tAcc@1  93.75 ( 92.77)\tAcc@5 100.00 ( 99.67)\n",
            "Epoch: [79][ 60/391]\tTime  0.168 ( 0.170)\tLoss 2.4793e-01 (2.3771e-01)\tAcc@1  93.75 ( 92.89)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [79][ 90/391]\tTime  0.168 ( 0.169)\tLoss 2.4109e-01 (2.3559e-01)\tAcc@1  94.53 ( 93.09)\tAcc@5  98.44 ( 99.73)\n",
            "Epoch: [79][120/391]\tTime  0.168 ( 0.169)\tLoss 1.3544e-01 (2.3252e-01)\tAcc@1  97.66 ( 93.08)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [79][150/391]\tTime  0.167 ( 0.168)\tLoss 2.5452e-01 (2.3671e-01)\tAcc@1  91.41 ( 92.87)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [79][180/391]\tTime  0.166 ( 0.168)\tLoss 2.3158e-01 (2.3969e-01)\tAcc@1  92.97 ( 92.77)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [79][210/391]\tTime  0.167 ( 0.168)\tLoss 1.3182e-01 (2.3821e-01)\tAcc@1  97.66 ( 92.78)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [79][240/391]\tTime  0.166 ( 0.168)\tLoss 1.5426e-01 (2.3848e-01)\tAcc@1  95.31 ( 92.69)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [79][270/391]\tTime  0.167 ( 0.168)\tLoss 2.3464e-01 (2.4194e-01)\tAcc@1  91.41 ( 92.60)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [79][300/391]\tTime  0.167 ( 0.168)\tLoss 4.2181e-01 (2.4341e-01)\tAcc@1  85.94 ( 92.54)\tAcc@5  99.22 ( 99.74)\n",
            "Epoch: [79][330/391]\tTime  0.167 ( 0.168)\tLoss 2.1252e-01 (2.4653e-01)\tAcc@1  94.53 ( 92.48)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [79][360/391]\tTime  0.166 ( 0.168)\tLoss 3.1566e-01 (2.5079e-01)\tAcc@1  88.28 ( 92.32)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [79][390/391]\tTime  0.150 ( 0.168)\tLoss 2.6170e-01 (2.5441e-01)\tAcc@1  93.75 ( 92.19)\tAcc@5  98.75 ( 99.71)\n",
            "==> Train Accuracy: Acc@1 92.192 || Acc@5 99.710\n",
            "==> Test Accuracy:  Acc@1 68.590 || Acc@5 90.220\n",
            "==> 69.68 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 80, lr: 0.020000000000000004 -----\n",
            "Epoch: [80][  0/391]\tTime  0.277 ( 0.277)\tLoss 2.1911e-01 (2.1911e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [80][ 30/391]\tTime  0.167 ( 0.170)\tLoss 2.2868e-01 (2.2396e-01)\tAcc@1  92.19 ( 92.72)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [80][ 60/391]\tTime  0.167 ( 0.169)\tLoss 2.3176e-01 (2.1954e-01)\tAcc@1  93.75 ( 93.06)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [80][ 90/391]\tTime  0.167 ( 0.168)\tLoss 2.5598e-01 (2.3131e-01)\tAcc@1  91.41 ( 92.70)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [80][120/391]\tTime  0.168 ( 0.168)\tLoss 2.1008e-01 (2.2904e-01)\tAcc@1  94.53 ( 92.88)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [80][150/391]\tTime  0.166 ( 0.168)\tLoss 2.3965e-01 (2.2852e-01)\tAcc@1  92.19 ( 92.94)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [80][180/391]\tTime  0.167 ( 0.168)\tLoss 3.0992e-01 (2.3300e-01)\tAcc@1  88.28 ( 92.83)\tAcc@5  99.22 ( 99.74)\n",
            "Epoch: [80][210/391]\tTime  0.167 ( 0.168)\tLoss 3.2728e-01 (2.3597e-01)\tAcc@1  89.84 ( 92.75)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [80][240/391]\tTime  0.167 ( 0.168)\tLoss 2.5505e-01 (2.3693e-01)\tAcc@1  92.19 ( 92.76)\tAcc@5  99.22 ( 99.71)\n",
            "Epoch: [80][270/391]\tTime  0.166 ( 0.167)\tLoss 3.1222e-01 (2.3911e-01)\tAcc@1  89.06 ( 92.67)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [80][300/391]\tTime  0.168 ( 0.167)\tLoss 1.9367e-01 (2.4044e-01)\tAcc@1  94.53 ( 92.63)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [80][330/391]\tTime  0.165 ( 0.167)\tLoss 1.9675e-01 (2.4382e-01)\tAcc@1  93.75 ( 92.48)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [80][360/391]\tTime  0.167 ( 0.167)\tLoss 3.8172e-01 (2.4705e-01)\tAcc@1  88.28 ( 92.35)\tAcc@5  99.22 ( 99.70)\n",
            "Epoch: [80][390/391]\tTime  0.149 ( 0.167)\tLoss 3.7680e-01 (2.5021e-01)\tAcc@1  90.00 ( 92.25)\tAcc@5 100.00 ( 99.70)\n",
            "==> Train Accuracy: Acc@1 92.250 || Acc@5 99.700\n",
            "==> Test Accuracy:  Acc@1 68.410 || Acc@5 90.320\n",
            "==> 69.56 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 81, lr: 0.020000000000000004 -----\n",
            "Epoch: [81][  0/391]\tTime  0.290 ( 0.290)\tLoss 1.5228e-01 (1.5228e-01)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [81][ 30/391]\tTime  0.166 ( 0.171)\tLoss 3.3678e-01 (2.4048e-01)\tAcc@1  88.28 ( 92.97)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [81][ 60/391]\tTime  0.172 ( 0.169)\tLoss 2.8181e-01 (2.3858e-01)\tAcc@1  88.28 ( 93.03)\tAcc@5 100.00 ( 99.67)\n",
            "Epoch: [81][ 90/391]\tTime  0.166 ( 0.169)\tLoss 1.6727e-01 (2.3451e-01)\tAcc@1  95.31 ( 93.08)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [81][120/391]\tTime  0.168 ( 0.168)\tLoss 1.4416e-01 (2.3252e-01)\tAcc@1  96.88 ( 93.13)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [81][150/391]\tTime  0.169 ( 0.168)\tLoss 3.3141e-01 (2.3431e-01)\tAcc@1  88.28 ( 92.97)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [81][180/391]\tTime  0.168 ( 0.168)\tLoss 2.2281e-01 (2.3402e-01)\tAcc@1  95.31 ( 92.94)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [81][210/391]\tTime  0.167 ( 0.168)\tLoss 2.0616e-01 (2.3410e-01)\tAcc@1  93.75 ( 92.96)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [81][240/391]\tTime  0.168 ( 0.168)\tLoss 2.2071e-01 (2.3770e-01)\tAcc@1  92.19 ( 92.81)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [81][270/391]\tTime  0.168 ( 0.168)\tLoss 3.1527e-01 (2.4039e-01)\tAcc@1  89.06 ( 92.73)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [81][300/391]\tTime  0.167 ( 0.168)\tLoss 2.5679e-01 (2.4304e-01)\tAcc@1  91.41 ( 92.64)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [81][330/391]\tTime  0.169 ( 0.168)\tLoss 2.6170e-01 (2.4598e-01)\tAcc@1  91.41 ( 92.52)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [81][360/391]\tTime  0.167 ( 0.168)\tLoss 2.8626e-01 (2.4871e-01)\tAcc@1  89.84 ( 92.40)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [81][390/391]\tTime  0.151 ( 0.168)\tLoss 3.4914e-01 (2.5307e-01)\tAcc@1  90.00 ( 92.25)\tAcc@5 100.00 ( 99.68)\n",
            "==> Train Accuracy: Acc@1 92.250 || Acc@5 99.684\n",
            "==> Test Accuracy:  Acc@1 68.520 || Acc@5 90.400\n",
            "==> 69.75 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 82, lr: 0.020000000000000004 -----\n",
            "Epoch: [82][  0/391]\tTime  0.296 ( 0.296)\tLoss 2.0257e-01 (2.0257e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [82][ 30/391]\tTime  0.166 ( 0.171)\tLoss 1.5241e-01 (2.2355e-01)\tAcc@1  94.53 ( 93.15)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [82][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.9832e-01 (2.1411e-01)\tAcc@1  93.75 ( 93.67)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [82][ 90/391]\tTime  0.163 ( 0.168)\tLoss 2.5641e-01 (2.2006e-01)\tAcc@1  91.41 ( 93.30)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [82][120/391]\tTime  0.168 ( 0.168)\tLoss 1.8754e-01 (2.2007e-01)\tAcc@1  96.09 ( 93.26)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [82][150/391]\tTime  0.169 ( 0.168)\tLoss 2.2283e-01 (2.2392e-01)\tAcc@1  92.97 ( 93.16)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [82][180/391]\tTime  0.168 ( 0.168)\tLoss 1.9345e-01 (2.2739e-01)\tAcc@1  93.75 ( 93.06)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [82][210/391]\tTime  0.168 ( 0.168)\tLoss 2.7912e-01 (2.3244e-01)\tAcc@1  91.41 ( 92.92)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [82][240/391]\tTime  0.167 ( 0.168)\tLoss 3.8550e-01 (2.3979e-01)\tAcc@1  88.28 ( 92.73)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [82][270/391]\tTime  0.167 ( 0.168)\tLoss 2.9049e-01 (2.4740e-01)\tAcc@1  90.62 ( 92.48)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [82][300/391]\tTime  0.165 ( 0.168)\tLoss 3.1815e-01 (2.5113e-01)\tAcc@1  89.06 ( 92.37)\tAcc@5  99.22 ( 99.68)\n",
            "Epoch: [82][330/391]\tTime  0.167 ( 0.168)\tLoss 2.8225e-01 (2.5354e-01)\tAcc@1  92.19 ( 92.28)\tAcc@5  98.44 ( 99.67)\n",
            "Epoch: [82][360/391]\tTime  0.167 ( 0.167)\tLoss 2.4896e-01 (2.5504e-01)\tAcc@1  93.75 ( 92.18)\tAcc@5 100.00 ( 99.66)\n",
            "Epoch: [82][390/391]\tTime  0.150 ( 0.167)\tLoss 2.4191e-01 (2.5767e-01)\tAcc@1  92.50 ( 92.11)\tAcc@5 100.00 ( 99.67)\n",
            "==> Train Accuracy: Acc@1 92.108 || Acc@5 99.668\n",
            "==> Test Accuracy:  Acc@1 69.580 || Acc@5 90.720\n",
            "==> 69.61 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 83, lr: 0.020000000000000004 -----\n",
            "Epoch: [83][  0/391]\tTime  0.297 ( 0.297)\tLoss 2.0777e-01 (2.0777e-01)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [83][ 30/391]\tTime  0.167 ( 0.170)\tLoss 2.7742e-01 (2.0989e-01)\tAcc@1  90.62 ( 93.72)\tAcc@5 100.00 ( 99.85)\n",
            "Epoch: [83][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.6359e-01 (2.1501e-01)\tAcc@1  94.53 ( 93.37)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [83][ 90/391]\tTime  0.168 ( 0.168)\tLoss 2.4062e-01 (2.1640e-01)\tAcc@1  93.75 ( 93.29)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [83][120/391]\tTime  0.166 ( 0.168)\tLoss 2.7409e-01 (2.1473e-01)\tAcc@1  90.62 ( 93.39)\tAcc@5  99.22 ( 99.81)\n",
            "Epoch: [83][150/391]\tTime  0.172 ( 0.168)\tLoss 2.0572e-01 (2.1764e-01)\tAcc@1  92.19 ( 93.29)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [83][180/391]\tTime  0.170 ( 0.168)\tLoss 2.6977e-01 (2.2246e-01)\tAcc@1  89.84 ( 93.10)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [83][210/391]\tTime  0.168 ( 0.168)\tLoss 3.1133e-01 (2.2857e-01)\tAcc@1  89.84 ( 92.88)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [83][240/391]\tTime  0.167 ( 0.168)\tLoss 2.6010e-01 (2.3248e-01)\tAcc@1  92.19 ( 92.79)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [83][270/391]\tTime  0.169 ( 0.168)\tLoss 3.0684e-01 (2.3493e-01)\tAcc@1  86.72 ( 92.68)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [83][300/391]\tTime  0.170 ( 0.168)\tLoss 4.2590e-01 (2.3837e-01)\tAcc@1  84.38 ( 92.57)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [83][330/391]\tTime  0.167 ( 0.168)\tLoss 2.2543e-01 (2.4224e-01)\tAcc@1  92.19 ( 92.45)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [83][360/391]\tTime  0.167 ( 0.168)\tLoss 3.0267e-01 (2.4659e-01)\tAcc@1  89.84 ( 92.31)\tAcc@5  98.44 ( 99.72)\n",
            "Epoch: [83][390/391]\tTime  0.151 ( 0.168)\tLoss 1.8493e-01 (2.5145e-01)\tAcc@1  95.00 ( 92.14)\tAcc@5 100.00 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.140 || Acc@5 99.718\n",
            "==> Test Accuracy:  Acc@1 68.030 || Acc@5 89.960\n",
            "==> 69.73 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 84, lr: 0.020000000000000004 -----\n",
            "Epoch: [84][  0/391]\tTime  0.321 ( 0.321)\tLoss 1.6999e-01 (1.6999e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [84][ 30/391]\tTime  0.167 ( 0.172)\tLoss 2.3310e-01 (2.2294e-01)\tAcc@1  93.75 ( 92.87)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [84][ 60/391]\tTime  0.167 ( 0.170)\tLoss 2.0413e-01 (2.2392e-01)\tAcc@1  93.75 ( 92.89)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [84][ 90/391]\tTime  0.169 ( 0.169)\tLoss 2.3035e-01 (2.2468e-01)\tAcc@1  92.19 ( 92.92)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [84][120/391]\tTime  0.168 ( 0.168)\tLoss 1.8845e-01 (2.2283e-01)\tAcc@1  93.75 ( 93.04)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [84][150/391]\tTime  0.165 ( 0.168)\tLoss 1.8226e-01 (2.2417e-01)\tAcc@1  93.75 ( 93.04)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [84][180/391]\tTime  0.168 ( 0.168)\tLoss 3.4179e-01 (2.2887e-01)\tAcc@1  89.84 ( 92.89)\tAcc@5  98.44 ( 99.79)\n",
            "Epoch: [84][210/391]\tTime  0.173 ( 0.168)\tLoss 3.7858e-01 (2.3422e-01)\tAcc@1  87.50 ( 92.74)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [84][240/391]\tTime  0.168 ( 0.168)\tLoss 2.5911e-01 (2.3573e-01)\tAcc@1  92.19 ( 92.72)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [84][270/391]\tTime  0.167 ( 0.168)\tLoss 3.0152e-01 (2.3685e-01)\tAcc@1  90.62 ( 92.73)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [84][300/391]\tTime  0.168 ( 0.168)\tLoss 2.1818e-01 (2.3908e-01)\tAcc@1  93.75 ( 92.68)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [84][330/391]\tTime  0.168 ( 0.168)\tLoss 3.4463e-01 (2.4293e-01)\tAcc@1  87.50 ( 92.50)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [84][360/391]\tTime  0.168 ( 0.167)\tLoss 2.5820e-01 (2.4717e-01)\tAcc@1  90.62 ( 92.34)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [84][390/391]\tTime  0.149 ( 0.167)\tLoss 4.2992e-01 (2.5151e-01)\tAcc@1  85.00 ( 92.20)\tAcc@5 100.00 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.204 || Acc@5 99.718\n",
            "==> Test Accuracy:  Acc@1 67.430 || Acc@5 89.840\n",
            "==> 69.62 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 85, lr: 0.020000000000000004 -----\n",
            "Epoch: [85][  0/391]\tTime  0.295 ( 0.295)\tLoss 2.3189e-01 (2.3189e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [85][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.9859e-01 (2.0628e-01)\tAcc@1  92.19 ( 93.60)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [85][ 60/391]\tTime  0.167 ( 0.169)\tLoss 2.2695e-01 (2.1230e-01)\tAcc@1  94.53 ( 93.85)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [85][ 90/391]\tTime  0.167 ( 0.168)\tLoss 2.1576e-01 (2.1053e-01)\tAcc@1  94.53 ( 93.72)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [85][120/391]\tTime  0.167 ( 0.168)\tLoss 2.2448e-01 (2.1067e-01)\tAcc@1  94.53 ( 93.80)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [85][150/391]\tTime  0.167 ( 0.168)\tLoss 3.0096e-01 (2.1429e-01)\tAcc@1  89.06 ( 93.58)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [85][180/391]\tTime  0.167 ( 0.168)\tLoss 2.3889e-01 (2.1802e-01)\tAcc@1  89.84 ( 93.40)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [85][210/391]\tTime  0.166 ( 0.168)\tLoss 3.9299e-01 (2.2253e-01)\tAcc@1  89.84 ( 93.32)\tAcc@5  98.44 ( 99.75)\n",
            "Epoch: [85][240/391]\tTime  0.171 ( 0.168)\tLoss 2.4320e-01 (2.2403e-01)\tAcc@1  92.19 ( 93.27)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [85][270/391]\tTime  0.167 ( 0.168)\tLoss 1.5825e-01 (2.2683e-01)\tAcc@1  96.09 ( 93.16)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [85][300/391]\tTime  0.169 ( 0.167)\tLoss 4.2735e-01 (2.3091e-01)\tAcc@1  89.06 ( 93.03)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [85][330/391]\tTime  0.168 ( 0.167)\tLoss 2.8544e-01 (2.3459e-01)\tAcc@1  91.41 ( 92.91)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [85][360/391]\tTime  0.167 ( 0.167)\tLoss 2.6898e-01 (2.3813e-01)\tAcc@1  90.62 ( 92.79)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [85][390/391]\tTime  0.150 ( 0.167)\tLoss 2.5313e-01 (2.4370e-01)\tAcc@1  93.75 ( 92.57)\tAcc@5 100.00 ( 99.69)\n",
            "==> Train Accuracy: Acc@1 92.574 || Acc@5 99.692\n",
            "==> Test Accuracy:  Acc@1 67.100 || Acc@5 89.560\n",
            "==> 69.63 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 86, lr: 0.020000000000000004 -----\n",
            "Epoch: [86][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.8988e-01 (1.8988e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [86][ 30/391]\tTime  0.168 ( 0.171)\tLoss 2.3678e-01 (2.3813e-01)\tAcc@1  92.19 ( 92.99)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [86][ 60/391]\tTime  0.168 ( 0.169)\tLoss 2.2505e-01 (2.2555e-01)\tAcc@1  93.75 ( 93.31)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [86][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.8063e-01 (2.2444e-01)\tAcc@1  94.53 ( 93.26)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [86][120/391]\tTime  0.162 ( 0.168)\tLoss 1.7275e-01 (2.2583e-01)\tAcc@1  94.53 ( 93.18)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [86][150/391]\tTime  0.169 ( 0.168)\tLoss 2.6373e-01 (2.2743e-01)\tAcc@1  92.97 ( 93.13)\tAcc@5  99.22 ( 99.72)\n",
            "Epoch: [86][180/391]\tTime  0.166 ( 0.168)\tLoss 2.0540e-01 (2.2767e-01)\tAcc@1  92.97 ( 93.09)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [86][210/391]\tTime  0.167 ( 0.168)\tLoss 2.5107e-01 (2.2684e-01)\tAcc@1  92.19 ( 93.11)\tAcc@5  99.22 ( 99.75)\n",
            "Epoch: [86][240/391]\tTime  0.169 ( 0.168)\tLoss 2.2078e-01 (2.3045e-01)\tAcc@1  93.75 ( 92.99)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [86][270/391]\tTime  0.168 ( 0.168)\tLoss 3.4534e-01 (2.3289e-01)\tAcc@1  85.94 ( 92.85)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [86][300/391]\tTime  0.164 ( 0.168)\tLoss 2.2940e-01 (2.3389e-01)\tAcc@1  92.97 ( 92.79)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [86][330/391]\tTime  0.166 ( 0.168)\tLoss 3.1653e-01 (2.3720e-01)\tAcc@1  88.28 ( 92.69)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [86][360/391]\tTime  0.166 ( 0.168)\tLoss 2.7946e-01 (2.4186e-01)\tAcc@1  92.19 ( 92.53)\tAcc@5  97.66 ( 99.71)\n",
            "Epoch: [86][390/391]\tTime  0.148 ( 0.168)\tLoss 3.0647e-01 (2.4666e-01)\tAcc@1  91.25 ( 92.36)\tAcc@5 100.00 ( 99.70)\n",
            "==> Train Accuracy: Acc@1 92.358 || Acc@5 99.696\n",
            "==> Test Accuracy:  Acc@1 68.430 || Acc@5 90.300\n",
            "==> 69.65 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 87, lr: 0.020000000000000004 -----\n",
            "Epoch: [87][  0/391]\tTime  0.281 ( 0.281)\tLoss 9.7499e-02 (9.7499e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [87][ 30/391]\tTime  0.167 ( 0.171)\tLoss 2.4324e-01 (2.2547e-01)\tAcc@1  90.62 ( 93.22)\tAcc@5 100.00 ( 99.70)\n",
            "Epoch: [87][ 60/391]\tTime  0.165 ( 0.169)\tLoss 2.3298e-01 (2.2598e-01)\tAcc@1  92.19 ( 93.22)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [87][ 90/391]\tTime  0.168 ( 0.168)\tLoss 2.1813e-01 (2.2683e-01)\tAcc@1  94.53 ( 93.29)\tAcc@5 100.00 ( 99.71)\n",
            "Epoch: [87][120/391]\tTime  0.168 ( 0.168)\tLoss 2.2637e-01 (2.2208e-01)\tAcc@1  92.19 ( 93.43)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [87][150/391]\tTime  0.168 ( 0.168)\tLoss 2.3403e-01 (2.2309e-01)\tAcc@1  91.41 ( 93.36)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [87][180/391]\tTime  0.166 ( 0.168)\tLoss 2.4437e-01 (2.2550e-01)\tAcc@1  94.53 ( 93.34)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [87][210/391]\tTime  0.169 ( 0.168)\tLoss 1.4691e-01 (2.2484e-01)\tAcc@1  93.75 ( 93.24)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [87][240/391]\tTime  0.165 ( 0.168)\tLoss 3.1422e-01 (2.2466e-01)\tAcc@1  90.62 ( 93.26)\tAcc@5  99.22 ( 99.74)\n",
            "Epoch: [87][270/391]\tTime  0.167 ( 0.168)\tLoss 2.8555e-01 (2.2885e-01)\tAcc@1  91.41 ( 93.10)\tAcc@5 100.00 ( 99.73)\n",
            "Epoch: [87][300/391]\tTime  0.170 ( 0.168)\tLoss 3.2396e-01 (2.3324e-01)\tAcc@1  89.06 ( 92.96)\tAcc@5  99.22 ( 99.73)\n",
            "Epoch: [87][330/391]\tTime  0.167 ( 0.168)\tLoss 2.7959e-01 (2.3657e-01)\tAcc@1  89.06 ( 92.83)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [87][360/391]\tTime  0.167 ( 0.167)\tLoss 1.9570e-01 (2.4013e-01)\tAcc@1  92.19 ( 92.72)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [87][390/391]\tTime  0.151 ( 0.167)\tLoss 4.3034e-01 (2.4311e-01)\tAcc@1  90.00 ( 92.61)\tAcc@5  98.75 ( 99.72)\n",
            "==> Train Accuracy: Acc@1 92.606 || Acc@5 99.722\n",
            "==> Test Accuracy:  Acc@1 68.480 || Acc@5 90.070\n",
            "==> 69.58 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 88, lr: 0.020000000000000004 -----\n",
            "Epoch: [88][  0/391]\tTime  0.282 ( 0.282)\tLoss 3.1821e-01 (3.1821e-01)\tAcc@1  89.84 ( 89.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [88][ 30/391]\tTime  0.167 ( 0.171)\tLoss 2.0267e-01 (2.0770e-01)\tAcc@1  95.31 ( 94.08)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [88][ 60/391]\tTime  0.168 ( 0.169)\tLoss 2.4149e-01 (2.0628e-01)\tAcc@1  94.53 ( 93.97)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [88][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.8728e-01 (2.0374e-01)\tAcc@1  94.53 ( 94.03)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [88][120/391]\tTime  0.167 ( 0.168)\tLoss 2.0054e-01 (2.0547e-01)\tAcc@1  93.75 ( 94.05)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [88][150/391]\tTime  0.170 ( 0.168)\tLoss 2.2357e-01 (2.0737e-01)\tAcc@1  92.19 ( 93.99)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [88][180/391]\tTime  0.168 ( 0.168)\tLoss 2.2716e-01 (2.0693e-01)\tAcc@1  91.41 ( 94.01)\tAcc@5 100.00 ( 99.82)\n",
            "Epoch: [88][210/391]\tTime  0.169 ( 0.168)\tLoss 1.7370e-01 (2.0978e-01)\tAcc@1  95.31 ( 93.87)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [88][240/391]\tTime  0.168 ( 0.168)\tLoss 2.5381e-01 (2.1332e-01)\tAcc@1  93.75 ( 93.72)\tAcc@5  99.22 ( 99.82)\n",
            "Epoch: [88][270/391]\tTime  0.167 ( 0.168)\tLoss 1.8400e-01 (2.1561e-01)\tAcc@1  94.53 ( 93.68)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [88][300/391]\tTime  0.168 ( 0.168)\tLoss 2.3147e-01 (2.1958e-01)\tAcc@1  92.97 ( 93.56)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [88][330/391]\tTime  0.168 ( 0.168)\tLoss 3.3249e-01 (2.2165e-01)\tAcc@1  89.06 ( 93.49)\tAcc@5  99.22 ( 99.79)\n",
            "Epoch: [88][360/391]\tTime  0.169 ( 0.168)\tLoss 3.1966e-01 (2.2608e-01)\tAcc@1  89.06 ( 93.30)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [88][390/391]\tTime  0.152 ( 0.168)\tLoss 3.1836e-01 (2.2957e-01)\tAcc@1  87.50 ( 93.19)\tAcc@5  97.50 ( 99.78)\n",
            "==> Train Accuracy: Acc@1 93.186 || Acc@5 99.776\n",
            "==> Test Accuracy:  Acc@1 67.980 || Acc@5 90.010\n",
            "==> 69.73 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 89, lr: 0.020000000000000004 -----\n",
            "Epoch: [89][  0/391]\tTime  0.284 ( 0.284)\tLoss 6.9387e-02 (6.9387e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [89][ 30/391]\tTime  0.166 ( 0.170)\tLoss 2.0940e-01 (2.0592e-01)\tAcc@1  92.97 ( 94.23)\tAcc@5 100.00 ( 99.72)\n",
            "Epoch: [89][ 60/391]\tTime  0.167 ( 0.169)\tLoss 3.1342e-01 (2.1278e-01)\tAcc@1  91.41 ( 93.79)\tAcc@5  99.22 ( 99.74)\n",
            "Epoch: [89][ 90/391]\tTime  0.166 ( 0.168)\tLoss 1.9683e-01 (2.1412e-01)\tAcc@1  93.75 ( 93.68)\tAcc@5 100.00 ( 99.74)\n",
            "Epoch: [89][120/391]\tTime  0.169 ( 0.168)\tLoss 1.1562e-01 (2.0904e-01)\tAcc@1  97.66 ( 93.85)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [89][150/391]\tTime  0.168 ( 0.168)\tLoss 2.6298e-01 (2.0990e-01)\tAcc@1  92.19 ( 93.87)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [89][180/391]\tTime  0.167 ( 0.168)\tLoss 1.9910e-01 (2.1275e-01)\tAcc@1  92.97 ( 93.81)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [89][210/391]\tTime  0.166 ( 0.168)\tLoss 2.2722e-01 (2.1401e-01)\tAcc@1  92.19 ( 93.72)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [89][240/391]\tTime  0.166 ( 0.167)\tLoss 2.3722e-01 (2.1617e-01)\tAcc@1  92.19 ( 93.62)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [89][270/391]\tTime  0.169 ( 0.167)\tLoss 1.8332e-01 (2.1797e-01)\tAcc@1  94.53 ( 93.51)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [89][300/391]\tTime  0.163 ( 0.167)\tLoss 2.0413e-01 (2.2012e-01)\tAcc@1  94.53 ( 93.43)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [89][330/391]\tTime  0.168 ( 0.167)\tLoss 3.9051e-01 (2.2381e-01)\tAcc@1  87.50 ( 93.33)\tAcc@5  99.22 ( 99.77)\n",
            "Epoch: [89][360/391]\tTime  0.168 ( 0.167)\tLoss 3.0503e-01 (2.2702e-01)\tAcc@1  87.50 ( 93.16)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [89][390/391]\tTime  0.149 ( 0.167)\tLoss 3.4624e-01 (2.3211e-01)\tAcc@1  88.75 ( 92.99)\tAcc@5  97.50 ( 99.75)\n",
            "==> Train Accuracy: Acc@1 92.992 || Acc@5 99.754\n",
            "==> Test Accuracy:  Acc@1 68.450 || Acc@5 89.820\n",
            "==> 69.58 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 90, lr: 0.004000000000000001 -----\n",
            "Epoch: [90][  0/391]\tTime  0.281 ( 0.281)\tLoss 2.6526e-01 (2.6526e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [90][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.3922e-01 (1.8680e-01)\tAcc@1  96.09 ( 94.53)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [90][ 60/391]\tTime  0.167 ( 0.169)\tLoss 7.8636e-02 (1.5660e-01)\tAcc@1  98.44 ( 95.63)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [90][ 90/391]\tTime  0.166 ( 0.168)\tLoss 1.1833e-01 (1.4176e-01)\tAcc@1  97.66 ( 96.06)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [90][120/391]\tTime  0.167 ( 0.168)\tLoss 1.1874e-01 (1.3288e-01)\tAcc@1  96.88 ( 96.24)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [90][150/391]\tTime  0.167 ( 0.168)\tLoss 6.8126e-02 (1.2488e-01)\tAcc@1  97.66 ( 96.46)\tAcc@5 100.00 ( 99.93)\n",
            "Epoch: [90][180/391]\tTime  0.168 ( 0.168)\tLoss 6.2466e-02 (1.1825e-01)\tAcc@1  99.22 ( 96.72)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [90][210/391]\tTime  0.168 ( 0.168)\tLoss 7.4758e-02 (1.1262e-01)\tAcc@1  98.44 ( 96.92)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [90][240/391]\tTime  0.167 ( 0.168)\tLoss 4.9793e-02 (1.0952e-01)\tAcc@1  97.66 ( 97.01)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [90][270/391]\tTime  0.165 ( 0.168)\tLoss 7.0677e-02 (1.0564e-01)\tAcc@1  98.44 ( 97.14)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [90][300/391]\tTime  0.168 ( 0.168)\tLoss 9.1486e-02 (1.0179e-01)\tAcc@1  99.22 ( 97.27)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [90][330/391]\tTime  0.168 ( 0.168)\tLoss 5.1886e-02 (9.9396e-02)\tAcc@1  99.22 ( 97.36)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [90][360/391]\tTime  0.167 ( 0.168)\tLoss 7.3090e-02 (9.7173e-02)\tAcc@1  97.66 ( 97.42)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [90][390/391]\tTime  0.150 ( 0.168)\tLoss 6.7469e-02 (9.4911e-02)\tAcc@1  98.75 ( 97.49)\tAcc@5 100.00 ( 99.96)\n",
            "==> Train Accuracy: Acc@1 97.490 || Acc@5 99.964\n",
            "==> Test Accuracy:  Acc@1 74.850 || Acc@5 93.050\n",
            "==> 69.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 91, lr: 0.004000000000000001 -----\n",
            "Epoch: [91][  0/391]\tTime  0.314 ( 0.314)\tLoss 7.1243e-02 (7.1243e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [91][ 30/391]\tTime  0.166 ( 0.172)\tLoss 5.0561e-02 (5.8985e-02)\tAcc@1  99.22 ( 98.84)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [91][ 60/391]\tTime  0.166 ( 0.170)\tLoss 4.3391e-02 (5.5092e-02)\tAcc@1 100.00 ( 99.03)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][ 90/391]\tTime  0.167 ( 0.169)\tLoss 5.1153e-02 (5.2960e-02)\tAcc@1  99.22 ( 99.04)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][120/391]\tTime  0.165 ( 0.168)\tLoss 5.1835e-02 (5.3055e-02)\tAcc@1  98.44 ( 98.97)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][150/391]\tTime  0.165 ( 0.168)\tLoss 3.7898e-02 (5.3396e-02)\tAcc@1  99.22 ( 98.94)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][180/391]\tTime  0.168 ( 0.168)\tLoss 8.0718e-02 (5.3975e-02)\tAcc@1  96.88 ( 98.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [91][210/391]\tTime  0.166 ( 0.168)\tLoss 2.7706e-02 (5.3562e-02)\tAcc@1 100.00 ( 98.89)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][240/391]\tTime  0.168 ( 0.168)\tLoss 6.0653e-02 (5.3130e-02)\tAcc@1  99.22 ( 98.92)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][270/391]\tTime  0.168 ( 0.168)\tLoss 3.3714e-02 (5.3115e-02)\tAcc@1 100.00 ( 98.92)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][300/391]\tTime  0.167 ( 0.168)\tLoss 3.2078e-02 (5.2684e-02)\tAcc@1 100.00 ( 98.93)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][330/391]\tTime  0.167 ( 0.168)\tLoss 4.8896e-02 (5.1901e-02)\tAcc@1  99.22 ( 98.94)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][360/391]\tTime  0.168 ( 0.168)\tLoss 5.9137e-02 (5.1438e-02)\tAcc@1  98.44 ( 98.95)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [91][390/391]\tTime  0.151 ( 0.167)\tLoss 5.3378e-02 (5.1236e-02)\tAcc@1  98.75 ( 98.96)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 98.956 || Acc@5 99.994\n",
            "==> Test Accuracy:  Acc@1 75.490 || Acc@5 93.510\n",
            "==> 69.65 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 92, lr: 0.004000000000000001 -----\n",
            "Epoch: [92][  0/391]\tTime  0.269 ( 0.269)\tLoss 5.1957e-02 (5.1957e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][ 30/391]\tTime  0.166 ( 0.170)\tLoss 1.8823e-02 (3.4882e-02)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.4238e-02 (3.7081e-02)\tAcc@1 100.00 ( 99.45)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][ 90/391]\tTime  0.168 ( 0.168)\tLoss 4.0343e-02 (3.7498e-02)\tAcc@1  99.22 ( 99.38)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][120/391]\tTime  0.167 ( 0.168)\tLoss 3.3127e-02 (3.7234e-02)\tAcc@1  99.22 ( 99.37)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][150/391]\tTime  0.167 ( 0.168)\tLoss 3.5191e-02 (3.8213e-02)\tAcc@1  99.22 ( 99.32)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][180/391]\tTime  0.167 ( 0.168)\tLoss 3.0192e-02 (3.8315e-02)\tAcc@1 100.00 ( 99.32)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][210/391]\tTime  0.167 ( 0.168)\tLoss 3.5458e-02 (3.8042e-02)\tAcc@1  99.22 ( 99.35)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][240/391]\tTime  0.169 ( 0.167)\tLoss 1.5884e-02 (3.7698e-02)\tAcc@1 100.00 ( 99.34)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][270/391]\tTime  0.168 ( 0.167)\tLoss 2.7462e-02 (3.7703e-02)\tAcc@1 100.00 ( 99.34)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][300/391]\tTime  0.163 ( 0.167)\tLoss 2.4520e-02 (3.7592e-02)\tAcc@1 100.00 ( 99.34)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][330/391]\tTime  0.168 ( 0.167)\tLoss 2.1002e-02 (3.7604e-02)\tAcc@1 100.00 ( 99.34)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][360/391]\tTime  0.172 ( 0.167)\tLoss 4.4128e-02 (3.7397e-02)\tAcc@1  99.22 ( 99.36)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][390/391]\tTime  0.152 ( 0.167)\tLoss 7.9176e-02 (3.7339e-02)\tAcc@1  97.50 ( 99.35)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.352 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 75.760 || Acc@5 93.350\n",
            "==> 69.58 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 93, lr: 0.004000000000000001 -----\n",
            "Epoch: [93][  0/391]\tTime  0.294 ( 0.294)\tLoss 2.2404e-02 (2.2404e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][ 30/391]\tTime  0.165 ( 0.171)\tLoss 4.4711e-02 (3.1671e-02)\tAcc@1  99.22 ( 99.55)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][ 60/391]\tTime  0.168 ( 0.170)\tLoss 3.6459e-02 (3.2922e-02)\tAcc@1  99.22 ( 99.50)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][ 90/391]\tTime  0.169 ( 0.169)\tLoss 1.4595e-02 (3.1669e-02)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][120/391]\tTime  0.168 ( 0.169)\tLoss 2.1379e-02 (3.1669e-02)\tAcc@1 100.00 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][150/391]\tTime  0.168 ( 0.169)\tLoss 2.4062e-02 (3.1336e-02)\tAcc@1 100.00 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][180/391]\tTime  0.168 ( 0.168)\tLoss 3.9682e-02 (3.1197e-02)\tAcc@1  99.22 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][210/391]\tTime  0.165 ( 0.168)\tLoss 3.8414e-02 (3.1194e-02)\tAcc@1  99.22 ( 99.55)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][240/391]\tTime  0.166 ( 0.168)\tLoss 2.1482e-02 (3.1200e-02)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][270/391]\tTime  0.162 ( 0.168)\tLoss 1.4451e-02 (3.1402e-02)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][300/391]\tTime  0.170 ( 0.168)\tLoss 1.8079e-02 (3.1525e-02)\tAcc@1 100.00 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][330/391]\tTime  0.167 ( 0.168)\tLoss 2.8764e-02 (3.1444e-02)\tAcc@1 100.00 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][360/391]\tTime  0.166 ( 0.168)\tLoss 2.7215e-02 (3.1588e-02)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][390/391]\tTime  0.149 ( 0.168)\tLoss 5.6562e-02 (3.1575e-02)\tAcc@1  98.75 ( 99.52)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.522 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 75.490 || Acc@5 93.380\n",
            "==> 69.77 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 94, lr: 0.004000000000000001 -----\n",
            "Epoch: [94][  0/391]\tTime  0.306 ( 0.306)\tLoss 3.3767e-02 (3.3767e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.2381e-02 (2.5935e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][ 60/391]\tTime  0.169 ( 0.169)\tLoss 1.9809e-02 (2.5479e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][ 90/391]\tTime  0.169 ( 0.168)\tLoss 1.5055e-02 (2.5439e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][120/391]\tTime  0.168 ( 0.168)\tLoss 1.9565e-02 (2.5380e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][150/391]\tTime  0.168 ( 0.168)\tLoss 2.3606e-02 (2.5680e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][180/391]\tTime  0.166 ( 0.168)\tLoss 3.4419e-02 (2.5976e-02)\tAcc@1  99.22 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][210/391]\tTime  0.168 ( 0.168)\tLoss 1.7672e-02 (2.5930e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][240/391]\tTime  0.167 ( 0.168)\tLoss 1.6111e-02 (2.5746e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][270/391]\tTime  0.168 ( 0.168)\tLoss 1.6447e-02 (2.6448e-02)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][300/391]\tTime  0.167 ( 0.168)\tLoss 2.7344e-02 (2.6261e-02)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][330/391]\tTime  0.166 ( 0.168)\tLoss 2.8328e-02 (2.6278e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][360/391]\tTime  0.167 ( 0.168)\tLoss 3.3682e-02 (2.6378e-02)\tAcc@1  99.22 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][390/391]\tTime  0.150 ( 0.168)\tLoss 1.7256e-02 (2.6444e-02)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.644 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 75.990 || Acc@5 93.470\n",
            "==> 69.69 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 95, lr: 0.004000000000000001 -----\n",
            "Epoch: [95][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.9364e-02 (1.9364e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][ 30/391]\tTime  0.168 ( 0.170)\tLoss 1.3686e-02 (2.1981e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][ 60/391]\tTime  0.168 ( 0.169)\tLoss 2.7430e-02 (2.2332e-02)\tAcc@1  99.22 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][ 90/391]\tTime  0.174 ( 0.168)\tLoss 2.9422e-02 (2.3298e-02)\tAcc@1  99.22 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][120/391]\tTime  0.168 ( 0.168)\tLoss 1.6133e-02 (2.2881e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][150/391]\tTime  0.166 ( 0.168)\tLoss 1.7005e-02 (2.2883e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][180/391]\tTime  0.168 ( 0.168)\tLoss 1.5100e-02 (2.3187e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][210/391]\tTime  0.168 ( 0.168)\tLoss 1.7984e-02 (2.3386e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][240/391]\tTime  0.168 ( 0.168)\tLoss 2.3828e-02 (2.3451e-02)\tAcc@1  99.22 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][270/391]\tTime  0.168 ( 0.168)\tLoss 1.3302e-02 (2.3409e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][300/391]\tTime  0.168 ( 0.168)\tLoss 2.1717e-02 (2.3612e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][330/391]\tTime  0.167 ( 0.168)\tLoss 1.7099e-02 (2.3652e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][360/391]\tTime  0.167 ( 0.168)\tLoss 1.4071e-02 (2.3454e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][390/391]\tTime  0.150 ( 0.168)\tLoss 1.5976e-02 (2.3656e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.706 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 75.820 || Acc@5 93.390\n",
            "==> 69.75 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 96, lr: 0.004000000000000001 -----\n",
            "Epoch: [96][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.8628e-02 (1.8628e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][ 30/391]\tTime  0.166 ( 0.170)\tLoss 2.6477e-02 (2.1937e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][ 60/391]\tTime  0.166 ( 0.169)\tLoss 2.8203e-02 (2.0090e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][ 90/391]\tTime  0.169 ( 0.168)\tLoss 1.9654e-02 (2.1037e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][120/391]\tTime  0.168 ( 0.168)\tLoss 3.3953e-02 (2.0993e-02)\tAcc@1  98.44 ( 99.76)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [96][150/391]\tTime  0.167 ( 0.168)\tLoss 1.1968e-02 (2.1487e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [96][180/391]\tTime  0.166 ( 0.168)\tLoss 1.1361e-02 (2.1415e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][210/391]\tTime  0.165 ( 0.168)\tLoss 2.5316e-02 (2.1539e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][240/391]\tTime  0.167 ( 0.167)\tLoss 4.2461e-02 (2.1414e-02)\tAcc@1  98.44 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][270/391]\tTime  0.170 ( 0.167)\tLoss 9.4006e-03 (2.0991e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][300/391]\tTime  0.167 ( 0.167)\tLoss 2.8240e-02 (2.0804e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][330/391]\tTime  0.168 ( 0.167)\tLoss 1.6970e-02 (2.0936e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][360/391]\tTime  0.168 ( 0.167)\tLoss 1.9984e-02 (2.1170e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][390/391]\tTime  0.151 ( 0.167)\tLoss 3.0182e-02 (2.1475e-02)\tAcc@1  98.75 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.744 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 76.200 || Acc@5 93.390\n",
            "==> 69.60 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 97, lr: 0.004000000000000001 -----\n",
            "Epoch: [97][  0/391]\tTime  0.281 ( 0.281)\tLoss 1.5287e-02 (1.5287e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][ 30/391]\tTime  0.168 ( 0.170)\tLoss 1.8651e-02 (1.9175e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.2199e-02 (1.8674e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][ 90/391]\tTime  0.166 ( 0.168)\tLoss 1.6782e-02 (1.9034e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][120/391]\tTime  0.172 ( 0.168)\tLoss 2.3407e-02 (1.9351e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][150/391]\tTime  0.165 ( 0.168)\tLoss 1.3265e-02 (1.9439e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][180/391]\tTime  0.166 ( 0.168)\tLoss 2.5150e-02 (1.9833e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][210/391]\tTime  0.167 ( 0.167)\tLoss 3.6970e-02 (1.9899e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][240/391]\tTime  0.167 ( 0.167)\tLoss 3.3582e-02 (1.9897e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][270/391]\tTime  0.168 ( 0.167)\tLoss 3.4523e-02 (2.0422e-02)\tAcc@1  98.44 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][300/391]\tTime  0.168 ( 0.167)\tLoss 1.0210e-02 (2.0310e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][330/391]\tTime  0.168 ( 0.167)\tLoss 1.9919e-02 (2.0161e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][360/391]\tTime  0.167 ( 0.167)\tLoss 2.3419e-02 (2.0421e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][390/391]\tTime  0.152 ( 0.167)\tLoss 6.0858e-03 (2.0478e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.740 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.130 || Acc@5 93.360\n",
            "==> 69.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 98, lr: 0.004000000000000001 -----\n",
            "Epoch: [98][  0/391]\tTime  0.297 ( 0.297)\tLoss 3.9664e-02 (3.9664e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.0370e-02 (1.9255e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][ 60/391]\tTime  0.169 ( 0.169)\tLoss 1.4523e-02 (1.8255e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.5928e-02 (1.7583e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][120/391]\tTime  0.168 ( 0.168)\tLoss 1.3522e-02 (1.7438e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][150/391]\tTime  0.167 ( 0.168)\tLoss 1.6976e-02 (1.7396e-02)\tAcc@1  99.22 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][180/391]\tTime  0.167 ( 0.168)\tLoss 1.8034e-02 (1.7713e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][210/391]\tTime  0.167 ( 0.168)\tLoss 1.6864e-02 (1.8230e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][240/391]\tTime  0.166 ( 0.168)\tLoss 2.3647e-02 (1.8516e-02)\tAcc@1  99.22 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][270/391]\tTime  0.166 ( 0.168)\tLoss 1.6147e-02 (1.8687e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][300/391]\tTime  0.167 ( 0.168)\tLoss 1.5755e-02 (1.8803e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][330/391]\tTime  0.167 ( 0.168)\tLoss 1.5590e-02 (1.8930e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][360/391]\tTime  0.164 ( 0.168)\tLoss 1.9264e-02 (1.8965e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][390/391]\tTime  0.151 ( 0.168)\tLoss 1.0411e-02 (1.8984e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.794 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.210 || Acc@5 93.390\n",
            "==> 69.66 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 99, lr: 0.004000000000000001 -----\n",
            "Epoch: [99][  0/391]\tTime  0.296 ( 0.296)\tLoss 2.6465e-02 (2.6465e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][ 30/391]\tTime  0.167 ( 0.171)\tLoss 2.6884e-02 (1.9463e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.7793e-02 (1.8735e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][ 90/391]\tTime  0.165 ( 0.168)\tLoss 2.4669e-02 (1.8232e-02)\tAcc@1  99.22 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][120/391]\tTime  0.167 ( 0.168)\tLoss 3.0954e-02 (1.8177e-02)\tAcc@1  99.22 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][150/391]\tTime  0.165 ( 0.168)\tLoss 3.8509e-02 (1.8701e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][180/391]\tTime  0.166 ( 0.168)\tLoss 1.2330e-02 (1.8801e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][210/391]\tTime  0.166 ( 0.168)\tLoss 2.5301e-02 (1.9099e-02)\tAcc@1  99.22 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][240/391]\tTime  0.167 ( 0.168)\tLoss 9.4645e-03 (1.9033e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][270/391]\tTime  0.169 ( 0.167)\tLoss 1.4703e-02 (1.9028e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][300/391]\tTime  0.166 ( 0.167)\tLoss 1.5244e-02 (1.8947e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][330/391]\tTime  0.167 ( 0.167)\tLoss 1.5207e-02 (1.8915e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][360/391]\tTime  0.166 ( 0.167)\tLoss 1.3198e-02 (1.8868e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][390/391]\tTime  0.151 ( 0.167)\tLoss 2.0294e-02 (1.8760e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.766 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.200 || Acc@5 93.480\n",
            "==> 69.56 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 100, lr: 0.004000000000000001 -----\n",
            "Epoch: [100][  0/391]\tTime  0.279 ( 0.279)\tLoss 9.9609e-03 (9.9609e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.8111e-02 (1.5343e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][ 60/391]\tTime  0.168 ( 0.169)\tLoss 3.7926e-02 (1.6724e-02)\tAcc@1  99.22 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][ 90/391]\tTime  0.172 ( 0.169)\tLoss 1.1470e-02 (1.7655e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][120/391]\tTime  0.167 ( 0.168)\tLoss 1.6822e-02 (1.7890e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][150/391]\tTime  0.167 ( 0.168)\tLoss 2.4736e-02 (1.8512e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][180/391]\tTime  0.168 ( 0.168)\tLoss 1.2408e-02 (1.8558e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][210/391]\tTime  0.168 ( 0.168)\tLoss 1.9667e-02 (1.8315e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][240/391]\tTime  0.168 ( 0.168)\tLoss 8.8039e-03 (1.8357e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][270/391]\tTime  0.168 ( 0.168)\tLoss 1.0719e-02 (1.8314e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][300/391]\tTime  0.168 ( 0.168)\tLoss 3.4746e-02 (1.8205e-02)\tAcc@1  99.22 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][330/391]\tTime  0.166 ( 0.168)\tLoss 1.5089e-02 (1.8054e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][360/391]\tTime  0.166 ( 0.168)\tLoss 1.0214e-02 (1.8101e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][390/391]\tTime  0.149 ( 0.168)\tLoss 2.7141e-02 (1.7955e-02)\tAcc@1  98.75 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.808 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.330 || Acc@5 93.460\n",
            "==> 69.73 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 101, lr: 0.004000000000000001 -----\n",
            "Epoch: [101][  0/391]\tTime  0.287 ( 0.287)\tLoss 1.0718e-02 (1.0718e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][ 30/391]\tTime  0.173 ( 0.171)\tLoss 8.9463e-03 (1.5060e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.2716e-02 (1.6572e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.5269e-02 (1.6833e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][120/391]\tTime  0.170 ( 0.168)\tLoss 1.2123e-02 (1.6563e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][150/391]\tTime  0.168 ( 0.168)\tLoss 1.0322e-02 (1.6584e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][180/391]\tTime  0.168 ( 0.168)\tLoss 1.3443e-02 (1.6630e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][210/391]\tTime  0.169 ( 0.168)\tLoss 1.0972e-02 (1.6582e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][240/391]\tTime  0.166 ( 0.168)\tLoss 1.2623e-02 (1.6423e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][270/391]\tTime  0.166 ( 0.168)\tLoss 8.3817e-03 (1.6598e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][300/391]\tTime  0.168 ( 0.168)\tLoss 1.6866e-02 (1.6708e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][330/391]\tTime  0.168 ( 0.168)\tLoss 7.5627e-03 (1.6760e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][360/391]\tTime  0.163 ( 0.167)\tLoss 1.4603e-02 (1.6753e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][390/391]\tTime  0.150 ( 0.167)\tLoss 1.3969e-02 (1.6635e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.816 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.180 || Acc@5 93.400\n",
            "==> 69.62 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 102, lr: 0.004000000000000001 -----\n",
            "Epoch: [102][  0/391]\tTime  0.296 ( 0.296)\tLoss 2.3377e-02 (2.3377e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 30/391]\tTime  0.168 ( 0.170)\tLoss 1.1652e-02 (1.5011e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 60/391]\tTime  0.167 ( 0.169)\tLoss 3.0909e-02 (1.4492e-02)\tAcc@1  99.22 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.3836e-02 (1.4485e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][120/391]\tTime  0.166 ( 0.168)\tLoss 1.4773e-02 (1.4534e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][150/391]\tTime  0.164 ( 0.168)\tLoss 1.0230e-02 (1.4651e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][180/391]\tTime  0.168 ( 0.168)\tLoss 8.0740e-03 (1.5003e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][210/391]\tTime  0.168 ( 0.168)\tLoss 2.5344e-02 (1.5304e-02)\tAcc@1  99.22 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][240/391]\tTime  0.169 ( 0.168)\tLoss 1.0974e-02 (1.5049e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][270/391]\tTime  0.169 ( 0.168)\tLoss 9.8214e-03 (1.5098e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][300/391]\tTime  0.167 ( 0.168)\tLoss 9.7013e-03 (1.5186e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][330/391]\tTime  0.168 ( 0.168)\tLoss 2.1236e-02 (1.5413e-02)\tAcc@1  99.22 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][360/391]\tTime  0.166 ( 0.168)\tLoss 2.1025e-02 (1.5565e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][390/391]\tTime  0.148 ( 0.168)\tLoss 2.8068e-02 (1.5587e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.854 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.350 || Acc@5 93.500\n",
            "==> 69.71 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 103, lr: 0.004000000000000001 -----\n",
            "Epoch: [103][  0/391]\tTime  0.304 ( 0.304)\tLoss 9.2443e-03 (9.2443e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 30/391]\tTime  0.168 ( 0.171)\tLoss 2.0158e-02 (1.3942e-02)\tAcc@1  99.22 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 60/391]\tTime  0.160 ( 0.169)\tLoss 1.8432e-02 (1.4627e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 90/391]\tTime  0.168 ( 0.168)\tLoss 8.0635e-03 (1.4167e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][120/391]\tTime  0.166 ( 0.168)\tLoss 1.3065e-02 (1.4047e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][150/391]\tTime  0.165 ( 0.168)\tLoss 1.5012e-02 (1.3937e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][180/391]\tTime  0.167 ( 0.168)\tLoss 1.6010e-02 (1.3820e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][210/391]\tTime  0.167 ( 0.168)\tLoss 1.3544e-02 (1.4204e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][240/391]\tTime  0.167 ( 0.168)\tLoss 9.5841e-03 (1.4478e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][270/391]\tTime  0.167 ( 0.168)\tLoss 1.6244e-02 (1.4522e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][300/391]\tTime  0.167 ( 0.168)\tLoss 1.2937e-02 (1.4724e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][330/391]\tTime  0.168 ( 0.167)\tLoss 1.5918e-02 (1.4868e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][360/391]\tTime  0.166 ( 0.167)\tLoss 1.6783e-02 (1.4885e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][390/391]\tTime  0.151 ( 0.167)\tLoss 1.5747e-02 (1.4730e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.882 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.340 || Acc@5 93.510\n",
            "==> 69.60 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 104, lr: 0.004000000000000001 -----\n",
            "Epoch: [104][  0/391]\tTime  0.293 ( 0.293)\tLoss 1.0342e-02 (1.0342e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][ 30/391]\tTime  0.169 ( 0.171)\tLoss 3.0820e-02 (1.3517e-02)\tAcc@1  99.22 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][ 60/391]\tTime  0.168 ( 0.169)\tLoss 2.3604e-02 (1.3375e-02)\tAcc@1  99.22 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][ 90/391]\tTime  0.166 ( 0.168)\tLoss 8.4543e-03 (1.3783e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][120/391]\tTime  0.167 ( 0.168)\tLoss 8.6592e-03 (1.3712e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][150/391]\tTime  0.168 ( 0.168)\tLoss 1.5537e-02 (1.4297e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][180/391]\tTime  0.168 ( 0.168)\tLoss 1.5583e-02 (1.4350e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][210/391]\tTime  0.167 ( 0.168)\tLoss 3.2720e-02 (1.4237e-02)\tAcc@1  99.22 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][240/391]\tTime  0.167 ( 0.168)\tLoss 9.5705e-03 (1.4278e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][270/391]\tTime  0.166 ( 0.168)\tLoss 1.4805e-02 (1.4366e-02)\tAcc@1  99.22 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][300/391]\tTime  0.167 ( 0.168)\tLoss 1.1849e-02 (1.4284e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][330/391]\tTime  0.170 ( 0.168)\tLoss 1.4360e-02 (1.4580e-02)\tAcc@1 100.00 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][360/391]\tTime  0.167 ( 0.168)\tLoss 1.9257e-02 (1.4747e-02)\tAcc@1  99.22 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][390/391]\tTime  0.151 ( 0.167)\tLoss 2.4508e-02 (1.4986e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.850 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.530 || Acc@5 93.630\n",
            "==> 69.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 105, lr: 0.004000000000000001 -----\n",
            "Epoch: [105][  0/391]\tTime  0.272 ( 0.272)\tLoss 9.7144e-03 (9.7144e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][ 30/391]\tTime  0.165 ( 0.171)\tLoss 1.0458e-02 (1.3021e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][ 60/391]\tTime  0.166 ( 0.169)\tLoss 8.6785e-03 (1.3871e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.8321e-02 (1.3552e-02)\tAcc@1  99.22 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][120/391]\tTime  0.163 ( 0.168)\tLoss 1.5342e-02 (1.3690e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][150/391]\tTime  0.170 ( 0.168)\tLoss 2.3476e-02 (1.3664e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][180/391]\tTime  0.166 ( 0.168)\tLoss 1.6050e-02 (1.4098e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][210/391]\tTime  0.166 ( 0.168)\tLoss 1.3276e-02 (1.4091e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][240/391]\tTime  0.169 ( 0.168)\tLoss 1.5623e-02 (1.4011e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][270/391]\tTime  0.173 ( 0.168)\tLoss 1.8028e-02 (1.4016e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][300/391]\tTime  0.168 ( 0.168)\tLoss 9.5638e-03 (1.4015e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][330/391]\tTime  0.166 ( 0.168)\tLoss 7.7727e-03 (1.4065e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][360/391]\tTime  0.168 ( 0.168)\tLoss 6.9009e-03 (1.4139e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][390/391]\tTime  0.150 ( 0.167)\tLoss 1.0413e-02 (1.4276e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.888 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.580 || Acc@5 93.590\n",
            "==> 69.63 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 106, lr: 0.004000000000000001 -----\n",
            "Epoch: [106][  0/391]\tTime  0.299 ( 0.299)\tLoss 1.2524e-02 (1.2524e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.5043e-02 (1.4795e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][ 60/391]\tTime  0.168 ( 0.169)\tLoss 2.0000e-02 (1.4416e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][ 90/391]\tTime  0.168 ( 0.168)\tLoss 9.4078e-03 (1.3936e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][120/391]\tTime  0.168 ( 0.168)\tLoss 5.5946e-02 (1.4425e-02)\tAcc@1  98.44 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][150/391]\tTime  0.169 ( 0.168)\tLoss 1.4555e-02 (1.4351e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][180/391]\tTime  0.169 ( 0.168)\tLoss 7.5078e-03 (1.4076e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][210/391]\tTime  0.168 ( 0.168)\tLoss 6.0004e-02 (1.4300e-02)\tAcc@1  98.44 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][240/391]\tTime  0.167 ( 0.168)\tLoss 1.0212e-02 (1.4179e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][270/391]\tTime  0.165 ( 0.167)\tLoss 1.1362e-02 (1.3993e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][300/391]\tTime  0.167 ( 0.167)\tLoss 1.0675e-02 (1.4025e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][330/391]\tTime  0.167 ( 0.167)\tLoss 1.5270e-02 (1.3856e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][360/391]\tTime  0.167 ( 0.167)\tLoss 8.5083e-03 (1.3714e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][390/391]\tTime  0.151 ( 0.167)\tLoss 1.9652e-02 (1.3659e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.916 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.720 || Acc@5 93.370\n",
            "==> 69.59 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 107, lr: 0.004000000000000001 -----\n",
            "Epoch: [107][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.0655e-02 (1.0655e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.0894e-02 (1.1870e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][ 60/391]\tTime  0.168 ( 0.169)\tLoss 2.4627e-02 (1.2174e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.3148e-02 (1.2416e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][120/391]\tTime  0.168 ( 0.169)\tLoss 1.8154e-02 (1.2864e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][150/391]\tTime  0.167 ( 0.168)\tLoss 9.8922e-03 (1.3125e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][180/391]\tTime  0.166 ( 0.168)\tLoss 1.8008e-02 (1.3569e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][210/391]\tTime  0.168 ( 0.168)\tLoss 1.2706e-02 (1.3450e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][240/391]\tTime  0.168 ( 0.168)\tLoss 3.2776e-02 (1.3582e-02)\tAcc@1  97.66 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][270/391]\tTime  0.166 ( 0.168)\tLoss 1.4864e-02 (1.3518e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][300/391]\tTime  0.165 ( 0.168)\tLoss 1.2145e-02 (1.3576e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][330/391]\tTime  0.165 ( 0.168)\tLoss 7.8818e-03 (1.3604e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][360/391]\tTime  0.167 ( 0.168)\tLoss 7.6280e-03 (1.3387e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][390/391]\tTime  0.147 ( 0.168)\tLoss 1.4263e-02 (1.3473e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.910 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.640 || Acc@5 93.670\n",
            "==> 69.68 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 108, lr: 0.004000000000000001 -----\n",
            "Epoch: [108][  0/391]\tTime  0.292 ( 0.292)\tLoss 1.2599e-02 (1.2599e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][ 30/391]\tTime  0.166 ( 0.171)\tLoss 1.3995e-02 (1.1573e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][ 60/391]\tTime  0.167 ( 0.169)\tLoss 9.9264e-03 (1.1261e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][ 90/391]\tTime  0.168 ( 0.168)\tLoss 8.7901e-03 (1.1617e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][120/391]\tTime  0.167 ( 0.168)\tLoss 9.4868e-03 (1.1835e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][150/391]\tTime  0.168 ( 0.168)\tLoss 1.9652e-02 (1.1832e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][180/391]\tTime  0.169 ( 0.168)\tLoss 1.1296e-02 (1.2223e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][210/391]\tTime  0.163 ( 0.168)\tLoss 1.0026e-02 (1.2604e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][240/391]\tTime  0.168 ( 0.168)\tLoss 1.0750e-02 (1.2843e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][270/391]\tTime  0.169 ( 0.168)\tLoss 1.0649e-02 (1.3094e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][300/391]\tTime  0.169 ( 0.168)\tLoss 6.3708e-03 (1.3259e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][330/391]\tTime  0.168 ( 0.168)\tLoss 1.4403e-02 (1.3353e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][360/391]\tTime  0.167 ( 0.168)\tLoss 1.1342e-02 (1.3599e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][390/391]\tTime  0.149 ( 0.168)\tLoss 1.3515e-02 (1.3541e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.882 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.500 || Acc@5 93.370\n",
            "==> 69.66 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 109, lr: 0.004000000000000001 -----\n",
            "Epoch: [109][  0/391]\tTime  0.305 ( 0.305)\tLoss 2.2278e-02 (2.2278e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][ 30/391]\tTime  0.166 ( 0.171)\tLoss 8.8945e-03 (1.2059e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][ 60/391]\tTime  0.166 ( 0.169)\tLoss 1.1277e-02 (1.2664e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][ 90/391]\tTime  0.172 ( 0.168)\tLoss 1.3800e-02 (1.2955e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][120/391]\tTime  0.167 ( 0.168)\tLoss 1.5484e-02 (1.3240e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][150/391]\tTime  0.167 ( 0.168)\tLoss 6.3016e-03 (1.3224e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][180/391]\tTime  0.170 ( 0.168)\tLoss 8.7923e-03 (1.3167e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][210/391]\tTime  0.166 ( 0.168)\tLoss 1.3299e-02 (1.3237e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][240/391]\tTime  0.167 ( 0.168)\tLoss 8.5405e-03 (1.3198e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][270/391]\tTime  0.167 ( 0.168)\tLoss 1.5560e-02 (1.3295e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][300/391]\tTime  0.168 ( 0.168)\tLoss 9.6927e-03 (1.3383e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][330/391]\tTime  0.168 ( 0.168)\tLoss 1.5435e-02 (1.3411e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][360/391]\tTime  0.166 ( 0.168)\tLoss 1.0058e-02 (1.3379e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][390/391]\tTime  0.152 ( 0.168)\tLoss 1.4571e-02 (1.3528e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.902 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.710 || Acc@5 93.700\n",
            "==> 69.76 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 110, lr: 0.004000000000000001 -----\n",
            "Epoch: [110][  0/391]\tTime  0.276 ( 0.276)\tLoss 1.4484e-02 (1.4484e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][ 30/391]\tTime  0.168 ( 0.170)\tLoss 1.2361e-02 (1.3495e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][ 60/391]\tTime  0.165 ( 0.169)\tLoss 8.8886e-03 (1.4178e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.1202e-02 (1.2985e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][120/391]\tTime  0.166 ( 0.168)\tLoss 1.3242e-02 (1.2776e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][150/391]\tTime  0.167 ( 0.168)\tLoss 8.2527e-03 (1.2801e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][180/391]\tTime  0.168 ( 0.168)\tLoss 5.8306e-03 (1.2855e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][210/391]\tTime  0.168 ( 0.167)\tLoss 1.1763e-02 (1.2905e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][240/391]\tTime  0.167 ( 0.167)\tLoss 1.0230e-02 (1.2803e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][270/391]\tTime  0.167 ( 0.167)\tLoss 6.1693e-03 (1.2871e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][300/391]\tTime  0.168 ( 0.167)\tLoss 1.5715e-02 (1.2811e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][330/391]\tTime  0.169 ( 0.167)\tLoss 8.8217e-03 (1.2781e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][360/391]\tTime  0.167 ( 0.167)\tLoss 1.2594e-02 (1.2825e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][390/391]\tTime  0.151 ( 0.167)\tLoss 1.6123e-02 (1.2834e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.914 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.740 || Acc@5 93.540\n",
            "==> 69.57 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 111, lr: 0.004000000000000001 -----\n",
            "Epoch: [111][  0/391]\tTime  0.293 ( 0.293)\tLoss 1.7149e-02 (1.7149e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.3784e-02 (1.3092e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][ 60/391]\tTime  0.168 ( 0.169)\tLoss 9.3939e-03 (1.3368e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][ 90/391]\tTime  0.167 ( 0.169)\tLoss 1.7989e-02 (1.2950e-02)\tAcc@1  99.22 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][120/391]\tTime  0.169 ( 0.168)\tLoss 1.3956e-02 (1.2925e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][150/391]\tTime  0.166 ( 0.168)\tLoss 4.0486e-02 (1.2771e-02)\tAcc@1  99.22 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][180/391]\tTime  0.166 ( 0.168)\tLoss 1.3388e-02 (1.2767e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][210/391]\tTime  0.167 ( 0.168)\tLoss 2.3859e-02 (1.3091e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][240/391]\tTime  0.167 ( 0.168)\tLoss 1.0308e-02 (1.3057e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][270/391]\tTime  0.167 ( 0.168)\tLoss 9.9359e-03 (1.3021e-02)\tAcc@1 100.00 ( 99.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][300/391]\tTime  0.169 ( 0.168)\tLoss 1.5833e-02 (1.3048e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][330/391]\tTime  0.166 ( 0.168)\tLoss 1.2310e-02 (1.2954e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][360/391]\tTime  0.166 ( 0.168)\tLoss 7.2768e-03 (1.2983e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][390/391]\tTime  0.151 ( 0.168)\tLoss 2.0737e-02 (1.2940e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.904 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.750 || Acc@5 93.600\n",
            "==> 69.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 112, lr: 0.004000000000000001 -----\n",
            "Epoch: [112][  0/391]\tTime  0.283 ( 0.283)\tLoss 9.7546e-03 (9.7546e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][ 30/391]\tTime  0.168 ( 0.171)\tLoss 9.8400e-03 (1.1148e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][ 60/391]\tTime  0.168 ( 0.170)\tLoss 1.3181e-02 (1.2167e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][ 90/391]\tTime  0.167 ( 0.169)\tLoss 5.6059e-03 (1.2089e-02)\tAcc@1 100.00 ( 99.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][120/391]\tTime  0.167 ( 0.169)\tLoss 2.0782e-02 (1.1874e-02)\tAcc@1  99.22 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][150/391]\tTime  0.167 ( 0.168)\tLoss 9.3224e-03 (1.1880e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][180/391]\tTime  0.167 ( 0.168)\tLoss 7.2887e-03 (1.2126e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][210/391]\tTime  0.165 ( 0.168)\tLoss 9.7324e-03 (1.2239e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][240/391]\tTime  0.162 ( 0.168)\tLoss 1.0090e-02 (1.2311e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][270/391]\tTime  0.166 ( 0.168)\tLoss 1.1444e-02 (1.2284e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][300/391]\tTime  0.166 ( 0.168)\tLoss 1.5555e-02 (1.2256e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][330/391]\tTime  0.167 ( 0.168)\tLoss 7.9238e-03 (1.2229e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][360/391]\tTime  0.167 ( 0.168)\tLoss 9.6539e-03 (1.2096e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][390/391]\tTime  0.150 ( 0.168)\tLoss 6.8489e-03 (1.2165e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.904 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.080 || Acc@5 93.690\n",
            "==> 69.66 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 113, lr: 0.004000000000000001 -----\n",
            "Epoch: [113][  0/391]\tTime  0.294 ( 0.294)\tLoss 8.6683e-03 (8.6683e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][ 30/391]\tTime  0.168 ( 0.171)\tLoss 9.8929e-03 (1.0778e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][ 60/391]\tTime  0.165 ( 0.169)\tLoss 1.0704e-02 (1.1124e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][ 90/391]\tTime  0.169 ( 0.168)\tLoss 1.0134e-02 (1.1407e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][120/391]\tTime  0.166 ( 0.168)\tLoss 1.1138e-02 (1.1348e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][150/391]\tTime  0.167 ( 0.168)\tLoss 1.2871e-02 (1.1531e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][180/391]\tTime  0.167 ( 0.168)\tLoss 1.4336e-02 (1.1593e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][210/391]\tTime  0.168 ( 0.168)\tLoss 2.1921e-02 (1.1902e-02)\tAcc@1  99.22 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][240/391]\tTime  0.168 ( 0.168)\tLoss 9.5472e-03 (1.1935e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][270/391]\tTime  0.168 ( 0.168)\tLoss 7.1358e-03 (1.1880e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][300/391]\tTime  0.169 ( 0.167)\tLoss 8.5100e-03 (1.1896e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][330/391]\tTime  0.167 ( 0.167)\tLoss 8.6417e-03 (1.1978e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][360/391]\tTime  0.168 ( 0.167)\tLoss 1.1035e-02 (1.1958e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][390/391]\tTime  0.150 ( 0.167)\tLoss 5.4623e-02 (1.2108e-02)\tAcc@1  98.75 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.924 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.000 || Acc@5 93.750\n",
            "==> 69.58 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 114, lr: 0.004000000000000001 -----\n",
            "Epoch: [114][  0/391]\tTime  0.295 ( 0.295)\tLoss 8.7690e-03 (8.7690e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.0067e-02 (1.0247e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 60/391]\tTime  0.167 ( 0.169)\tLoss 7.1586e-03 (1.0800e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 90/391]\tTime  0.168 ( 0.169)\tLoss 2.0335e-02 (1.0890e-02)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][120/391]\tTime  0.167 ( 0.168)\tLoss 1.5315e-02 (1.1021e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][150/391]\tTime  0.166 ( 0.168)\tLoss 2.8139e-02 (1.1364e-02)\tAcc@1  98.44 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][180/391]\tTime  0.168 ( 0.168)\tLoss 1.1499e-02 (1.1498e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][210/391]\tTime  0.167 ( 0.168)\tLoss 1.1973e-02 (1.1827e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][240/391]\tTime  0.168 ( 0.168)\tLoss 7.3858e-03 (1.1940e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][270/391]\tTime  0.167 ( 0.168)\tLoss 1.1831e-02 (1.1899e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][300/391]\tTime  0.167 ( 0.168)\tLoss 1.3271e-02 (1.2098e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][330/391]\tTime  0.167 ( 0.168)\tLoss 7.0299e-03 (1.2187e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][360/391]\tTime  0.168 ( 0.168)\tLoss 1.3598e-02 (1.2241e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][390/391]\tTime  0.150 ( 0.168)\tLoss 1.9994e-02 (1.2359e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.910 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.020 || Acc@5 93.760\n",
            "==> 69.70 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 115, lr: 0.004000000000000001 -----\n",
            "Epoch: [115][  0/391]\tTime  0.286 ( 0.286)\tLoss 8.0867e-03 (8.0867e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.3279e-02 (1.1695e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 60/391]\tTime  0.166 ( 0.169)\tLoss 1.0332e-02 (1.1970e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 90/391]\tTime  0.168 ( 0.168)\tLoss 1.0157e-02 (1.1907e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][120/391]\tTime  0.167 ( 0.168)\tLoss 1.6046e-02 (1.1929e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][150/391]\tTime  0.168 ( 0.168)\tLoss 7.8407e-03 (1.1840e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][180/391]\tTime  0.167 ( 0.168)\tLoss 1.1070e-02 (1.1771e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][210/391]\tTime  0.167 ( 0.168)\tLoss 1.2341e-02 (1.1730e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][240/391]\tTime  0.163 ( 0.168)\tLoss 1.6860e-02 (1.1841e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][270/391]\tTime  0.167 ( 0.168)\tLoss 7.1569e-03 (1.1873e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][300/391]\tTime  0.168 ( 0.168)\tLoss 1.4791e-02 (1.1729e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][330/391]\tTime  0.168 ( 0.168)\tLoss 7.4649e-03 (1.1671e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][360/391]\tTime  0.169 ( 0.168)\tLoss 2.0460e-02 (1.1630e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][390/391]\tTime  0.152 ( 0.167)\tLoss 2.0943e-02 (1.1751e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.928 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.030 || Acc@5 93.700\n",
            "==> 69.65 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 116, lr: 0.004000000000000001 -----\n",
            "Epoch: [116][  0/391]\tTime  0.285 ( 0.285)\tLoss 1.0164e-02 (1.0164e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][ 30/391]\tTime  0.167 ( 0.170)\tLoss 7.9021e-03 (1.2093e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][ 60/391]\tTime  0.172 ( 0.169)\tLoss 5.0213e-03 (1.1023e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][ 90/391]\tTime  0.165 ( 0.168)\tLoss 1.1912e-02 (1.1424e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][120/391]\tTime  0.167 ( 0.168)\tLoss 1.1708e-02 (1.1883e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][150/391]\tTime  0.168 ( 0.168)\tLoss 1.7146e-02 (1.1914e-02)\tAcc@1  99.22 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][180/391]\tTime  0.167 ( 0.168)\tLoss 2.4236e-02 (1.1972e-02)\tAcc@1  99.22 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][210/391]\tTime  0.168 ( 0.168)\tLoss 9.2924e-03 (1.2098e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][240/391]\tTime  0.173 ( 0.168)\tLoss 1.3372e-02 (1.2240e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][270/391]\tTime  0.167 ( 0.168)\tLoss 2.5978e-02 (1.2414e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][300/391]\tTime  0.168 ( 0.168)\tLoss 1.8428e-02 (1.2416e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][330/391]\tTime  0.168 ( 0.168)\tLoss 8.2117e-03 (1.2219e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][360/391]\tTime  0.167 ( 0.168)\tLoss 2.6289e-02 (1.2256e-02)\tAcc@1  99.22 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][390/391]\tTime  0.151 ( 0.168)\tLoss 7.7716e-03 (1.2179e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.912 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.800 || Acc@5 93.570\n",
            "==> 69.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 117, lr: 0.004000000000000001 -----\n",
            "Epoch: [117][  0/391]\tTime  0.282 ( 0.282)\tLoss 1.0253e-02 (1.0253e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.2287e-02 (1.2952e-02)\tAcc@1  99.22 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.0199e-02 (1.2508e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][ 90/391]\tTime  0.166 ( 0.168)\tLoss 1.0690e-02 (1.2467e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][120/391]\tTime  0.166 ( 0.168)\tLoss 1.1064e-02 (1.2285e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][150/391]\tTime  0.167 ( 0.168)\tLoss 1.3000e-02 (1.2311e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][180/391]\tTime  0.166 ( 0.168)\tLoss 8.8969e-03 (1.2411e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][210/391]\tTime  0.167 ( 0.168)\tLoss 9.6641e-03 (1.2185e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][240/391]\tTime  0.167 ( 0.167)\tLoss 1.4619e-02 (1.2125e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][270/391]\tTime  0.168 ( 0.167)\tLoss 1.2739e-02 (1.2127e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][300/391]\tTime  0.168 ( 0.167)\tLoss 8.5812e-03 (1.2335e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][330/391]\tTime  0.167 ( 0.167)\tLoss 1.6119e-02 (1.2270e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][360/391]\tTime  0.167 ( 0.167)\tLoss 1.0823e-02 (1.2331e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][390/391]\tTime  0.149 ( 0.167)\tLoss 1.5971e-02 (1.2593e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.910 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.250 || Acc@5 93.490\n",
            "==> 69.56 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 118, lr: 0.004000000000000001 -----\n",
            "Epoch: [118][  0/391]\tTime  0.305 ( 0.305)\tLoss 1.1257e-02 (1.1257e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][ 30/391]\tTime  0.169 ( 0.171)\tLoss 1.9058e-02 (1.1837e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][ 60/391]\tTime  0.168 ( 0.169)\tLoss 7.7581e-03 (1.1682e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][ 90/391]\tTime  0.169 ( 0.169)\tLoss 7.6636e-03 (1.2094e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][120/391]\tTime  0.167 ( 0.168)\tLoss 1.3611e-02 (1.1933e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][150/391]\tTime  0.168 ( 0.168)\tLoss 1.6014e-02 (1.2105e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][180/391]\tTime  0.166 ( 0.168)\tLoss 9.7049e-03 (1.2014e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][210/391]\tTime  0.168 ( 0.168)\tLoss 1.6131e-02 (1.1976e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][240/391]\tTime  0.167 ( 0.168)\tLoss 1.3394e-02 (1.2061e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][270/391]\tTime  0.166 ( 0.168)\tLoss 2.0303e-02 (1.2144e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][300/391]\tTime  0.168 ( 0.167)\tLoss 1.2945e-02 (1.2164e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][330/391]\tTime  0.167 ( 0.167)\tLoss 1.1956e-02 (1.2241e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][360/391]\tTime  0.168 ( 0.167)\tLoss 9.3943e-03 (1.2410e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][390/391]\tTime  0.150 ( 0.167)\tLoss 1.2911e-02 (1.2363e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.906 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 76.910 || Acc@5 93.590\n",
            "==> 69.61 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 119, lr: 0.004000000000000001 -----\n",
            "Epoch: [119][  0/391]\tTime  0.282 ( 0.282)\tLoss 1.5677e-02 (1.5677e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.9086e-02 (1.1161e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 60/391]\tTime  0.171 ( 0.169)\tLoss 1.0461e-02 (1.1215e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.1255e-02 (1.1240e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][120/391]\tTime  0.168 ( 0.168)\tLoss 1.2236e-02 (1.1365e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][150/391]\tTime  0.167 ( 0.168)\tLoss 5.8189e-03 (1.1480e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][180/391]\tTime  0.166 ( 0.168)\tLoss 1.7015e-02 (1.1500e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][210/391]\tTime  0.166 ( 0.168)\tLoss 3.5584e-02 (1.1827e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][240/391]\tTime  0.167 ( 0.168)\tLoss 9.2890e-03 (1.1805e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][270/391]\tTime  0.167 ( 0.168)\tLoss 1.0728e-02 (1.1742e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][300/391]\tTime  0.165 ( 0.168)\tLoss 1.7339e-02 (1.1771e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][330/391]\tTime  0.167 ( 0.168)\tLoss 6.4114e-03 (1.1731e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][360/391]\tTime  0.168 ( 0.168)\tLoss 9.8358e-03 (1.1884e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][390/391]\tTime  0.152 ( 0.168)\tLoss 1.2877e-02 (1.1904e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.916 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.100 || Acc@5 93.550\n",
            "==> 69.70 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 120, lr: 0.0008000000000000003 -----\n",
            "Epoch: [120][  0/391]\tTime  0.287 ( 0.287)\tLoss 6.7464e-03 (6.7464e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][ 30/391]\tTime  0.166 ( 0.170)\tLoss 1.1209e-02 (1.0885e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][ 60/391]\tTime  0.161 ( 0.169)\tLoss 1.1013e-02 (1.0918e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][ 90/391]\tTime  0.168 ( 0.168)\tLoss 1.3850e-02 (1.0828e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][120/391]\tTime  0.166 ( 0.168)\tLoss 8.9164e-03 (1.0887e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][150/391]\tTime  0.167 ( 0.168)\tLoss 9.4830e-03 (1.0850e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][180/391]\tTime  0.169 ( 0.168)\tLoss 9.2395e-03 (1.1066e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][210/391]\tTime  0.166 ( 0.168)\tLoss 5.7007e-03 (1.1142e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][240/391]\tTime  0.168 ( 0.168)\tLoss 8.8332e-03 (1.1236e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][270/391]\tTime  0.168 ( 0.168)\tLoss 3.0346e-02 (1.1227e-02)\tAcc@1  99.22 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][300/391]\tTime  0.167 ( 0.168)\tLoss 6.0589e-03 (1.1133e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][330/391]\tTime  0.168 ( 0.167)\tLoss 6.9963e-03 (1.0994e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][360/391]\tTime  0.167 ( 0.167)\tLoss 6.9686e-03 (1.0837e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][390/391]\tTime  0.150 ( 0.167)\tLoss 2.0628e-02 (1.0823e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.936 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.180 || Acc@5 93.700\n",
            "==> 69.56 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 121, lr: 0.0008000000000000003 -----\n",
            "Epoch: [121][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.0150e-02 (1.0150e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][ 30/391]\tTime  0.168 ( 0.170)\tLoss 8.7239e-03 (1.0518e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][ 60/391]\tTime  0.165 ( 0.169)\tLoss 1.0890e-02 (1.0037e-02)\tAcc@1 100.00 ( 99.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][ 90/391]\tTime  0.169 ( 0.168)\tLoss 8.3715e-03 (9.8645e-03)\tAcc@1 100.00 ( 99.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][120/391]\tTime  0.169 ( 0.168)\tLoss 9.8963e-03 (9.9839e-03)\tAcc@1 100.00 ( 99.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][150/391]\tTime  0.169 ( 0.168)\tLoss 9.2289e-03 (9.9066e-03)\tAcc@1 100.00 ( 99.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][180/391]\tTime  0.167 ( 0.168)\tLoss 8.1433e-03 (9.7925e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][210/391]\tTime  0.167 ( 0.168)\tLoss 1.1321e-02 (9.9062e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][240/391]\tTime  0.168 ( 0.168)\tLoss 5.6755e-03 (1.0217e-02)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][270/391]\tTime  0.169 ( 0.168)\tLoss 6.7783e-03 (1.0227e-02)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][300/391]\tTime  0.169 ( 0.168)\tLoss 8.7830e-03 (1.0468e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][330/391]\tTime  0.168 ( 0.168)\tLoss 1.0042e-02 (1.0468e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][360/391]\tTime  0.168 ( 0.168)\tLoss 1.3636e-02 (1.0475e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][390/391]\tTime  0.150 ( 0.168)\tLoss 1.1195e-02 (1.0467e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.964 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.320 || Acc@5 93.600\n",
            "==> 69.72 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 122, lr: 0.0008000000000000003 -----\n",
            "Epoch: [122][  0/391]\tTime  0.274 ( 0.274)\tLoss 7.0074e-03 (7.0074e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.0914e-02 (1.0232e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 60/391]\tTime  0.167 ( 0.168)\tLoss 8.2126e-03 (9.8678e-03)\tAcc@1 100.00 ( 99.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 90/391]\tTime  0.171 ( 0.168)\tLoss 2.6505e-02 (9.9942e-03)\tAcc@1  99.22 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][120/391]\tTime  0.167 ( 0.168)\tLoss 8.5353e-03 (1.0031e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][150/391]\tTime  0.167 ( 0.168)\tLoss 7.2180e-03 (1.0159e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][180/391]\tTime  0.168 ( 0.168)\tLoss 9.6000e-03 (1.0001e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][210/391]\tTime  0.167 ( 0.168)\tLoss 1.0157e-02 (1.0112e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][240/391]\tTime  0.167 ( 0.168)\tLoss 7.7157e-03 (1.0038e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][270/391]\tTime  0.167 ( 0.167)\tLoss 1.0566e-02 (1.0025e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][300/391]\tTime  0.167 ( 0.168)\tLoss 1.1146e-02 (1.0060e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][330/391]\tTime  0.163 ( 0.168)\tLoss 1.0248e-02 (9.9652e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][360/391]\tTime  0.166 ( 0.168)\tLoss 1.1787e-02 (1.0006e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][390/391]\tTime  0.150 ( 0.167)\tLoss 2.6456e-02 (1.0016e-02)\tAcc@1  98.75 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.962 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.150 || Acc@5 93.630\n",
            "==> 69.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 123, lr: 0.0008000000000000003 -----\n",
            "Epoch: [123][  0/391]\tTime  0.274 ( 0.274)\tLoss 8.4688e-03 (8.4688e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.5789e-02 (1.1912e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][ 60/391]\tTime  0.165 ( 0.169)\tLoss 1.6576e-02 (1.0883e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][ 90/391]\tTime  0.168 ( 0.168)\tLoss 7.5649e-03 (1.1001e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][120/391]\tTime  0.164 ( 0.168)\tLoss 8.7541e-03 (1.0676e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][150/391]\tTime  0.169 ( 0.168)\tLoss 5.9779e-03 (1.0468e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][180/391]\tTime  0.168 ( 0.168)\tLoss 1.6309e-02 (1.0434e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][210/391]\tTime  0.172 ( 0.168)\tLoss 1.1118e-02 (1.0470e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][240/391]\tTime  0.166 ( 0.167)\tLoss 9.0515e-03 (1.0442e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][270/391]\tTime  0.169 ( 0.167)\tLoss 1.3068e-02 (1.0339e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][300/391]\tTime  0.164 ( 0.167)\tLoss 1.1277e-02 (1.0301e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][330/391]\tTime  0.169 ( 0.167)\tLoss 1.0021e-02 (1.0257e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][360/391]\tTime  0.169 ( 0.167)\tLoss 1.0422e-02 (1.0320e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][390/391]\tTime  0.150 ( 0.167)\tLoss 1.5440e-02 (1.0295e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.946 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.210 || Acc@5 93.610\n",
            "==> 69.66 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 124, lr: 0.0008000000000000003 -----\n",
            "Epoch: [124][  0/391]\tTime  0.287 ( 0.287)\tLoss 8.1360e-03 (8.1360e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][ 30/391]\tTime  0.168 ( 0.171)\tLoss 7.5923e-03 (1.0393e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][ 60/391]\tTime  0.168 ( 0.169)\tLoss 9.0503e-03 (1.0242e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.7376e-02 (1.0339e-02)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][120/391]\tTime  0.168 ( 0.169)\tLoss 1.1803e-02 (1.0347e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][150/391]\tTime  0.167 ( 0.168)\tLoss 1.4729e-02 (1.0431e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][180/391]\tTime  0.167 ( 0.168)\tLoss 1.6188e-02 (1.0391e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][210/391]\tTime  0.167 ( 0.168)\tLoss 1.0446e-02 (1.0422e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][240/391]\tTime  0.166 ( 0.168)\tLoss 8.5602e-03 (1.0340e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][270/391]\tTime  0.165 ( 0.168)\tLoss 9.8614e-03 (1.0246e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][300/391]\tTime  0.167 ( 0.168)\tLoss 8.7212e-03 (1.0172e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][330/391]\tTime  0.168 ( 0.168)\tLoss 7.1568e-03 (1.0116e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][360/391]\tTime  0.166 ( 0.168)\tLoss 1.1186e-02 (1.0076e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][390/391]\tTime  0.151 ( 0.168)\tLoss 1.2113e-02 (1.0040e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.962 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.180 || Acc@5 93.600\n",
            "==> 69.65 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 125, lr: 0.0008000000000000003 -----\n",
            "Epoch: [125][  0/391]\tTime  0.302 ( 0.302)\tLoss 7.1156e-03 (7.1156e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][ 30/391]\tTime  0.168 ( 0.171)\tLoss 1.2040e-02 (1.0199e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][ 60/391]\tTime  0.166 ( 0.169)\tLoss 8.7570e-03 (1.0240e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][ 90/391]\tTime  0.166 ( 0.169)\tLoss 6.5477e-03 (9.9266e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][120/391]\tTime  0.166 ( 0.168)\tLoss 7.5441e-03 (1.0270e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][150/391]\tTime  0.167 ( 0.168)\tLoss 8.0330e-03 (1.0226e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][180/391]\tTime  0.168 ( 0.168)\tLoss 1.1544e-02 (1.0241e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][210/391]\tTime  0.167 ( 0.168)\tLoss 1.0052e-02 (1.0155e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][240/391]\tTime  0.167 ( 0.168)\tLoss 1.6621e-02 (1.0126e-02)\tAcc@1  99.22 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][270/391]\tTime  0.166 ( 0.168)\tLoss 7.6321e-03 (1.0044e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][300/391]\tTime  0.166 ( 0.168)\tLoss 1.0480e-02 (9.9606e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][330/391]\tTime  0.161 ( 0.168)\tLoss 7.7399e-03 (9.9518e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][360/391]\tTime  0.167 ( 0.168)\tLoss 9.7758e-03 (9.9680e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][390/391]\tTime  0.150 ( 0.167)\tLoss 1.2978e-02 (9.9030e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.968 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.290 || Acc@5 93.700\n",
            "==> 69.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 126, lr: 0.0008000000000000003 -----\n",
            "Epoch: [126][  0/391]\tTime  0.296 ( 0.296)\tLoss 8.5017e-03 (8.5017e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 30/391]\tTime  0.166 ( 0.171)\tLoss 1.3772e-02 (1.0092e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 60/391]\tTime  0.169 ( 0.169)\tLoss 9.1503e-03 (1.0072e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.1745e-02 (1.0241e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][120/391]\tTime  0.169 ( 0.168)\tLoss 8.3473e-03 (1.0109e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][150/391]\tTime  0.168 ( 0.168)\tLoss 1.0914e-02 (1.0025e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][180/391]\tTime  0.165 ( 0.168)\tLoss 1.2983e-02 (1.0001e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][210/391]\tTime  0.167 ( 0.168)\tLoss 1.0463e-02 (1.0060e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][240/391]\tTime  0.169 ( 0.168)\tLoss 7.6157e-03 (9.9964e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][270/391]\tTime  0.167 ( 0.168)\tLoss 1.0226e-02 (1.0013e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][300/391]\tTime  0.167 ( 0.168)\tLoss 8.9452e-03 (9.9744e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][330/391]\tTime  0.168 ( 0.168)\tLoss 8.4975e-03 (9.9385e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][360/391]\tTime  0.168 ( 0.168)\tLoss 1.0979e-02 (1.0057e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][390/391]\tTime  0.150 ( 0.168)\tLoss 1.0216e-02 (1.0071e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.960 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.290 || Acc@5 93.550\n",
            "==> 69.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 127, lr: 0.0008000000000000003 -----\n",
            "Epoch: [127][  0/391]\tTime  0.272 ( 0.272)\tLoss 1.0794e-02 (1.0794e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 30/391]\tTime  0.167 ( 0.170)\tLoss 9.3189e-03 (1.0019e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.0076e-02 (1.1014e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 90/391]\tTime  0.169 ( 0.168)\tLoss 1.0831e-02 (1.0508e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][120/391]\tTime  0.168 ( 0.168)\tLoss 6.6221e-03 (1.0441e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][150/391]\tTime  0.168 ( 0.168)\tLoss 5.2097e-03 (1.0377e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][180/391]\tTime  0.169 ( 0.168)\tLoss 7.1391e-03 (1.0267e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][210/391]\tTime  0.169 ( 0.168)\tLoss 2.0078e-02 (1.0178e-02)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][240/391]\tTime  0.167 ( 0.168)\tLoss 1.0515e-02 (1.0258e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][270/391]\tTime  0.168 ( 0.168)\tLoss 6.5957e-03 (1.0141e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][300/391]\tTime  0.166 ( 0.168)\tLoss 8.7446e-03 (1.0109e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][330/391]\tTime  0.168 ( 0.168)\tLoss 1.2808e-02 (1.0095e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][360/391]\tTime  0.166 ( 0.168)\tLoss 1.8642e-02 (1.0149e-02)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][390/391]\tTime  0.149 ( 0.168)\tLoss 8.3690e-03 (1.0230e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.944 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.140 || Acc@5 93.630\n",
            "==> 69.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 128, lr: 0.0008000000000000003 -----\n",
            "Epoch: [128][  0/391]\tTime  0.284 ( 0.284)\tLoss 5.9981e-03 (5.9981e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 30/391]\tTime  0.166 ( 0.170)\tLoss 7.7115e-03 (8.8020e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 60/391]\tTime  0.167 ( 0.169)\tLoss 6.9800e-03 (9.7310e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.1095e-02 (1.0089e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][120/391]\tTime  0.166 ( 0.168)\tLoss 6.4158e-03 (9.8054e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][150/391]\tTime  0.166 ( 0.168)\tLoss 7.5323e-03 (9.6974e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][180/391]\tTime  0.168 ( 0.168)\tLoss 6.2051e-03 (9.6820e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][210/391]\tTime  0.168 ( 0.168)\tLoss 1.0836e-02 (9.7993e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][240/391]\tTime  0.168 ( 0.168)\tLoss 1.0092e-02 (9.7361e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][270/391]\tTime  0.169 ( 0.168)\tLoss 5.8027e-03 (9.8750e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][300/391]\tTime  0.166 ( 0.168)\tLoss 8.6127e-03 (9.8703e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][330/391]\tTime  0.168 ( 0.168)\tLoss 7.8739e-03 (9.9452e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][360/391]\tTime  0.165 ( 0.168)\tLoss 1.0876e-02 (9.9808e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][390/391]\tTime  0.150 ( 0.168)\tLoss 1.2891e-02 (1.0008e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.966 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.120 || Acc@5 93.720\n",
            "==> 69.70 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 129, lr: 0.0008000000000000003 -----\n",
            "Epoch: [129][  0/391]\tTime  0.283 ( 0.283)\tLoss 1.8140e-02 (1.8140e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.2357e-02 (9.7591e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.1862e-02 (1.0453e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][ 90/391]\tTime  0.169 ( 0.168)\tLoss 9.2266e-03 (1.0061e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][120/391]\tTime  0.168 ( 0.168)\tLoss 1.0666e-02 (1.0389e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][150/391]\tTime  0.164 ( 0.168)\tLoss 8.3294e-03 (1.0166e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][180/391]\tTime  0.168 ( 0.168)\tLoss 1.5516e-02 (1.0000e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][210/391]\tTime  0.168 ( 0.168)\tLoss 1.3896e-02 (1.0166e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][240/391]\tTime  0.167 ( 0.168)\tLoss 9.7091e-03 (1.0027e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][270/391]\tTime  0.166 ( 0.168)\tLoss 5.2587e-03 (1.0070e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][300/391]\tTime  0.168 ( 0.167)\tLoss 8.4701e-03 (1.0114e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][330/391]\tTime  0.167 ( 0.167)\tLoss 8.6245e-03 (1.0147e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][360/391]\tTime  0.168 ( 0.167)\tLoss 1.4839e-02 (1.0079e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][390/391]\tTime  0.149 ( 0.167)\tLoss 1.6311e-02 (1.0087e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.948 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.190 || Acc@5 93.770\n",
            "==> 69.60 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 130, lr: 0.0008000000000000003 -----\n",
            "Epoch: [130][  0/391]\tTime  0.292 ( 0.292)\tLoss 1.4411e-02 (1.4411e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][ 30/391]\tTime  0.166 ( 0.170)\tLoss 1.2082e-02 (1.0039e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][ 60/391]\tTime  0.167 ( 0.169)\tLoss 7.8959e-03 (9.9952e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][ 90/391]\tTime  0.165 ( 0.168)\tLoss 8.5467e-03 (9.7505e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][120/391]\tTime  0.165 ( 0.168)\tLoss 2.4521e-02 (9.9168e-03)\tAcc@1  99.22 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][150/391]\tTime  0.167 ( 0.168)\tLoss 7.8103e-03 (9.6411e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][180/391]\tTime  0.169 ( 0.168)\tLoss 4.3651e-03 (9.7073e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][210/391]\tTime  0.168 ( 0.168)\tLoss 1.0545e-02 (9.7161e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][240/391]\tTime  0.167 ( 0.167)\tLoss 6.6290e-03 (9.6398e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][270/391]\tTime  0.167 ( 0.167)\tLoss 1.0551e-02 (9.7418e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][300/391]\tTime  0.168 ( 0.167)\tLoss 7.3786e-03 (9.7531e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][330/391]\tTime  0.168 ( 0.167)\tLoss 6.7594e-03 (9.7145e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][360/391]\tTime  0.168 ( 0.168)\tLoss 1.2890e-02 (9.6814e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][390/391]\tTime  0.150 ( 0.167)\tLoss 1.9479e-02 (9.7947e-03)\tAcc@1  98.75 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.948 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.260 || Acc@5 93.780\n",
            "==> 69.65 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 131, lr: 0.0008000000000000003 -----\n",
            "Epoch: [131][  0/391]\tTime  0.280 ( 0.280)\tLoss 8.9497e-03 (8.9497e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][ 30/391]\tTime  0.167 ( 0.171)\tLoss 1.0414e-02 (9.9134e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][ 60/391]\tTime  0.168 ( 0.169)\tLoss 9.3009e-03 (1.0009e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][ 90/391]\tTime  0.167 ( 0.168)\tLoss 7.4053e-03 (1.0174e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][120/391]\tTime  0.167 ( 0.168)\tLoss 7.6850e-03 (1.0150e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][150/391]\tTime  0.167 ( 0.168)\tLoss 8.5665e-03 (1.0015e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][180/391]\tTime  0.167 ( 0.168)\tLoss 6.0632e-03 (1.0001e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][210/391]\tTime  0.166 ( 0.168)\tLoss 8.4721e-03 (9.9128e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][240/391]\tTime  0.168 ( 0.168)\tLoss 1.1427e-02 (9.9228e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][270/391]\tTime  0.168 ( 0.168)\tLoss 1.1724e-02 (1.0027e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][300/391]\tTime  0.166 ( 0.168)\tLoss 1.0364e-02 (1.0027e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][330/391]\tTime  0.168 ( 0.168)\tLoss 8.3193e-03 (1.0147e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][360/391]\tTime  0.169 ( 0.167)\tLoss 1.6127e-02 (1.0027e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][390/391]\tTime  0.151 ( 0.167)\tLoss 1.8192e-02 (1.0085e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.954 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.210 || Acc@5 93.620\n",
            "==> 69.62 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 132, lr: 0.0008000000000000003 -----\n",
            "Epoch: [132][  0/391]\tTime  0.274 ( 0.274)\tLoss 1.5932e-02 (1.5932e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][ 30/391]\tTime  0.168 ( 0.170)\tLoss 2.1018e-02 (9.5064e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.2995e-02 (9.5184e-03)\tAcc@1 100.00 ( 99.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][ 90/391]\tTime  0.167 ( 0.168)\tLoss 8.4978e-03 (9.5554e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][120/391]\tTime  0.166 ( 0.168)\tLoss 8.8128e-03 (9.6719e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][150/391]\tTime  0.167 ( 0.168)\tLoss 1.0343e-02 (9.7589e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][180/391]\tTime  0.167 ( 0.168)\tLoss 9.1278e-03 (9.6904e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][210/391]\tTime  0.167 ( 0.168)\tLoss 1.0692e-02 (9.8241e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][240/391]\tTime  0.167 ( 0.167)\tLoss 9.7566e-03 (1.0077e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][270/391]\tTime  0.167 ( 0.167)\tLoss 1.0674e-02 (1.0033e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][300/391]\tTime  0.167 ( 0.167)\tLoss 7.3286e-03 (1.0005e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][330/391]\tTime  0.166 ( 0.167)\tLoss 9.8838e-03 (9.9232e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][360/391]\tTime  0.167 ( 0.167)\tLoss 1.2724e-02 (9.9555e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][390/391]\tTime  0.150 ( 0.167)\tLoss 1.5168e-02 (9.9738e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.962 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.330 || Acc@5 93.560\n",
            "==> 69.54 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 133, lr: 0.0008000000000000003 -----\n",
            "Epoch: [133][  0/391]\tTime  0.318 ( 0.318)\tLoss 5.7273e-03 (5.7273e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][ 30/391]\tTime  0.170 ( 0.172)\tLoss 7.6593e-03 (1.0504e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][ 60/391]\tTime  0.169 ( 0.170)\tLoss 9.2741e-03 (1.0013e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][ 90/391]\tTime  0.169 ( 0.169)\tLoss 7.2798e-03 (1.0228e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][120/391]\tTime  0.167 ( 0.169)\tLoss 1.0459e-02 (1.0272e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][150/391]\tTime  0.166 ( 0.169)\tLoss 2.2089e-02 (1.0197e-02)\tAcc@1  98.44 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][180/391]\tTime  0.169 ( 0.168)\tLoss 1.1504e-02 (1.0060e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][210/391]\tTime  0.166 ( 0.168)\tLoss 1.0779e-02 (1.0156e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][240/391]\tTime  0.166 ( 0.168)\tLoss 8.3477e-03 (1.0022e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][270/391]\tTime  0.167 ( 0.168)\tLoss 7.4291e-03 (1.0007e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][300/391]\tTime  0.167 ( 0.168)\tLoss 8.2595e-03 (9.9611e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][330/391]\tTime  0.167 ( 0.168)\tLoss 1.4790e-02 (9.9933e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][360/391]\tTime  0.168 ( 0.168)\tLoss 7.9698e-03 (1.0045e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][390/391]\tTime  0.151 ( 0.168)\tLoss 7.8643e-03 (1.0016e-02)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.942 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.250 || Acc@5 93.700\n",
            "==> 69.70 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 134, lr: 0.0008000000000000003 -----\n",
            "Epoch: [134][  0/391]\tTime  0.282 ( 0.282)\tLoss 7.6293e-03 (7.6293e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 30/391]\tTime  0.166 ( 0.170)\tLoss 8.7575e-03 (1.0360e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.5074e-02 (1.0192e-02)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 90/391]\tTime  0.166 ( 0.168)\tLoss 6.4933e-03 (9.8005e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][120/391]\tTime  0.167 ( 0.168)\tLoss 1.2872e-02 (9.7199e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][150/391]\tTime  0.168 ( 0.168)\tLoss 1.0259e-02 (9.7671e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][180/391]\tTime  0.165 ( 0.168)\tLoss 5.5250e-03 (9.8453e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][210/391]\tTime  0.168 ( 0.168)\tLoss 8.7867e-03 (9.9165e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][240/391]\tTime  0.167 ( 0.168)\tLoss 7.4474e-03 (9.8037e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][270/391]\tTime  0.168 ( 0.168)\tLoss 8.4001e-03 (9.7555e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][300/391]\tTime  0.168 ( 0.168)\tLoss 1.9433e-02 (9.7610e-03)\tAcc@1  99.22 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][330/391]\tTime  0.164 ( 0.168)\tLoss 9.3753e-03 (9.6921e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][360/391]\tTime  0.168 ( 0.168)\tLoss 9.7780e-03 (9.6712e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][390/391]\tTime  0.150 ( 0.167)\tLoss 1.2948e-02 (9.6587e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.962 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.110 || Acc@5 93.610\n",
            "==> 69.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 135, lr: 0.0008000000000000003 -----\n",
            "Epoch: [135][  0/391]\tTime  0.299 ( 0.299)\tLoss 7.1330e-03 (7.1330e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 30/391]\tTime  0.168 ( 0.171)\tLoss 9.0354e-03 (1.1011e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.0483e-02 (1.0320e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 90/391]\tTime  0.170 ( 0.168)\tLoss 1.9902e-02 (1.0501e-02)\tAcc@1  99.22 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][120/391]\tTime  0.165 ( 0.168)\tLoss 8.5271e-03 (1.0399e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][150/391]\tTime  0.168 ( 0.168)\tLoss 9.7170e-03 (1.0225e-02)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][180/391]\tTime  0.167 ( 0.168)\tLoss 1.0695e-02 (9.9899e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][210/391]\tTime  0.168 ( 0.168)\tLoss 8.9094e-03 (9.9566e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][240/391]\tTime  0.168 ( 0.168)\tLoss 7.1190e-03 (9.9946e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][270/391]\tTime  0.169 ( 0.168)\tLoss 5.6137e-03 (9.9585e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][300/391]\tTime  0.168 ( 0.168)\tLoss 8.1627e-03 (9.8222e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][330/391]\tTime  0.167 ( 0.168)\tLoss 7.3844e-03 (9.7533e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][360/391]\tTime  0.167 ( 0.168)\tLoss 7.0484e-03 (9.7111e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][390/391]\tTime  0.150 ( 0.168)\tLoss 9.1687e-03 (9.6665e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.950 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.260 || Acc@5 93.680\n",
            "==> 69.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 136, lr: 0.0008000000000000003 -----\n",
            "Epoch: [136][  0/391]\tTime  0.300 ( 0.300)\tLoss 1.1848e-02 (1.1848e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 30/391]\tTime  0.169 ( 0.171)\tLoss 8.8894e-03 (9.3150e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 60/391]\tTime  0.167 ( 0.169)\tLoss 9.6649e-03 (9.2402e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 90/391]\tTime  0.166 ( 0.168)\tLoss 1.0055e-02 (9.2652e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][120/391]\tTime  0.168 ( 0.168)\tLoss 7.5137e-03 (9.4612e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][150/391]\tTime  0.168 ( 0.168)\tLoss 1.0378e-02 (9.4178e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][180/391]\tTime  0.167 ( 0.168)\tLoss 7.7824e-03 (9.4481e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][210/391]\tTime  0.166 ( 0.168)\tLoss 3.0741e-02 (9.5910e-03)\tAcc@1  98.44 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][240/391]\tTime  0.170 ( 0.168)\tLoss 1.1601e-02 (9.6238e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][270/391]\tTime  0.167 ( 0.168)\tLoss 1.1894e-02 (9.6818e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][300/391]\tTime  0.169 ( 0.167)\tLoss 8.8567e-03 (9.6718e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][330/391]\tTime  0.167 ( 0.167)\tLoss 7.1880e-03 (9.7284e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][360/391]\tTime  0.167 ( 0.167)\tLoss 6.2887e-03 (9.6438e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][390/391]\tTime  0.151 ( 0.167)\tLoss 1.3240e-02 (9.6649e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.962 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.310 || Acc@5 93.690\n",
            "==> 69.63 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 137, lr: 0.0008000000000000003 -----\n",
            "Epoch: [137][  0/391]\tTime  0.280 ( 0.280)\tLoss 1.0668e-02 (1.0668e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 30/391]\tTime  0.167 ( 0.170)\tLoss 7.5884e-03 (9.3211e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 60/391]\tTime  0.168 ( 0.169)\tLoss 8.8195e-03 (9.4264e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 90/391]\tTime  0.168 ( 0.168)\tLoss 8.0564e-03 (9.4924e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][120/391]\tTime  0.165 ( 0.168)\tLoss 7.3336e-03 (9.6519e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][150/391]\tTime  0.167 ( 0.168)\tLoss 2.7386e-02 (9.7546e-03)\tAcc@1  99.22 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][180/391]\tTime  0.168 ( 0.168)\tLoss 5.3173e-03 (9.8342e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][210/391]\tTime  0.167 ( 0.168)\tLoss 5.7355e-03 (9.7032e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][240/391]\tTime  0.167 ( 0.168)\tLoss 1.3770e-02 (9.8570e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][270/391]\tTime  0.168 ( 0.167)\tLoss 1.7355e-02 (1.0006e-02)\tAcc@1  99.22 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][300/391]\tTime  0.170 ( 0.168)\tLoss 6.1078e-03 (9.9686e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][330/391]\tTime  0.166 ( 0.168)\tLoss 9.3746e-03 (9.9338e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][360/391]\tTime  0.168 ( 0.168)\tLoss 5.5407e-03 (1.0035e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][390/391]\tTime  0.151 ( 0.168)\tLoss 1.2397e-02 (9.9862e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.958 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.290 || Acc@5 93.710\n",
            "==> 69.65 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 138, lr: 0.0008000000000000003 -----\n",
            "Epoch: [138][  0/391]\tTime  0.277 ( 0.277)\tLoss 7.9906e-03 (7.9906e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 30/391]\tTime  0.167 ( 0.170)\tLoss 1.8531e-02 (9.6233e-03)\tAcc@1  99.22 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 60/391]\tTime  0.167 ( 0.169)\tLoss 9.4956e-03 (9.7494e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 90/391]\tTime  0.167 ( 0.168)\tLoss 8.5742e-03 (9.7413e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][120/391]\tTime  0.167 ( 0.168)\tLoss 6.8880e-03 (9.6630e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][150/391]\tTime  0.168 ( 0.168)\tLoss 7.8963e-03 (9.7700e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][180/391]\tTime  0.166 ( 0.168)\tLoss 1.1929e-02 (9.7023e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][210/391]\tTime  0.168 ( 0.168)\tLoss 7.2698e-03 (9.6636e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][240/391]\tTime  0.167 ( 0.168)\tLoss 9.0159e-03 (9.6869e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][270/391]\tTime  0.168 ( 0.167)\tLoss 8.1322e-03 (9.6304e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][300/391]\tTime  0.165 ( 0.167)\tLoss 6.9340e-03 (9.5805e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][330/391]\tTime  0.167 ( 0.167)\tLoss 1.1249e-02 (9.6478e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][360/391]\tTime  0.166 ( 0.167)\tLoss 9.0641e-03 (9.7343e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][390/391]\tTime  0.150 ( 0.167)\tLoss 6.0607e-03 (9.7334e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.954 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.270 || Acc@5 93.690\n",
            "==> 69.55 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 139, lr: 0.0008000000000000003 -----\n",
            "Epoch: [139][  0/391]\tTime  0.296 ( 0.296)\tLoss 1.1706e-02 (1.1706e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 30/391]\tTime  0.168 ( 0.171)\tLoss 5.3743e-03 (9.3843e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.2369e-02 (9.6653e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.5573e-02 (9.7053e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][120/391]\tTime  0.165 ( 0.168)\tLoss 9.1027e-03 (9.5394e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][150/391]\tTime  0.166 ( 0.168)\tLoss 1.2014e-02 (9.5122e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][180/391]\tTime  0.167 ( 0.168)\tLoss 7.2568e-03 (9.4747e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][210/391]\tTime  0.165 ( 0.168)\tLoss 8.6206e-03 (9.7901e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][240/391]\tTime  0.166 ( 0.167)\tLoss 1.0504e-02 (9.8163e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][270/391]\tTime  0.166 ( 0.167)\tLoss 7.1883e-03 (9.7545e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][300/391]\tTime  0.167 ( 0.167)\tLoss 1.2263e-02 (9.7813e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][330/391]\tTime  0.167 ( 0.167)\tLoss 1.1138e-02 (9.6534e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][360/391]\tTime  0.169 ( 0.167)\tLoss 7.9713e-03 (9.6660e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][390/391]\tTime  0.150 ( 0.167)\tLoss 1.1747e-02 (9.6954e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.950 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.310 || Acc@5 93.680\n",
            "==> 69.57 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 140, lr: 0.0008000000000000003 -----\n",
            "Epoch: [140][  0/391]\tTime  0.279 ( 0.279)\tLoss 8.5030e-03 (8.5030e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 30/391]\tTime  0.167 ( 0.171)\tLoss 7.1840e-03 (9.0832e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 60/391]\tTime  0.168 ( 0.169)\tLoss 7.5272e-03 (9.5265e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 90/391]\tTime  0.168 ( 0.169)\tLoss 8.3402e-03 (9.5498e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][120/391]\tTime  0.168 ( 0.169)\tLoss 7.3559e-03 (9.5120e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][150/391]\tTime  0.168 ( 0.168)\tLoss 9.8106e-03 (9.6222e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][180/391]\tTime  0.167 ( 0.168)\tLoss 9.2712e-03 (9.6385e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][210/391]\tTime  0.168 ( 0.168)\tLoss 1.1659e-02 (9.5550e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][240/391]\tTime  0.167 ( 0.168)\tLoss 7.8828e-03 (9.6307e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][270/391]\tTime  0.166 ( 0.168)\tLoss 7.6870e-03 (9.6639e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][300/391]\tTime  0.168 ( 0.168)\tLoss 6.5723e-03 (9.8423e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][330/391]\tTime  0.167 ( 0.168)\tLoss 8.2305e-03 (9.8177e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][360/391]\tTime  0.169 ( 0.168)\tLoss 6.5064e-03 (9.7576e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][390/391]\tTime  0.149 ( 0.168)\tLoss 1.1317e-02 (9.8213e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.942 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.270 || Acc@5 93.820\n",
            "==> 69.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 141, lr: 0.0008000000000000003 -----\n",
            "Epoch: [141][  0/391]\tTime  0.287 ( 0.287)\tLoss 2.3046e-02 (2.3046e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 30/391]\tTime  0.167 ( 0.171)\tLoss 8.7099e-03 (1.1132e-02)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 60/391]\tTime  0.167 ( 0.169)\tLoss 9.2975e-03 (1.0161e-02)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.0418e-02 (9.7460e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][120/391]\tTime  0.164 ( 0.168)\tLoss 1.3816e-02 (9.8118e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][150/391]\tTime  0.168 ( 0.168)\tLoss 8.2819e-03 (1.0004e-02)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][180/391]\tTime  0.166 ( 0.168)\tLoss 9.1918e-03 (9.9311e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][210/391]\tTime  0.165 ( 0.168)\tLoss 7.0958e-03 (9.7845e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][240/391]\tTime  0.167 ( 0.168)\tLoss 7.2280e-03 (9.9138e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][270/391]\tTime  0.167 ( 0.168)\tLoss 1.3678e-02 (9.8685e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][300/391]\tTime  0.167 ( 0.168)\tLoss 2.1075e-02 (9.9335e-03)\tAcc@1  99.22 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][330/391]\tTime  0.167 ( 0.167)\tLoss 7.8655e-03 (9.8273e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][360/391]\tTime  0.167 ( 0.167)\tLoss 1.2296e-02 (9.7673e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][390/391]\tTime  0.150 ( 0.167)\tLoss 1.0300e-02 (9.7848e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.958 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.350 || Acc@5 93.710\n",
            "==> 69.57 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 142, lr: 0.0008000000000000003 -----\n",
            "Epoch: [142][  0/391]\tTime  0.296 ( 0.296)\tLoss 2.2437e-02 (2.2437e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][ 30/391]\tTime  0.166 ( 0.170)\tLoss 1.1482e-02 (1.0867e-02)\tAcc@1 100.00 ( 99.90)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][ 60/391]\tTime  0.168 ( 0.169)\tLoss 8.4602e-03 (9.8548e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][ 90/391]\tTime  0.167 ( 0.168)\tLoss 5.9626e-03 (9.8298e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][120/391]\tTime  0.168 ( 0.168)\tLoss 9.4963e-03 (9.7873e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][150/391]\tTime  0.168 ( 0.168)\tLoss 8.9245e-03 (9.5907e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][180/391]\tTime  0.166 ( 0.168)\tLoss 9.7773e-03 (9.6619e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][210/391]\tTime  0.169 ( 0.168)\tLoss 1.4841e-02 (9.5216e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][240/391]\tTime  0.167 ( 0.168)\tLoss 7.6791e-03 (9.4870e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][270/391]\tTime  0.168 ( 0.168)\tLoss 5.4232e-03 (9.5630e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][300/391]\tTime  0.169 ( 0.168)\tLoss 1.4425e-02 (9.5377e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][330/391]\tTime  0.167 ( 0.168)\tLoss 1.0900e-02 (9.5191e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][360/391]\tTime  0.166 ( 0.168)\tLoss 1.0048e-02 (9.5225e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][390/391]\tTime  0.148 ( 0.168)\tLoss 1.6942e-02 (9.5914e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.964 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.290 || Acc@5 93.750\n",
            "==> 69.69 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 143, lr: 0.0008000000000000003 -----\n",
            "Epoch: [143][  0/391]\tTime  0.277 ( 0.277)\tLoss 1.0386e-02 (1.0386e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 30/391]\tTime  0.167 ( 0.170)\tLoss 8.4771e-03 (9.9545e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 60/391]\tTime  0.169 ( 0.168)\tLoss 7.2451e-03 (9.7298e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 90/391]\tTime  0.168 ( 0.168)\tLoss 8.9634e-03 (9.6505e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][120/391]\tTime  0.168 ( 0.168)\tLoss 1.1888e-02 (9.5437e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][150/391]\tTime  0.167 ( 0.168)\tLoss 9.7432e-03 (9.4656e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][180/391]\tTime  0.166 ( 0.168)\tLoss 7.3632e-03 (9.6713e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][210/391]\tTime  0.169 ( 0.168)\tLoss 7.8327e-03 (9.6229e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][240/391]\tTime  0.168 ( 0.167)\tLoss 7.3557e-03 (9.5242e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][270/391]\tTime  0.165 ( 0.168)\tLoss 1.1730e-02 (9.5327e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][300/391]\tTime  0.167 ( 0.167)\tLoss 1.2337e-02 (9.6348e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][330/391]\tTime  0.168 ( 0.167)\tLoss 1.0455e-02 (9.6684e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][360/391]\tTime  0.166 ( 0.167)\tLoss 1.6555e-02 (9.6109e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][390/391]\tTime  0.149 ( 0.167)\tLoss 1.3738e-02 (9.5777e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.956 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.300 || Acc@5 93.760\n",
            "==> 69.63 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 144, lr: 0.0008000000000000003 -----\n",
            "Epoch: [144][  0/391]\tTime  0.278 ( 0.278)\tLoss 1.0851e-02 (1.0851e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 30/391]\tTime  0.167 ( 0.170)\tLoss 7.3055e-03 (9.4247e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 60/391]\tTime  0.166 ( 0.169)\tLoss 7.4489e-03 (9.6839e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 90/391]\tTime  0.167 ( 0.168)\tLoss 1.2003e-02 (1.0319e-02)\tAcc@1 100.00 ( 99.91)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][120/391]\tTime  0.167 ( 0.168)\tLoss 1.1614e-02 (9.9820e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][150/391]\tTime  0.169 ( 0.168)\tLoss 1.0221e-02 (9.8160e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][180/391]\tTime  0.167 ( 0.168)\tLoss 9.0815e-03 (9.7822e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][210/391]\tTime  0.167 ( 0.167)\tLoss 7.9276e-03 (9.8383e-03)\tAcc@1 100.00 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][240/391]\tTime  0.166 ( 0.167)\tLoss 8.5593e-03 (9.7523e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][270/391]\tTime  0.167 ( 0.167)\tLoss 8.5950e-03 (9.7518e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][300/391]\tTime  0.168 ( 0.168)\tLoss 8.0875e-03 (9.6978e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][330/391]\tTime  0.168 ( 0.168)\tLoss 1.5128e-02 (9.7636e-03)\tAcc@1  99.22 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][360/391]\tTime  0.168 ( 0.168)\tLoss 6.5073e-03 (9.7292e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][390/391]\tTime  0.151 ( 0.168)\tLoss 1.1234e-02 (9.7566e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.946 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.160 || Acc@5 93.700\n",
            "==> 69.66 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 145, lr: 0.0008000000000000003 -----\n",
            "Epoch: [145][  0/391]\tTime  0.294 ( 0.294)\tLoss 1.4326e-02 (1.4326e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 30/391]\tTime  0.168 ( 0.171)\tLoss 9.6729e-03 (1.0134e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.1374e-02 (1.0151e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 90/391]\tTime  0.168 ( 0.169)\tLoss 1.4784e-02 (9.8864e-03)\tAcc@1  99.22 ( 99.93)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][120/391]\tTime  0.167 ( 0.168)\tLoss 1.0934e-02 (9.8891e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][150/391]\tTime  0.169 ( 0.168)\tLoss 6.3538e-03 (9.8350e-03)\tAcc@1 100.00 ( 99.94)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][180/391]\tTime  0.165 ( 0.168)\tLoss 9.0940e-03 (9.7234e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][210/391]\tTime  0.167 ( 0.168)\tLoss 7.9387e-03 (9.7332e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][240/391]\tTime  0.167 ( 0.168)\tLoss 1.3066e-02 (9.6922e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][270/391]\tTime  0.167 ( 0.168)\tLoss 3.0855e-02 (9.7865e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][300/391]\tTime  0.167 ( 0.167)\tLoss 6.8365e-03 (9.7295e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][330/391]\tTime  0.166 ( 0.167)\tLoss 8.0849e-03 (9.7165e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][360/391]\tTime  0.169 ( 0.167)\tLoss 9.1894e-03 (9.7161e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][390/391]\tTime  0.150 ( 0.167)\tLoss 7.6271e-03 (9.6765e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.956 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.390 || Acc@5 93.810\n",
            "==> 69.59 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 146, lr: 0.0008000000000000003 -----\n",
            "Epoch: [146][  0/391]\tTime  0.282 ( 0.282)\tLoss 6.7446e-03 (6.7446e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][ 30/391]\tTime  0.168 ( 0.170)\tLoss 8.1676e-03 (9.8434e-03)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][ 60/391]\tTime  0.168 ( 0.169)\tLoss 7.3914e-03 (9.8202e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][ 90/391]\tTime  0.168 ( 0.168)\tLoss 1.1812e-02 (9.7995e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][120/391]\tTime  0.167 ( 0.168)\tLoss 8.9694e-03 (9.5825e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][150/391]\tTime  0.167 ( 0.168)\tLoss 6.4921e-03 (9.3563e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][180/391]\tTime  0.169 ( 0.168)\tLoss 7.3512e-03 (9.3109e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][210/391]\tTime  0.167 ( 0.168)\tLoss 1.1104e-02 (9.3397e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][240/391]\tTime  0.167 ( 0.168)\tLoss 1.2306e-02 (9.4468e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][270/391]\tTime  0.165 ( 0.167)\tLoss 8.6559e-03 (9.5115e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][300/391]\tTime  0.163 ( 0.167)\tLoss 1.3255e-02 (9.5195e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][330/391]\tTime  0.167 ( 0.167)\tLoss 7.4373e-03 (9.4493e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][360/391]\tTime  0.167 ( 0.167)\tLoss 8.3511e-03 (9.4728e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][390/391]\tTime  0.152 ( 0.167)\tLoss 8.5714e-03 (9.4253e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.958 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.100 || Acc@5 93.640\n",
            "==> 69.56 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 147, lr: 0.0008000000000000003 -----\n",
            "Epoch: [147][  0/391]\tTime  0.279 ( 0.279)\tLoss 1.3916e-02 (1.3916e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 30/391]\tTime  0.167 ( 0.171)\tLoss 8.2816e-03 (9.5824e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 60/391]\tTime  0.168 ( 0.169)\tLoss 1.3127e-02 (9.6019e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 90/391]\tTime  0.165 ( 0.169)\tLoss 7.8715e-03 (9.2039e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][120/391]\tTime  0.167 ( 0.168)\tLoss 9.9402e-03 (9.5595e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][150/391]\tTime  0.168 ( 0.168)\tLoss 8.8025e-03 (9.6527e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][180/391]\tTime  0.168 ( 0.168)\tLoss 1.0510e-02 (9.5974e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][210/391]\tTime  0.169 ( 0.168)\tLoss 8.5665e-03 (9.8115e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][240/391]\tTime  0.167 ( 0.168)\tLoss 7.6009e-03 (9.8722e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][270/391]\tTime  0.169 ( 0.168)\tLoss 8.2028e-03 (9.8153e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][300/391]\tTime  0.167 ( 0.168)\tLoss 1.9978e-02 (9.9010e-03)\tAcc@1  99.22 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][330/391]\tTime  0.167 ( 0.168)\tLoss 6.5849e-03 (9.7728e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][360/391]\tTime  0.168 ( 0.168)\tLoss 8.4791e-03 (9.7710e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][390/391]\tTime  0.151 ( 0.168)\tLoss 1.6437e-02 (9.7323e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.960 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.330 || Acc@5 93.730\n",
            "==> 69.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 148, lr: 0.0008000000000000003 -----\n",
            "Epoch: [148][  0/391]\tTime  0.296 ( 0.296)\tLoss 9.0590e-03 (9.0590e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 30/391]\tTime  0.167 ( 0.170)\tLoss 8.1714e-03 (1.0950e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 60/391]\tTime  0.167 ( 0.169)\tLoss 1.3773e-02 (1.0119e-02)\tAcc@1 100.00 ( 99.92)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 90/391]\tTime  0.167 ( 0.168)\tLoss 7.6379e-03 (9.8245e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][120/391]\tTime  0.167 ( 0.168)\tLoss 2.1401e-02 (9.6567e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][150/391]\tTime  0.166 ( 0.168)\tLoss 6.3428e-03 (9.8320e-03)\tAcc@1 100.00 ( 99.95)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][180/391]\tTime  0.168 ( 0.168)\tLoss 9.8581e-03 (9.6741e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][210/391]\tTime  0.166 ( 0.168)\tLoss 1.2940e-02 (9.6322e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][240/391]\tTime  0.168 ( 0.168)\tLoss 1.0552e-02 (9.7198e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][270/391]\tTime  0.166 ( 0.168)\tLoss 8.2862e-03 (9.6892e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][300/391]\tTime  0.168 ( 0.168)\tLoss 9.6142e-03 (9.6903e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][330/391]\tTime  0.167 ( 0.167)\tLoss 8.0840e-03 (9.6391e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][360/391]\tTime  0.168 ( 0.167)\tLoss 1.3377e-02 (9.5956e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][390/391]\tTime  0.150 ( 0.167)\tLoss 1.5786e-02 (9.5561e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.964 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.390 || Acc@5 93.640\n",
            "==> 69.58 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 149, lr: 0.0008000000000000003 -----\n",
            "Epoch: [149][  0/391]\tTime  0.268 ( 0.268)\tLoss 6.1465e-03 (6.1465e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 30/391]\tTime  0.166 ( 0.170)\tLoss 5.7826e-03 (9.2745e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 60/391]\tTime  0.167 ( 0.168)\tLoss 1.0380e-02 (9.0739e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 90/391]\tTime  0.168 ( 0.168)\tLoss 1.0256e-02 (8.9532e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][120/391]\tTime  0.166 ( 0.168)\tLoss 6.6761e-03 (9.0031e-03)\tAcc@1 100.00 ( 99.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][150/391]\tTime  0.169 ( 0.168)\tLoss 1.0179e-02 (9.1278e-03)\tAcc@1 100.00 ( 99.98)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][180/391]\tTime  0.163 ( 0.168)\tLoss 8.1133e-03 (9.0385e-03)\tAcc@1 100.00 ( 99.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][210/391]\tTime  0.167 ( 0.168)\tLoss 8.2265e-03 (9.1238e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][240/391]\tTime  0.168 ( 0.168)\tLoss 1.1740e-02 (9.0860e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][270/391]\tTime  0.169 ( 0.168)\tLoss 8.2886e-03 (9.2091e-03)\tAcc@1 100.00 ( 99.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][300/391]\tTime  0.172 ( 0.168)\tLoss 7.1742e-03 (9.3084e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][330/391]\tTime  0.168 ( 0.168)\tLoss 1.0155e-02 (9.3631e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][360/391]\tTime  0.166 ( 0.168)\tLoss 9.0467e-03 (9.3749e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][390/391]\tTime  0.151 ( 0.168)\tLoss 8.3542e-03 (9.4284e-03)\tAcc@1 100.00 ( 99.96)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.960 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 77.290 || Acc@5 93.660\n",
            "==> 69.66 seconds to train this epoch\n",
            "\n",
            "Best Top-1 Accuracy: 77.39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DuPOuVVT8yN6"
      },
      "source": [
        "# 위 결과를 바탕으로 p = 8 ,length = 14로 다른 DA방식과 섞어봤다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ouf5tNgIr-P8"
      },
      "source": [
        "Cutshadow + Cutmix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h7ttqZf5-CJC",
        "outputId": "a32536cb-1bd6-4d81-fa2c-b4630081d8da"
      },
      "source": [
        "#Cutshadow + Cutmix(0.5)\n",
        "def train(train_loader, epoch, model, optimizer, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(len(train_loader), batch_time, losses,\n",
        "                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "        mix_decision = np.random.rand()\n",
        "        if mix_decision < 0.5:\n",
        "          input, targets = cutmix(input, target, 0.01)\n",
        "        # measure data loading time\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "\n",
        "        if mix_decision < 0.5:\n",
        "          target_a = targets[0].cuda()\n",
        "          target_b = targets[1].cuda()\n",
        "          lam = targets[2]\n",
        "          if lam>0.5:\n",
        "            target = target_a\n",
        "          else:\n",
        "            target = target_b\n",
        "          loss = criterion(output, target_a) * lam + criterion(output, target_b) * (1. - lam)\n",
        "        else:\n",
        "          target = target.cuda()\n",
        "          loss = loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss, accuracy \n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "def test(test_loader,epoch, model):\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    model.eval()\n",
        "    for i,(input,target) in enumerate(test_loader):\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        output = model(input)\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "model = ResNet34(num_classes=num_classes).cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
        "\n",
        "scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "###########################################################\n",
        "best_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n",
        "        epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "    # train for one epoch\n",
        "    start_time = time.time()\n",
        "    train(train_loader, epoch, model, optimizer, criterion)\n",
        "    test_acc = test(test_loader,epoch,model)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n",
        "    # learning rate scheduling\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Save model for best accuracy\n",
        "    if best_acc < test_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'model_best.pt')\n",
        "\n",
        "torch.save(model.state_dict(),'model_latest.pt')\n",
        "print(f\"Best Top-1 Accuracy: {best_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----- epoch: 0, lr: 0.1 -----\n",
            "Epoch: [0][  0/391]\tTime  0.234 ( 0.234)\tLoss 4.6667e+00 (4.6667e+00)\tAcc@1   2.34 (  2.34)\tAcc@5   6.25 (  6.25)\n",
            "Epoch: [0][ 30/391]\tTime  0.089 ( 0.096)\tLoss 4.6106e+00 (5.2920e+00)\tAcc@1   0.78 (  1.23)\tAcc@5   5.47 (  5.27)\n",
            "Epoch: [0][ 60/391]\tTime  0.090 ( 0.093)\tLoss 4.5598e+00 (4.9638e+00)\tAcc@1   0.00 (  1.32)\tAcc@5   5.47 (  6.02)\n",
            "Epoch: [0][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.5285e+00 (4.8321e+00)\tAcc@1   0.78 (  1.48)\tAcc@5  13.28 (  6.87)\n",
            "Epoch: [0][120/391]\tTime  0.090 ( 0.092)\tLoss 4.4977e+00 (4.7531e+00)\tAcc@1   3.91 (  1.67)\tAcc@5   4.69 (  7.41)\n",
            "Epoch: [0][150/391]\tTime  0.090 ( 0.091)\tLoss 4.5319e+00 (4.6827e+00)\tAcc@1   1.56 (  1.91)\tAcc@5  14.84 (  8.63)\n",
            "Epoch: [0][180/391]\tTime  0.090 ( 0.091)\tLoss 4.3106e+00 (4.6339e+00)\tAcc@1   3.12 (  2.15)\tAcc@5  13.28 (  9.56)\n",
            "Epoch: [0][210/391]\tTime  0.091 ( 0.091)\tLoss 4.5935e+00 (4.5873e+00)\tAcc@1   1.56 (  2.49)\tAcc@5  14.84 ( 10.63)\n",
            "Epoch: [0][240/391]\tTime  0.090 ( 0.091)\tLoss 4.4803e+00 (4.5525e+00)\tAcc@1   3.91 (  2.67)\tAcc@5  11.72 ( 11.42)\n",
            "Epoch: [0][270/391]\tTime  0.090 ( 0.091)\tLoss 4.1646e+00 (4.5194e+00)\tAcc@1   4.69 (  2.86)\tAcc@5  21.09 ( 12.29)\n",
            "Epoch: [0][300/391]\tTime  0.090 ( 0.091)\tLoss 4.1844e+00 (4.4951e+00)\tAcc@1   3.12 (  3.08)\tAcc@5  20.31 ( 12.99)\n",
            "Epoch: [0][330/391]\tTime  0.090 ( 0.091)\tLoss 4.1316e+00 (4.4705e+00)\tAcc@1   5.47 (  3.31)\tAcc@5  25.78 ( 13.73)\n",
            "Epoch: [0][360/391]\tTime  0.090 ( 0.091)\tLoss 4.4926e+00 (4.4491e+00)\tAcc@1   3.91 (  3.54)\tAcc@5  17.19 ( 14.36)\n",
            "Epoch: [0][390/391]\tTime  0.082 ( 0.091)\tLoss 4.2876e+00 (4.4258e+00)\tAcc@1   3.75 (  3.80)\tAcc@5  23.75 ( 15.06)\n",
            "==> Train Accuracy: Acc@1 3.800 || Acc@5 15.056\n",
            "==> Test Accuracy:  Acc@1 3.800 || Acc@5 16.500\n",
            "==> 37.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 1, lr: 0.1 -----\n",
            "Epoch: [1][  0/391]\tTime  0.234 ( 0.234)\tLoss 3.8815e+00 (3.8815e+00)\tAcc@1   7.03 (  7.03)\tAcc@5  26.56 ( 26.56)\n",
            "Epoch: [1][ 30/391]\tTime  0.092 ( 0.096)\tLoss 4.2379e+00 (4.2004e+00)\tAcc@1   6.25 (  5.95)\tAcc@5  24.22 ( 21.37)\n",
            "Epoch: [1][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.8491e+00 (4.1750e+00)\tAcc@1  10.94 (  6.34)\tAcc@5  35.16 ( 22.35)\n",
            "Epoch: [1][ 90/391]\tTime  0.091 ( 0.093)\tLoss 4.3161e+00 (4.1598e+00)\tAcc@1   8.59 (  6.75)\tAcc@5  22.66 ( 23.05)\n",
            "Epoch: [1][120/391]\tTime  0.090 ( 0.092)\tLoss 3.6782e+00 (4.1430e+00)\tAcc@1  17.19 (  7.11)\tAcc@5  37.50 ( 23.85)\n",
            "Epoch: [1][150/391]\tTime  0.092 ( 0.092)\tLoss 4.3590e+00 (4.1358e+00)\tAcc@1   3.12 (  7.12)\tAcc@5  10.16 ( 23.95)\n",
            "Epoch: [1][180/391]\tTime  0.091 ( 0.092)\tLoss 4.4670e+00 (4.1209e+00)\tAcc@1   7.03 (  7.38)\tAcc@5  20.31 ( 24.49)\n",
            "Epoch: [1][210/391]\tTime  0.090 ( 0.091)\tLoss 3.9562e+00 (4.1212e+00)\tAcc@1   7.81 (  7.46)\tAcc@5  30.47 ( 24.67)\n",
            "Epoch: [1][240/391]\tTime  0.090 ( 0.091)\tLoss 3.8719e+00 (4.1050e+00)\tAcc@1  12.50 (  7.69)\tAcc@5  35.16 ( 25.40)\n",
            "Epoch: [1][270/391]\tTime  0.089 ( 0.091)\tLoss 4.2106e+00 (4.0955e+00)\tAcc@1   7.81 (  7.87)\tAcc@5  25.00 ( 25.63)\n",
            "Epoch: [1][300/391]\tTime  0.087 ( 0.091)\tLoss 3.8749e+00 (4.0853e+00)\tAcc@1   9.38 (  8.06)\tAcc@5  28.12 ( 25.91)\n",
            "Epoch: [1][330/391]\tTime  0.090 ( 0.091)\tLoss 3.6545e+00 (4.0764e+00)\tAcc@1  17.97 (  8.21)\tAcc@5  38.28 ( 26.27)\n",
            "Epoch: [1][360/391]\tTime  0.090 ( 0.091)\tLoss 4.0977e+00 (4.0680e+00)\tAcc@1   8.59 (  8.37)\tAcc@5  28.91 ( 26.58)\n",
            "Epoch: [1][390/391]\tTime  0.082 ( 0.091)\tLoss 4.2440e+00 (4.0580e+00)\tAcc@1   7.50 (  8.51)\tAcc@5  26.25 ( 26.97)\n",
            "==> Train Accuracy: Acc@1 8.512 || Acc@5 26.966\n",
            "==> Test Accuracy:  Acc@1 5.220 || Acc@5 19.250\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 2, lr: 0.1 -----\n",
            "Epoch: [2][  0/391]\tTime  0.250 ( 0.250)\tLoss 4.2034e+00 (4.2034e+00)\tAcc@1   6.25 (  6.25)\tAcc@5  19.53 ( 19.53)\n",
            "Epoch: [2][ 30/391]\tTime  0.090 ( 0.096)\tLoss 3.6995e+00 (3.9201e+00)\tAcc@1  14.84 ( 10.53)\tAcc@5  34.38 ( 31.40)\n",
            "Epoch: [2][ 60/391]\tTime  0.086 ( 0.093)\tLoss 4.1855e+00 (3.9163e+00)\tAcc@1   7.03 ( 10.34)\tAcc@5  22.66 ( 31.66)\n",
            "Epoch: [2][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.7917e+00 (3.9162e+00)\tAcc@1  12.50 ( 10.57)\tAcc@5  39.06 ( 31.89)\n",
            "Epoch: [2][120/391]\tTime  0.090 ( 0.092)\tLoss 4.1177e+00 (3.9283e+00)\tAcc@1  14.84 ( 10.63)\tAcc@5  39.84 ( 32.24)\n",
            "Epoch: [2][150/391]\tTime  0.089 ( 0.092)\tLoss 4.0780e+00 (3.9067e+00)\tAcc@1  11.72 ( 10.91)\tAcc@5  39.06 ( 32.72)\n",
            "Epoch: [2][180/391]\tTime  0.091 ( 0.091)\tLoss 4.2428e+00 (3.8850e+00)\tAcc@1  10.94 ( 11.33)\tAcc@5  23.44 ( 33.48)\n",
            "Epoch: [2][210/391]\tTime  0.090 ( 0.091)\tLoss 3.5087e+00 (3.8816e+00)\tAcc@1  14.84 ( 11.35)\tAcc@5  42.97 ( 33.49)\n",
            "Epoch: [2][240/391]\tTime  0.088 ( 0.091)\tLoss 3.4837e+00 (3.8810e+00)\tAcc@1  18.75 ( 11.41)\tAcc@5  40.62 ( 33.63)\n",
            "Epoch: [2][270/391]\tTime  0.090 ( 0.091)\tLoss 4.2697e+00 (3.8763e+00)\tAcc@1   9.38 ( 11.49)\tAcc@5  31.25 ( 33.71)\n",
            "Epoch: [2][300/391]\tTime  0.090 ( 0.091)\tLoss 3.6064e+00 (3.8555e+00)\tAcc@1  17.97 ( 11.80)\tAcc@5  42.19 ( 34.28)\n",
            "Epoch: [2][330/391]\tTime  0.087 ( 0.091)\tLoss 3.9950e+00 (3.8537e+00)\tAcc@1  12.50 ( 11.79)\tAcc@5  38.28 ( 34.35)\n",
            "Epoch: [2][360/391]\tTime  0.091 ( 0.091)\tLoss 4.3161e+00 (3.8572e+00)\tAcc@1   3.12 ( 11.78)\tAcc@5  17.19 ( 34.36)\n",
            "Epoch: [2][390/391]\tTime  0.082 ( 0.091)\tLoss 4.1292e+00 (3.8450e+00)\tAcc@1  12.50 ( 12.04)\tAcc@5  42.50 ( 34.83)\n",
            "==> Train Accuracy: Acc@1 12.044 || Acc@5 34.826\n",
            "==> Test Accuracy:  Acc@1 7.960 || Acc@5 24.400\n",
            "==> 38.03 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 3, lr: 0.1 -----\n",
            "Epoch: [3][  0/391]\tTime  0.243 ( 0.243)\tLoss 3.5925e+00 (3.5925e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  34.38 ( 34.38)\n",
            "Epoch: [3][ 30/391]\tTime  0.088 ( 0.095)\tLoss 3.2647e+00 (3.6934e+00)\tAcc@1  21.88 ( 14.97)\tAcc@5  49.22 ( 39.31)\n",
            "Epoch: [3][ 60/391]\tTime  0.090 ( 0.093)\tLoss 3.4333e+00 (3.7811e+00)\tAcc@1  16.41 ( 14.20)\tAcc@5  43.75 ( 37.46)\n",
            "Epoch: [3][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.1945e+00 (3.7611e+00)\tAcc@1  23.44 ( 14.23)\tAcc@5  50.00 ( 37.53)\n",
            "Epoch: [3][120/391]\tTime  0.091 ( 0.092)\tLoss 3.3100e+00 (3.7666e+00)\tAcc@1  20.31 ( 14.17)\tAcc@5  50.78 ( 37.20)\n",
            "Epoch: [3][150/391]\tTime  0.089 ( 0.092)\tLoss 4.1888e+00 (3.7266e+00)\tAcc@1   8.59 ( 14.71)\tAcc@5  29.69 ( 38.33)\n",
            "Epoch: [3][180/391]\tTime  0.091 ( 0.091)\tLoss 3.6892e+00 (3.7250e+00)\tAcc@1  17.97 ( 14.77)\tAcc@5  43.75 ( 38.52)\n",
            "Epoch: [3][210/391]\tTime  0.091 ( 0.091)\tLoss 3.2124e+00 (3.7222e+00)\tAcc@1  18.75 ( 14.86)\tAcc@5  48.44 ( 38.58)\n",
            "Epoch: [3][240/391]\tTime  0.089 ( 0.091)\tLoss 3.0324e+00 (3.6995e+00)\tAcc@1  23.44 ( 15.15)\tAcc@5  53.91 ( 39.32)\n",
            "Epoch: [3][270/391]\tTime  0.090 ( 0.091)\tLoss 4.0434e+00 (3.7055e+00)\tAcc@1   2.34 ( 14.95)\tAcc@5  25.00 ( 39.13)\n",
            "Epoch: [3][300/391]\tTime  0.089 ( 0.091)\tLoss 3.2846e+00 (3.7015e+00)\tAcc@1  25.00 ( 14.99)\tAcc@5  52.34 ( 39.39)\n",
            "Epoch: [3][330/391]\tTime  0.091 ( 0.091)\tLoss 3.9802e+00 (3.7057e+00)\tAcc@1  12.50 ( 15.03)\tAcc@5  26.56 ( 39.27)\n",
            "Epoch: [3][360/391]\tTime  0.090 ( 0.091)\tLoss 3.9829e+00 (3.6967e+00)\tAcc@1  12.50 ( 15.25)\tAcc@5  35.94 ( 39.52)\n",
            "Epoch: [3][390/391]\tTime  0.082 ( 0.091)\tLoss 4.0082e+00 (3.6962e+00)\tAcc@1  11.25 ( 15.31)\tAcc@5  40.00 ( 39.59)\n",
            "==> Train Accuracy: Acc@1 15.308 || Acc@5 39.594\n",
            "==> Test Accuracy:  Acc@1 13.270 || Acc@5 34.110\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 4, lr: 0.1 -----\n",
            "Epoch: [4][  0/391]\tTime  0.263 ( 0.263)\tLoss 3.9229e+00 (3.9229e+00)\tAcc@1  17.19 ( 17.19)\tAcc@5  38.28 ( 38.28)\n",
            "Epoch: [4][ 30/391]\tTime  0.090 ( 0.097)\tLoss 3.2291e+00 (3.5704e+00)\tAcc@1  24.22 ( 18.45)\tAcc@5  53.91 ( 45.44)\n",
            "Epoch: [4][ 60/391]\tTime  0.090 ( 0.094)\tLoss 4.0148e+00 (3.6140e+00)\tAcc@1  14.06 ( 17.58)\tAcc@5  33.59 ( 43.53)\n",
            "Epoch: [4][ 90/391]\tTime  0.089 ( 0.093)\tLoss 2.7938e+00 (3.5483e+00)\tAcc@1  27.34 ( 18.27)\tAcc@5  59.38 ( 44.79)\n",
            "Epoch: [4][120/391]\tTime  0.090 ( 0.092)\tLoss 3.0660e+00 (3.5272e+00)\tAcc@1  25.78 ( 18.47)\tAcc@5  57.03 ( 45.43)\n",
            "Epoch: [4][150/391]\tTime  0.090 ( 0.092)\tLoss 3.0387e+00 (3.5513e+00)\tAcc@1  25.78 ( 18.23)\tAcc@5  55.47 ( 45.11)\n",
            "Epoch: [4][180/391]\tTime  0.091 ( 0.092)\tLoss 3.7771e+00 (3.5447e+00)\tAcc@1  18.75 ( 18.34)\tAcc@5  47.66 ( 45.45)\n",
            "Epoch: [4][210/391]\tTime  0.092 ( 0.091)\tLoss 4.2242e+00 (3.4984e+00)\tAcc@1  10.16 ( 18.96)\tAcc@5  32.03 ( 46.49)\n",
            "Epoch: [4][240/391]\tTime  0.090 ( 0.091)\tLoss 2.9906e+00 (3.4906e+00)\tAcc@1  24.22 ( 19.16)\tAcc@5  57.03 ( 46.83)\n",
            "Epoch: [4][270/391]\tTime  0.091 ( 0.091)\tLoss 3.8223e+00 (3.4986e+00)\tAcc@1  12.50 ( 19.19)\tAcc@5  42.19 ( 46.65)\n",
            "Epoch: [4][300/391]\tTime  0.090 ( 0.091)\tLoss 3.9396e+00 (3.5013e+00)\tAcc@1  17.97 ( 19.26)\tAcc@5  42.19 ( 46.87)\n",
            "Epoch: [4][330/391]\tTime  0.091 ( 0.091)\tLoss 4.0115e+00 (3.4939e+00)\tAcc@1  11.72 ( 19.45)\tAcc@5  40.62 ( 47.00)\n",
            "Epoch: [4][360/391]\tTime  0.093 ( 0.091)\tLoss 4.1187e+00 (3.4960e+00)\tAcc@1   5.47 ( 19.46)\tAcc@5  19.53 ( 46.93)\n",
            "Epoch: [4][390/391]\tTime  0.082 ( 0.091)\tLoss 4.1450e+00 (3.5013e+00)\tAcc@1   7.50 ( 19.37)\tAcc@5  16.25 ( 46.79)\n",
            "==> Train Accuracy: Acc@1 19.372 || Acc@5 46.788\n",
            "==> Test Accuracy:  Acc@1 14.010 || Acc@5 36.550\n",
            "==> 38.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 5, lr: 0.1 -----\n",
            "Epoch: [5][  0/391]\tTime  0.237 ( 0.237)\tLoss 2.9907e+00 (2.9907e+00)\tAcc@1  26.56 ( 26.56)\tAcc@5  57.03 ( 57.03)\n",
            "Epoch: [5][ 30/391]\tTime  0.091 ( 0.095)\tLoss 3.8028e+00 (3.3436e+00)\tAcc@1  22.66 ( 21.72)\tAcc@5  50.78 ( 51.44)\n",
            "Epoch: [5][ 60/391]\tTime  0.090 ( 0.093)\tLoss 4.0428e+00 (3.3278e+00)\tAcc@1  14.84 ( 22.02)\tAcc@5  33.59 ( 51.51)\n",
            "Epoch: [5][ 90/391]\tTime  0.092 ( 0.092)\tLoss 2.8931e+00 (3.3793e+00)\tAcc@1  29.69 ( 21.39)\tAcc@5  59.38 ( 49.55)\n",
            "Epoch: [5][120/391]\tTime  0.091 ( 0.092)\tLoss 3.9779e+00 (3.4057e+00)\tAcc@1  17.97 ( 21.11)\tAcc@5  35.16 ( 49.00)\n",
            "Epoch: [5][150/391]\tTime  0.090 ( 0.091)\tLoss 2.8704e+00 (3.3889e+00)\tAcc@1  26.56 ( 21.42)\tAcc@5  54.69 ( 49.28)\n",
            "Epoch: [5][180/391]\tTime  0.092 ( 0.091)\tLoss 2.9045e+00 (3.3984e+00)\tAcc@1  29.69 ( 21.33)\tAcc@5  60.94 ( 49.15)\n",
            "Epoch: [5][210/391]\tTime  0.090 ( 0.091)\tLoss 2.8007e+00 (3.3983e+00)\tAcc@1  25.00 ( 21.36)\tAcc@5  57.03 ( 49.10)\n",
            "Epoch: [5][240/391]\tTime  0.094 ( 0.091)\tLoss 4.0508e+00 (3.4193e+00)\tAcc@1  10.94 ( 21.11)\tAcc@5  29.69 ( 48.58)\n",
            "Epoch: [5][270/391]\tTime  0.091 ( 0.091)\tLoss 3.7376e+00 (3.4173e+00)\tAcc@1  10.94 ( 21.12)\tAcc@5  30.47 ( 48.53)\n",
            "Epoch: [5][300/391]\tTime  0.090 ( 0.091)\tLoss 4.1053e+00 (3.4095e+00)\tAcc@1   8.59 ( 21.27)\tAcc@5  24.22 ( 48.67)\n",
            "Epoch: [5][330/391]\tTime  0.093 ( 0.091)\tLoss 4.0812e+00 (3.3878e+00)\tAcc@1  10.16 ( 21.61)\tAcc@5  30.47 ( 49.22)\n",
            "Epoch: [5][360/391]\tTime  0.091 ( 0.091)\tLoss 3.8727e+00 (3.3804e+00)\tAcc@1  14.84 ( 21.79)\tAcc@5  39.06 ( 49.36)\n",
            "Epoch: [5][390/391]\tTime  0.081 ( 0.091)\tLoss 2.6547e+00 (3.3667e+00)\tAcc@1  27.50 ( 22.00)\tAcc@5  67.50 ( 49.71)\n",
            "==> Train Accuracy: Acc@1 22.000 || Acc@5 49.708\n",
            "==> Test Accuracy:  Acc@1 16.690 || Acc@5 40.310\n",
            "==> 37.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 6, lr: 0.1 -----\n",
            "Epoch: [6][  0/391]\tTime  0.245 ( 0.245)\tLoss 4.1485e+00 (4.1485e+00)\tAcc@1  10.16 ( 10.16)\tAcc@5  32.03 ( 32.03)\n",
            "Epoch: [6][ 30/391]\tTime  0.089 ( 0.096)\tLoss 2.8036e+00 (3.1820e+00)\tAcc@1  24.22 ( 25.93)\tAcc@5  63.28 ( 55.65)\n",
            "Epoch: [6][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.8533e+00 (3.2183e+00)\tAcc@1  28.91 ( 25.63)\tAcc@5  57.81 ( 55.47)\n",
            "Epoch: [6][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.8088e+00 (3.2288e+00)\tAcc@1  16.41 ( 24.99)\tAcc@5  44.53 ( 54.65)\n",
            "Epoch: [6][120/391]\tTime  0.093 ( 0.092)\tLoss 3.8148e+00 (3.2703e+00)\tAcc@1  15.62 ( 24.22)\tAcc@5  38.28 ( 53.33)\n",
            "Epoch: [6][150/391]\tTime  0.090 ( 0.091)\tLoss 2.3999e+00 (3.2474e+00)\tAcc@1  36.72 ( 24.45)\tAcc@5  75.00 ( 54.00)\n",
            "Epoch: [6][180/391]\tTime  0.089 ( 0.091)\tLoss 2.6329e+00 (3.2425e+00)\tAcc@1  34.38 ( 24.58)\tAcc@5  66.41 ( 53.92)\n",
            "Epoch: [6][210/391]\tTime  0.090 ( 0.091)\tLoss 3.9478e+00 (3.2506e+00)\tAcc@1  17.19 ( 24.46)\tAcc@5  39.84 ( 53.62)\n",
            "Epoch: [6][240/391]\tTime  0.093 ( 0.091)\tLoss 3.8501e+00 (3.2533e+00)\tAcc@1  15.62 ( 24.59)\tAcc@5  39.06 ( 53.73)\n",
            "Epoch: [6][270/391]\tTime  0.090 ( 0.091)\tLoss 2.5526e+00 (3.2466e+00)\tAcc@1  36.72 ( 24.86)\tAcc@5  68.75 ( 53.92)\n",
            "Epoch: [6][300/391]\tTime  0.091 ( 0.091)\tLoss 3.9591e+00 (3.2545e+00)\tAcc@1  19.53 ( 24.79)\tAcc@5  41.41 ( 53.73)\n",
            "Epoch: [6][330/391]\tTime  0.090 ( 0.091)\tLoss 2.4371e+00 (3.2413e+00)\tAcc@1  37.50 ( 25.04)\tAcc@5  67.19 ( 54.00)\n",
            "Epoch: [6][360/391]\tTime  0.090 ( 0.091)\tLoss 2.5413e+00 (3.2517e+00)\tAcc@1  39.84 ( 24.86)\tAcc@5  69.53 ( 53.67)\n",
            "Epoch: [6][390/391]\tTime  0.082 ( 0.091)\tLoss 3.7103e+00 (3.2465e+00)\tAcc@1  12.50 ( 25.01)\tAcc@5  40.00 ( 53.92)\n",
            "==> Train Accuracy: Acc@1 25.014 || Acc@5 53.920\n",
            "==> Test Accuracy:  Acc@1 22.600 || Acc@5 50.180\n",
            "==> 37.96 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 7, lr: 0.1 -----\n",
            "Epoch: [7][  0/391]\tTime  0.266 ( 0.266)\tLoss 3.8679e+00 (3.8679e+00)\tAcc@1  22.66 ( 22.66)\tAcc@5  46.88 ( 46.88)\n",
            "Epoch: [7][ 30/391]\tTime  0.091 ( 0.097)\tLoss 3.8854e+00 (3.1547e+00)\tAcc@1  16.41 ( 27.70)\tAcc@5  34.38 ( 55.85)\n",
            "Epoch: [7][ 60/391]\tTime  0.090 ( 0.094)\tLoss 2.4845e+00 (3.0613e+00)\tAcc@1  34.38 ( 28.41)\tAcc@5  69.53 ( 57.62)\n",
            "Epoch: [7][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.3182e+00 (3.0542e+00)\tAcc@1  39.06 ( 29.11)\tAcc@5  74.22 ( 58.37)\n",
            "Epoch: [7][120/391]\tTime  0.090 ( 0.092)\tLoss 3.5859e+00 (3.0966e+00)\tAcc@1  24.22 ( 28.67)\tAcc@5  52.34 ( 58.10)\n",
            "Epoch: [7][150/391]\tTime  0.091 ( 0.092)\tLoss 3.8407e+00 (3.1033e+00)\tAcc@1  14.84 ( 28.67)\tAcc@5  40.62 ( 58.19)\n",
            "Epoch: [7][180/391]\tTime  0.092 ( 0.091)\tLoss 3.6607e+00 (3.1275e+00)\tAcc@1  21.88 ( 28.18)\tAcc@5  57.03 ( 57.33)\n",
            "Epoch: [7][210/391]\tTime  0.090 ( 0.091)\tLoss 2.4372e+00 (3.1261e+00)\tAcc@1  32.81 ( 28.47)\tAcc@5  75.00 ( 57.75)\n",
            "Epoch: [7][240/391]\tTime  0.091 ( 0.091)\tLoss 3.8105e+00 (3.1078e+00)\tAcc@1  23.44 ( 28.58)\tAcc@5  53.91 ( 58.03)\n",
            "Epoch: [7][270/391]\tTime  0.093 ( 0.091)\tLoss 2.5638e+00 (3.0893e+00)\tAcc@1  27.34 ( 28.64)\tAcc@5  66.41 ( 58.18)\n",
            "Epoch: [7][300/391]\tTime  0.091 ( 0.091)\tLoss 2.3982e+00 (3.0951e+00)\tAcc@1  37.50 ( 28.55)\tAcc@5  73.44 ( 57.97)\n",
            "Epoch: [7][330/391]\tTime  0.091 ( 0.091)\tLoss 3.5610e+00 (3.1010e+00)\tAcc@1  26.56 ( 28.40)\tAcc@5  50.78 ( 58.00)\n",
            "Epoch: [7][360/391]\tTime  0.091 ( 0.091)\tLoss 3.4376e+00 (3.0831e+00)\tAcc@1  28.12 ( 28.63)\tAcc@5  61.72 ( 58.48)\n",
            "Epoch: [7][390/391]\tTime  0.081 ( 0.091)\tLoss 2.5544e+00 (3.0987e+00)\tAcc@1  43.75 ( 28.39)\tAcc@5  67.50 ( 58.18)\n",
            "==> Train Accuracy: Acc@1 28.392 || Acc@5 58.176\n",
            "==> Test Accuracy:  Acc@1 20.440 || Acc@5 47.670\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 8, lr: 0.1 -----\n",
            "Epoch: [8][  0/391]\tTime  0.224 ( 0.224)\tLoss 2.2022e+00 (2.2022e+00)\tAcc@1  41.41 ( 41.41)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [8][ 30/391]\tTime  0.090 ( 0.095)\tLoss 2.5255e+00 (3.1318e+00)\tAcc@1  38.28 ( 28.18)\tAcc@5  70.31 ( 59.58)\n",
            "Epoch: [8][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.1899e+00 (3.0824e+00)\tAcc@1  40.62 ( 29.26)\tAcc@5  79.69 ( 59.85)\n",
            "Epoch: [8][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.9705e+00 (3.0824e+00)\tAcc@1  18.75 ( 29.36)\tAcc@5  40.62 ( 59.18)\n",
            "Epoch: [8][120/391]\tTime  0.091 ( 0.091)\tLoss 3.5296e+00 (3.0518e+00)\tAcc@1  30.47 ( 30.00)\tAcc@5  59.38 ( 60.32)\n",
            "Epoch: [8][150/391]\tTime  0.090 ( 0.091)\tLoss 2.3110e+00 (3.0020e+00)\tAcc@1  39.06 ( 30.51)\tAcc@5  71.88 ( 60.73)\n",
            "Epoch: [8][180/391]\tTime  0.090 ( 0.091)\tLoss 3.4813e+00 (3.0254e+00)\tAcc@1  31.25 ( 30.36)\tAcc@5  66.41 ( 60.55)\n",
            "Epoch: [8][210/391]\tTime  0.090 ( 0.091)\tLoss 2.2516e+00 (3.0097e+00)\tAcc@1  42.19 ( 30.70)\tAcc@5  71.09 ( 60.87)\n",
            "Epoch: [8][240/391]\tTime  0.091 ( 0.091)\tLoss 2.0952e+00 (2.9750e+00)\tAcc@1  47.66 ( 31.19)\tAcc@5  76.56 ( 61.36)\n",
            "Epoch: [8][270/391]\tTime  0.090 ( 0.091)\tLoss 2.2734e+00 (2.9767e+00)\tAcc@1  39.84 ( 31.08)\tAcc@5  78.91 ( 61.13)\n",
            "Epoch: [8][300/391]\tTime  0.091 ( 0.091)\tLoss 3.8089e+00 (2.9759e+00)\tAcc@1  25.00 ( 31.11)\tAcc@5  55.47 ( 61.21)\n",
            "Epoch: [8][330/391]\tTime  0.091 ( 0.091)\tLoss 3.3882e+00 (2.9743e+00)\tAcc@1  32.03 ( 31.12)\tAcc@5  60.16 ( 61.20)\n",
            "Epoch: [8][360/391]\tTime  0.090 ( 0.091)\tLoss 2.3325e+00 (2.9631e+00)\tAcc@1  40.62 ( 31.39)\tAcc@5  71.88 ( 61.50)\n",
            "Epoch: [8][390/391]\tTime  0.081 ( 0.091)\tLoss 2.2764e+00 (2.9704e+00)\tAcc@1  40.00 ( 31.30)\tAcc@5  70.00 ( 61.30)\n",
            "==> Train Accuracy: Acc@1 31.296 || Acc@5 61.296\n",
            "==> Test Accuracy:  Acc@1 34.170 || Acc@5 65.890\n",
            "==> 38.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 9, lr: 0.1 -----\n",
            "Epoch: [9][  0/391]\tTime  0.249 ( 0.249)\tLoss 2.2025e+00 (2.2025e+00)\tAcc@1  39.84 ( 39.84)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [9][ 30/391]\tTime  0.090 ( 0.097)\tLoss 3.8493e+00 (2.8978e+00)\tAcc@1   8.59 ( 31.10)\tAcc@5  28.12 ( 61.11)\n",
            "Epoch: [9][ 60/391]\tTime  0.090 ( 0.094)\tLoss 2.0079e+00 (2.9382e+00)\tAcc@1  53.12 ( 31.16)\tAcc@5  81.25 ( 60.40)\n",
            "Epoch: [9][ 90/391]\tTime  0.090 ( 0.093)\tLoss 2.1801e+00 (2.8969e+00)\tAcc@1  42.19 ( 31.89)\tAcc@5  75.78 ( 61.34)\n",
            "Epoch: [9][120/391]\tTime  0.090 ( 0.092)\tLoss 3.8451e+00 (2.9141e+00)\tAcc@1  16.41 ( 31.92)\tAcc@5  46.09 ( 61.54)\n",
            "Epoch: [9][150/391]\tTime  0.091 ( 0.092)\tLoss 3.6111e+00 (2.9183e+00)\tAcc@1  19.53 ( 31.83)\tAcc@5  40.62 ( 61.74)\n",
            "Epoch: [9][180/391]\tTime  0.091 ( 0.092)\tLoss 3.7721e+00 (2.9217e+00)\tAcc@1  25.00 ( 31.89)\tAcc@5  44.53 ( 61.86)\n",
            "Epoch: [9][210/391]\tTime  0.091 ( 0.091)\tLoss 3.7879e+00 (2.9103e+00)\tAcc@1  17.19 ( 32.12)\tAcc@5  45.31 ( 62.17)\n",
            "Epoch: [9][240/391]\tTime  0.090 ( 0.091)\tLoss 3.7499e+00 (2.9395e+00)\tAcc@1  21.09 ( 31.78)\tAcc@5  42.97 ( 61.78)\n",
            "Epoch: [9][270/391]\tTime  0.090 ( 0.091)\tLoss 2.1948e+00 (2.9485e+00)\tAcc@1  44.53 ( 31.86)\tAcc@5  75.78 ( 61.74)\n",
            "Epoch: [9][300/391]\tTime  0.090 ( 0.091)\tLoss 2.1736e+00 (2.9138e+00)\tAcc@1  39.84 ( 32.43)\tAcc@5  76.56 ( 62.38)\n",
            "Epoch: [9][330/391]\tTime  0.091 ( 0.091)\tLoss 3.6312e+00 (2.9194e+00)\tAcc@1  21.09 ( 32.26)\tAcc@5  40.62 ( 62.13)\n",
            "Epoch: [9][360/391]\tTime  0.089 ( 0.091)\tLoss 2.1325e+00 (2.9295e+00)\tAcc@1  43.75 ( 32.07)\tAcc@5  78.12 ( 62.09)\n",
            "Epoch: [9][390/391]\tTime  0.081 ( 0.091)\tLoss 2.0826e+00 (2.9247e+00)\tAcc@1  46.25 ( 32.11)\tAcc@5  75.00 ( 62.16)\n",
            "==> Train Accuracy: Acc@1 32.114 || Acc@5 62.158\n",
            "==> Test Accuracy:  Acc@1 34.790 || Acc@5 66.380\n",
            "==> 38.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 10, lr: 0.1 -----\n",
            "Epoch: [10][  0/391]\tTime  0.221 ( 0.221)\tLoss 1.8755e+00 (1.8755e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  80.47 ( 80.47)\n",
            "Epoch: [10][ 30/391]\tTime  0.086 ( 0.096)\tLoss 2.1409e+00 (2.8050e+00)\tAcc@1  45.31 ( 35.69)\tAcc@5  75.78 ( 66.96)\n",
            "Epoch: [10][ 60/391]\tTime  0.090 ( 0.093)\tLoss 3.4149e+00 (2.8902e+00)\tAcc@1  35.94 ( 33.98)\tAcc@5  68.75 ( 64.75)\n",
            "Epoch: [10][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.7575e+00 (2.8084e+00)\tAcc@1  53.12 ( 34.68)\tAcc@5  82.81 ( 65.60)\n",
            "Epoch: [10][120/391]\tTime  0.090 ( 0.092)\tLoss 1.7591e+00 (2.7356e+00)\tAcc@1  49.22 ( 35.65)\tAcc@5  83.59 ( 66.43)\n",
            "Epoch: [10][150/391]\tTime  0.090 ( 0.092)\tLoss 3.5196e+00 (2.7615e+00)\tAcc@1  28.12 ( 35.82)\tAcc@5  58.59 ( 66.67)\n",
            "Epoch: [10][180/391]\tTime  0.090 ( 0.091)\tLoss 2.0756e+00 (2.7702e+00)\tAcc@1  49.22 ( 35.69)\tAcc@5  77.34 ( 66.22)\n",
            "Epoch: [10][210/391]\tTime  0.090 ( 0.091)\tLoss 2.1769e+00 (2.7687e+00)\tAcc@1  50.78 ( 36.00)\tAcc@5  71.09 ( 66.38)\n",
            "Epoch: [10][240/391]\tTime  0.090 ( 0.091)\tLoss 2.0534e+00 (2.7820e+00)\tAcc@1  42.19 ( 35.83)\tAcc@5  80.47 ( 65.98)\n",
            "Epoch: [10][270/391]\tTime  0.091 ( 0.091)\tLoss 3.6632e+00 (2.7682e+00)\tAcc@1  21.88 ( 35.91)\tAcc@5  44.53 ( 66.18)\n",
            "Epoch: [10][300/391]\tTime  0.090 ( 0.091)\tLoss 3.5136e+00 (2.7668e+00)\tAcc@1  29.69 ( 36.06)\tAcc@5  60.16 ( 66.16)\n",
            "Epoch: [10][330/391]\tTime  0.090 ( 0.091)\tLoss 3.7486e+00 (2.7701e+00)\tAcc@1  12.50 ( 36.10)\tAcc@5  38.28 ( 66.21)\n",
            "Epoch: [10][360/391]\tTime  0.091 ( 0.091)\tLoss 3.5903e+00 (2.7739e+00)\tAcc@1  25.78 ( 36.22)\tAcc@5  56.25 ( 66.46)\n",
            "Epoch: [10][390/391]\tTime  0.081 ( 0.091)\tLoss 1.8152e+00 (2.7632e+00)\tAcc@1  58.75 ( 36.40)\tAcc@5  81.25 ( 66.60)\n",
            "==> Train Accuracy: Acc@1 36.402 || Acc@5 66.598\n",
            "==> Test Accuracy:  Acc@1 41.550 || Acc@5 73.450\n",
            "==> 37.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 11, lr: 0.1 -----\n",
            "Epoch: [11][  0/391]\tTime  0.241 ( 0.241)\tLoss 3.4022e+00 (3.4022e+00)\tAcc@1  32.03 ( 32.03)\tAcc@5  64.84 ( 64.84)\n",
            "Epoch: [11][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.8580e+00 (2.8164e+00)\tAcc@1  47.66 ( 36.49)\tAcc@5  85.16 ( 66.73)\n",
            "Epoch: [11][ 60/391]\tTime  0.093 ( 0.093)\tLoss 3.7811e+00 (2.6362e+00)\tAcc@1  23.44 ( 39.28)\tAcc@5  51.56 ( 68.90)\n",
            "Epoch: [11][ 90/391]\tTime  0.093 ( 0.093)\tLoss 1.8632e+00 (2.5741e+00)\tAcc@1  53.91 ( 40.20)\tAcc@5  85.94 ( 70.04)\n",
            "Epoch: [11][120/391]\tTime  0.099 ( 0.092)\tLoss 3.2859e+00 (2.6103e+00)\tAcc@1  36.72 ( 39.68)\tAcc@5  68.75 ( 69.62)\n",
            "Epoch: [11][150/391]\tTime  0.090 ( 0.092)\tLoss 3.7343e+00 (2.6524e+00)\tAcc@1  10.16 ( 38.90)\tAcc@5  40.62 ( 68.70)\n",
            "Epoch: [11][180/391]\tTime  0.090 ( 0.092)\tLoss 1.8691e+00 (2.6480e+00)\tAcc@1  57.03 ( 39.06)\tAcc@5  77.34 ( 68.94)\n",
            "Epoch: [11][210/391]\tTime  0.091 ( 0.091)\tLoss 3.5940e+00 (2.6598e+00)\tAcc@1  30.47 ( 38.52)\tAcc@5  64.84 ( 68.41)\n",
            "Epoch: [11][240/391]\tTime  0.091 ( 0.091)\tLoss 3.4963e+00 (2.6700e+00)\tAcc@1  25.78 ( 38.14)\tAcc@5  55.47 ( 68.11)\n",
            "Epoch: [11][270/391]\tTime  0.090 ( 0.091)\tLoss 2.0244e+00 (2.6940e+00)\tAcc@1  45.31 ( 37.96)\tAcc@5  79.69 ( 67.97)\n",
            "Epoch: [11][300/391]\tTime  0.089 ( 0.091)\tLoss 3.4285e+00 (2.6727e+00)\tAcc@1  25.00 ( 38.16)\tAcc@5  58.59 ( 68.31)\n",
            "Epoch: [11][330/391]\tTime  0.090 ( 0.091)\tLoss 2.1540e+00 (2.6772e+00)\tAcc@1  35.94 ( 37.97)\tAcc@5  77.34 ( 68.07)\n",
            "Epoch: [11][360/391]\tTime  0.088 ( 0.091)\tLoss 1.9503e+00 (2.6725e+00)\tAcc@1  47.66 ( 38.12)\tAcc@5  79.69 ( 68.12)\n",
            "Epoch: [11][390/391]\tTime  0.082 ( 0.091)\tLoss 2.3104e+00 (2.6699e+00)\tAcc@1  36.25 ( 38.12)\tAcc@5  75.00 ( 68.21)\n",
            "==> Train Accuracy: Acc@1 38.122 || Acc@5 68.212\n",
            "==> Test Accuracy:  Acc@1 37.520 || Acc@5 69.610\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 12, lr: 0.1 -----\n",
            "Epoch: [12][  0/391]\tTime  0.247 ( 0.247)\tLoss 3.3645e+00 (3.3645e+00)\tAcc@1  36.72 ( 36.72)\tAcc@5  68.75 ( 68.75)\n",
            "Epoch: [12][ 30/391]\tTime  0.088 ( 0.096)\tLoss 1.8177e+00 (2.4952e+00)\tAcc@1  51.56 ( 41.81)\tAcc@5  78.91 ( 72.35)\n",
            "Epoch: [12][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.6936e+00 (2.5437e+00)\tAcc@1  56.25 ( 40.93)\tAcc@5  84.38 ( 70.41)\n",
            "Epoch: [12][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.6970e+00 (2.5860e+00)\tAcc@1  58.59 ( 40.35)\tAcc@5  82.81 ( 69.40)\n",
            "Epoch: [12][120/391]\tTime  0.091 ( 0.092)\tLoss 3.4211e+00 (2.5986e+00)\tAcc@1  33.59 ( 39.82)\tAcc@5  70.31 ( 69.15)\n",
            "Epoch: [12][150/391]\tTime  0.090 ( 0.091)\tLoss 1.7289e+00 (2.5919e+00)\tAcc@1  56.25 ( 39.60)\tAcc@5  82.81 ( 68.81)\n",
            "Epoch: [12][180/391]\tTime  0.091 ( 0.091)\tLoss 3.6233e+00 (2.6027e+00)\tAcc@1  20.31 ( 39.63)\tAcc@5  43.75 ( 68.97)\n",
            "Epoch: [12][210/391]\tTime  0.090 ( 0.091)\tLoss 3.4443e+00 (2.5929e+00)\tAcc@1  19.53 ( 39.53)\tAcc@5  42.97 ( 69.15)\n",
            "Epoch: [12][240/391]\tTime  0.090 ( 0.091)\tLoss 1.9320e+00 (2.5939e+00)\tAcc@1  48.44 ( 39.46)\tAcc@5  80.47 ( 69.31)\n",
            "Epoch: [12][270/391]\tTime  0.090 ( 0.091)\tLoss 3.6544e+00 (2.6107e+00)\tAcc@1  25.78 ( 39.19)\tAcc@5  53.91 ( 69.09)\n",
            "Epoch: [12][300/391]\tTime  0.088 ( 0.091)\tLoss 1.8859e+00 (2.6080e+00)\tAcc@1  50.78 ( 39.28)\tAcc@5  77.34 ( 69.19)\n",
            "Epoch: [12][330/391]\tTime  0.087 ( 0.091)\tLoss 1.6453e+00 (2.6233e+00)\tAcc@1  51.56 ( 39.02)\tAcc@5  83.59 ( 68.96)\n",
            "Epoch: [12][360/391]\tTime  0.090 ( 0.091)\tLoss 3.0465e+00 (2.6339e+00)\tAcc@1  40.62 ( 39.00)\tAcc@5  70.31 ( 68.88)\n",
            "Epoch: [12][390/391]\tTime  0.082 ( 0.091)\tLoss 3.3498e+00 (2.6281e+00)\tAcc@1  31.25 ( 38.99)\tAcc@5  56.25 ( 68.92)\n",
            "==> Train Accuracy: Acc@1 38.992 || Acc@5 68.918\n",
            "==> Test Accuracy:  Acc@1 45.290 || Acc@5 76.450\n",
            "==> 37.95 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 13, lr: 0.1 -----\n",
            "Epoch: [13][  0/391]\tTime  0.260 ( 0.260)\tLoss 3.4977e+00 (3.4977e+00)\tAcc@1  19.53 ( 19.53)\tAcc@5  46.09 ( 46.09)\n",
            "Epoch: [13][ 30/391]\tTime  0.088 ( 0.096)\tLoss 1.7558e+00 (2.5138e+00)\tAcc@1  53.91 ( 42.01)\tAcc@5  81.25 ( 72.43)\n",
            "Epoch: [13][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.7562e+00 (2.4886e+00)\tAcc@1  50.78 ( 42.58)\tAcc@5  80.47 ( 72.54)\n",
            "Epoch: [13][ 90/391]\tTime  0.095 ( 0.092)\tLoss 1.8038e+00 (2.4614e+00)\tAcc@1  44.53 ( 42.32)\tAcc@5  85.94 ( 72.23)\n",
            "Epoch: [13][120/391]\tTime  0.091 ( 0.092)\tLoss 1.8714e+00 (2.4931e+00)\tAcc@1  47.66 ( 41.91)\tAcc@5  78.91 ( 71.97)\n",
            "Epoch: [13][150/391]\tTime  0.090 ( 0.092)\tLoss 3.5898e+00 (2.5022e+00)\tAcc@1  27.34 ( 41.77)\tAcc@5  57.03 ( 71.67)\n",
            "Epoch: [13][180/391]\tTime  0.090 ( 0.091)\tLoss 1.9547e+00 (2.5330e+00)\tAcc@1  46.09 ( 41.09)\tAcc@5  76.56 ( 71.05)\n",
            "Epoch: [13][210/391]\tTime  0.090 ( 0.091)\tLoss 1.6037e+00 (2.5409e+00)\tAcc@1  58.59 ( 41.00)\tAcc@5  83.59 ( 71.05)\n",
            "Epoch: [13][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5489e+00 (2.5335e+00)\tAcc@1  55.47 ( 41.33)\tAcc@5  88.28 ( 71.35)\n",
            "Epoch: [13][270/391]\tTime  0.096 ( 0.091)\tLoss 2.6541e+00 (2.5272e+00)\tAcc@1  49.22 ( 41.52)\tAcc@5  78.12 ( 71.64)\n",
            "Epoch: [13][300/391]\tTime  0.091 ( 0.091)\tLoss 3.5592e+00 (2.5376e+00)\tAcc@1  33.59 ( 41.31)\tAcc@5  57.81 ( 71.25)\n",
            "Epoch: [13][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9750e+00 (2.5367e+00)\tAcc@1  46.88 ( 41.41)\tAcc@5  78.12 ( 71.27)\n",
            "Epoch: [13][360/391]\tTime  0.093 ( 0.091)\tLoss 3.4469e+00 (2.5216e+00)\tAcc@1  29.69 ( 41.64)\tAcc@5  60.16 ( 71.54)\n",
            "Epoch: [13][390/391]\tTime  0.081 ( 0.091)\tLoss 3.5042e+00 (2.5484e+00)\tAcc@1  15.00 ( 41.01)\tAcc@5  33.75 ( 70.84)\n",
            "==> Train Accuracy: Acc@1 41.010 || Acc@5 70.838\n",
            "==> Test Accuracy:  Acc@1 45.300 || Acc@5 76.580\n",
            "==> 38.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 14, lr: 0.1 -----\n",
            "Epoch: [14][  0/391]\tTime  0.253 ( 0.253)\tLoss 3.5338e+00 (3.5338e+00)\tAcc@1  21.09 ( 21.09)\tAcc@5  55.47 ( 55.47)\n",
            "Epoch: [14][ 30/391]\tTime  0.089 ( 0.096)\tLoss 1.5166e+00 (2.6575e+00)\tAcc@1  59.38 ( 39.64)\tAcc@5  90.62 ( 70.21)\n",
            "Epoch: [14][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.7216e+00 (2.6497e+00)\tAcc@1  52.34 ( 39.77)\tAcc@5  83.59 ( 69.85)\n",
            "Epoch: [14][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.3274e+00 (2.6051e+00)\tAcc@1  32.03 ( 40.30)\tAcc@5  53.91 ( 70.07)\n",
            "Epoch: [14][120/391]\tTime  0.091 ( 0.092)\tLoss 3.2456e+00 (2.5919e+00)\tAcc@1  36.72 ( 41.28)\tAcc@5  62.50 ( 70.93)\n",
            "Epoch: [14][150/391]\tTime  0.090 ( 0.092)\tLoss 1.6425e+00 (2.5401e+00)\tAcc@1  53.12 ( 41.70)\tAcc@5  85.16 ( 71.42)\n",
            "Epoch: [14][180/391]\tTime  0.090 ( 0.091)\tLoss 1.7068e+00 (2.5331e+00)\tAcc@1  55.47 ( 41.89)\tAcc@5  82.81 ( 71.49)\n",
            "Epoch: [14][210/391]\tTime  0.091 ( 0.091)\tLoss 3.4066e+00 (2.5241e+00)\tAcc@1  26.56 ( 42.01)\tAcc@5  53.91 ( 71.64)\n",
            "Epoch: [14][240/391]\tTime  0.090 ( 0.091)\tLoss 1.7341e+00 (2.5117e+00)\tAcc@1  52.34 ( 42.11)\tAcc@5  84.38 ( 71.77)\n",
            "Epoch: [14][270/391]\tTime  0.091 ( 0.091)\tLoss 3.4311e+00 (2.5272e+00)\tAcc@1  35.16 ( 41.78)\tAcc@5  66.41 ( 71.58)\n",
            "Epoch: [14][300/391]\tTime  0.091 ( 0.091)\tLoss 2.6454e+00 (2.5251e+00)\tAcc@1  49.22 ( 41.97)\tAcc@5  78.12 ( 71.72)\n",
            "Epoch: [14][330/391]\tTime  0.091 ( 0.091)\tLoss 3.2723e+00 (2.5248e+00)\tAcc@1  36.72 ( 42.08)\tAcc@5  63.28 ( 71.72)\n",
            "Epoch: [14][360/391]\tTime  0.090 ( 0.091)\tLoss 3.5117e+00 (2.5118e+00)\tAcc@1  21.09 ( 42.16)\tAcc@5  50.00 ( 71.84)\n",
            "Epoch: [14][390/391]\tTime  0.082 ( 0.091)\tLoss 3.7332e+00 (2.5273e+00)\tAcc@1  13.75 ( 41.94)\tAcc@5  31.25 ( 71.62)\n",
            "==> Train Accuracy: Acc@1 41.936 || Acc@5 71.616\n",
            "==> Test Accuracy:  Acc@1 44.990 || Acc@5 76.490\n",
            "==> 37.94 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 15, lr: 0.1 -----\n",
            "Epoch: [15][  0/391]\tTime  0.235 ( 0.235)\tLoss 3.5485e+00 (3.5485e+00)\tAcc@1  30.47 ( 30.47)\tAcc@5  63.28 ( 63.28)\n",
            "Epoch: [15][ 30/391]\tTime  0.091 ( 0.095)\tLoss 2.8938e+00 (2.3734e+00)\tAcc@1  40.62 ( 46.67)\tAcc@5  77.34 ( 77.60)\n",
            "Epoch: [15][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.9496e+00 (2.4362e+00)\tAcc@1  44.53 ( 45.15)\tAcc@5  82.81 ( 76.18)\n",
            "Epoch: [15][ 90/391]\tTime  0.089 ( 0.092)\tLoss 1.6322e+00 (2.4225e+00)\tAcc@1  60.94 ( 44.81)\tAcc@5  83.59 ( 75.07)\n",
            "Epoch: [15][120/391]\tTime  0.090 ( 0.092)\tLoss 1.6898e+00 (2.4899e+00)\tAcc@1  51.56 ( 43.00)\tAcc@5  83.59 ( 73.18)\n",
            "Epoch: [15][150/391]\tTime  0.091 ( 0.092)\tLoss 3.0245e+00 (2.5754e+00)\tAcc@1  40.62 ( 41.34)\tAcc@5  75.00 ( 71.33)\n",
            "Epoch: [15][180/391]\tTime  0.093 ( 0.091)\tLoss 3.1638e+00 (2.5639e+00)\tAcc@1  35.16 ( 41.64)\tAcc@5  64.84 ( 71.42)\n",
            "Epoch: [15][210/391]\tTime  0.090 ( 0.091)\tLoss 1.6267e+00 (2.5374e+00)\tAcc@1  54.69 ( 41.96)\tAcc@5  83.59 ( 71.89)\n",
            "Epoch: [15][240/391]\tTime  0.091 ( 0.091)\tLoss 3.1629e+00 (2.5383e+00)\tAcc@1  33.59 ( 41.89)\tAcc@5  64.06 ( 71.74)\n",
            "Epoch: [15][270/391]\tTime  0.091 ( 0.091)\tLoss 3.5292e+00 (2.5479e+00)\tAcc@1  20.31 ( 41.59)\tAcc@5  49.22 ( 71.44)\n",
            "Epoch: [15][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6001e+00 (2.5471e+00)\tAcc@1  60.94 ( 41.69)\tAcc@5  85.94 ( 71.35)\n",
            "Epoch: [15][330/391]\tTime  0.091 ( 0.091)\tLoss 3.3109e+00 (2.5803e+00)\tAcc@1  29.69 ( 41.23)\tAcc@5  62.50 ( 70.82)\n",
            "Epoch: [15][360/391]\tTime  0.091 ( 0.091)\tLoss 3.5991e+00 (2.5525e+00)\tAcc@1  28.91 ( 41.65)\tAcc@5  53.12 ( 71.29)\n",
            "Epoch: [15][390/391]\tTime  0.081 ( 0.091)\tLoss 1.8267e+00 (2.5624e+00)\tAcc@1  47.50 ( 41.54)\tAcc@5  81.25 ( 71.12)\n",
            "==> Train Accuracy: Acc@1 41.536 || Acc@5 71.120\n",
            "==> Test Accuracy:  Acc@1 48.540 || Acc@5 79.410\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 16, lr: 0.1 -----\n",
            "Epoch: [16][  0/391]\tTime  0.236 ( 0.236)\tLoss 1.8367e+00 (1.8367e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  78.91 ( 78.91)\n",
            "Epoch: [16][ 30/391]\tTime  0.092 ( 0.096)\tLoss 3.4383e+00 (2.6459e+00)\tAcc@1  19.53 ( 40.80)\tAcc@5  52.34 ( 69.10)\n",
            "Epoch: [16][ 60/391]\tTime  0.089 ( 0.094)\tLoss 1.5587e+00 (2.5480e+00)\tAcc@1  60.16 ( 42.30)\tAcc@5  87.50 ( 71.12)\n",
            "Epoch: [16][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.2987e+00 (2.4725e+00)\tAcc@1  36.72 ( 43.60)\tAcc@5  64.84 ( 72.74)\n",
            "Epoch: [16][120/391]\tTime  0.098 ( 0.092)\tLoss 3.1405e+00 (2.5153e+00)\tAcc@1  44.53 ( 42.89)\tAcc@5  75.00 ( 71.88)\n",
            "Epoch: [16][150/391]\tTime  0.091 ( 0.092)\tLoss 3.4936e+00 (2.5054e+00)\tAcc@1  12.50 ( 42.84)\tAcc@5  35.94 ( 71.93)\n",
            "Epoch: [16][180/391]\tTime  0.090 ( 0.091)\tLoss 1.3516e+00 (2.4731e+00)\tAcc@1  64.84 ( 43.24)\tAcc@5  87.50 ( 72.41)\n",
            "Epoch: [16][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5476e+00 (2.4233e+00)\tAcc@1  53.12 ( 43.90)\tAcc@5  86.72 ( 73.04)\n",
            "Epoch: [16][240/391]\tTime  0.094 ( 0.091)\tLoss 1.6766e+00 (2.4474e+00)\tAcc@1  50.78 ( 43.80)\tAcc@5  83.59 ( 72.88)\n",
            "Epoch: [16][270/391]\tTime  0.091 ( 0.091)\tLoss 3.3717e+00 (2.4377e+00)\tAcc@1  36.72 ( 44.05)\tAcc@5  64.84 ( 72.98)\n",
            "Epoch: [16][300/391]\tTime  0.088 ( 0.091)\tLoss 3.1560e+00 (2.4391e+00)\tAcc@1  37.50 ( 44.04)\tAcc@5  63.28 ( 73.02)\n",
            "Epoch: [16][330/391]\tTime  0.088 ( 0.091)\tLoss 2.7723e+00 (2.4607e+00)\tAcc@1  44.53 ( 43.71)\tAcc@5  79.69 ( 72.74)\n",
            "Epoch: [16][360/391]\tTime  0.090 ( 0.091)\tLoss 3.3393e+00 (2.4728e+00)\tAcc@1  18.75 ( 43.55)\tAcc@5  49.22 ( 72.50)\n",
            "Epoch: [16][390/391]\tTime  0.081 ( 0.091)\tLoss 1.6000e+00 (2.4879e+00)\tAcc@1  57.50 ( 43.25)\tAcc@5  85.00 ( 72.23)\n",
            "==> Train Accuracy: Acc@1 43.250 || Acc@5 72.228\n",
            "==> Test Accuracy:  Acc@1 49.360 || Acc@5 81.180\n",
            "==> 37.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 17, lr: 0.1 -----\n",
            "Epoch: [17][  0/391]\tTime  0.259 ( 0.259)\tLoss 3.2876e+00 (3.2876e+00)\tAcc@1  23.44 ( 23.44)\tAcc@5  52.34 ( 52.34)\n",
            "Epoch: [17][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.3310e+00 (2.3453e+00)\tAcc@1  64.06 ( 45.79)\tAcc@5  91.41 ( 75.48)\n",
            "Epoch: [17][ 60/391]\tTime  0.090 ( 0.093)\tLoss 3.4134e+00 (2.4785e+00)\tAcc@1  32.03 ( 43.80)\tAcc@5  57.03 ( 73.16)\n",
            "Epoch: [17][ 90/391]\tTime  0.087 ( 0.093)\tLoss 1.7626e+00 (2.3953e+00)\tAcc@1  55.47 ( 44.86)\tAcc@5  83.59 ( 74.69)\n",
            "Epoch: [17][120/391]\tTime  0.090 ( 0.092)\tLoss 3.6948e+00 (2.3255e+00)\tAcc@1  25.00 ( 46.56)\tAcc@5  54.69 ( 75.92)\n",
            "Epoch: [17][150/391]\tTime  0.090 ( 0.092)\tLoss 3.4460e+00 (2.3227e+00)\tAcc@1  14.06 ( 46.18)\tAcc@5  37.50 ( 75.64)\n",
            "Epoch: [17][180/391]\tTime  0.090 ( 0.091)\tLoss 1.6091e+00 (2.3561e+00)\tAcc@1  53.91 ( 45.83)\tAcc@5  86.72 ( 75.32)\n",
            "Epoch: [17][210/391]\tTime  0.090 ( 0.091)\tLoss 3.6293e+00 (2.3509e+00)\tAcc@1  15.62 ( 45.88)\tAcc@5  42.19 ( 75.33)\n",
            "Epoch: [17][240/391]\tTime  0.091 ( 0.091)\tLoss 1.6366e+00 (2.3758e+00)\tAcc@1  57.81 ( 45.41)\tAcc@5  82.03 ( 74.97)\n",
            "Epoch: [17][270/391]\tTime  0.090 ( 0.091)\tLoss 3.1106e+00 (2.3866e+00)\tAcc@1  45.31 ( 45.54)\tAcc@5  76.56 ( 75.13)\n",
            "Epoch: [17][300/391]\tTime  0.089 ( 0.091)\tLoss 1.3518e+00 (2.3848e+00)\tAcc@1  65.62 ( 45.77)\tAcc@5  89.84 ( 75.16)\n",
            "Epoch: [17][330/391]\tTime  0.090 ( 0.091)\tLoss 2.9896e+00 (2.3950e+00)\tAcc@1  42.97 ( 45.60)\tAcc@5  77.34 ( 75.00)\n",
            "Epoch: [17][360/391]\tTime  0.090 ( 0.091)\tLoss 3.1534e+00 (2.3797e+00)\tAcc@1  34.38 ( 45.73)\tAcc@5  69.53 ( 75.16)\n",
            "Epoch: [17][390/391]\tTime  0.082 ( 0.091)\tLoss 3.5290e+00 (2.3829e+00)\tAcc@1  20.00 ( 45.53)\tAcc@5  38.75 ( 74.98)\n",
            "==> Train Accuracy: Acc@1 45.532 || Acc@5 74.978\n",
            "==> Test Accuracy:  Acc@1 50.060 || Acc@5 80.280\n",
            "==> 37.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 18, lr: 0.1 -----\n",
            "Epoch: [18][  0/391]\tTime  0.243 ( 0.243)\tLoss 2.7226e+00 (2.7226e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  81.25 ( 81.25)\n",
            "Epoch: [18][ 30/391]\tTime  0.090 ( 0.096)\tLoss 2.9253e+00 (2.2996e+00)\tAcc@1  48.44 ( 50.05)\tAcc@5  82.03 ( 79.03)\n",
            "Epoch: [18][ 60/391]\tTime  0.086 ( 0.093)\tLoss 2.8531e+00 (2.3863e+00)\tAcc@1  51.56 ( 46.31)\tAcc@5  77.34 ( 75.82)\n",
            "Epoch: [18][ 90/391]\tTime  0.091 ( 0.093)\tLoss 3.4698e+00 (2.4113e+00)\tAcc@1  25.00 ( 45.14)\tAcc@5  53.12 ( 74.39)\n",
            "Epoch: [18][120/391]\tTime  0.090 ( 0.092)\tLoss 2.6740e+00 (2.3916e+00)\tAcc@1  53.91 ( 46.07)\tAcc@5  86.72 ( 75.06)\n",
            "Epoch: [18][150/391]\tTime  0.088 ( 0.092)\tLoss 3.3781e+00 (2.3493e+00)\tAcc@1  22.66 ( 46.89)\tAcc@5  53.12 ( 75.83)\n",
            "Epoch: [18][180/391]\tTime  0.090 ( 0.092)\tLoss 1.8222e+00 (2.3503e+00)\tAcc@1  54.69 ( 46.96)\tAcc@5  80.47 ( 75.70)\n",
            "Epoch: [18][210/391]\tTime  0.090 ( 0.091)\tLoss 1.7081e+00 (2.3501e+00)\tAcc@1  53.91 ( 46.89)\tAcc@5  82.03 ( 75.57)\n",
            "Epoch: [18][240/391]\tTime  0.090 ( 0.091)\tLoss 1.8789e+00 (2.3931e+00)\tAcc@1  50.78 ( 46.05)\tAcc@5  82.81 ( 74.80)\n",
            "Epoch: [18][270/391]\tTime  0.090 ( 0.091)\tLoss 3.2550e+00 (2.4099e+00)\tAcc@1  29.69 ( 45.68)\tAcc@5  60.16 ( 74.50)\n",
            "Epoch: [18][300/391]\tTime  0.091 ( 0.091)\tLoss 3.4063e+00 (2.4221e+00)\tAcc@1  25.78 ( 45.44)\tAcc@5  50.78 ( 74.37)\n",
            "Epoch: [18][330/391]\tTime  0.091 ( 0.091)\tLoss 3.3171e+00 (2.4275e+00)\tAcc@1  29.69 ( 45.19)\tAcc@5  61.72 ( 74.10)\n",
            "Epoch: [18][360/391]\tTime  0.090 ( 0.091)\tLoss 1.6406e+00 (2.4530e+00)\tAcc@1  58.59 ( 44.81)\tAcc@5  84.38 ( 73.78)\n",
            "Epoch: [18][390/391]\tTime  0.082 ( 0.091)\tLoss 3.2058e+00 (2.4386e+00)\tAcc@1  16.25 ( 44.96)\tAcc@5  42.50 ( 73.97)\n",
            "==> Train Accuracy: Acc@1 44.960 || Acc@5 73.966\n",
            "==> Test Accuracy:  Acc@1 49.330 || Acc@5 79.250\n",
            "==> 37.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 19, lr: 0.1 -----\n",
            "Epoch: [19][  0/391]\tTime  0.268 ( 0.268)\tLoss 3.1518e+00 (3.1518e+00)\tAcc@1  21.09 ( 21.09)\tAcc@5  57.81 ( 57.81)\n",
            "Epoch: [19][ 30/391]\tTime  0.091 ( 0.096)\tLoss 3.5469e+00 (2.4863e+00)\tAcc@1  30.47 ( 45.49)\tAcc@5  57.81 ( 75.58)\n",
            "Epoch: [19][ 60/391]\tTime  0.090 ( 0.093)\tLoss 3.2835e+00 (2.1876e+00)\tAcc@1  42.97 ( 50.09)\tAcc@5  70.31 ( 79.24)\n",
            "Epoch: [19][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.5990e+00 (2.1583e+00)\tAcc@1  59.38 ( 50.01)\tAcc@5  86.72 ( 78.76)\n",
            "Epoch: [19][120/391]\tTime  0.090 ( 0.092)\tLoss 2.9384e+00 (2.2623e+00)\tAcc@1  47.66 ( 48.31)\tAcc@5  71.88 ( 76.76)\n",
            "Epoch: [19][150/391]\tTime  0.090 ( 0.091)\tLoss 3.2913e+00 (2.2987e+00)\tAcc@1  30.47 ( 47.53)\tAcc@5  70.31 ( 76.45)\n",
            "Epoch: [19][180/391]\tTime  0.092 ( 0.091)\tLoss 3.3728e+00 (2.3441e+00)\tAcc@1  11.72 ( 46.56)\tAcc@5  41.41 ( 75.46)\n",
            "Epoch: [19][210/391]\tTime  0.090 ( 0.091)\tLoss 1.6309e+00 (2.3526e+00)\tAcc@1  50.78 ( 46.24)\tAcc@5  85.16 ( 75.16)\n",
            "Epoch: [19][240/391]\tTime  0.090 ( 0.091)\tLoss 1.4141e+00 (2.3655e+00)\tAcc@1  59.38 ( 46.11)\tAcc@5  89.84 ( 75.15)\n",
            "Epoch: [19][270/391]\tTime  0.092 ( 0.091)\tLoss 3.0631e+00 (2.3800e+00)\tAcc@1  52.34 ( 45.92)\tAcc@5  79.69 ( 74.99)\n",
            "Epoch: [19][300/391]\tTime  0.090 ( 0.091)\tLoss 1.3137e+00 (2.3835e+00)\tAcc@1  57.03 ( 45.71)\tAcc@5  90.62 ( 74.84)\n",
            "Epoch: [19][330/391]\tTime  0.088 ( 0.091)\tLoss 3.2194e+00 (2.4066e+00)\tAcc@1  35.94 ( 45.26)\tAcc@5  60.16 ( 74.39)\n",
            "Epoch: [19][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4367e+00 (2.3844e+00)\tAcc@1  61.72 ( 45.58)\tAcc@5  87.50 ( 74.59)\n",
            "Epoch: [19][390/391]\tTime  0.081 ( 0.091)\tLoss 1.3650e+00 (2.3871e+00)\tAcc@1  63.75 ( 45.45)\tAcc@5  90.00 ( 74.51)\n",
            "==> Train Accuracy: Acc@1 45.454 || Acc@5 74.514\n",
            "==> Test Accuracy:  Acc@1 47.990 || Acc@5 78.960\n",
            "==> 37.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 20, lr: 0.1 -----\n",
            "Epoch: [20][  0/391]\tTime  0.226 ( 0.226)\tLoss 1.6178e+00 (1.6178e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [20][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.3119e+00 (2.0266e+00)\tAcc@1  64.06 ( 49.87)\tAcc@5  87.50 ( 77.42)\n",
            "Epoch: [20][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.2703e+00 (2.1988e+00)\tAcc@1  63.28 ( 47.18)\tAcc@5  89.84 ( 75.08)\n",
            "Epoch: [20][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.1247e+00 (2.2567e+00)\tAcc@1  28.91 ( 46.72)\tAcc@5  61.72 ( 75.05)\n",
            "Epoch: [20][120/391]\tTime  0.090 ( 0.092)\tLoss 3.2450e+00 (2.2540e+00)\tAcc@1  23.44 ( 47.04)\tAcc@5  54.69 ( 75.48)\n",
            "Epoch: [20][150/391]\tTime  0.091 ( 0.091)\tLoss 3.1466e+00 (2.2715e+00)\tAcc@1  34.38 ( 46.53)\tAcc@5  67.97 ( 75.39)\n",
            "Epoch: [20][180/391]\tTime  0.090 ( 0.091)\tLoss 2.7434e+00 (2.3181e+00)\tAcc@1  56.25 ( 46.44)\tAcc@5  83.59 ( 75.34)\n",
            "Epoch: [20][210/391]\tTime  0.090 ( 0.091)\tLoss 1.6183e+00 (2.3107e+00)\tAcc@1  56.25 ( 46.63)\tAcc@5  85.94 ( 75.46)\n",
            "Epoch: [20][240/391]\tTime  0.090 ( 0.091)\tLoss 3.0957e+00 (2.3115e+00)\tAcc@1  37.50 ( 46.78)\tAcc@5  74.22 ( 75.68)\n",
            "Epoch: [20][270/391]\tTime  0.087 ( 0.091)\tLoss 1.4019e+00 (2.3078e+00)\tAcc@1  63.28 ( 46.79)\tAcc@5  87.50 ( 75.75)\n",
            "Epoch: [20][300/391]\tTime  0.091 ( 0.091)\tLoss 3.1457e+00 (2.3474e+00)\tAcc@1  15.62 ( 46.22)\tAcc@5  52.34 ( 75.22)\n",
            "Epoch: [20][330/391]\tTime  0.091 ( 0.091)\tLoss 1.3941e+00 (2.3552e+00)\tAcc@1  62.50 ( 46.07)\tAcc@5  88.28 ( 75.00)\n",
            "Epoch: [20][360/391]\tTime  0.090 ( 0.091)\tLoss 3.1543e+00 (2.3506e+00)\tAcc@1  38.28 ( 46.18)\tAcc@5  71.09 ( 75.00)\n",
            "Epoch: [20][390/391]\tTime  0.082 ( 0.091)\tLoss 1.3350e+00 (2.3643e+00)\tAcc@1  66.25 ( 45.83)\tAcc@5  90.00 ( 74.63)\n",
            "==> Train Accuracy: Acc@1 45.832 || Acc@5 74.634\n",
            "==> Test Accuracy:  Acc@1 53.330 || Acc@5 82.030\n",
            "==> 37.89 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 21, lr: 0.1 -----\n",
            "Epoch: [21][  0/391]\tTime  0.222 ( 0.222)\tLoss 1.2282e+00 (1.2282e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [21][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.6806e+00 (2.4023e+00)\tAcc@1  55.47 ( 46.80)\tAcc@5  82.81 ( 75.66)\n",
            "Epoch: [21][ 60/391]\tTime  0.089 ( 0.093)\tLoss 1.4390e+00 (2.3538e+00)\tAcc@1  61.72 ( 47.25)\tAcc@5  90.62 ( 76.49)\n",
            "Epoch: [21][ 90/391]\tTime  0.092 ( 0.092)\tLoss 1.5539e+00 (2.3273e+00)\tAcc@1  57.81 ( 47.47)\tAcc@5  85.94 ( 76.61)\n",
            "Epoch: [21][120/391]\tTime  0.090 ( 0.092)\tLoss 3.5273e+00 (2.4277e+00)\tAcc@1  36.72 ( 46.14)\tAcc@5  60.94 ( 75.32)\n",
            "Epoch: [21][150/391]\tTime  0.089 ( 0.091)\tLoss 1.5246e+00 (2.4235e+00)\tAcc@1  60.94 ( 46.05)\tAcc@5  86.72 ( 75.09)\n",
            "Epoch: [21][180/391]\tTime  0.087 ( 0.091)\tLoss 3.2167e+00 (2.4023e+00)\tAcc@1  26.56 ( 46.50)\tAcc@5  57.03 ( 75.48)\n",
            "Epoch: [21][210/391]\tTime  0.090 ( 0.091)\tLoss 1.4392e+00 (2.3844e+00)\tAcc@1  57.81 ( 46.65)\tAcc@5  87.50 ( 75.63)\n",
            "Epoch: [21][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5287e+00 (2.4066e+00)\tAcc@1  65.62 ( 45.96)\tAcc@5  87.50 ( 74.95)\n",
            "Epoch: [21][270/391]\tTime  0.090 ( 0.091)\tLoss 1.5874e+00 (2.4046e+00)\tAcc@1  57.03 ( 46.11)\tAcc@5  84.38 ( 74.99)\n",
            "Epoch: [21][300/391]\tTime  0.090 ( 0.091)\tLoss 2.8283e+00 (2.4024e+00)\tAcc@1  50.00 ( 46.03)\tAcc@5  75.78 ( 74.96)\n",
            "Epoch: [21][330/391]\tTime  0.090 ( 0.091)\tLoss 1.7442e+00 (2.4064e+00)\tAcc@1  53.12 ( 45.82)\tAcc@5  82.81 ( 74.69)\n",
            "Epoch: [21][360/391]\tTime  0.089 ( 0.091)\tLoss 1.3525e+00 (2.3952e+00)\tAcc@1  60.94 ( 46.05)\tAcc@5  91.41 ( 74.92)\n",
            "Epoch: [21][390/391]\tTime  0.081 ( 0.091)\tLoss 1.6873e+00 (2.4010e+00)\tAcc@1  55.00 ( 45.80)\tAcc@5  87.50 ( 74.65)\n",
            "==> Train Accuracy: Acc@1 45.800 || Acc@5 74.648\n",
            "==> Test Accuracy:  Acc@1 47.040 || Acc@5 77.700\n",
            "==> 37.95 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 22, lr: 0.1 -----\n",
            "Epoch: [22][  0/391]\tTime  0.242 ( 0.242)\tLoss 1.3131e+00 (1.3131e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [22][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.3212e+00 (2.5073e+00)\tAcc@1  61.72 ( 46.24)\tAcc@5  91.41 ( 74.70)\n",
            "Epoch: [22][ 60/391]\tTime  0.091 ( 0.094)\tLoss 3.1220e+00 (2.5635e+00)\tAcc@1  41.41 ( 44.24)\tAcc@5  68.75 ( 72.98)\n",
            "Epoch: [22][ 90/391]\tTime  0.091 ( 0.093)\tLoss 3.2476e+00 (2.4945e+00)\tAcc@1  28.91 ( 44.54)\tAcc@5  59.38 ( 73.28)\n",
            "Epoch: [22][120/391]\tTime  0.090 ( 0.092)\tLoss 1.6989e+00 (2.4417e+00)\tAcc@1  55.47 ( 45.20)\tAcc@5  84.38 ( 73.90)\n",
            "Epoch: [22][150/391]\tTime  0.090 ( 0.092)\tLoss 1.8449e+00 (2.4118e+00)\tAcc@1  53.91 ( 46.09)\tAcc@5  78.12 ( 74.82)\n",
            "Epoch: [22][180/391]\tTime  0.090 ( 0.092)\tLoss 1.2203e+00 (2.4471e+00)\tAcc@1  67.97 ( 45.45)\tAcc@5  92.97 ( 74.41)\n",
            "Epoch: [22][210/391]\tTime  0.091 ( 0.091)\tLoss 1.5565e+00 (2.4331e+00)\tAcc@1  59.38 ( 45.69)\tAcc@5  83.59 ( 74.48)\n",
            "Epoch: [22][240/391]\tTime  0.090 ( 0.091)\tLoss 3.1695e+00 (2.4385e+00)\tAcc@1  39.84 ( 45.74)\tAcc@5  74.22 ( 74.58)\n",
            "Epoch: [22][270/391]\tTime  0.088 ( 0.091)\tLoss 3.2687e+00 (2.4133e+00)\tAcc@1  20.31 ( 46.22)\tAcc@5  45.31 ( 75.04)\n",
            "Epoch: [22][300/391]\tTime  0.091 ( 0.091)\tLoss 1.2825e+00 (2.4193e+00)\tAcc@1  65.62 ( 46.37)\tAcc@5  89.84 ( 75.10)\n",
            "Epoch: [22][330/391]\tTime  0.091 ( 0.091)\tLoss 2.8137e+00 (2.3978e+00)\tAcc@1  53.91 ( 46.80)\tAcc@5  85.94 ( 75.56)\n",
            "Epoch: [22][360/391]\tTime  0.091 ( 0.091)\tLoss 3.2212e+00 (2.3986e+00)\tAcc@1  39.06 ( 46.71)\tAcc@5  71.88 ( 75.50)\n",
            "Epoch: [22][390/391]\tTime  0.081 ( 0.091)\tLoss 1.4045e+00 (2.3858e+00)\tAcc@1  63.75 ( 46.75)\tAcc@5  88.75 ( 75.55)\n",
            "==> Train Accuracy: Acc@1 46.752 || Acc@5 75.550\n",
            "==> Test Accuracy:  Acc@1 48.170 || Acc@5 78.450\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 23, lr: 0.1 -----\n",
            "Epoch: [23][  0/391]\tTime  0.236 ( 0.236)\tLoss 1.4363e+00 (1.4363e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [23][ 30/391]\tTime  0.091 ( 0.095)\tLoss 3.0923e+00 (2.1587e+00)\tAcc@1  36.72 ( 51.41)\tAcc@5  73.44 ( 79.96)\n",
            "Epoch: [23][ 60/391]\tTime  0.087 ( 0.093)\tLoss 1.5600e+00 (2.2750e+00)\tAcc@1  56.25 ( 47.67)\tAcc@5  86.72 ( 75.56)\n",
            "Epoch: [23][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.0738e+00 (2.2682e+00)\tAcc@1  35.94 ( 48.02)\tAcc@5  74.22 ( 76.12)\n",
            "Epoch: [23][120/391]\tTime  0.090 ( 0.092)\tLoss 3.0179e+00 (2.2961e+00)\tAcc@1  37.50 ( 47.66)\tAcc@5  70.31 ( 76.25)\n",
            "Epoch: [23][150/391]\tTime  0.091 ( 0.091)\tLoss 3.3259e+00 (2.3037e+00)\tAcc@1  27.34 ( 47.53)\tAcc@5  57.03 ( 76.18)\n",
            "Epoch: [23][180/391]\tTime  0.090 ( 0.091)\tLoss 1.3158e+00 (2.2852e+00)\tAcc@1  61.72 ( 47.73)\tAcc@5  89.84 ( 76.39)\n",
            "Epoch: [23][210/391]\tTime  0.090 ( 0.091)\tLoss 1.4042e+00 (2.2936e+00)\tAcc@1  61.72 ( 47.44)\tAcc@5  87.50 ( 76.17)\n",
            "Epoch: [23][240/391]\tTime  0.090 ( 0.091)\tLoss 2.6309e+00 (2.2970e+00)\tAcc@1  57.81 ( 47.83)\tAcc@5  86.72 ( 76.48)\n",
            "Epoch: [23][270/391]\tTime  0.091 ( 0.091)\tLoss 3.3783e+00 (2.2720e+00)\tAcc@1  32.81 ( 48.05)\tAcc@5  61.72 ( 76.66)\n",
            "Epoch: [23][300/391]\tTime  0.090 ( 0.091)\tLoss 3.1514e+00 (2.2838e+00)\tAcc@1  39.84 ( 47.68)\tAcc@5  77.34 ( 76.30)\n",
            "Epoch: [23][330/391]\tTime  0.090 ( 0.091)\tLoss 3.2783e+00 (2.3110e+00)\tAcc@1  32.81 ( 47.24)\tAcc@5  58.59 ( 75.84)\n",
            "Epoch: [23][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4551e+00 (2.3130e+00)\tAcc@1  54.69 ( 47.10)\tAcc@5  90.62 ( 75.68)\n",
            "Epoch: [23][390/391]\tTime  0.082 ( 0.091)\tLoss 3.3318e+00 (2.3226e+00)\tAcc@1  26.25 ( 47.11)\tAcc@5  67.50 ( 75.72)\n",
            "==> Train Accuracy: Acc@1 47.114 || Acc@5 75.716\n",
            "==> Test Accuracy:  Acc@1 43.430 || Acc@5 72.600\n",
            "==> 37.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 24, lr: 0.1 -----\n",
            "Epoch: [24][  0/391]\tTime  0.243 ( 0.243)\tLoss 3.2742e+00 (3.2742e+00)\tAcc@1  29.69 ( 29.69)\tAcc@5  57.81 ( 57.81)\n",
            "Epoch: [24][ 30/391]\tTime  0.091 ( 0.096)\tLoss 3.3330e+00 (2.3182e+00)\tAcc@1  36.72 ( 47.61)\tAcc@5  70.31 ( 76.61)\n",
            "Epoch: [24][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.1358e+00 (2.2952e+00)\tAcc@1  68.75 ( 48.59)\tAcc@5  90.62 ( 76.97)\n",
            "Epoch: [24][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3938e+00 (2.3383e+00)\tAcc@1  64.84 ( 48.69)\tAcc@5  88.28 ( 76.96)\n",
            "Epoch: [24][120/391]\tTime  0.090 ( 0.092)\tLoss 1.4021e+00 (2.3978e+00)\tAcc@1  63.28 ( 47.55)\tAcc@5  89.84 ( 75.76)\n",
            "Epoch: [24][150/391]\tTime  0.090 ( 0.092)\tLoss 1.2308e+00 (2.3654e+00)\tAcc@1  67.97 ( 47.72)\tAcc@5  87.50 ( 76.05)\n",
            "Epoch: [24][180/391]\tTime  0.090 ( 0.091)\tLoss 1.2818e+00 (2.3574e+00)\tAcc@1  67.19 ( 48.01)\tAcc@5  90.62 ( 76.29)\n",
            "Epoch: [24][210/391]\tTime  0.096 ( 0.091)\tLoss 1.4650e+00 (2.3557e+00)\tAcc@1  61.72 ( 47.82)\tAcc@5  88.28 ( 76.28)\n",
            "Epoch: [24][240/391]\tTime  0.089 ( 0.091)\tLoss 1.2785e+00 (2.3242e+00)\tAcc@1  64.84 ( 48.34)\tAcc@5  89.84 ( 76.71)\n",
            "Epoch: [24][270/391]\tTime  0.090 ( 0.091)\tLoss 2.9920e+00 (2.3350e+00)\tAcc@1  39.84 ( 48.13)\tAcc@5  79.69 ( 76.67)\n",
            "Epoch: [24][300/391]\tTime  0.093 ( 0.091)\tLoss 2.7820e+00 (2.3460e+00)\tAcc@1  51.56 ( 47.85)\tAcc@5  86.72 ( 76.48)\n",
            "Epoch: [24][330/391]\tTime  0.089 ( 0.091)\tLoss 1.3081e+00 (2.3480e+00)\tAcc@1  66.41 ( 47.84)\tAcc@5  86.72 ( 76.37)\n",
            "Epoch: [24][360/391]\tTime  0.095 ( 0.091)\tLoss 1.5637e+00 (2.3238e+00)\tAcc@1  53.12 ( 48.09)\tAcc@5  89.84 ( 76.56)\n",
            "Epoch: [24][390/391]\tTime  0.079 ( 0.091)\tLoss 3.3352e+00 (2.3272e+00)\tAcc@1  22.50 ( 48.17)\tAcc@5  47.50 ( 76.69)\n",
            "==> Train Accuracy: Acc@1 48.174 || Acc@5 76.688\n",
            "==> Test Accuracy:  Acc@1 44.470 || Acc@5 74.680\n",
            "==> 37.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 25, lr: 0.1 -----\n",
            "Epoch: [25][  0/391]\tTime  0.241 ( 0.241)\tLoss 1.2517e+00 (1.2517e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [25][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.3461e+00 (2.1480e+00)\tAcc@1  65.62 ( 48.61)\tAcc@5  90.62 ( 77.42)\n",
            "Epoch: [25][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.5094e+00 (2.1438e+00)\tAcc@1  55.47 ( 49.58)\tAcc@5  85.16 ( 77.66)\n",
            "Epoch: [25][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.1881e+00 (2.1973e+00)\tAcc@1  33.59 ( 48.53)\tAcc@5  65.62 ( 77.06)\n",
            "Epoch: [25][120/391]\tTime  0.090 ( 0.092)\tLoss 1.5139e+00 (2.2559e+00)\tAcc@1  55.47 ( 47.68)\tAcc@5  87.50 ( 76.43)\n",
            "Epoch: [25][150/391]\tTime  0.090 ( 0.091)\tLoss 1.3496e+00 (2.2827e+00)\tAcc@1  65.62 ( 47.69)\tAcc@5  89.84 ( 76.15)\n",
            "Epoch: [25][180/391]\tTime  0.090 ( 0.091)\tLoss 1.4730e+00 (2.3035e+00)\tAcc@1  61.72 ( 47.49)\tAcc@5  86.72 ( 75.92)\n",
            "Epoch: [25][210/391]\tTime  0.090 ( 0.091)\tLoss 2.4838e+00 (2.2694e+00)\tAcc@1  60.94 ( 48.30)\tAcc@5  91.41 ( 76.60)\n",
            "Epoch: [25][240/391]\tTime  0.087 ( 0.091)\tLoss 1.6728e+00 (2.2821e+00)\tAcc@1  53.12 ( 48.08)\tAcc@5  86.72 ( 76.33)\n",
            "Epoch: [25][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3556e+00 (2.2554e+00)\tAcc@1  62.50 ( 48.59)\tAcc@5  88.28 ( 76.85)\n",
            "Epoch: [25][300/391]\tTime  0.092 ( 0.091)\tLoss 1.5319e+00 (2.2402e+00)\tAcc@1  60.16 ( 48.81)\tAcc@5  83.59 ( 77.07)\n",
            "Epoch: [25][330/391]\tTime  0.092 ( 0.091)\tLoss 3.2199e+00 (2.2513e+00)\tAcc@1  28.12 ( 48.58)\tAcc@5  62.50 ( 76.78)\n",
            "Epoch: [25][360/391]\tTime  0.095 ( 0.091)\tLoss 1.2804e+00 (2.2559e+00)\tAcc@1  64.84 ( 48.50)\tAcc@5  89.06 ( 76.65)\n",
            "Epoch: [25][390/391]\tTime  0.081 ( 0.091)\tLoss 1.1737e+00 (2.2821e+00)\tAcc@1  62.50 ( 48.00)\tAcc@5  93.75 ( 76.28)\n",
            "==> Train Accuracy: Acc@1 47.998 || Acc@5 76.282\n",
            "==> Test Accuracy:  Acc@1 50.150 || Acc@5 79.950\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 26, lr: 0.1 -----\n",
            "Epoch: [26][  0/391]\tTime  0.232 ( 0.232)\tLoss 1.3497e+00 (1.3497e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [26][ 30/391]\tTime  0.091 ( 0.095)\tLoss 3.2392e+00 (2.0013e+00)\tAcc@1  35.94 ( 54.99)\tAcc@5  71.09 ( 82.33)\n",
            "Epoch: [26][ 60/391]\tTime  0.090 ( 0.093)\tLoss 3.1940e+00 (2.2121e+00)\tAcc@1  42.97 ( 51.29)\tAcc@5  79.69 ( 79.37)\n",
            "Epoch: [26][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.0810e+00 (2.2254e+00)\tAcc@1  47.66 ( 50.34)\tAcc@5  80.47 ( 78.60)\n",
            "Epoch: [26][120/391]\tTime  0.092 ( 0.092)\tLoss 3.5118e+00 (2.2693e+00)\tAcc@1  29.69 ( 49.43)\tAcc@5  51.56 ( 77.58)\n",
            "Epoch: [26][150/391]\tTime  0.090 ( 0.091)\tLoss 1.3358e+00 (2.2889e+00)\tAcc@1  62.50 ( 49.00)\tAcc@5  91.41 ( 77.34)\n",
            "Epoch: [26][180/391]\tTime  0.089 ( 0.091)\tLoss 1.5401e+00 (2.2850e+00)\tAcc@1  53.91 ( 49.18)\tAcc@5  87.50 ( 77.56)\n",
            "Epoch: [26][210/391]\tTime  0.089 ( 0.091)\tLoss 2.6693e+00 (2.2908e+00)\tAcc@1  59.38 ( 48.87)\tAcc@5  83.59 ( 77.15)\n",
            "Epoch: [26][240/391]\tTime  0.091 ( 0.091)\tLoss 3.2043e+00 (2.2962e+00)\tAcc@1  15.62 ( 48.67)\tAcc@5  52.34 ( 76.93)\n",
            "Epoch: [26][270/391]\tTime  0.090 ( 0.091)\tLoss 1.4678e+00 (2.3199e+00)\tAcc@1  60.94 ( 48.55)\tAcc@5  86.72 ( 76.75)\n",
            "Epoch: [26][300/391]\tTime  0.090 ( 0.091)\tLoss 1.5798e+00 (2.3316e+00)\tAcc@1  56.25 ( 48.25)\tAcc@5  88.28 ( 76.51)\n",
            "Epoch: [26][330/391]\tTime  0.090 ( 0.091)\tLoss 1.2501e+00 (2.3388e+00)\tAcc@1  64.84 ( 48.15)\tAcc@5  89.06 ( 76.52)\n",
            "Epoch: [26][360/391]\tTime  0.090 ( 0.091)\tLoss 1.2793e+00 (2.3398e+00)\tAcc@1  68.75 ( 47.89)\tAcc@5  89.06 ( 76.29)\n",
            "Epoch: [26][390/391]\tTime  0.082 ( 0.091)\tLoss 3.2201e+00 (2.3235e+00)\tAcc@1  47.50 ( 48.11)\tAcc@5  71.25 ( 76.58)\n",
            "==> Train Accuracy: Acc@1 48.110 || Acc@5 76.580\n",
            "==> Test Accuracy:  Acc@1 46.140 || Acc@5 75.430\n",
            "==> 37.92 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 27, lr: 0.1 -----\n",
            "Epoch: [27][  0/391]\tTime  0.244 ( 0.244)\tLoss 3.1348e+00 (3.1348e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  64.06 ( 64.06)\n",
            "Epoch: [27][ 30/391]\tTime  0.091 ( 0.095)\tLoss 3.0194e+00 (2.5842e+00)\tAcc@1  35.94 ( 44.30)\tAcc@5  67.19 ( 71.95)\n",
            "Epoch: [27][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.8503e+00 (2.5408e+00)\tAcc@1  50.78 ( 44.17)\tAcc@5  84.38 ( 72.87)\n",
            "Epoch: [27][ 90/391]\tTime  0.099 ( 0.092)\tLoss 3.1148e+00 (2.4501e+00)\tAcc@1  25.78 ( 45.59)\tAcc@5  55.47 ( 73.75)\n",
            "Epoch: [27][120/391]\tTime  0.091 ( 0.092)\tLoss 1.3786e+00 (2.4190e+00)\tAcc@1  63.28 ( 45.79)\tAcc@5  85.94 ( 73.86)\n",
            "Epoch: [27][150/391]\tTime  0.090 ( 0.092)\tLoss 1.4451e+00 (2.3971e+00)\tAcc@1  60.94 ( 45.88)\tAcc@5  90.62 ( 74.47)\n",
            "Epoch: [27][180/391]\tTime  0.096 ( 0.091)\tLoss 3.1858e+00 (2.3720e+00)\tAcc@1  20.31 ( 46.23)\tAcc@5  53.12 ( 74.78)\n",
            "Epoch: [27][210/391]\tTime  0.091 ( 0.091)\tLoss 3.3575e+00 (2.4125e+00)\tAcc@1  16.41 ( 45.57)\tAcc@5  41.41 ( 74.20)\n",
            "Epoch: [27][240/391]\tTime  0.090 ( 0.091)\tLoss 1.3691e+00 (2.3917e+00)\tAcc@1  60.94 ( 46.00)\tAcc@5  85.94 ( 74.57)\n",
            "Epoch: [27][270/391]\tTime  0.091 ( 0.091)\tLoss 3.3041e+00 (2.3612e+00)\tAcc@1  38.28 ( 46.49)\tAcc@5  65.62 ( 75.01)\n",
            "Epoch: [27][300/391]\tTime  0.090 ( 0.091)\tLoss 3.0603e+00 (2.3782e+00)\tAcc@1  36.72 ( 46.11)\tAcc@5  71.09 ( 74.80)\n",
            "Epoch: [27][330/391]\tTime  0.091 ( 0.091)\tLoss 2.9917e+00 (2.3608e+00)\tAcc@1  42.97 ( 46.33)\tAcc@5  75.00 ( 75.06)\n",
            "Epoch: [27][360/391]\tTime  0.091 ( 0.091)\tLoss 3.2330e+00 (2.3645e+00)\tAcc@1  21.09 ( 46.13)\tAcc@5  47.66 ( 74.84)\n",
            "Epoch: [27][390/391]\tTime  0.081 ( 0.091)\tLoss 1.3670e+00 (2.3508e+00)\tAcc@1  66.25 ( 46.56)\tAcc@5  92.50 ( 75.17)\n",
            "==> Train Accuracy: Acc@1 46.558 || Acc@5 75.168\n",
            "==> Test Accuracy:  Acc@1 55.720 || Acc@5 84.050\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 28, lr: 0.1 -----\n",
            "Epoch: [28][  0/391]\tTime  0.249 ( 0.249)\tLoss 1.4255e+00 (1.4255e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [28][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.3165e+00 (2.1342e+00)\tAcc@1  64.84 ( 49.75)\tAcc@5  85.94 ( 77.80)\n",
            "Epoch: [28][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.3121e+00 (2.2344e+00)\tAcc@1  28.91 ( 49.91)\tAcc@5  61.72 ( 77.97)\n",
            "Epoch: [28][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.7976e+00 (2.1482e+00)\tAcc@1  53.12 ( 51.45)\tAcc@5  80.47 ( 79.34)\n",
            "Epoch: [28][120/391]\tTime  0.091 ( 0.092)\tLoss 2.9621e+00 (2.2325e+00)\tAcc@1  41.41 ( 50.10)\tAcc@5  74.22 ( 77.95)\n",
            "Epoch: [28][150/391]\tTime  0.090 ( 0.092)\tLoss 1.5794e+00 (2.2350e+00)\tAcc@1  53.91 ( 49.58)\tAcc@5  89.06 ( 77.71)\n",
            "Epoch: [28][180/391]\tTime  0.090 ( 0.091)\tLoss 1.3042e+00 (2.2301e+00)\tAcc@1  57.81 ( 50.10)\tAcc@5  89.84 ( 78.22)\n",
            "Epoch: [28][210/391]\tTime  0.090 ( 0.091)\tLoss 1.4738e+00 (2.2473e+00)\tAcc@1  60.94 ( 49.70)\tAcc@5  87.50 ( 77.90)\n",
            "Epoch: [28][240/391]\tTime  0.090 ( 0.091)\tLoss 3.3366e+00 (2.2641e+00)\tAcc@1  32.81 ( 49.13)\tAcc@5  60.94 ( 77.36)\n",
            "Epoch: [28][270/391]\tTime  0.090 ( 0.091)\tLoss 2.9461e+00 (2.2588e+00)\tAcc@1  50.00 ( 49.47)\tAcc@5  80.47 ( 77.49)\n",
            "Epoch: [28][300/391]\tTime  0.091 ( 0.091)\tLoss 3.4142e+00 (2.2693e+00)\tAcc@1  15.62 ( 49.36)\tAcc@5  39.84 ( 77.30)\n",
            "Epoch: [28][330/391]\tTime  0.090 ( 0.091)\tLoss 1.3878e+00 (2.2438e+00)\tAcc@1  60.94 ( 49.63)\tAcc@5  85.94 ( 77.47)\n",
            "Epoch: [28][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4929e+00 (2.2611e+00)\tAcc@1  58.59 ( 49.27)\tAcc@5  89.06 ( 77.16)\n",
            "Epoch: [28][390/391]\tTime  0.081 ( 0.091)\tLoss 1.1392e+00 (2.2692e+00)\tAcc@1  75.00 ( 49.00)\tAcc@5  92.50 ( 76.94)\n",
            "==> Train Accuracy: Acc@1 48.996 || Acc@5 76.942\n",
            "==> Test Accuracy:  Acc@1 55.780 || Acc@5 84.260\n",
            "==> 37.92 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 29, lr: 0.1 -----\n",
            "Epoch: [29][  0/391]\tTime  0.253 ( 0.253)\tLoss 3.3652e+00 (3.3652e+00)\tAcc@1  23.44 ( 23.44)\tAcc@5  60.16 ( 60.16)\n",
            "Epoch: [29][ 30/391]\tTime  0.092 ( 0.096)\tLoss 1.4373e+00 (2.3509e+00)\tAcc@1  60.16 ( 47.20)\tAcc@5  92.19 ( 75.83)\n",
            "Epoch: [29][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.2486e+00 (2.2364e+00)\tAcc@1  65.62 ( 49.18)\tAcc@5  90.62 ( 77.45)\n",
            "Epoch: [29][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.2771e+00 (2.3192e+00)\tAcc@1  35.16 ( 48.29)\tAcc@5  67.19 ( 76.18)\n",
            "Epoch: [29][120/391]\tTime  0.090 ( 0.092)\tLoss 1.4725e+00 (2.3388e+00)\tAcc@1  58.59 ( 47.99)\tAcc@5  86.72 ( 75.76)\n",
            "Epoch: [29][150/391]\tTime  0.086 ( 0.092)\tLoss 1.4128e+00 (2.3366e+00)\tAcc@1  57.03 ( 47.49)\tAcc@5  89.84 ( 75.45)\n",
            "Epoch: [29][180/391]\tTime  0.090 ( 0.091)\tLoss 3.1568e+00 (2.2735e+00)\tAcc@1  29.69 ( 48.42)\tAcc@5  66.41 ( 76.39)\n",
            "Epoch: [29][210/391]\tTime  0.089 ( 0.091)\tLoss 1.4920e+00 (2.2299e+00)\tAcc@1  60.94 ( 49.12)\tAcc@5  85.16 ( 77.00)\n",
            "Epoch: [29][240/391]\tTime  0.086 ( 0.091)\tLoss 3.1536e+00 (2.2803e+00)\tAcc@1  40.62 ( 48.32)\tAcc@5  69.53 ( 76.28)\n",
            "Epoch: [29][270/391]\tTime  0.092 ( 0.091)\tLoss 3.2103e+00 (2.2899e+00)\tAcc@1  45.31 ( 48.26)\tAcc@5  67.19 ( 76.10)\n",
            "Epoch: [29][300/391]\tTime  0.090 ( 0.091)\tLoss 2.9478e+00 (2.3217e+00)\tAcc@1  43.75 ( 47.97)\tAcc@5  80.47 ( 75.90)\n",
            "Epoch: [29][330/391]\tTime  0.090 ( 0.091)\tLoss 1.4625e+00 (2.3105e+00)\tAcc@1  57.81 ( 48.08)\tAcc@5  88.28 ( 76.09)\n",
            "Epoch: [29][360/391]\tTime  0.091 ( 0.091)\tLoss 1.4933e+00 (2.2915e+00)\tAcc@1  60.16 ( 48.35)\tAcc@5  88.28 ( 76.38)\n",
            "Epoch: [29][390/391]\tTime  0.081 ( 0.091)\tLoss 1.4202e+00 (2.3033e+00)\tAcc@1  65.00 ( 48.27)\tAcc@5  88.75 ( 76.33)\n",
            "==> Train Accuracy: Acc@1 48.270 || Acc@5 76.328\n",
            "==> Test Accuracy:  Acc@1 51.710 || Acc@5 81.570\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 30, lr: 0.1 -----\n",
            "Epoch: [30][  0/391]\tTime  0.237 ( 0.237)\tLoss 1.3698e+00 (1.3698e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [30][ 30/391]\tTime  0.091 ( 0.096)\tLoss 3.0536e+00 (1.9542e+00)\tAcc@1  39.84 ( 53.18)\tAcc@5  73.44 ( 80.27)\n",
            "Epoch: [30][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.1886e+00 (2.0347e+00)\tAcc@1  66.41 ( 51.90)\tAcc@5  90.62 ( 79.53)\n",
            "Epoch: [30][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.2992e+00 (2.1323e+00)\tAcc@1  21.88 ( 50.09)\tAcc@5  53.91 ( 78.24)\n",
            "Epoch: [30][120/391]\tTime  0.091 ( 0.092)\tLoss 3.1418e+00 (2.2579e+00)\tAcc@1  42.97 ( 47.91)\tAcc@5  78.91 ( 76.15)\n",
            "Epoch: [30][150/391]\tTime  0.090 ( 0.092)\tLoss 1.1341e+00 (2.2021e+00)\tAcc@1  67.97 ( 49.65)\tAcc@5  93.75 ( 77.67)\n",
            "Epoch: [30][180/391]\tTime  0.091 ( 0.091)\tLoss 3.2113e+00 (2.1912e+00)\tAcc@1  42.97 ( 50.31)\tAcc@5  74.22 ( 78.21)\n",
            "Epoch: [30][210/391]\tTime  0.091 ( 0.091)\tLoss 3.3171e+00 (2.1755e+00)\tAcc@1  31.25 ( 50.72)\tAcc@5  54.69 ( 78.41)\n",
            "Epoch: [30][240/391]\tTime  0.090 ( 0.091)\tLoss 3.1104e+00 (2.2036e+00)\tAcc@1  35.94 ( 50.30)\tAcc@5  67.19 ( 78.09)\n",
            "Epoch: [30][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3458e+00 (2.1904e+00)\tAcc@1  61.72 ( 50.37)\tAcc@5  91.41 ( 78.16)\n",
            "Epoch: [30][300/391]\tTime  0.090 ( 0.091)\tLoss 1.4376e+00 (2.2050e+00)\tAcc@1  62.50 ( 50.18)\tAcc@5  87.50 ( 77.98)\n",
            "Epoch: [30][330/391]\tTime  0.090 ( 0.091)\tLoss 1.3696e+00 (2.2201e+00)\tAcc@1  58.59 ( 49.85)\tAcc@5  92.19 ( 77.73)\n",
            "Epoch: [30][360/391]\tTime  0.090 ( 0.091)\tLoss 1.3400e+00 (2.2401e+00)\tAcc@1  66.41 ( 49.49)\tAcc@5  90.62 ( 77.51)\n",
            "Epoch: [30][390/391]\tTime  0.082 ( 0.091)\tLoss 3.3560e+00 (2.2249e+00)\tAcc@1  26.25 ( 49.85)\tAcc@5  61.25 ( 77.84)\n",
            "==> Train Accuracy: Acc@1 49.848 || Acc@5 77.838\n",
            "==> Test Accuracy:  Acc@1 54.550 || Acc@5 83.760\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 31, lr: 0.1 -----\n",
            "Epoch: [31][  0/391]\tTime  0.239 ( 0.239)\tLoss 1.1601e+00 (1.1601e+00)\tAcc@1  71.09 ( 71.09)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [31][ 30/391]\tTime  0.090 ( 0.096)\tLoss 3.3395e+00 (2.2802e+00)\tAcc@1  19.53 ( 47.98)\tAcc@5  46.88 ( 75.86)\n",
            "Epoch: [31][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.0256e+00 (2.3111e+00)\tAcc@1  32.81 ( 47.96)\tAcc@5  62.50 ( 75.97)\n",
            "Epoch: [31][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.1472e+00 (2.4056e+00)\tAcc@1  22.66 ( 46.34)\tAcc@5  52.34 ( 74.18)\n",
            "Epoch: [31][120/391]\tTime  0.091 ( 0.092)\tLoss 3.4937e+00 (2.2583e+00)\tAcc@1  30.47 ( 48.74)\tAcc@5  60.94 ( 76.82)\n",
            "Epoch: [31][150/391]\tTime  0.090 ( 0.091)\tLoss 1.2069e+00 (2.2574e+00)\tAcc@1  65.62 ( 49.19)\tAcc@5  92.19 ( 77.26)\n",
            "Epoch: [31][180/391]\tTime  0.090 ( 0.091)\tLoss 1.1408e+00 (2.2103e+00)\tAcc@1  65.62 ( 49.67)\tAcc@5  89.84 ( 77.71)\n",
            "Epoch: [31][210/391]\tTime  0.090 ( 0.091)\tLoss 1.3249e+00 (2.2259e+00)\tAcc@1  64.84 ( 49.51)\tAcc@5  91.41 ( 77.61)\n",
            "Epoch: [31][240/391]\tTime  0.090 ( 0.091)\tLoss 1.2921e+00 (2.2286e+00)\tAcc@1  66.41 ( 50.00)\tAcc@5  88.28 ( 78.03)\n",
            "Epoch: [31][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3350e+00 (2.2080e+00)\tAcc@1  63.28 ( 50.33)\tAcc@5  90.62 ( 78.27)\n",
            "Epoch: [31][300/391]\tTime  0.091 ( 0.091)\tLoss 3.2696e+00 (2.1981e+00)\tAcc@1  45.31 ( 50.42)\tAcc@5  77.34 ( 78.34)\n",
            "Epoch: [31][330/391]\tTime  0.091 ( 0.091)\tLoss 3.3433e+00 (2.2009e+00)\tAcc@1  21.88 ( 50.29)\tAcc@5  56.25 ( 78.17)\n",
            "Epoch: [31][360/391]\tTime  0.090 ( 0.091)\tLoss 1.2654e+00 (2.1821e+00)\tAcc@1  64.06 ( 50.51)\tAcc@5  89.84 ( 78.39)\n",
            "Epoch: [31][390/391]\tTime  0.081 ( 0.091)\tLoss 1.2998e+00 (2.1744e+00)\tAcc@1  68.75 ( 50.68)\tAcc@5  88.75 ( 78.49)\n",
            "==> Train Accuracy: Acc@1 50.684 || Acc@5 78.486\n",
            "==> Test Accuracy:  Acc@1 53.380 || Acc@5 82.700\n",
            "==> 37.94 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 32, lr: 0.1 -----\n",
            "Epoch: [32][  0/391]\tTime  0.227 ( 0.227)\tLoss 1.3344e+00 (1.3344e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [32][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.2701e+00 (2.2717e+00)\tAcc@1  70.31 ( 47.98)\tAcc@5  86.72 ( 75.50)\n",
            "Epoch: [32][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.4407e+00 (2.3306e+00)\tAcc@1  29.69 ( 46.70)\tAcc@5  61.72 ( 74.88)\n",
            "Epoch: [32][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.9275e+00 (2.1827e+00)\tAcc@1  49.22 ( 49.43)\tAcc@5  82.03 ( 77.20)\n",
            "Epoch: [32][120/391]\tTime  0.090 ( 0.091)\tLoss 1.2916e+00 (2.1557e+00)\tAcc@1  64.84 ( 50.12)\tAcc@5  85.94 ( 77.98)\n",
            "Epoch: [32][150/391]\tTime  0.092 ( 0.091)\tLoss 1.3834e+00 (2.1559e+00)\tAcc@1  59.38 ( 50.59)\tAcc@5  89.06 ( 78.48)\n",
            "Epoch: [32][180/391]\tTime  0.091 ( 0.091)\tLoss 3.0594e+00 (2.1918e+00)\tAcc@1  42.97 ( 50.00)\tAcc@5  72.66 ( 77.77)\n",
            "Epoch: [32][210/391]\tTime  0.090 ( 0.091)\tLoss 3.0801e+00 (2.1950e+00)\tAcc@1  26.56 ( 50.01)\tAcc@5  57.81 ( 77.85)\n",
            "Epoch: [32][240/391]\tTime  0.091 ( 0.091)\tLoss 3.2652e+00 (2.1947e+00)\tAcc@1  36.72 ( 49.61)\tAcc@5  62.50 ( 77.45)\n",
            "Epoch: [32][270/391]\tTime  0.090 ( 0.091)\tLoss 1.4049e+00 (2.1795e+00)\tAcc@1  62.50 ( 49.90)\tAcc@5  90.62 ( 77.73)\n",
            "Epoch: [32][300/391]\tTime  0.090 ( 0.091)\tLoss 1.3765e+00 (2.1860e+00)\tAcc@1  62.50 ( 49.69)\tAcc@5  87.50 ( 77.65)\n",
            "Epoch: [32][330/391]\tTime  0.090 ( 0.091)\tLoss 1.4088e+00 (2.1991e+00)\tAcc@1  64.06 ( 49.44)\tAcc@5  84.38 ( 77.37)\n",
            "Epoch: [32][360/391]\tTime  0.091 ( 0.091)\tLoss 1.2652e+00 (2.1960e+00)\tAcc@1  68.75 ( 49.50)\tAcc@5  89.84 ( 77.46)\n",
            "Epoch: [32][390/391]\tTime  0.082 ( 0.091)\tLoss 1.4398e+00 (2.2103e+00)\tAcc@1  62.50 ( 49.34)\tAcc@5  86.25 ( 77.39)\n",
            "==> Train Accuracy: Acc@1 49.342 || Acc@5 77.388\n",
            "==> Test Accuracy:  Acc@1 52.420 || Acc@5 82.630\n",
            "==> 37.92 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 33, lr: 0.1 -----\n",
            "Epoch: [33][  0/391]\tTime  0.234 ( 0.234)\tLoss 1.1737e+00 (1.1737e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [33][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.4341e+00 (2.0083e+00)\tAcc@1  61.72 ( 55.19)\tAcc@5  88.28 ( 81.70)\n",
            "Epoch: [33][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.2639e+00 (1.9553e+00)\tAcc@1  68.75 ( 55.39)\tAcc@5  92.19 ( 82.47)\n",
            "Epoch: [33][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.2761e+00 (2.1312e+00)\tAcc@1  64.84 ( 51.38)\tAcc@5  92.19 ( 78.98)\n",
            "Epoch: [33][120/391]\tTime  0.095 ( 0.092)\tLoss 2.9402e+00 (2.1273e+00)\tAcc@1  47.66 ( 51.81)\tAcc@5  80.47 ( 79.41)\n",
            "Epoch: [33][150/391]\tTime  0.090 ( 0.091)\tLoss 1.2578e+00 (2.1157e+00)\tAcc@1  70.31 ( 52.09)\tAcc@5  92.97 ( 79.70)\n",
            "Epoch: [33][180/391]\tTime  0.090 ( 0.091)\tLoss 1.2881e+00 (2.1113e+00)\tAcc@1  64.06 ( 52.34)\tAcc@5  92.19 ( 79.89)\n",
            "Epoch: [33][210/391]\tTime  0.091 ( 0.091)\tLoss 1.3945e+00 (2.1336e+00)\tAcc@1  64.84 ( 51.58)\tAcc@5  89.06 ( 79.18)\n",
            "Epoch: [33][240/391]\tTime  0.091 ( 0.091)\tLoss 1.1956e+00 (2.1274e+00)\tAcc@1  64.06 ( 51.56)\tAcc@5  89.84 ( 79.31)\n",
            "Epoch: [33][270/391]\tTime  0.091 ( 0.091)\tLoss 3.1819e+00 (2.1218e+00)\tAcc@1  29.69 ( 51.71)\tAcc@5  59.38 ( 79.50)\n",
            "Epoch: [33][300/391]\tTime  0.091 ( 0.091)\tLoss 3.0568e+00 (2.1691e+00)\tAcc@1  42.19 ( 50.85)\tAcc@5  71.88 ( 78.73)\n",
            "Epoch: [33][330/391]\tTime  0.090 ( 0.091)\tLoss 2.9869e+00 (2.1552e+00)\tAcc@1  41.41 ( 51.01)\tAcc@5  71.88 ( 78.89)\n",
            "Epoch: [33][360/391]\tTime  0.091 ( 0.091)\tLoss 3.0984e+00 (2.1659e+00)\tAcc@1  29.69 ( 50.88)\tAcc@5  59.38 ( 78.68)\n",
            "Epoch: [33][390/391]\tTime  0.081 ( 0.091)\tLoss 1.1914e+00 (2.1565e+00)\tAcc@1  70.00 ( 50.97)\tAcc@5  92.50 ( 78.71)\n",
            "==> Train Accuracy: Acc@1 50.968 || Acc@5 78.710\n",
            "==> Test Accuracy:  Acc@1 51.740 || Acc@5 81.080\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 34, lr: 0.1 -----\n",
            "Epoch: [34][  0/391]\tTime  0.251 ( 0.251)\tLoss 2.8999e+00 (2.8999e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  82.03 ( 82.03)\n",
            "Epoch: [34][ 30/391]\tTime  0.091 ( 0.096)\tLoss 3.1819e+00 (2.2617e+00)\tAcc@1  20.31 ( 49.65)\tAcc@5  56.25 ( 76.94)\n",
            "Epoch: [34][ 60/391]\tTime  0.087 ( 0.093)\tLoss 1.0438e+00 (2.1530e+00)\tAcc@1  73.44 ( 50.78)\tAcc@5  90.62 ( 78.32)\n",
            "Epoch: [34][ 90/391]\tTime  0.091 ( 0.092)\tLoss 3.4443e+00 (2.1143e+00)\tAcc@1  11.72 ( 51.61)\tAcc@5  40.62 ( 79.15)\n",
            "Epoch: [34][120/391]\tTime  0.090 ( 0.092)\tLoss 1.2031e+00 (2.1128e+00)\tAcc@1  65.62 ( 51.61)\tAcc@5  92.19 ( 79.04)\n",
            "Epoch: [34][150/391]\tTime  0.089 ( 0.091)\tLoss 1.5622e+00 (2.1001e+00)\tAcc@1  54.69 ( 51.58)\tAcc@5  89.06 ( 78.98)\n",
            "Epoch: [34][180/391]\tTime  0.091 ( 0.091)\tLoss 2.9315e+00 (2.1427e+00)\tAcc@1  47.66 ( 51.09)\tAcc@5  80.47 ( 78.42)\n",
            "Epoch: [34][210/391]\tTime  0.089 ( 0.091)\tLoss 1.4778e+00 (2.1700e+00)\tAcc@1  60.16 ( 50.67)\tAcc@5  89.06 ( 78.18)\n",
            "Epoch: [34][240/391]\tTime  0.091 ( 0.091)\tLoss 1.2520e+00 (2.1552e+00)\tAcc@1  63.28 ( 50.83)\tAcc@5  89.84 ( 78.40)\n",
            "Epoch: [34][270/391]\tTime  0.090 ( 0.091)\tLoss 1.4290e+00 (2.1567e+00)\tAcc@1  64.06 ( 50.88)\tAcc@5  87.50 ( 78.38)\n",
            "Epoch: [34][300/391]\tTime  0.093 ( 0.091)\tLoss 1.4776e+00 (2.1588e+00)\tAcc@1  60.16 ( 50.89)\tAcc@5  87.50 ( 78.38)\n",
            "Epoch: [34][330/391]\tTime  0.088 ( 0.091)\tLoss 1.4545e+00 (2.1515e+00)\tAcc@1  63.28 ( 50.80)\tAcc@5  85.16 ( 78.34)\n",
            "Epoch: [34][360/391]\tTime  0.090 ( 0.091)\tLoss 3.3054e+00 (2.1635e+00)\tAcc@1  36.72 ( 50.65)\tAcc@5  66.41 ( 78.31)\n",
            "Epoch: [34][390/391]\tTime  0.082 ( 0.091)\tLoss 3.2643e+00 (2.1626e+00)\tAcc@1  43.75 ( 50.61)\tAcc@5  72.50 ( 78.31)\n",
            "==> Train Accuracy: Acc@1 50.610 || Acc@5 78.308\n",
            "==> Test Accuracy:  Acc@1 53.010 || Acc@5 81.530\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 35, lr: 0.1 -----\n",
            "Epoch: [35][  0/391]\tTime  0.253 ( 0.253)\tLoss 3.4297e+00 (3.4297e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  40.62 ( 40.62)\n",
            "Epoch: [35][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.3014e+00 (1.8258e+00)\tAcc@1  60.16 ( 56.58)\tAcc@5  89.84 ( 82.96)\n",
            "Epoch: [35][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.9447e+00 (2.0645e+00)\tAcc@1  48.44 ( 52.95)\tAcc@5  72.66 ( 80.14)\n",
            "Epoch: [35][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.6606e+00 (2.1671e+00)\tAcc@1  50.78 ( 50.88)\tAcc@5  88.28 ( 78.39)\n",
            "Epoch: [35][120/391]\tTime  0.090 ( 0.092)\tLoss 1.2410e+00 (2.1423e+00)\tAcc@1  67.97 ( 51.76)\tAcc@5  89.84 ( 79.15)\n",
            "Epoch: [35][150/391]\tTime  0.088 ( 0.092)\tLoss 1.4286e+00 (2.1696e+00)\tAcc@1  61.72 ( 51.37)\tAcc@5  85.94 ( 78.94)\n",
            "Epoch: [35][180/391]\tTime  0.091 ( 0.091)\tLoss 3.3491e+00 (2.1640e+00)\tAcc@1  18.75 ( 51.38)\tAcc@5  46.88 ( 78.96)\n",
            "Epoch: [35][210/391]\tTime  0.090 ( 0.091)\tLoss 1.1246e+00 (2.1510e+00)\tAcc@1  64.06 ( 51.83)\tAcc@5  92.19 ( 79.29)\n",
            "Epoch: [35][240/391]\tTime  0.090 ( 0.091)\tLoss 1.3478e+00 (2.1386e+00)\tAcc@1  67.19 ( 51.99)\tAcc@5  89.06 ( 79.53)\n",
            "Epoch: [35][270/391]\tTime  0.091 ( 0.091)\tLoss 3.2872e+00 (2.1756e+00)\tAcc@1  17.97 ( 50.98)\tAcc@5  46.09 ( 78.66)\n",
            "Epoch: [35][300/391]\tTime  0.095 ( 0.091)\tLoss 3.2689e+00 (2.2093e+00)\tAcc@1  26.56 ( 50.33)\tAcc@5  57.81 ( 78.05)\n",
            "Epoch: [35][330/391]\tTime  0.091 ( 0.091)\tLoss 3.2981e+00 (2.2162e+00)\tAcc@1  23.44 ( 50.43)\tAcc@5  54.69 ( 78.17)\n",
            "Epoch: [35][360/391]\tTime  0.091 ( 0.091)\tLoss 3.1458e+00 (2.2290e+00)\tAcc@1  38.28 ( 50.14)\tAcc@5  73.44 ( 78.00)\n",
            "Epoch: [35][390/391]\tTime  0.082 ( 0.091)\tLoss 3.1282e+00 (2.2423e+00)\tAcc@1  26.25 ( 49.67)\tAcc@5  58.75 ( 77.69)\n",
            "==> Train Accuracy: Acc@1 49.674 || Acc@5 77.692\n",
            "==> Test Accuracy:  Acc@1 56.540 || Acc@5 84.120\n",
            "==> 37.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 36, lr: 0.1 -----\n",
            "Epoch: [36][  0/391]\tTime  0.235 ( 0.235)\tLoss 9.5435e-01 (9.5435e-01)\tAcc@1  75.00 ( 75.00)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [36][ 30/391]\tTime  0.094 ( 0.096)\tLoss 2.7356e+00 (2.2406e+00)\tAcc@1  46.88 ( 49.87)\tAcc@5  72.66 ( 78.12)\n",
            "Epoch: [36][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.1494e+00 (2.2198e+00)\tAcc@1  33.59 ( 50.76)\tAcc@5  60.94 ( 79.10)\n",
            "Epoch: [36][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.1147e+00 (2.2198e+00)\tAcc@1  71.88 ( 50.82)\tAcc@5  90.62 ( 78.91)\n",
            "Epoch: [36][120/391]\tTime  0.091 ( 0.092)\tLoss 3.1941e+00 (2.2192e+00)\tAcc@1  34.38 ( 51.45)\tAcc@5  60.16 ( 78.85)\n",
            "Epoch: [36][150/391]\tTime  0.090 ( 0.092)\tLoss 3.2313e+00 (2.2571e+00)\tAcc@1  31.25 ( 50.24)\tAcc@5  60.94 ( 77.72)\n",
            "Epoch: [36][180/391]\tTime  0.090 ( 0.091)\tLoss 1.2715e+00 (2.2517e+00)\tAcc@1  67.97 ( 50.46)\tAcc@5  90.62 ( 77.94)\n",
            "Epoch: [36][210/391]\tTime  0.090 ( 0.091)\tLoss 3.3983e+00 (2.2460e+00)\tAcc@1  25.78 ( 50.17)\tAcc@5  58.59 ( 77.48)\n",
            "Epoch: [36][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1511e+00 (2.2316e+00)\tAcc@1  71.88 ( 50.35)\tAcc@5  90.62 ( 77.69)\n",
            "Epoch: [36][270/391]\tTime  0.090 ( 0.091)\tLoss 1.2728e+00 (2.2119e+00)\tAcc@1  64.84 ( 50.73)\tAcc@5  89.06 ( 78.18)\n",
            "Epoch: [36][300/391]\tTime  0.091 ( 0.091)\tLoss 3.0687e+00 (2.2345e+00)\tAcc@1  37.50 ( 50.28)\tAcc@5  69.53 ( 77.74)\n",
            "Epoch: [36][330/391]\tTime  0.090 ( 0.091)\tLoss 1.2918e+00 (2.2511e+00)\tAcc@1  69.53 ( 50.10)\tAcc@5  88.28 ( 77.54)\n",
            "Epoch: [36][360/391]\tTime  0.095 ( 0.091)\tLoss 1.2402e+00 (2.2573e+00)\tAcc@1  67.97 ( 49.92)\tAcc@5  88.28 ( 77.28)\n",
            "Epoch: [36][390/391]\tTime  0.082 ( 0.091)\tLoss 3.3129e+00 (2.2498e+00)\tAcc@1  17.50 ( 49.87)\tAcc@5  46.25 ( 77.21)\n",
            "==> Train Accuracy: Acc@1 49.866 || Acc@5 77.212\n",
            "==> Test Accuracy:  Acc@1 53.200 || Acc@5 83.360\n",
            "==> 38.02 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 37, lr: 0.1 -----\n",
            "Epoch: [37][  0/391]\tTime  0.236 ( 0.236)\tLoss 1.4487e+00 (1.4487e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [37][ 30/391]\tTime  0.092 ( 0.095)\tLoss 1.3204e+00 (2.2609e+00)\tAcc@1  65.62 ( 49.45)\tAcc@5  88.28 ( 76.69)\n",
            "Epoch: [37][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.3375e+00 (2.2800e+00)\tAcc@1  29.69 ( 49.60)\tAcc@5  62.50 ( 77.13)\n",
            "Epoch: [37][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3476e+00 (2.2297e+00)\tAcc@1  64.06 ( 49.84)\tAcc@5  86.72 ( 77.05)\n",
            "Epoch: [37][120/391]\tTime  0.092 ( 0.092)\tLoss 1.3598e+00 (2.2087e+00)\tAcc@1  56.25 ( 50.28)\tAcc@5  92.97 ( 77.60)\n",
            "Epoch: [37][150/391]\tTime  0.090 ( 0.091)\tLoss 2.9610e+00 (2.2080e+00)\tAcc@1  34.38 ( 50.30)\tAcc@5  60.94 ( 77.70)\n",
            "Epoch: [37][180/391]\tTime  0.090 ( 0.091)\tLoss 3.3380e+00 (2.1944e+00)\tAcc@1  16.41 ( 50.23)\tAcc@5  41.41 ( 77.56)\n",
            "Epoch: [37][210/391]\tTime  0.092 ( 0.091)\tLoss 1.1794e+00 (2.2168e+00)\tAcc@1  68.75 ( 49.86)\tAcc@5  91.41 ( 77.28)\n",
            "Epoch: [37][240/391]\tTime  0.090 ( 0.091)\tLoss 3.3052e+00 (2.2198e+00)\tAcc@1  33.59 ( 50.02)\tAcc@5  65.62 ( 77.54)\n",
            "Epoch: [37][270/391]\tTime  0.090 ( 0.091)\tLoss 3.3808e+00 (2.2351e+00)\tAcc@1  23.44 ( 49.70)\tAcc@5  49.22 ( 77.31)\n",
            "Epoch: [37][300/391]\tTime  0.090 ( 0.091)\tLoss 1.3757e+00 (2.2270e+00)\tAcc@1  61.72 ( 49.74)\tAcc@5  88.28 ( 77.37)\n",
            "Epoch: [37][330/391]\tTime  0.091 ( 0.091)\tLoss 2.6657e+00 (2.2117e+00)\tAcc@1  64.06 ( 49.91)\tAcc@5  91.41 ( 77.53)\n",
            "Epoch: [37][360/391]\tTime  0.090 ( 0.091)\tLoss 1.2301e+00 (2.1902e+00)\tAcc@1  64.06 ( 50.23)\tAcc@5  92.97 ( 77.90)\n",
            "Epoch: [37][390/391]\tTime  0.083 ( 0.091)\tLoss 1.3755e+00 (2.1979e+00)\tAcc@1  62.50 ( 50.10)\tAcc@5  88.75 ( 77.77)\n",
            "==> Train Accuracy: Acc@1 50.100 || Acc@5 77.770\n",
            "==> Test Accuracy:  Acc@1 54.720 || Acc@5 82.930\n",
            "==> 37.92 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 38, lr: 0.1 -----\n",
            "Epoch: [38][  0/391]\tTime  0.249 ( 0.249)\tLoss 3.2758e+00 (3.2758e+00)\tAcc@1  19.53 ( 19.53)\tAcc@5  50.78 ( 50.78)\n",
            "Epoch: [38][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.4480e+00 (2.2110e+00)\tAcc@1  58.59 ( 49.47)\tAcc@5  87.50 ( 77.42)\n",
            "Epoch: [38][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.7092e+00 (2.3800e+00)\tAcc@1  62.50 ( 48.31)\tAcc@5  92.19 ( 76.46)\n",
            "Epoch: [38][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.1843e+00 (2.2078e+00)\tAcc@1  64.84 ( 50.37)\tAcc@5  92.97 ( 77.94)\n",
            "Epoch: [38][120/391]\tTime  0.090 ( 0.092)\tLoss 3.1977e+00 (2.2095e+00)\tAcc@1  43.75 ( 49.90)\tAcc@5  77.34 ( 77.62)\n",
            "Epoch: [38][150/391]\tTime  0.092 ( 0.091)\tLoss 1.1815e+00 (2.2164e+00)\tAcc@1  64.84 ( 50.19)\tAcc@5  89.84 ( 77.89)\n",
            "Epoch: [38][180/391]\tTime  0.090 ( 0.091)\tLoss 1.6060e+00 (2.1432e+00)\tAcc@1  58.59 ( 51.36)\tAcc@5  82.03 ( 78.95)\n",
            "Epoch: [38][210/391]\tTime  0.090 ( 0.091)\tLoss 3.1166e+00 (2.1761e+00)\tAcc@1  28.12 ( 50.93)\tAcc@5  60.16 ( 78.74)\n",
            "Epoch: [38][240/391]\tTime  0.095 ( 0.091)\tLoss 2.9523e+00 (2.1874e+00)\tAcc@1  46.88 ( 51.04)\tAcc@5  75.00 ( 78.91)\n",
            "Epoch: [38][270/391]\tTime  0.091 ( 0.091)\tLoss 1.1045e+00 (2.1952e+00)\tAcc@1  66.41 ( 50.87)\tAcc@5  95.31 ( 78.70)\n",
            "Epoch: [38][300/391]\tTime  0.091 ( 0.091)\tLoss 3.0687e+00 (2.1992e+00)\tAcc@1  35.16 ( 50.82)\tAcc@5  67.97 ( 78.60)\n",
            "Epoch: [38][330/391]\tTime  0.092 ( 0.091)\tLoss 1.2049e+00 (2.1903e+00)\tAcc@1  65.62 ( 51.01)\tAcc@5  90.62 ( 78.68)\n",
            "Epoch: [38][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1612e+00 (2.2018e+00)\tAcc@1  68.75 ( 50.77)\tAcc@5  89.06 ( 78.48)\n",
            "Epoch: [38][390/391]\tTime  0.082 ( 0.091)\tLoss 3.2227e+00 (2.2010e+00)\tAcc@1  38.75 ( 50.82)\tAcc@5  72.50 ( 78.59)\n",
            "==> Train Accuracy: Acc@1 50.824 || Acc@5 78.592\n",
            "==> Test Accuracy:  Acc@1 54.430 || Acc@5 83.590\n",
            "==> 37.92 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 39, lr: 0.1 -----\n",
            "Epoch: [39][  0/391]\tTime  0.244 ( 0.244)\tLoss 1.1112e+00 (1.1112e+00)\tAcc@1  73.44 ( 73.44)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [39][ 30/391]\tTime  0.093 ( 0.095)\tLoss 9.7692e-01 (2.1233e+00)\tAcc@1  72.66 ( 54.71)\tAcc@5  93.75 ( 80.97)\n",
            "Epoch: [39][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.2462e+00 (2.2475e+00)\tAcc@1  34.38 ( 50.99)\tAcc@5  58.59 ( 78.32)\n",
            "Epoch: [39][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.7262e+00 (2.2217e+00)\tAcc@1  58.59 ( 51.18)\tAcc@5  85.16 ( 78.55)\n",
            "Epoch: [39][120/391]\tTime  0.090 ( 0.092)\tLoss 1.2750e+00 (2.1654e+00)\tAcc@1  60.94 ( 51.84)\tAcc@5  90.62 ( 79.16)\n",
            "Epoch: [39][150/391]\tTime  0.089 ( 0.092)\tLoss 1.2108e+00 (2.1295e+00)\tAcc@1  68.75 ( 52.20)\tAcc@5  89.84 ( 79.56)\n",
            "Epoch: [39][180/391]\tTime  0.084 ( 0.091)\tLoss 3.2690e+00 (2.1406e+00)\tAcc@1  29.69 ( 51.88)\tAcc@5  55.47 ( 79.23)\n",
            "Epoch: [39][210/391]\tTime  0.090 ( 0.091)\tLoss 1.4299e+00 (2.1451e+00)\tAcc@1  59.38 ( 51.76)\tAcc@5  89.06 ( 79.10)\n",
            "Epoch: [39][240/391]\tTime  0.090 ( 0.091)\tLoss 1.3081e+00 (2.1288e+00)\tAcc@1  64.06 ( 51.90)\tAcc@5  88.28 ( 79.19)\n",
            "Epoch: [39][270/391]\tTime  0.091 ( 0.091)\tLoss 3.1269e+00 (2.1409e+00)\tAcc@1  35.16 ( 51.70)\tAcc@5  59.38 ( 79.08)\n",
            "Epoch: [39][300/391]\tTime  0.090 ( 0.091)\tLoss 3.2985e+00 (2.1493e+00)\tAcc@1  26.56 ( 51.49)\tAcc@5  53.12 ( 78.96)\n",
            "Epoch: [39][330/391]\tTime  0.088 ( 0.091)\tLoss 1.2445e+00 (2.1457e+00)\tAcc@1  64.06 ( 51.60)\tAcc@5  91.41 ( 79.02)\n",
            "Epoch: [39][360/391]\tTime  0.091 ( 0.091)\tLoss 3.2635e+00 (2.1597e+00)\tAcc@1  25.78 ( 51.40)\tAcc@5  59.38 ( 78.92)\n",
            "Epoch: [39][390/391]\tTime  0.082 ( 0.091)\tLoss 3.3128e+00 (2.1650e+00)\tAcc@1  25.00 ( 51.24)\tAcc@5  51.25 ( 78.81)\n",
            "==> Train Accuracy: Acc@1 51.238 || Acc@5 78.806\n",
            "==> Test Accuracy:  Acc@1 54.750 || Acc@5 83.040\n",
            "==> 37.95 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 40, lr: 0.1 -----\n",
            "Epoch: [40][  0/391]\tTime  0.248 ( 0.248)\tLoss 1.3689e+00 (1.3689e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [40][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.3298e+00 (1.9738e+00)\tAcc@1  69.53 ( 57.13)\tAcc@5  89.06 ( 82.08)\n",
            "Epoch: [40][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.9632e+00 (1.9937e+00)\tAcc@1  30.47 ( 54.96)\tAcc@5  64.06 ( 81.83)\n",
            "Epoch: [40][ 90/391]\tTime  0.092 ( 0.092)\tLoss 3.4538e+00 (2.0989e+00)\tAcc@1  14.06 ( 51.83)\tAcc@5  43.75 ( 79.13)\n",
            "Epoch: [40][120/391]\tTime  0.090 ( 0.092)\tLoss 3.0341e+00 (2.0734e+00)\tAcc@1  48.44 ( 52.25)\tAcc@5  79.69 ( 79.85)\n",
            "Epoch: [40][150/391]\tTime  0.092 ( 0.091)\tLoss 3.1619e+00 (2.1226e+00)\tAcc@1  23.44 ( 51.53)\tAcc@5  53.12 ( 79.13)\n",
            "Epoch: [40][180/391]\tTime  0.090 ( 0.091)\tLoss 2.8891e+00 (2.1465e+00)\tAcc@1  53.12 ( 51.22)\tAcc@5  78.12 ( 78.99)\n",
            "Epoch: [40][210/391]\tTime  0.095 ( 0.091)\tLoss 3.3051e+00 (2.1286e+00)\tAcc@1  39.84 ( 51.85)\tAcc@5  65.62 ( 79.41)\n",
            "Epoch: [40][240/391]\tTime  0.091 ( 0.091)\tLoss 2.8116e+00 (2.1449e+00)\tAcc@1  50.00 ( 51.67)\tAcc@5  82.03 ( 79.27)\n",
            "Epoch: [40][270/391]\tTime  0.090 ( 0.091)\tLoss 3.4800e+00 (2.1479e+00)\tAcc@1  19.53 ( 51.58)\tAcc@5  42.97 ( 79.26)\n",
            "Epoch: [40][300/391]\tTime  0.093 ( 0.091)\tLoss 3.3230e+00 (2.1577e+00)\tAcc@1  20.31 ( 51.25)\tAcc@5  36.72 ( 78.86)\n",
            "Epoch: [40][330/391]\tTime  0.090 ( 0.091)\tLoss 3.0628e+00 (2.1521e+00)\tAcc@1  55.47 ( 51.44)\tAcc@5  82.03 ( 79.02)\n",
            "Epoch: [40][360/391]\tTime  0.088 ( 0.091)\tLoss 1.5818e+00 (2.1501e+00)\tAcc@1  57.81 ( 51.52)\tAcc@5  87.50 ( 79.20)\n",
            "Epoch: [40][390/391]\tTime  0.083 ( 0.091)\tLoss 3.1897e+00 (2.1591e+00)\tAcc@1  38.75 ( 51.47)\tAcc@5  63.75 ( 79.19)\n",
            "==> Train Accuracy: Acc@1 51.472 || Acc@5 79.188\n",
            "==> Test Accuracy:  Acc@1 49.710 || Acc@5 78.160\n",
            "==> 38.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 41, lr: 0.1 -----\n",
            "Epoch: [41][  0/391]\tTime  0.263 ( 0.263)\tLoss 3.2841e+00 (3.2841e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  64.06 ( 64.06)\n",
            "Epoch: [41][ 30/391]\tTime  0.091 ( 0.096)\tLoss 2.7726e+00 (2.3908e+00)\tAcc@1  50.78 ( 46.95)\tAcc@5  76.56 ( 74.04)\n",
            "Epoch: [41][ 60/391]\tTime  0.096 ( 0.093)\tLoss 3.1371e+00 (2.3137e+00)\tAcc@1  28.91 ( 48.23)\tAcc@5  58.59 ( 75.83)\n",
            "Epoch: [41][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.8886e+00 (2.3137e+00)\tAcc@1  41.41 ( 48.17)\tAcc@5  72.66 ( 76.22)\n",
            "Epoch: [41][120/391]\tTime  0.089 ( 0.092)\tLoss 1.2932e+00 (2.3024e+00)\tAcc@1  66.41 ( 48.75)\tAcc@5  90.62 ( 76.81)\n",
            "Epoch: [41][150/391]\tTime  0.091 ( 0.092)\tLoss 2.7218e+00 (2.2873e+00)\tAcc@1  45.31 ( 48.89)\tAcc@5  78.12 ( 76.89)\n",
            "Epoch: [41][180/391]\tTime  0.092 ( 0.091)\tLoss 2.8364e+00 (2.2919e+00)\tAcc@1  53.12 ( 48.80)\tAcc@5  84.38 ( 77.04)\n",
            "Epoch: [41][210/391]\tTime  0.090 ( 0.091)\tLoss 3.0290e+00 (2.2447e+00)\tAcc@1  47.66 ( 49.58)\tAcc@5  71.09 ( 77.59)\n",
            "Epoch: [41][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1650e+00 (2.2281e+00)\tAcc@1  65.62 ( 49.76)\tAcc@5  92.97 ( 77.85)\n",
            "Epoch: [41][270/391]\tTime  0.085 ( 0.091)\tLoss 1.2155e+00 (2.2326e+00)\tAcc@1  65.62 ( 49.47)\tAcc@5  92.97 ( 77.57)\n",
            "Epoch: [41][300/391]\tTime  0.091 ( 0.091)\tLoss 3.2119e+00 (2.2216e+00)\tAcc@1  30.47 ( 49.47)\tAcc@5  55.47 ( 77.67)\n",
            "Epoch: [41][330/391]\tTime  0.090 ( 0.091)\tLoss 1.2644e+00 (2.2018e+00)\tAcc@1  64.84 ( 49.63)\tAcc@5  89.06 ( 77.82)\n",
            "Epoch: [41][360/391]\tTime  0.090 ( 0.091)\tLoss 1.3938e+00 (2.2116e+00)\tAcc@1  62.50 ( 49.51)\tAcc@5  89.06 ( 77.69)\n",
            "Epoch: [41][390/391]\tTime  0.081 ( 0.091)\tLoss 1.2881e+00 (2.2105e+00)\tAcc@1  66.25 ( 49.53)\tAcc@5  91.25 ( 77.70)\n",
            "==> Train Accuracy: Acc@1 49.534 || Acc@5 77.698\n",
            "==> Test Accuracy:  Acc@1 53.700 || Acc@5 81.580\n",
            "==> 37.94 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 42, lr: 0.1 -----\n",
            "Epoch: [42][  0/391]\tTime  0.245 ( 0.245)\tLoss 3.1343e+00 (3.1343e+00)\tAcc@1  34.38 ( 34.38)\tAcc@5  58.59 ( 58.59)\n",
            "Epoch: [42][ 30/391]\tTime  0.088 ( 0.096)\tLoss 3.2755e+00 (2.1542e+00)\tAcc@1  32.03 ( 51.26)\tAcc@5  60.94 ( 78.86)\n",
            "Epoch: [42][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.4412e+00 (2.2023e+00)\tAcc@1  65.62 ( 51.09)\tAcc@5  89.06 ( 78.59)\n",
            "Epoch: [42][ 90/391]\tTime  0.092 ( 0.092)\tLoss 1.1863e+00 (2.2606e+00)\tAcc@1  67.19 ( 51.06)\tAcc@5  90.62 ( 78.30)\n",
            "Epoch: [42][120/391]\tTime  0.089 ( 0.092)\tLoss 1.2892e+00 (2.2601e+00)\tAcc@1  63.28 ( 50.77)\tAcc@5  91.41 ( 78.25)\n",
            "Epoch: [42][150/391]\tTime  0.090 ( 0.092)\tLoss 1.1141e+00 (2.2136e+00)\tAcc@1  70.31 ( 51.21)\tAcc@5  92.97 ( 78.34)\n",
            "Epoch: [42][180/391]\tTime  0.091 ( 0.091)\tLoss 3.2243e+00 (2.1838e+00)\tAcc@1  22.66 ( 51.35)\tAcc@5  53.12 ( 78.56)\n",
            "Epoch: [42][210/391]\tTime  0.090 ( 0.091)\tLoss 1.3238e+00 (2.2330e+00)\tAcc@1  63.28 ( 50.64)\tAcc@5  89.84 ( 78.11)\n",
            "Epoch: [42][240/391]\tTime  0.091 ( 0.091)\tLoss 3.3183e+00 (2.2266e+00)\tAcc@1  25.78 ( 50.75)\tAcc@5  55.47 ( 78.20)\n",
            "Epoch: [42][270/391]\tTime  0.090 ( 0.091)\tLoss 1.2944e+00 (2.2015e+00)\tAcc@1  64.84 ( 51.06)\tAcc@5  86.72 ( 78.45)\n",
            "Epoch: [42][300/391]\tTime  0.089 ( 0.091)\tLoss 1.2454e+00 (2.1846e+00)\tAcc@1  64.06 ( 51.18)\tAcc@5  88.28 ( 78.55)\n",
            "Epoch: [42][330/391]\tTime  0.090 ( 0.091)\tLoss 3.0951e+00 (2.1980e+00)\tAcc@1  42.97 ( 50.89)\tAcc@5  75.00 ( 78.33)\n",
            "Epoch: [42][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1354e+00 (2.2098e+00)\tAcc@1  67.97 ( 50.74)\tAcc@5  94.53 ( 78.26)\n",
            "Epoch: [42][390/391]\tTime  0.080 ( 0.091)\tLoss 1.3106e+00 (2.1961e+00)\tAcc@1  68.75 ( 51.05)\tAcc@5  88.75 ( 78.51)\n",
            "==> Train Accuracy: Acc@1 51.054 || Acc@5 78.514\n",
            "==> Test Accuracy:  Acc@1 52.590 || Acc@5 81.560\n",
            "==> 37.94 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 43, lr: 0.1 -----\n",
            "Epoch: [43][  0/391]\tTime  0.239 ( 0.239)\tLoss 1.2346e+00 (1.2346e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [43][ 30/391]\tTime  0.091 ( 0.096)\tLoss 3.1313e+00 (2.1616e+00)\tAcc@1  44.53 ( 50.71)\tAcc@5  73.44 ( 78.20)\n",
            "Epoch: [43][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.1573e+00 (2.1944e+00)\tAcc@1  62.50 ( 49.94)\tAcc@5  90.62 ( 76.90)\n",
            "Epoch: [43][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.2961e+00 (2.2315e+00)\tAcc@1  62.50 ( 49.91)\tAcc@5  91.41 ( 76.92)\n",
            "Epoch: [43][120/391]\tTime  0.090 ( 0.092)\tLoss 1.2029e+00 (2.1645e+00)\tAcc@1  65.62 ( 51.39)\tAcc@5  94.53 ( 78.20)\n",
            "Epoch: [43][150/391]\tTime  0.091 ( 0.092)\tLoss 3.0914e+00 (2.1662e+00)\tAcc@1  53.12 ( 51.20)\tAcc@5  77.34 ( 78.16)\n",
            "Epoch: [43][180/391]\tTime  0.090 ( 0.091)\tLoss 3.0664e+00 (2.1592e+00)\tAcc@1  42.97 ( 51.17)\tAcc@5  67.97 ( 78.17)\n",
            "Epoch: [43][210/391]\tTime  0.090 ( 0.091)\tLoss 3.1305e+00 (2.1562e+00)\tAcc@1  39.06 ( 51.05)\tAcc@5  67.19 ( 78.34)\n",
            "Epoch: [43][240/391]\tTime  0.091 ( 0.091)\tLoss 1.4252e+00 (2.1652e+00)\tAcc@1  60.94 ( 50.99)\tAcc@5  88.28 ( 78.19)\n",
            "Epoch: [43][270/391]\tTime  0.091 ( 0.091)\tLoss 3.2237e+00 (2.1683e+00)\tAcc@1  29.69 ( 50.69)\tAcc@5  60.94 ( 77.92)\n",
            "Epoch: [43][300/391]\tTime  0.091 ( 0.091)\tLoss 2.6202e+00 (2.1942e+00)\tAcc@1  51.56 ( 50.22)\tAcc@5  79.69 ( 77.60)\n",
            "Epoch: [43][330/391]\tTime  0.090 ( 0.091)\tLoss 1.3242e+00 (2.1713e+00)\tAcc@1  66.41 ( 50.64)\tAcc@5  87.50 ( 78.04)\n",
            "Epoch: [43][360/391]\tTime  0.090 ( 0.091)\tLoss 3.2706e+00 (2.1749e+00)\tAcc@1  28.12 ( 50.46)\tAcc@5  61.72 ( 77.91)\n",
            "Epoch: [43][390/391]\tTime  0.081 ( 0.091)\tLoss 1.2827e+00 (2.1687e+00)\tAcc@1  61.25 ( 50.62)\tAcc@5  88.75 ( 77.97)\n",
            "==> Train Accuracy: Acc@1 50.622 || Acc@5 77.972\n",
            "==> Test Accuracy:  Acc@1 55.210 || Acc@5 82.800\n",
            "==> 37.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 44, lr: 0.1 -----\n",
            "Epoch: [44][  0/391]\tTime  0.229 ( 0.229)\tLoss 1.5790e+00 (1.5790e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [44][ 30/391]\tTime  0.091 ( 0.095)\tLoss 3.1618e+00 (2.1450e+00)\tAcc@1  25.00 ( 52.85)\tAcc@5  57.03 ( 80.65)\n",
            "Epoch: [44][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.1303e+00 (2.1617e+00)\tAcc@1  69.53 ( 53.43)\tAcc@5  90.62 ( 81.20)\n",
            "Epoch: [44][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3288e+00 (2.1163e+00)\tAcc@1  64.06 ( 53.23)\tAcc@5  87.50 ( 80.60)\n",
            "Epoch: [44][120/391]\tTime  0.096 ( 0.092)\tLoss 1.1977e+00 (2.0922e+00)\tAcc@1  67.97 ( 53.54)\tAcc@5  93.75 ( 80.80)\n",
            "Epoch: [44][150/391]\tTime  0.091 ( 0.091)\tLoss 2.8538e+00 (2.0879e+00)\tAcc@1  41.41 ( 53.13)\tAcc@5  77.34 ( 80.40)\n",
            "Epoch: [44][180/391]\tTime  0.091 ( 0.091)\tLoss 1.2488e+00 (2.0661e+00)\tAcc@1  63.28 ( 53.26)\tAcc@5  87.50 ( 80.62)\n",
            "Epoch: [44][210/391]\tTime  0.091 ( 0.091)\tLoss 1.1370e+00 (2.0539e+00)\tAcc@1  69.53 ( 53.56)\tAcc@5  92.19 ( 80.97)\n",
            "Epoch: [44][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5220e+00 (2.0338e+00)\tAcc@1  56.25 ( 54.02)\tAcc@5  85.94 ( 81.41)\n",
            "Epoch: [44][270/391]\tTime  0.090 ( 0.091)\tLoss 3.1052e+00 (2.0515e+00)\tAcc@1  26.56 ( 53.37)\tAcc@5  57.81 ( 80.90)\n",
            "Epoch: [44][300/391]\tTime  0.092 ( 0.091)\tLoss 3.1216e+00 (2.0677e+00)\tAcc@1  25.78 ( 53.02)\tAcc@5  56.25 ( 80.58)\n",
            "Epoch: [44][330/391]\tTime  0.090 ( 0.091)\tLoss 3.2965e+00 (2.0749e+00)\tAcc@1  25.00 ( 52.80)\tAcc@5  60.94 ( 80.36)\n",
            "Epoch: [44][360/391]\tTime  0.091 ( 0.091)\tLoss 3.0941e+00 (2.1010e+00)\tAcc@1  47.66 ( 52.38)\tAcc@5  75.78 ( 79.92)\n",
            "Epoch: [44][390/391]\tTime  0.081 ( 0.091)\tLoss 1.3694e+00 (2.0930e+00)\tAcc@1  63.75 ( 52.70)\tAcc@5  90.00 ( 80.21)\n",
            "==> Train Accuracy: Acc@1 52.698 || Acc@5 80.208\n",
            "==> Test Accuracy:  Acc@1 50.170 || Acc@5 78.790\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 45, lr: 0.1 -----\n",
            "Epoch: [45][  0/391]\tTime  0.213 ( 0.213)\tLoss 1.2395e+00 (1.2395e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [45][ 30/391]\tTime  0.089 ( 0.095)\tLoss 1.1168e+00 (2.1078e+00)\tAcc@1  66.41 ( 51.39)\tAcc@5  92.97 ( 78.83)\n",
            "Epoch: [45][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.2440e+00 (2.2564e+00)\tAcc@1  68.75 ( 49.55)\tAcc@5  87.50 ( 77.96)\n",
            "Epoch: [45][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.8833e+00 (2.2082e+00)\tAcc@1  37.50 ( 50.91)\tAcc@5  75.00 ( 78.32)\n",
            "Epoch: [45][120/391]\tTime  0.090 ( 0.092)\tLoss 3.1856e+00 (2.2330e+00)\tAcc@1  21.09 ( 50.24)\tAcc@5  53.91 ( 77.98)\n",
            "Epoch: [45][150/391]\tTime  0.093 ( 0.091)\tLoss 2.9138e+00 (2.3297e+00)\tAcc@1  45.31 ( 49.20)\tAcc@5  71.09 ( 77.35)\n",
            "Epoch: [45][180/391]\tTime  0.090 ( 0.091)\tLoss 1.0345e+00 (2.3170e+00)\tAcc@1  72.66 ( 49.18)\tAcc@5  93.75 ( 77.27)\n",
            "Epoch: [45][210/391]\tTime  0.091 ( 0.091)\tLoss 3.4546e+00 (2.2868e+00)\tAcc@1  35.16 ( 49.53)\tAcc@5  68.75 ( 77.51)\n",
            "Epoch: [45][240/391]\tTime  0.086 ( 0.091)\tLoss 2.7314e+00 (2.2654e+00)\tAcc@1  57.81 ( 50.15)\tAcc@5  89.84 ( 78.03)\n",
            "Epoch: [45][270/391]\tTime  0.090 ( 0.091)\tLoss 1.2435e+00 (2.2523e+00)\tAcc@1  64.06 ( 50.16)\tAcc@5  89.06 ( 78.07)\n",
            "Epoch: [45][300/391]\tTime  0.091 ( 0.091)\tLoss 3.2628e+00 (2.2630e+00)\tAcc@1  21.88 ( 49.71)\tAcc@5  53.91 ( 77.61)\n",
            "Epoch: [45][330/391]\tTime  0.090 ( 0.091)\tLoss 2.8452e+00 (2.2521e+00)\tAcc@1  38.28 ( 49.83)\tAcc@5  71.88 ( 77.70)\n",
            "Epoch: [45][360/391]\tTime  0.089 ( 0.091)\tLoss 1.3209e+00 (2.2610e+00)\tAcc@1  64.84 ( 49.54)\tAcc@5  89.06 ( 77.41)\n",
            "Epoch: [45][390/391]\tTime  0.081 ( 0.091)\tLoss 1.2976e+00 (2.2482e+00)\tAcc@1  62.50 ( 49.82)\tAcc@5  92.50 ( 77.65)\n",
            "==> Train Accuracy: Acc@1 49.822 || Acc@5 77.652\n",
            "==> Test Accuracy:  Acc@1 50.870 || Acc@5 81.830\n",
            "==> 37.95 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 46, lr: 0.1 -----\n",
            "Epoch: [46][  0/391]\tTime  0.258 ( 0.258)\tLoss 3.3623e+00 (3.3623e+00)\tAcc@1  19.53 ( 19.53)\tAcc@5  43.75 ( 43.75)\n",
            "Epoch: [46][ 30/391]\tTime  0.090 ( 0.096)\tLoss 3.2861e+00 (2.0505e+00)\tAcc@1  40.62 ( 50.93)\tAcc@5  71.88 ( 77.67)\n",
            "Epoch: [46][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.1681e+00 (2.0517e+00)\tAcc@1  70.31 ( 52.48)\tAcc@5  89.84 ( 79.74)\n",
            "Epoch: [46][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.9519e+00 (2.1626e+00)\tAcc@1  39.06 ( 51.78)\tAcc@5  67.19 ( 79.05)\n",
            "Epoch: [46][120/391]\tTime  0.090 ( 0.092)\tLoss 1.2637e+00 (2.1688e+00)\tAcc@1  64.06 ( 51.60)\tAcc@5  88.28 ( 78.60)\n",
            "Epoch: [46][150/391]\tTime  0.091 ( 0.091)\tLoss 3.1258e+00 (2.2024e+00)\tAcc@1  34.38 ( 51.25)\tAcc@5  68.75 ( 78.41)\n",
            "Epoch: [46][180/391]\tTime  0.090 ( 0.091)\tLoss 1.2963e+00 (2.1641e+00)\tAcc@1  63.28 ( 51.83)\tAcc@5  89.06 ( 78.88)\n",
            "Epoch: [46][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5104e+00 (2.1884e+00)\tAcc@1  57.81 ( 51.31)\tAcc@5  84.38 ( 78.46)\n",
            "Epoch: [46][240/391]\tTime  0.091 ( 0.091)\tLoss 2.9809e+00 (2.1847e+00)\tAcc@1  52.34 ( 51.28)\tAcc@5  78.91 ( 78.44)\n",
            "Epoch: [46][270/391]\tTime  0.091 ( 0.091)\tLoss 1.4808e+00 (2.1817e+00)\tAcc@1  57.03 ( 51.34)\tAcc@5  87.50 ( 78.59)\n",
            "Epoch: [46][300/391]\tTime  0.091 ( 0.091)\tLoss 3.0735e+00 (2.1688e+00)\tAcc@1  30.47 ( 51.45)\tAcc@5  65.62 ( 78.80)\n",
            "Epoch: [46][330/391]\tTime  0.090 ( 0.091)\tLoss 2.7629e+00 (2.1666e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  82.03 ( 79.01)\n",
            "Epoch: [46][360/391]\tTime  0.092 ( 0.091)\tLoss 3.3340e+00 (2.1693e+00)\tAcc@1  10.16 ( 51.48)\tAcc@5  37.50 ( 79.04)\n",
            "Epoch: [46][390/391]\tTime  0.081 ( 0.091)\tLoss 1.1524e+00 (2.1788e+00)\tAcc@1  66.25 ( 51.19)\tAcc@5  91.25 ( 78.85)\n",
            "==> Train Accuracy: Acc@1 51.194 || Acc@5 78.852\n",
            "==> Test Accuracy:  Acc@1 57.370 || Acc@5 84.940\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 47, lr: 0.1 -----\n",
            "Epoch: [47][  0/391]\tTime  0.261 ( 0.261)\tLoss 3.0002e+00 (3.0002e+00)\tAcc@1  32.81 ( 32.81)\tAcc@5  64.06 ( 64.06)\n",
            "Epoch: [47][ 30/391]\tTime  0.089 ( 0.097)\tLoss 1.4020e+00 (2.1703e+00)\tAcc@1  60.94 ( 50.50)\tAcc@5  86.72 ( 77.92)\n",
            "Epoch: [47][ 60/391]\tTime  0.092 ( 0.094)\tLoss 2.6690e+00 (2.2157e+00)\tAcc@1  53.12 ( 49.37)\tAcc@5  80.47 ( 77.18)\n",
            "Epoch: [47][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.9475e+00 (2.2196e+00)\tAcc@1  40.62 ( 49.40)\tAcc@5  72.66 ( 77.16)\n",
            "Epoch: [47][120/391]\tTime  0.089 ( 0.092)\tLoss 1.0553e+00 (2.2644e+00)\tAcc@1  67.97 ( 49.37)\tAcc@5  96.09 ( 77.19)\n",
            "Epoch: [47][150/391]\tTime  0.091 ( 0.092)\tLoss 3.0482e+00 (2.2301e+00)\tAcc@1  47.66 ( 50.21)\tAcc@5  74.22 ( 77.85)\n",
            "Epoch: [47][180/391]\tTime  0.091 ( 0.092)\tLoss 1.1942e+00 (2.2560e+00)\tAcc@1  64.84 ( 50.08)\tAcc@5  93.75 ( 77.83)\n",
            "Epoch: [47][210/391]\tTime  0.089 ( 0.092)\tLoss 1.2147e+00 (2.2299e+00)\tAcc@1  66.41 ( 50.36)\tAcc@5  90.62 ( 78.20)\n",
            "Epoch: [47][240/391]\tTime  0.091 ( 0.091)\tLoss 2.9478e+00 (2.2160e+00)\tAcc@1  41.41 ( 50.40)\tAcc@5  76.56 ( 78.29)\n",
            "Epoch: [47][270/391]\tTime  0.089 ( 0.091)\tLoss 1.2420e+00 (2.1929e+00)\tAcc@1  67.19 ( 50.93)\tAcc@5  89.84 ( 78.73)\n",
            "Epoch: [47][300/391]\tTime  0.090 ( 0.091)\tLoss 3.1902e+00 (2.1896e+00)\tAcc@1  24.22 ( 51.10)\tAcc@5  59.38 ( 78.95)\n",
            "Epoch: [47][330/391]\tTime  0.090 ( 0.091)\tLoss 1.3691e+00 (2.1795e+00)\tAcc@1  64.06 ( 51.16)\tAcc@5  90.62 ( 78.88)\n",
            "Epoch: [47][360/391]\tTime  0.091 ( 0.091)\tLoss 1.1969e+00 (2.1638e+00)\tAcc@1  64.06 ( 51.20)\tAcc@5  88.28 ( 78.98)\n",
            "Epoch: [47][390/391]\tTime  0.082 ( 0.091)\tLoss 2.3123e+00 (2.1795e+00)\tAcc@1  61.25 ( 50.85)\tAcc@5  90.00 ( 78.66)\n",
            "==> Train Accuracy: Acc@1 50.850 || Acc@5 78.660\n",
            "==> Test Accuracy:  Acc@1 55.750 || Acc@5 84.090\n",
            "==> 38.02 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 48, lr: 0.1 -----\n",
            "Epoch: [48][  0/391]\tTime  0.263 ( 0.263)\tLoss 2.9901e+00 (2.9901e+00)\tAcc@1  32.81 ( 32.81)\tAcc@5  69.53 ( 69.53)\n",
            "Epoch: [48][ 30/391]\tTime  0.091 ( 0.096)\tLoss 3.0791e+00 (2.3954e+00)\tAcc@1  47.66 ( 48.61)\tAcc@5  77.34 ( 76.39)\n",
            "Epoch: [48][ 60/391]\tTime  0.090 ( 0.093)\tLoss 9.3572e-01 (2.2729e+00)\tAcc@1  71.88 ( 51.75)\tAcc@5  96.88 ( 79.67)\n",
            "Epoch: [48][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.5021e+00 (2.2201e+00)\tAcc@1  57.81 ( 51.82)\tAcc@5  89.06 ( 79.68)\n",
            "Epoch: [48][120/391]\tTime  0.089 ( 0.092)\tLoss 1.2723e+00 (2.2098e+00)\tAcc@1  62.50 ( 51.63)\tAcc@5  92.97 ( 79.22)\n",
            "Epoch: [48][150/391]\tTime  0.090 ( 0.092)\tLoss 1.1511e+00 (2.2257e+00)\tAcc@1  69.53 ( 51.48)\tAcc@5  89.06 ( 79.22)\n",
            "Epoch: [48][180/391]\tTime  0.090 ( 0.091)\tLoss 1.2187e+00 (2.2069e+00)\tAcc@1  64.06 ( 51.89)\tAcc@5  92.97 ( 79.51)\n",
            "Epoch: [48][210/391]\tTime  0.090 ( 0.091)\tLoss 1.1352e+00 (2.1797e+00)\tAcc@1  65.62 ( 52.60)\tAcc@5  93.75 ( 80.04)\n",
            "Epoch: [48][240/391]\tTime  0.091 ( 0.091)\tLoss 2.9654e+00 (2.1858e+00)\tAcc@1  35.16 ( 52.55)\tAcc@5  64.84 ( 79.97)\n",
            "Epoch: [48][270/391]\tTime  0.091 ( 0.091)\tLoss 3.2127e+00 (2.2107e+00)\tAcc@1  35.94 ( 52.40)\tAcc@5  67.97 ( 79.91)\n",
            "Epoch: [48][300/391]\tTime  0.091 ( 0.091)\tLoss 3.2226e+00 (2.1684e+00)\tAcc@1  39.84 ( 52.90)\tAcc@5  73.44 ( 80.37)\n",
            "Epoch: [48][330/391]\tTime  0.091 ( 0.091)\tLoss 3.0830e+00 (2.1747e+00)\tAcc@1  50.78 ( 52.61)\tAcc@5  77.34 ( 80.14)\n",
            "Epoch: [48][360/391]\tTime  0.091 ( 0.091)\tLoss 1.2040e+00 (2.1686e+00)\tAcc@1  68.75 ( 52.79)\tAcc@5  90.62 ( 80.14)\n",
            "Epoch: [48][390/391]\tTime  0.081 ( 0.091)\tLoss 1.5198e+00 (2.1722e+00)\tAcc@1  58.75 ( 52.61)\tAcc@5  86.25 ( 80.04)\n",
            "==> Train Accuracy: Acc@1 52.610 || Acc@5 80.038\n",
            "==> Test Accuracy:  Acc@1 53.420 || Acc@5 82.020\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 49, lr: 0.1 -----\n",
            "Epoch: [49][  0/391]\tTime  0.226 ( 0.226)\tLoss 1.2574e+00 (1.2574e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [49][ 30/391]\tTime  0.090 ( 0.095)\tLoss 3.2750e+00 (2.0185e+00)\tAcc@1  39.06 ( 52.67)\tAcc@5  63.28 ( 79.18)\n",
            "Epoch: [49][ 60/391]\tTime  0.100 ( 0.093)\tLoss 1.0060e+00 (2.0560e+00)\tAcc@1  69.53 ( 52.86)\tAcc@5  92.19 ( 79.25)\n",
            "Epoch: [49][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.2381e+00 (2.1862e+00)\tAcc@1  65.62 ( 51.26)\tAcc@5  91.41 ( 78.25)\n",
            "Epoch: [49][120/391]\tTime  0.091 ( 0.092)\tLoss 2.9769e+00 (2.1119e+00)\tAcc@1  37.50 ( 52.36)\tAcc@5  74.22 ( 79.18)\n",
            "Epoch: [49][150/391]\tTime  0.090 ( 0.091)\tLoss 2.9523e+00 (2.1311e+00)\tAcc@1  49.22 ( 52.07)\tAcc@5  72.66 ( 79.05)\n",
            "Epoch: [49][180/391]\tTime  0.090 ( 0.091)\tLoss 1.5284e+00 (2.0807e+00)\tAcc@1  57.81 ( 53.01)\tAcc@5  81.25 ( 79.94)\n",
            "Epoch: [49][210/391]\tTime  0.090 ( 0.091)\tLoss 1.2894e+00 (2.1009e+00)\tAcc@1  64.06 ( 52.29)\tAcc@5  90.62 ( 79.55)\n",
            "Epoch: [49][240/391]\tTime  0.090 ( 0.091)\tLoss 1.2923e+00 (2.1187e+00)\tAcc@1  65.62 ( 52.04)\tAcc@5  91.41 ( 79.41)\n",
            "Epoch: [49][270/391]\tTime  0.091 ( 0.091)\tLoss 3.1168e+00 (2.1002e+00)\tAcc@1  39.06 ( 52.51)\tAcc@5  74.22 ( 79.81)\n",
            "Epoch: [49][300/391]\tTime  0.091 ( 0.091)\tLoss 3.4378e+00 (2.1177e+00)\tAcc@1  22.66 ( 52.11)\tAcc@5  62.50 ( 79.47)\n",
            "Epoch: [49][330/391]\tTime  0.090 ( 0.091)\tLoss 1.4039e+00 (2.1153e+00)\tAcc@1  63.28 ( 52.24)\tAcc@5  85.94 ( 79.61)\n",
            "Epoch: [49][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4289e+00 (2.1427e+00)\tAcc@1  62.50 ( 51.79)\tAcc@5  85.94 ( 79.34)\n",
            "Epoch: [49][390/391]\tTime  0.081 ( 0.091)\tLoss 1.2076e+00 (2.1328e+00)\tAcc@1  60.00 ( 51.90)\tAcc@5  93.75 ( 79.32)\n",
            "==> Train Accuracy: Acc@1 51.902 || Acc@5 79.322\n",
            "==> Test Accuracy:  Acc@1 49.680 || Acc@5 78.280\n",
            "==> 37.91 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 50, lr: 0.1 -----\n",
            "Epoch: [50][  0/391]\tTime  0.264 ( 0.264)\tLoss 3.0022e+00 (3.0022e+00)\tAcc@1  29.69 ( 29.69)\tAcc@5  57.81 ( 57.81)\n",
            "Epoch: [50][ 30/391]\tTime  0.091 ( 0.097)\tLoss 1.2340e+00 (2.1660e+00)\tAcc@1  66.41 ( 53.07)\tAcc@5  91.41 ( 80.39)\n",
            "Epoch: [50][ 60/391]\tTime  0.091 ( 0.094)\tLoss 1.0621e+00 (2.1136e+00)\tAcc@1  72.66 ( 53.01)\tAcc@5  92.97 ( 80.66)\n",
            "Epoch: [50][ 90/391]\tTime  0.096 ( 0.093)\tLoss 3.2468e+00 (2.1320e+00)\tAcc@1  25.78 ( 52.32)\tAcc@5  60.16 ( 79.91)\n",
            "Epoch: [50][120/391]\tTime  0.090 ( 0.092)\tLoss 3.3509e+00 (2.0946e+00)\tAcc@1  22.66 ( 52.17)\tAcc@5  52.34 ( 79.72)\n",
            "Epoch: [50][150/391]\tTime  0.090 ( 0.092)\tLoss 3.2127e+00 (2.1135e+00)\tAcc@1  31.25 ( 51.39)\tAcc@5  57.03 ( 79.38)\n",
            "Epoch: [50][180/391]\tTime  0.090 ( 0.092)\tLoss 1.2822e+00 (2.1536e+00)\tAcc@1  65.62 ( 50.88)\tAcc@5  86.72 ( 78.97)\n",
            "Epoch: [50][210/391]\tTime  0.090 ( 0.091)\tLoss 1.2755e+00 (2.1700e+00)\tAcc@1  62.50 ( 50.40)\tAcc@5  93.75 ( 78.40)\n",
            "Epoch: [50][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1832e+00 (2.1716e+00)\tAcc@1  67.97 ( 50.70)\tAcc@5  91.41 ( 78.60)\n",
            "Epoch: [50][270/391]\tTime  0.091 ( 0.091)\tLoss 3.1076e+00 (2.1335e+00)\tAcc@1  35.16 ( 51.15)\tAcc@5  67.97 ( 79.06)\n",
            "Epoch: [50][300/391]\tTime  0.090 ( 0.091)\tLoss 1.2338e+00 (2.1381e+00)\tAcc@1  63.28 ( 50.85)\tAcc@5  87.50 ( 78.89)\n",
            "Epoch: [50][330/391]\tTime  0.090 ( 0.091)\tLoss 1.5070e+00 (2.1312e+00)\tAcc@1  55.47 ( 51.07)\tAcc@5  89.06 ( 79.02)\n",
            "Epoch: [50][360/391]\tTime  0.091 ( 0.091)\tLoss 3.0884e+00 (2.1445e+00)\tAcc@1  32.81 ( 50.94)\tAcc@5  63.28 ( 78.89)\n",
            "Epoch: [50][390/391]\tTime  0.082 ( 0.091)\tLoss 1.2194e+00 (2.1600e+00)\tAcc@1  65.00 ( 50.85)\tAcc@5  90.00 ( 78.79)\n",
            "==> Train Accuracy: Acc@1 50.846 || Acc@5 78.786\n",
            "==> Test Accuracy:  Acc@1 58.250 || Acc@5 85.630\n",
            "==> 37.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 51, lr: 0.1 -----\n",
            "Epoch: [51][  0/391]\tTime  0.254 ( 0.254)\tLoss 9.7681e-01 (9.7681e-01)\tAcc@1  73.44 ( 73.44)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [51][ 30/391]\tTime  0.091 ( 0.096)\tLoss 2.5967e+00 (1.9327e+00)\tAcc@1  61.72 ( 58.34)\tAcc@5  89.84 ( 84.48)\n",
            "Epoch: [51][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.1674e+00 (2.0251e+00)\tAcc@1  68.75 ( 56.37)\tAcc@5  92.19 ( 82.86)\n",
            "Epoch: [51][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3902e+00 (2.0105e+00)\tAcc@1  61.72 ( 55.41)\tAcc@5  89.84 ( 82.33)\n",
            "Epoch: [51][120/391]\tTime  0.090 ( 0.092)\tLoss 3.2537e+00 (1.9885e+00)\tAcc@1  25.78 ( 55.28)\tAcc@5  62.50 ( 82.22)\n",
            "Epoch: [51][150/391]\tTime  0.091 ( 0.091)\tLoss 3.0093e+00 (2.0642e+00)\tAcc@1  39.84 ( 53.47)\tAcc@5  65.62 ( 80.82)\n",
            "Epoch: [51][180/391]\tTime  0.090 ( 0.091)\tLoss 1.2592e+00 (2.0899e+00)\tAcc@1  60.16 ( 52.91)\tAcc@5  92.97 ( 80.45)\n",
            "Epoch: [51][210/391]\tTime  0.091 ( 0.091)\tLoss 3.0918e+00 (2.1097e+00)\tAcc@1  34.38 ( 52.37)\tAcc@5  78.12 ( 79.81)\n",
            "Epoch: [51][240/391]\tTime  0.092 ( 0.091)\tLoss 1.0450e+00 (2.1292e+00)\tAcc@1  67.97 ( 51.82)\tAcc@5  92.19 ( 79.21)\n",
            "Epoch: [51][270/391]\tTime  0.098 ( 0.091)\tLoss 1.3434e+00 (2.1146e+00)\tAcc@1  60.94 ( 52.06)\tAcc@5  89.06 ( 79.48)\n",
            "Epoch: [51][300/391]\tTime  0.090 ( 0.091)\tLoss 1.1908e+00 (2.0952e+00)\tAcc@1  64.06 ( 52.40)\tAcc@5  89.84 ( 79.78)\n",
            "Epoch: [51][330/391]\tTime  0.092 ( 0.091)\tLoss 1.1990e+00 (2.0834e+00)\tAcc@1  65.62 ( 52.61)\tAcc@5  90.62 ( 79.90)\n",
            "Epoch: [51][360/391]\tTime  0.091 ( 0.091)\tLoss 3.3183e+00 (2.0952e+00)\tAcc@1  21.09 ( 52.25)\tAcc@5  53.12 ( 79.56)\n",
            "Epoch: [51][390/391]\tTime  0.082 ( 0.091)\tLoss 3.0749e+00 (2.1069e+00)\tAcc@1  43.75 ( 52.04)\tAcc@5  76.25 ( 79.43)\n",
            "==> Train Accuracy: Acc@1 52.038 || Acc@5 79.430\n",
            "==> Test Accuracy:  Acc@1 56.620 || Acc@5 85.230\n",
            "==> 37.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 52, lr: 0.1 -----\n",
            "Epoch: [52][  0/391]\tTime  0.252 ( 0.252)\tLoss 1.0948e+00 (1.0948e+00)\tAcc@1  67.19 ( 67.19)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [52][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.0727e+00 (1.9295e+00)\tAcc@1  69.53 ( 57.99)\tAcc@5  94.53 ( 84.53)\n",
            "Epoch: [52][ 60/391]\tTime  0.089 ( 0.093)\tLoss 3.2411e+00 (1.9325e+00)\tAcc@1  20.31 ( 57.17)\tAcc@5  50.00 ( 83.18)\n",
            "Epoch: [52][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.0243e+00 (1.8982e+00)\tAcc@1  46.88 ( 57.15)\tAcc@5  72.66 ( 83.34)\n",
            "Epoch: [52][120/391]\tTime  0.090 ( 0.092)\tLoss 1.5043e+00 (1.8961e+00)\tAcc@1  62.50 ( 56.85)\tAcc@5  89.84 ( 83.26)\n",
            "Epoch: [52][150/391]\tTime  0.091 ( 0.091)\tLoss 2.9972e+00 (1.9293e+00)\tAcc@1  49.22 ( 55.83)\tAcc@5  81.25 ( 82.65)\n",
            "Epoch: [52][180/391]\tTime  0.091 ( 0.091)\tLoss 3.3439e+00 (1.9821e+00)\tAcc@1  17.19 ( 54.90)\tAcc@5  53.12 ( 81.92)\n",
            "Epoch: [52][210/391]\tTime  0.091 ( 0.091)\tLoss 2.5030e+00 (1.9857e+00)\tAcc@1  57.81 ( 55.10)\tAcc@5  89.06 ( 82.01)\n",
            "Epoch: [52][240/391]\tTime  0.090 ( 0.091)\tLoss 2.9790e+00 (2.0071e+00)\tAcc@1  55.47 ( 55.10)\tAcc@5  81.25 ( 81.90)\n",
            "Epoch: [52][270/391]\tTime  0.093 ( 0.091)\tLoss 1.3013e+00 (2.0432e+00)\tAcc@1  64.06 ( 54.19)\tAcc@5  92.97 ( 81.15)\n",
            "Epoch: [52][300/391]\tTime  0.090 ( 0.091)\tLoss 1.3174e+00 (2.0460e+00)\tAcc@1  65.62 ( 53.97)\tAcc@5  90.62 ( 80.98)\n",
            "Epoch: [52][330/391]\tTime  0.091 ( 0.091)\tLoss 3.0392e+00 (2.0784e+00)\tAcc@1  28.12 ( 53.45)\tAcc@5  58.59 ( 80.55)\n",
            "Epoch: [52][360/391]\tTime  0.091 ( 0.091)\tLoss 3.3710e+00 (2.0705e+00)\tAcc@1  21.09 ( 53.36)\tAcc@5  42.97 ( 80.42)\n",
            "Epoch: [52][390/391]\tTime  0.081 ( 0.091)\tLoss 1.2323e+00 (2.0710e+00)\tAcc@1  67.50 ( 53.34)\tAcc@5  91.25 ( 80.42)\n",
            "==> Train Accuracy: Acc@1 53.344 || Acc@5 80.418\n",
            "==> Test Accuracy:  Acc@1 55.760 || Acc@5 83.550\n",
            "==> 37.95 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 53, lr: 0.1 -----\n",
            "Epoch: [53][  0/391]\tTime  0.232 ( 0.232)\tLoss 1.1922e+00 (1.1922e+00)\tAcc@1  67.97 ( 67.97)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [53][ 30/391]\tTime  0.090 ( 0.095)\tLoss 3.0386e+00 (2.1140e+00)\tAcc@1  25.00 ( 53.60)\tAcc@5  56.25 ( 81.33)\n",
            "Epoch: [53][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.2653e+00 (2.1154e+00)\tAcc@1  64.84 ( 53.79)\tAcc@5  90.62 ( 80.75)\n",
            "Epoch: [53][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.2423e+00 (2.1038e+00)\tAcc@1  64.06 ( 53.87)\tAcc@5  89.84 ( 80.55)\n",
            "Epoch: [53][120/391]\tTime  0.091 ( 0.092)\tLoss 3.1983e+00 (2.1289e+00)\tAcc@1  22.66 ( 52.38)\tAcc@5  55.47 ( 79.33)\n",
            "Epoch: [53][150/391]\tTime  0.091 ( 0.091)\tLoss 2.2804e+00 (2.1191e+00)\tAcc@1  67.19 ( 52.57)\tAcc@5  92.19 ( 79.39)\n",
            "Epoch: [53][180/391]\tTime  0.091 ( 0.091)\tLoss 2.9799e+00 (2.0828e+00)\tAcc@1  47.66 ( 53.01)\tAcc@5  76.56 ( 79.98)\n",
            "Epoch: [53][210/391]\tTime  0.091 ( 0.091)\tLoss 2.3937e+00 (2.1362e+00)\tAcc@1  60.94 ( 52.52)\tAcc@5  87.50 ( 79.70)\n",
            "Epoch: [53][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1972e+00 (2.1270e+00)\tAcc@1  64.84 ( 52.61)\tAcc@5  89.84 ( 79.89)\n",
            "Epoch: [53][270/391]\tTime  0.091 ( 0.091)\tLoss 2.8723e+00 (2.1184e+00)\tAcc@1  42.19 ( 52.90)\tAcc@5  71.09 ( 80.20)\n",
            "Epoch: [53][300/391]\tTime  0.090 ( 0.091)\tLoss 1.2353e+00 (2.1098e+00)\tAcc@1  73.44 ( 52.94)\tAcc@5  91.41 ( 80.21)\n",
            "Epoch: [53][330/391]\tTime  0.090 ( 0.091)\tLoss 2.9327e+00 (2.0978e+00)\tAcc@1  44.53 ( 53.13)\tAcc@5  75.78 ( 80.36)\n",
            "Epoch: [53][360/391]\tTime  0.091 ( 0.091)\tLoss 2.8188e+00 (2.1316e+00)\tAcc@1  57.03 ( 52.42)\tAcc@5  77.34 ( 79.73)\n",
            "Epoch: [53][390/391]\tTime  0.082 ( 0.091)\tLoss 2.7600e+00 (2.1420e+00)\tAcc@1  40.00 ( 52.13)\tAcc@5  75.00 ( 79.48)\n",
            "==> Train Accuracy: Acc@1 52.134 || Acc@5 79.484\n",
            "==> Test Accuracy:  Acc@1 57.520 || Acc@5 85.090\n",
            "==> 37.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 54, lr: 0.1 -----\n",
            "Epoch: [54][  0/391]\tTime  0.239 ( 0.239)\tLoss 1.2489e+00 (1.2489e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [54][ 30/391]\tTime  0.090 ( 0.096)\tLoss 3.2150e+00 (2.0517e+00)\tAcc@1  28.12 ( 52.37)\tAcc@5  62.50 ( 79.54)\n",
            "Epoch: [54][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.2051e+00 (2.0952e+00)\tAcc@1  67.97 ( 52.00)\tAcc@5  88.28 ( 79.02)\n",
            "Epoch: [54][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.0185e+00 (2.1274e+00)\tAcc@1  73.44 ( 51.80)\tAcc@5  92.97 ( 79.33)\n",
            "Epoch: [54][120/391]\tTime  0.090 ( 0.092)\tLoss 3.3406e+00 (2.1545e+00)\tAcc@1  24.22 ( 52.11)\tAcc@5  52.34 ( 79.45)\n",
            "Epoch: [54][150/391]\tTime  0.090 ( 0.091)\tLoss 2.8814e+00 (2.1524e+00)\tAcc@1  57.03 ( 52.30)\tAcc@5  76.56 ( 79.67)\n",
            "Epoch: [54][180/391]\tTime  0.088 ( 0.091)\tLoss 2.9616e+00 (2.1570e+00)\tAcc@1  46.09 ( 52.12)\tAcc@5  76.56 ( 79.57)\n",
            "Epoch: [54][210/391]\tTime  0.090 ( 0.091)\tLoss 1.1373e+00 (2.1809e+00)\tAcc@1  69.53 ( 51.45)\tAcc@5  94.53 ( 78.81)\n",
            "Epoch: [54][240/391]\tTime  0.090 ( 0.091)\tLoss 1.0368e+00 (2.1801e+00)\tAcc@1  65.62 ( 51.38)\tAcc@5  95.31 ( 78.80)\n",
            "Epoch: [54][270/391]\tTime  0.091 ( 0.091)\tLoss 2.9527e+00 (2.1732e+00)\tAcc@1  54.69 ( 51.70)\tAcc@5  80.47 ( 79.08)\n",
            "Epoch: [54][300/391]\tTime  0.091 ( 0.091)\tLoss 3.2424e+00 (2.1858e+00)\tAcc@1  18.75 ( 51.26)\tAcc@5  53.91 ( 78.70)\n",
            "Epoch: [54][330/391]\tTime  0.091 ( 0.091)\tLoss 3.2980e+00 (2.1680e+00)\tAcc@1  32.03 ( 51.59)\tAcc@5  58.59 ( 78.94)\n",
            "Epoch: [54][360/391]\tTime  0.090 ( 0.091)\tLoss 1.2323e+00 (2.1778e+00)\tAcc@1  65.62 ( 51.37)\tAcc@5  94.53 ( 78.82)\n",
            "Epoch: [54][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5252e+00 (2.1542e+00)\tAcc@1  58.75 ( 51.58)\tAcc@5  81.25 ( 79.01)\n",
            "==> Train Accuracy: Acc@1 51.582 || Acc@5 79.008\n",
            "==> Test Accuracy:  Acc@1 54.160 || Acc@5 83.430\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 55, lr: 0.1 -----\n",
            "Epoch: [55][  0/391]\tTime  0.246 ( 0.246)\tLoss 2.0888e+00 (2.0888e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [55][ 30/391]\tTime  0.091 ( 0.095)\tLoss 3.3328e+00 (2.1807e+00)\tAcc@1  35.16 ( 50.96)\tAcc@5  67.19 ( 78.53)\n",
            "Epoch: [55][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.0236e+00 (2.0830e+00)\tAcc@1  24.22 ( 53.00)\tAcc@5  54.69 ( 80.14)\n",
            "Epoch: [55][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.0199e+00 (2.1365e+00)\tAcc@1  67.19 ( 52.30)\tAcc@5  96.09 ( 79.40)\n",
            "Epoch: [55][120/391]\tTime  0.091 ( 0.092)\tLoss 2.4295e+00 (2.0710e+00)\tAcc@1  59.38 ( 53.64)\tAcc@5  86.72 ( 80.71)\n",
            "Epoch: [55][150/391]\tTime  0.091 ( 0.092)\tLoss 3.3336e+00 (2.0770e+00)\tAcc@1  29.69 ( 52.95)\tAcc@5  61.72 ( 80.20)\n",
            "Epoch: [55][180/391]\tTime  0.090 ( 0.091)\tLoss 3.0394e+00 (2.0988e+00)\tAcc@1  41.41 ( 52.69)\tAcc@5  71.88 ( 80.08)\n",
            "Epoch: [55][210/391]\tTime  0.091 ( 0.091)\tLoss 1.3551e+00 (2.0806e+00)\tAcc@1  61.72 ( 52.93)\tAcc@5  92.19 ( 80.33)\n",
            "Epoch: [55][240/391]\tTime  0.090 ( 0.091)\tLoss 3.1131e+00 (2.0813e+00)\tAcc@1  49.22 ( 52.73)\tAcc@5  81.25 ( 79.98)\n",
            "Epoch: [55][270/391]\tTime  0.090 ( 0.091)\tLoss 2.4445e+00 (2.0881e+00)\tAcc@1  58.59 ( 52.88)\tAcc@5  85.94 ( 80.08)\n",
            "Epoch: [55][300/391]\tTime  0.091 ( 0.091)\tLoss 1.1815e+00 (2.1072e+00)\tAcc@1  69.53 ( 52.58)\tAcc@5  91.41 ( 79.88)\n",
            "Epoch: [55][330/391]\tTime  0.090 ( 0.091)\tLoss 3.2305e+00 (2.1068e+00)\tAcc@1  18.75 ( 52.58)\tAcc@5  46.09 ( 79.86)\n",
            "Epoch: [55][360/391]\tTime  0.090 ( 0.091)\tLoss 1.3206e+00 (2.0973e+00)\tAcc@1  63.28 ( 52.59)\tAcc@5  88.28 ( 79.83)\n",
            "Epoch: [55][390/391]\tTime  0.082 ( 0.091)\tLoss 1.1443e+00 (2.1050e+00)\tAcc@1  68.75 ( 52.52)\tAcc@5  96.25 ( 79.79)\n",
            "==> Train Accuracy: Acc@1 52.524 || Acc@5 79.792\n",
            "==> Test Accuracy:  Acc@1 57.920 || Acc@5 85.250\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 56, lr: 0.1 -----\n",
            "Epoch: [56][  0/391]\tTime  0.231 ( 0.231)\tLoss 1.0629e+00 (1.0629e+00)\tAcc@1  70.31 ( 70.31)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [56][ 30/391]\tTime  0.091 ( 0.095)\tLoss 3.1343e+00 (1.9817e+00)\tAcc@1  28.12 ( 53.60)\tAcc@5  53.91 ( 79.94)\n",
            "Epoch: [56][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.0534e+00 (1.9828e+00)\tAcc@1  67.97 ( 53.97)\tAcc@5  93.75 ( 80.64)\n",
            "Epoch: [56][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.1796e+00 (1.9306e+00)\tAcc@1  67.19 ( 54.93)\tAcc@5  90.62 ( 81.36)\n",
            "Epoch: [56][120/391]\tTime  0.091 ( 0.092)\tLoss 2.9247e+00 (1.9922e+00)\tAcc@1  49.22 ( 54.25)\tAcc@5  78.12 ( 80.61)\n",
            "Epoch: [56][150/391]\tTime  0.089 ( 0.091)\tLoss 1.0412e+00 (2.0233e+00)\tAcc@1  69.53 ( 53.59)\tAcc@5  93.75 ( 80.26)\n",
            "Epoch: [56][180/391]\tTime  0.090 ( 0.091)\tLoss 1.1216e+00 (2.0410e+00)\tAcc@1  65.62 ( 53.35)\tAcc@5  93.75 ( 80.31)\n",
            "Epoch: [56][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5147e+00 (2.0302e+00)\tAcc@1  59.38 ( 53.21)\tAcc@5  85.94 ( 80.11)\n",
            "Epoch: [56][240/391]\tTime  0.092 ( 0.091)\tLoss 1.2332e+00 (2.0592e+00)\tAcc@1  67.97 ( 53.08)\tAcc@5  89.84 ( 80.05)\n",
            "Epoch: [56][270/391]\tTime  0.091 ( 0.091)\tLoss 3.2041e+00 (2.0747e+00)\tAcc@1  34.38 ( 52.74)\tAcc@5  64.06 ( 79.87)\n",
            "Epoch: [56][300/391]\tTime  0.091 ( 0.091)\tLoss 2.9586e+00 (2.1034e+00)\tAcc@1  39.06 ( 52.13)\tAcc@5  71.09 ( 79.32)\n",
            "Epoch: [56][330/391]\tTime  0.091 ( 0.091)\tLoss 2.9996e+00 (2.1052e+00)\tAcc@1  37.50 ( 51.91)\tAcc@5  67.97 ( 79.19)\n",
            "Epoch: [56][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1374e+00 (2.0959e+00)\tAcc@1  65.62 ( 51.92)\tAcc@5  90.62 ( 79.25)\n",
            "Epoch: [56][390/391]\tTime  0.082 ( 0.091)\tLoss 3.0115e+00 (2.1111e+00)\tAcc@1  41.25 ( 51.85)\tAcc@5  73.75 ( 79.23)\n",
            "==> Train Accuracy: Acc@1 51.850 || Acc@5 79.230\n",
            "==> Test Accuracy:  Acc@1 53.200 || Acc@5 80.910\n",
            "==> 37.95 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 57, lr: 0.1 -----\n",
            "Epoch: [57][  0/391]\tTime  0.246 ( 0.246)\tLoss 1.1015e+00 (1.1015e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [57][ 30/391]\tTime  0.091 ( 0.096)\tLoss 3.0061e+00 (1.9348e+00)\tAcc@1  32.81 ( 55.65)\tAcc@5  64.06 ( 82.64)\n",
            "Epoch: [57][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.8569e+00 (2.0176e+00)\tAcc@1  52.34 ( 53.79)\tAcc@5  85.16 ( 80.66)\n",
            "Epoch: [57][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3683e+00 (1.9858e+00)\tAcc@1  63.28 ( 54.05)\tAcc@5  94.53 ( 80.74)\n",
            "Epoch: [57][120/391]\tTime  0.090 ( 0.092)\tLoss 3.2885e+00 (2.0597e+00)\tAcc@1  17.19 ( 53.57)\tAcc@5  44.53 ( 80.24)\n",
            "Epoch: [57][150/391]\tTime  0.090 ( 0.091)\tLoss 1.2616e+00 (2.0740e+00)\tAcc@1  63.28 ( 52.86)\tAcc@5  89.84 ( 79.89)\n",
            "Epoch: [57][180/391]\tTime  0.091 ( 0.091)\tLoss 1.1067e+00 (2.0715e+00)\tAcc@1  69.53 ( 53.08)\tAcc@5  90.62 ( 79.88)\n",
            "Epoch: [57][210/391]\tTime  0.090 ( 0.091)\tLoss 1.1722e+00 (2.0872e+00)\tAcc@1  67.97 ( 52.69)\tAcc@5  92.19 ( 79.46)\n",
            "Epoch: [57][240/391]\tTime  0.091 ( 0.091)\tLoss 3.0341e+00 (2.0865e+00)\tAcc@1  40.62 ( 52.62)\tAcc@5  72.66 ( 79.49)\n",
            "Epoch: [57][270/391]\tTime  0.091 ( 0.091)\tLoss 3.0934e+00 (2.1031e+00)\tAcc@1  40.62 ( 52.46)\tAcc@5  71.09 ( 79.42)\n",
            "Epoch: [57][300/391]\tTime  0.091 ( 0.091)\tLoss 1.2100e+00 (2.0791e+00)\tAcc@1  66.41 ( 52.90)\tAcc@5  89.06 ( 79.83)\n",
            "Epoch: [57][330/391]\tTime  0.090 ( 0.091)\tLoss 2.9974e+00 (2.0787e+00)\tAcc@1  43.75 ( 52.68)\tAcc@5  68.75 ( 79.79)\n",
            "Epoch: [57][360/391]\tTime  0.087 ( 0.091)\tLoss 1.2095e+00 (2.0923e+00)\tAcc@1  66.41 ( 52.28)\tAcc@5  91.41 ( 79.47)\n",
            "Epoch: [57][390/391]\tTime  0.081 ( 0.091)\tLoss 9.5315e-01 (2.1031e+00)\tAcc@1  76.25 ( 52.04)\tAcc@5  95.00 ( 79.28)\n",
            "==> Train Accuracy: Acc@1 52.040 || Acc@5 79.282\n",
            "==> Test Accuracy:  Acc@1 54.680 || Acc@5 82.980\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 58, lr: 0.1 -----\n",
            "Epoch: [58][  0/391]\tTime  0.234 ( 0.234)\tLoss 1.0916e+00 (1.0916e+00)\tAcc@1  69.53 ( 69.53)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [58][ 30/391]\tTime  0.090 ( 0.095)\tLoss 9.2175e-01 (2.1518e+00)\tAcc@1  67.19 ( 52.92)\tAcc@5  97.66 ( 79.84)\n",
            "Epoch: [58][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.1603e+00 (2.0103e+00)\tAcc@1  64.06 ( 54.52)\tAcc@5  92.19 ( 81.98)\n",
            "Epoch: [58][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.3127e+00 (2.0077e+00)\tAcc@1  67.19 ( 54.75)\tAcc@5  89.84 ( 81.91)\n",
            "Epoch: [58][120/391]\tTime  0.089 ( 0.092)\tLoss 1.3013e+00 (2.0756e+00)\tAcc@1  66.41 ( 53.07)\tAcc@5  87.50 ( 80.32)\n",
            "Epoch: [58][150/391]\tTime  0.093 ( 0.091)\tLoss 3.2219e+00 (2.1576e+00)\tAcc@1  36.72 ( 51.57)\tAcc@5  71.09 ( 79.18)\n",
            "Epoch: [58][180/391]\tTime  0.091 ( 0.091)\tLoss 3.1243e+00 (2.1310e+00)\tAcc@1  37.50 ( 51.83)\tAcc@5  68.75 ( 79.26)\n",
            "Epoch: [58][210/391]\tTime  0.091 ( 0.091)\tLoss 3.0622e+00 (2.1522e+00)\tAcc@1  32.03 ( 51.54)\tAcc@5  61.72 ( 78.82)\n",
            "Epoch: [58][240/391]\tTime  0.086 ( 0.091)\tLoss 3.3495e+00 (2.1586e+00)\tAcc@1  21.09 ( 51.23)\tAcc@5  48.44 ( 78.57)\n",
            "Epoch: [58][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3337e+00 (2.1728e+00)\tAcc@1  63.28 ( 51.11)\tAcc@5  89.06 ( 78.43)\n",
            "Epoch: [58][300/391]\tTime  0.091 ( 0.091)\tLoss 1.0962e+00 (2.1664e+00)\tAcc@1  66.41 ( 51.06)\tAcc@5  92.97 ( 78.48)\n",
            "Epoch: [58][330/391]\tTime  0.090 ( 0.091)\tLoss 1.3516e+00 (2.1548e+00)\tAcc@1  60.94 ( 51.35)\tAcc@5  87.50 ( 78.85)\n",
            "Epoch: [58][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4602e+00 (2.1613e+00)\tAcc@1  63.28 ( 51.17)\tAcc@5  84.38 ( 78.74)\n",
            "Epoch: [58][390/391]\tTime  0.082 ( 0.091)\tLoss 3.1921e+00 (2.1712e+00)\tAcc@1  28.75 ( 51.24)\tAcc@5  63.75 ( 78.83)\n",
            "==> Train Accuracy: Acc@1 51.244 || Acc@5 78.834\n",
            "==> Test Accuracy:  Acc@1 57.320 || Acc@5 84.560\n",
            "==> 37.91 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 59, lr: 0.1 -----\n",
            "Epoch: [59][  0/391]\tTime  0.244 ( 0.244)\tLoss 1.0645e+00 (1.0645e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [59][ 30/391]\tTime  0.088 ( 0.095)\tLoss 1.0484e+00 (1.8280e+00)\tAcc@1  69.53 ( 58.57)\tAcc@5  91.41 ( 84.12)\n",
            "Epoch: [59][ 60/391]\tTime  0.091 ( 0.093)\tLoss 3.0158e+00 (1.9313e+00)\tAcc@1  29.69 ( 55.57)\tAcc@5  60.16 ( 81.86)\n",
            "Epoch: [59][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.2035e+00 (1.9363e+00)\tAcc@1  25.00 ( 55.98)\tAcc@5  57.81 ( 82.61)\n",
            "Epoch: [59][120/391]\tTime  0.091 ( 0.092)\tLoss 3.0273e+00 (2.0271e+00)\tAcc@1  35.94 ( 53.62)\tAcc@5  67.97 ( 80.86)\n",
            "Epoch: [59][150/391]\tTime  0.090 ( 0.091)\tLoss 1.3231e+00 (2.0586e+00)\tAcc@1  60.94 ( 53.30)\tAcc@5  89.84 ( 80.59)\n",
            "Epoch: [59][180/391]\tTime  0.090 ( 0.091)\tLoss 3.2613e+00 (2.1210e+00)\tAcc@1  43.75 ( 52.60)\tAcc@5  74.22 ( 79.99)\n",
            "Epoch: [59][210/391]\tTime  0.093 ( 0.091)\tLoss 1.1835e+00 (2.1142e+00)\tAcc@1  67.97 ( 52.64)\tAcc@5  92.19 ( 79.95)\n",
            "Epoch: [59][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1392e+00 (2.1245e+00)\tAcc@1  65.62 ( 52.42)\tAcc@5  89.84 ( 79.72)\n",
            "Epoch: [59][270/391]\tTime  0.089 ( 0.091)\tLoss 1.1892e+00 (2.1287e+00)\tAcc@1  64.06 ( 52.34)\tAcc@5  92.19 ( 79.61)\n",
            "Epoch: [59][300/391]\tTime  0.090 ( 0.091)\tLoss 1.2915e+00 (2.1278e+00)\tAcc@1  66.41 ( 52.49)\tAcc@5  90.62 ( 79.75)\n",
            "Epoch: [59][330/391]\tTime  0.090 ( 0.091)\tLoss 3.1230e+00 (2.1409e+00)\tAcc@1  29.69 ( 52.32)\tAcc@5  61.72 ( 79.67)\n",
            "Epoch: [59][360/391]\tTime  0.091 ( 0.091)\tLoss 3.3861e+00 (2.1381e+00)\tAcc@1  27.34 ( 52.40)\tAcc@5  59.38 ( 79.82)\n",
            "Epoch: [59][390/391]\tTime  0.082 ( 0.091)\tLoss 2.9072e+00 (2.1416e+00)\tAcc@1  42.50 ( 52.32)\tAcc@5  67.50 ( 79.63)\n",
            "==> Train Accuracy: Acc@1 52.320 || Acc@5 79.632\n",
            "==> Test Accuracy:  Acc@1 49.740 || Acc@5 78.640\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 60, lr: 0.020000000000000004 -----\n",
            "Epoch: [60][  0/391]\tTime  0.244 ( 0.244)\tLoss 1.2011e+00 (1.2011e+00)\tAcc@1  68.75 ( 68.75)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [60][ 30/391]\tTime  0.092 ( 0.095)\tLoss 3.0680e+00 (2.2659e+00)\tAcc@1  16.41 ( 50.96)\tAcc@5  47.66 ( 77.09)\n",
            "Epoch: [60][ 60/391]\tTime  0.090 ( 0.093)\tLoss 9.4021e-01 (2.1135e+00)\tAcc@1  75.00 ( 55.02)\tAcc@5  91.41 ( 80.64)\n",
            "Epoch: [60][ 90/391]\tTime  0.090 ( 0.092)\tLoss 9.0780e-01 (2.0017e+00)\tAcc@1  71.09 ( 56.59)\tAcc@5  94.53 ( 81.92)\n",
            "Epoch: [60][120/391]\tTime  0.093 ( 0.092)\tLoss 2.7636e+00 (1.9519e+00)\tAcc@1  46.88 ( 57.35)\tAcc@5  71.88 ( 82.43)\n",
            "Epoch: [60][150/391]\tTime  0.090 ( 0.092)\tLoss 7.2673e-01 (1.8955e+00)\tAcc@1  78.12 ( 58.62)\tAcc@5  96.88 ( 83.43)\n",
            "Epoch: [60][180/391]\tTime  0.089 ( 0.092)\tLoss 6.8718e-01 (1.8192e+00)\tAcc@1  79.69 ( 60.21)\tAcc@5  95.31 ( 84.50)\n",
            "Epoch: [60][210/391]\tTime  0.090 ( 0.091)\tLoss 2.6154e+00 (1.8361e+00)\tAcc@1  42.19 ( 59.72)\tAcc@5  74.22 ( 84.13)\n",
            "Epoch: [60][240/391]\tTime  0.089 ( 0.091)\tLoss 2.9212e+00 (1.8177e+00)\tAcc@1  51.56 ( 59.96)\tAcc@5  78.91 ( 84.35)\n",
            "Epoch: [60][270/391]\tTime  0.090 ( 0.091)\tLoss 7.5389e-01 (1.8063e+00)\tAcc@1  79.69 ( 60.33)\tAcc@5  93.75 ( 84.49)\n",
            "Epoch: [60][300/391]\tTime  0.091 ( 0.091)\tLoss 2.6074e+00 (1.7862e+00)\tAcc@1  42.19 ( 60.44)\tAcc@5  75.78 ( 84.55)\n",
            "Epoch: [60][330/391]\tTime  0.091 ( 0.091)\tLoss 2.6230e+00 (1.7916e+00)\tAcc@1  56.25 ( 60.58)\tAcc@5  85.94 ( 84.67)\n",
            "Epoch: [60][360/391]\tTime  0.090 ( 0.091)\tLoss 2.7297e+00 (1.7962e+00)\tAcc@1  43.75 ( 60.43)\tAcc@5  75.78 ( 84.60)\n",
            "Epoch: [60][390/391]\tTime  0.082 ( 0.091)\tLoss 2.8992e+00 (1.7939e+00)\tAcc@1  18.75 ( 60.50)\tAcc@5  53.75 ( 84.66)\n",
            "==> Train Accuracy: Acc@1 60.500 || Acc@5 84.658\n",
            "==> Test Accuracy:  Acc@1 71.060 || Acc@5 92.940\n",
            "==> 38.07 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 61, lr: 0.020000000000000004 -----\n",
            "Epoch: [61][  0/391]\tTime  0.255 ( 0.255)\tLoss 2.6415e+00 (2.6415e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [61][ 30/391]\tTime  0.090 ( 0.096)\tLoss 5.2510e-01 (1.3024e+00)\tAcc@1  85.94 ( 67.39)\tAcc@5  99.22 ( 88.10)\n",
            "Epoch: [61][ 60/391]\tTime  0.092 ( 0.093)\tLoss 2.5626e+00 (1.5103e+00)\tAcc@1  57.81 ( 66.11)\tAcc@5  75.78 ( 87.74)\n",
            "Epoch: [61][ 90/391]\tTime  0.089 ( 0.092)\tLoss 6.8915e-01 (1.5468e+00)\tAcc@1  81.25 ( 66.38)\tAcc@5  95.31 ( 88.02)\n",
            "Epoch: [61][120/391]\tTime  0.090 ( 0.092)\tLoss 6.1725e-01 (1.5834e+00)\tAcc@1  82.03 ( 66.08)\tAcc@5  96.09 ( 88.07)\n",
            "Epoch: [61][150/391]\tTime  0.090 ( 0.092)\tLoss 2.4036e+00 (1.5768e+00)\tAcc@1  58.59 ( 66.28)\tAcc@5  84.38 ( 88.16)\n",
            "Epoch: [61][180/391]\tTime  0.090 ( 0.091)\tLoss 2.6147e+00 (1.5978e+00)\tAcc@1  48.44 ( 65.91)\tAcc@5  76.56 ( 88.00)\n",
            "Epoch: [61][210/391]\tTime  0.090 ( 0.091)\tLoss 6.1129e-01 (1.6170e+00)\tAcc@1  80.47 ( 65.34)\tAcc@5  98.44 ( 87.71)\n",
            "Epoch: [61][240/391]\tTime  0.091 ( 0.091)\tLoss 2.7829e+00 (1.6069e+00)\tAcc@1  56.25 ( 65.51)\tAcc@5  84.38 ( 87.84)\n",
            "Epoch: [61][270/391]\tTime  0.091 ( 0.091)\tLoss 2.6604e+00 (1.6165e+00)\tAcc@1  56.25 ( 65.29)\tAcc@5  88.28 ( 87.78)\n",
            "Epoch: [61][300/391]\tTime  0.090 ( 0.091)\tLoss 6.9975e-01 (1.5972e+00)\tAcc@1  81.25 ( 65.48)\tAcc@5  94.53 ( 87.99)\n",
            "Epoch: [61][330/391]\tTime  0.090 ( 0.091)\tLoss 2.6667e+00 (1.6171e+00)\tAcc@1  50.78 ( 64.97)\tAcc@5  77.34 ( 87.60)\n",
            "Epoch: [61][360/391]\tTime  0.090 ( 0.091)\tLoss 5.6566e-01 (1.6157e+00)\tAcc@1  84.38 ( 65.04)\tAcc@5  99.22 ( 87.72)\n",
            "Epoch: [61][390/391]\tTime  0.081 ( 0.091)\tLoss 8.2890e-01 (1.6089e+00)\tAcc@1  80.00 ( 65.12)\tAcc@5  95.00 ( 87.73)\n",
            "==> Train Accuracy: Acc@1 65.116 || Acc@5 87.730\n",
            "==> Test Accuracy:  Acc@1 71.500 || Acc@5 92.750\n",
            "==> 37.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 62, lr: 0.020000000000000004 -----\n",
            "Epoch: [62][  0/391]\tTime  0.259 ( 0.259)\tLoss 2.5385e+00 (2.5385e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [62][ 30/391]\tTime  0.090 ( 0.097)\tLoss 6.3733e-01 (1.7074e+00)\tAcc@1  81.25 ( 63.41)\tAcc@5  93.75 ( 86.57)\n",
            "Epoch: [62][ 60/391]\tTime  0.089 ( 0.093)\tLoss 2.2217e+00 (1.6468e+00)\tAcc@1  76.56 ( 66.44)\tAcc@5  96.88 ( 88.63)\n",
            "Epoch: [62][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.8626e+00 (1.6509e+00)\tAcc@1  17.97 ( 65.74)\tAcc@5  58.59 ( 88.07)\n",
            "Epoch: [62][120/391]\tTime  0.090 ( 0.092)\tLoss 2.7791e+00 (1.6346e+00)\tAcc@1  25.78 ( 65.37)\tAcc@5  64.06 ( 88.07)\n",
            "Epoch: [62][150/391]\tTime  0.090 ( 0.092)\tLoss 6.4028e-01 (1.5977e+00)\tAcc@1  83.59 ( 65.82)\tAcc@5  96.09 ( 88.37)\n",
            "Epoch: [62][180/391]\tTime  0.090 ( 0.091)\tLoss 2.6661e+00 (1.6344e+00)\tAcc@1  53.91 ( 65.64)\tAcc@5  76.56 ( 88.31)\n",
            "Epoch: [62][210/391]\tTime  0.088 ( 0.091)\tLoss 2.4035e+00 (1.6428e+00)\tAcc@1  67.19 ( 65.52)\tAcc@5  92.97 ( 88.24)\n",
            "Epoch: [62][240/391]\tTime  0.090 ( 0.091)\tLoss 6.2753e-01 (1.6426e+00)\tAcc@1  80.47 ( 65.57)\tAcc@5  97.66 ( 88.22)\n",
            "Epoch: [62][270/391]\tTime  0.089 ( 0.091)\tLoss 7.6175e-01 (1.6202e+00)\tAcc@1  75.00 ( 65.82)\tAcc@5  96.88 ( 88.26)\n",
            "Epoch: [62][300/391]\tTime  0.091 ( 0.091)\tLoss 2.3912e+00 (1.6118e+00)\tAcc@1  56.25 ( 65.75)\tAcc@5  84.38 ( 88.24)\n",
            "Epoch: [62][330/391]\tTime  0.090 ( 0.091)\tLoss 5.0911e-01 (1.6156e+00)\tAcc@1  85.16 ( 66.06)\tAcc@5  97.66 ( 88.38)\n",
            "Epoch: [62][360/391]\tTime  0.090 ( 0.091)\tLoss 2.5541e+00 (1.6077e+00)\tAcc@1  53.12 ( 66.04)\tAcc@5  79.69 ( 88.45)\n",
            "Epoch: [62][390/391]\tTime  0.082 ( 0.091)\tLoss 2.4351e+00 (1.6274e+00)\tAcc@1  51.25 ( 65.31)\tAcc@5  86.25 ( 87.94)\n",
            "==> Train Accuracy: Acc@1 65.306 || Acc@5 87.940\n",
            "==> Test Accuracy:  Acc@1 70.890 || Acc@5 92.550\n",
            "==> 37.95 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 63, lr: 0.020000000000000004 -----\n",
            "Epoch: [63][  0/391]\tTime  0.244 ( 0.244)\tLoss 2.4627e+00 (2.4627e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [63][ 30/391]\tTime  0.090 ( 0.095)\tLoss 2.6686e+00 (1.6685e+00)\tAcc@1  38.28 ( 63.05)\tAcc@5  67.97 ( 86.54)\n",
            "Epoch: [63][ 60/391]\tTime  0.089 ( 0.093)\tLoss 2.6508e+00 (1.6621e+00)\tAcc@1  35.94 ( 64.31)\tAcc@5  68.75 ( 87.50)\n",
            "Epoch: [63][ 90/391]\tTime  0.090 ( 0.092)\tLoss 7.5577e-01 (1.7065e+00)\tAcc@1  82.81 ( 64.08)\tAcc@5  95.31 ( 87.16)\n",
            "Epoch: [63][120/391]\tTime  0.091 ( 0.092)\tLoss 4.1360e-01 (1.6483e+00)\tAcc@1  88.28 ( 65.37)\tAcc@5  98.44 ( 87.59)\n",
            "Epoch: [63][150/391]\tTime  0.090 ( 0.091)\tLoss 7.8047e-01 (1.6230e+00)\tAcc@1  77.34 ( 66.23)\tAcc@5  96.09 ( 88.03)\n",
            "Epoch: [63][180/391]\tTime  0.093 ( 0.091)\tLoss 2.6033e+00 (1.5689e+00)\tAcc@1  53.91 ( 66.50)\tAcc@5  86.72 ( 88.19)\n",
            "Epoch: [63][210/391]\tTime  0.090 ( 0.091)\tLoss 5.8519e-01 (1.5583e+00)\tAcc@1  81.25 ( 66.61)\tAcc@5  97.66 ( 88.35)\n",
            "Epoch: [63][240/391]\tTime  0.090 ( 0.091)\tLoss 5.6441e-01 (1.5946e+00)\tAcc@1  84.38 ( 66.25)\tAcc@5  96.09 ( 88.25)\n",
            "Epoch: [63][270/391]\tTime  0.090 ( 0.091)\tLoss 2.6233e+00 (1.6031e+00)\tAcc@1  56.25 ( 66.05)\tAcc@5  89.84 ( 88.14)\n",
            "Epoch: [63][300/391]\tTime  0.090 ( 0.091)\tLoss 5.6226e-01 (1.6220e+00)\tAcc@1  82.81 ( 65.78)\tAcc@5  96.88 ( 88.04)\n",
            "Epoch: [63][330/391]\tTime  0.091 ( 0.091)\tLoss 2.7625e+00 (1.6406e+00)\tAcc@1  31.25 ( 65.51)\tAcc@5  62.50 ( 87.88)\n",
            "Epoch: [63][360/391]\tTime  0.092 ( 0.091)\tLoss 2.5960e+00 (1.6695e+00)\tAcc@1  61.72 ( 64.89)\tAcc@5  89.06 ( 87.62)\n",
            "Epoch: [63][390/391]\tTime  0.082 ( 0.091)\tLoss 6.2205e-01 (1.6395e+00)\tAcc@1  81.25 ( 65.48)\tAcc@5  98.75 ( 87.92)\n",
            "==> Train Accuracy: Acc@1 65.476 || Acc@5 87.924\n",
            "==> Test Accuracy:  Acc@1 72.710 || Acc@5 93.350\n",
            "==> 37.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 64, lr: 0.020000000000000004 -----\n",
            "Epoch: [64][  0/391]\tTime  0.231 ( 0.231)\tLoss 7.5143e-01 (7.5143e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [64][ 30/391]\tTime  0.091 ( 0.095)\tLoss 4.2513e-01 (1.3609e+00)\tAcc@1  84.38 ( 70.34)\tAcc@5  99.22 ( 90.25)\n",
            "Epoch: [64][ 60/391]\tTime  0.090 ( 0.093)\tLoss 5.0012e-01 (1.4512e+00)\tAcc@1  84.38 ( 69.43)\tAcc@5  97.66 ( 90.09)\n",
            "Epoch: [64][ 90/391]\tTime  0.092 ( 0.092)\tLoss 2.7189e+00 (1.4854e+00)\tAcc@1  50.78 ( 68.25)\tAcc@5  84.38 ( 89.58)\n",
            "Epoch: [64][120/391]\tTime  0.089 ( 0.092)\tLoss 4.5374e-01 (1.4664e+00)\tAcc@1  85.94 ( 68.86)\tAcc@5  97.66 ( 89.78)\n",
            "Epoch: [64][150/391]\tTime  0.090 ( 0.091)\tLoss 5.8129e-01 (1.4603e+00)\tAcc@1  82.81 ( 68.96)\tAcc@5  98.44 ( 89.92)\n",
            "Epoch: [64][180/391]\tTime  0.092 ( 0.091)\tLoss 5.0633e-01 (1.4885e+00)\tAcc@1  84.38 ( 68.31)\tAcc@5  99.22 ( 89.60)\n",
            "Epoch: [64][210/391]\tTime  0.091 ( 0.091)\tLoss 2.1948e+00 (1.5457e+00)\tAcc@1  59.38 ( 67.45)\tAcc@5  87.50 ( 89.21)\n",
            "Epoch: [64][240/391]\tTime  0.091 ( 0.091)\tLoss 7.8872e-01 (1.5118e+00)\tAcc@1  76.56 ( 67.93)\tAcc@5  95.31 ( 89.45)\n",
            "Epoch: [64][270/391]\tTime  0.090 ( 0.091)\tLoss 3.7388e-01 (1.5437e+00)\tAcc@1  88.28 ( 67.31)\tAcc@5 100.00 ( 89.15)\n",
            "Epoch: [64][300/391]\tTime  0.088 ( 0.091)\tLoss 2.4058e+00 (1.5283e+00)\tAcc@1  74.22 ( 67.79)\tAcc@5  89.84 ( 89.34)\n",
            "Epoch: [64][330/391]\tTime  0.090 ( 0.091)\tLoss 6.1594e-01 (1.5277e+00)\tAcc@1  81.25 ( 67.78)\tAcc@5  96.88 ( 89.39)\n",
            "Epoch: [64][360/391]\tTime  0.091 ( 0.091)\tLoss 2.8548e+00 (1.5280e+00)\tAcc@1  31.25 ( 67.67)\tAcc@5  61.72 ( 89.28)\n",
            "Epoch: [64][390/391]\tTime  0.082 ( 0.091)\tLoss 2.5404e+00 (1.5162e+00)\tAcc@1  51.25 ( 67.83)\tAcc@5  82.50 ( 89.38)\n",
            "==> Train Accuracy: Acc@1 67.834 || Acc@5 89.382\n",
            "==> Test Accuracy:  Acc@1 73.500 || Acc@5 93.440\n",
            "==> 37.90 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 65, lr: 0.020000000000000004 -----\n",
            "Epoch: [65][  0/391]\tTime  0.276 ( 0.276)\tLoss 2.7406e+00 (2.7406e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [65][ 30/391]\tTime  0.090 ( 0.096)\tLoss 5.0184e-01 (1.3939e+00)\tAcc@1  82.81 ( 69.51)\tAcc@5  97.66 ( 90.47)\n",
            "Epoch: [65][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.5540e+00 (1.5942e+00)\tAcc@1  43.75 ( 66.29)\tAcc@5  80.47 ( 88.50)\n",
            "Epoch: [65][ 90/391]\tTime  0.090 ( 0.092)\tLoss 5.9990e-01 (1.5861e+00)\tAcc@1  82.81 ( 66.35)\tAcc@5  96.88 ( 88.33)\n",
            "Epoch: [65][120/391]\tTime  0.090 ( 0.092)\tLoss 5.7267e-01 (1.5505e+00)\tAcc@1  85.94 ( 67.12)\tAcc@5  98.44 ( 88.82)\n",
            "Epoch: [65][150/391]\tTime  0.090 ( 0.092)\tLoss 4.3539e-01 (1.5230e+00)\tAcc@1  89.84 ( 67.51)\tAcc@5  99.22 ( 89.00)\n",
            "Epoch: [65][180/391]\tTime  0.091 ( 0.091)\tLoss 2.3130e+00 (1.4587e+00)\tAcc@1  71.09 ( 68.75)\tAcc@5  90.62 ( 89.70)\n",
            "Epoch: [65][210/391]\tTime  0.091 ( 0.091)\tLoss 2.2456e+00 (1.5100e+00)\tAcc@1  74.22 ( 67.82)\tAcc@5  92.97 ( 89.26)\n",
            "Epoch: [65][240/391]\tTime  0.090 ( 0.091)\tLoss 2.4854e+00 (1.5110e+00)\tAcc@1  68.75 ( 68.12)\tAcc@5  90.62 ( 89.43)\n",
            "Epoch: [65][270/391]\tTime  0.090 ( 0.091)\tLoss 2.3203e+00 (1.4972e+00)\tAcc@1  57.03 ( 68.27)\tAcc@5  85.16 ( 89.55)\n",
            "Epoch: [65][300/391]\tTime  0.090 ( 0.091)\tLoss 5.4152e-01 (1.4883e+00)\tAcc@1  82.81 ( 68.21)\tAcc@5  96.88 ( 89.46)\n",
            "Epoch: [65][330/391]\tTime  0.090 ( 0.091)\tLoss 4.7958e-01 (1.4637e+00)\tAcc@1  89.06 ( 68.70)\tAcc@5  97.66 ( 89.77)\n",
            "Epoch: [65][360/391]\tTime  0.090 ( 0.091)\tLoss 4.7034e-01 (1.4813e+00)\tAcc@1  87.50 ( 68.61)\tAcc@5  99.22 ( 89.75)\n",
            "Epoch: [65][390/391]\tTime  0.081 ( 0.091)\tLoss 5.6903e-01 (1.4607e+00)\tAcc@1  83.75 ( 68.90)\tAcc@5  97.50 ( 89.93)\n",
            "==> Train Accuracy: Acc@1 68.902 || Acc@5 89.926\n",
            "==> Test Accuracy:  Acc@1 72.270 || Acc@5 92.920\n",
            "==> 37.94 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 66, lr: 0.020000000000000004 -----\n",
            "Epoch: [66][  0/391]\tTime  0.247 ( 0.247)\tLoss 2.6531e+00 (2.6531e+00)\tAcc@1  30.47 ( 30.47)\tAcc@5  63.28 ( 63.28)\n",
            "Epoch: [66][ 30/391]\tTime  0.090 ( 0.095)\tLoss 3.3578e-01 (1.5930e+00)\tAcc@1  91.41 ( 68.60)\tAcc@5  98.44 ( 90.85)\n",
            "Epoch: [66][ 60/391]\tTime  0.090 ( 0.093)\tLoss 4.5726e-01 (1.5475e+00)\tAcc@1  89.84 ( 68.90)\tAcc@5  98.44 ( 90.38)\n",
            "Epoch: [66][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.6825e-01 (1.5131e+00)\tAcc@1  87.50 ( 69.26)\tAcc@5  97.66 ( 90.33)\n",
            "Epoch: [66][120/391]\tTime  0.090 ( 0.092)\tLoss 4.9860e-01 (1.5717e+00)\tAcc@1  83.59 ( 67.15)\tAcc@5  96.88 ( 89.05)\n",
            "Epoch: [66][150/391]\tTime  0.091 ( 0.091)\tLoss 2.4399e+00 (1.5234e+00)\tAcc@1  42.97 ( 67.34)\tAcc@5  78.12 ( 88.93)\n",
            "Epoch: [66][180/391]\tTime  0.090 ( 0.091)\tLoss 6.9994e-01 (1.4930e+00)\tAcc@1  81.25 ( 67.68)\tAcc@5  96.09 ( 89.19)\n",
            "Epoch: [66][210/391]\tTime  0.091 ( 0.091)\tLoss 2.5077e+00 (1.5036e+00)\tAcc@1  40.62 ( 67.52)\tAcc@5  77.34 ( 89.14)\n",
            "Epoch: [66][240/391]\tTime  0.091 ( 0.091)\tLoss 4.5905e-01 (1.5164e+00)\tAcc@1  86.72 ( 67.40)\tAcc@5  98.44 ( 89.11)\n",
            "Epoch: [66][270/391]\tTime  0.091 ( 0.091)\tLoss 2.6753e+00 (1.5235e+00)\tAcc@1  47.66 ( 67.40)\tAcc@5  83.59 ( 89.08)\n",
            "Epoch: [66][300/391]\tTime  0.090 ( 0.091)\tLoss 2.6600e+00 (1.5177e+00)\tAcc@1  29.69 ( 67.56)\tAcc@5  55.47 ( 89.18)\n",
            "Epoch: [66][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9064e+00 (1.5089e+00)\tAcc@1  79.69 ( 67.74)\tAcc@5  97.66 ( 89.25)\n",
            "Epoch: [66][360/391]\tTime  0.090 ( 0.091)\tLoss 4.8723e-01 (1.4907e+00)\tAcc@1  85.16 ( 67.99)\tAcc@5  98.44 ( 89.42)\n",
            "Epoch: [66][390/391]\tTime  0.081 ( 0.091)\tLoss 5.9786e-01 (1.4771e+00)\tAcc@1  82.50 ( 68.29)\tAcc@5  96.25 ( 89.62)\n",
            "==> Train Accuracy: Acc@1 68.288 || Acc@5 89.618\n",
            "==> Test Accuracy:  Acc@1 73.000 || Acc@5 93.010\n",
            "==> 37.92 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 67, lr: 0.020000000000000004 -----\n",
            "Epoch: [67][  0/391]\tTime  0.228 ( 0.228)\tLoss 3.6709e-01 (3.6709e-01)\tAcc@1  92.19 ( 92.19)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [67][ 30/391]\tTime  0.090 ( 0.095)\tLoss 4.7309e-01 (1.6032e+00)\tAcc@1  84.38 ( 69.03)\tAcc@5  98.44 ( 90.57)\n",
            "Epoch: [67][ 60/391]\tTime  0.090 ( 0.093)\tLoss 5.5259e-01 (1.5572e+00)\tAcc@1  80.47 ( 69.34)\tAcc@5  97.66 ( 90.27)\n",
            "Epoch: [67][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.9361e-01 (1.5640e+00)\tAcc@1  84.38 ( 67.72)\tAcc@5  97.66 ( 89.48)\n",
            "Epoch: [67][120/391]\tTime  0.089 ( 0.092)\tLoss 4.0770e-01 (1.5039e+00)\tAcc@1  86.72 ( 68.93)\tAcc@5 100.00 ( 90.00)\n",
            "Epoch: [67][150/391]\tTime  0.091 ( 0.091)\tLoss 2.6638e+00 (1.4250e+00)\tAcc@1  41.41 ( 69.66)\tAcc@5  75.00 ( 90.16)\n",
            "Epoch: [67][180/391]\tTime  0.090 ( 0.091)\tLoss 2.5113e+00 (1.4182e+00)\tAcc@1  59.38 ( 69.71)\tAcc@5  84.38 ( 90.19)\n",
            "Epoch: [67][210/391]\tTime  0.091 ( 0.091)\tLoss 2.7150e+00 (1.4122e+00)\tAcc@1  48.44 ( 70.25)\tAcc@5  74.22 ( 90.54)\n",
            "Epoch: [67][240/391]\tTime  0.091 ( 0.091)\tLoss 2.5455e+00 (1.4443e+00)\tAcc@1  31.25 ( 69.49)\tAcc@5  72.66 ( 90.13)\n",
            "Epoch: [67][270/391]\tTime  0.093 ( 0.091)\tLoss 2.4190e+00 (1.4399e+00)\tAcc@1  40.62 ( 69.73)\tAcc@5  78.91 ( 90.31)\n",
            "Epoch: [67][300/391]\tTime  0.091 ( 0.091)\tLoss 2.8015e+00 (1.4548e+00)\tAcc@1  25.00 ( 69.42)\tAcc@5  54.69 ( 90.13)\n",
            "Epoch: [67][330/391]\tTime  0.090 ( 0.091)\tLoss 3.7413e-01 (1.4574e+00)\tAcc@1  89.06 ( 69.26)\tAcc@5  99.22 ( 90.06)\n",
            "Epoch: [67][360/391]\tTime  0.090 ( 0.091)\tLoss 5.5572e-01 (1.4569e+00)\tAcc@1  78.91 ( 69.13)\tAcc@5  99.22 ( 89.98)\n",
            "Epoch: [67][390/391]\tTime  0.082 ( 0.091)\tLoss 2.5314e+00 (1.4765e+00)\tAcc@1  47.50 ( 68.80)\tAcc@5  91.25 ( 89.86)\n",
            "==> Train Accuracy: Acc@1 68.798 || Acc@5 89.860\n",
            "==> Test Accuracy:  Acc@1 72.050 || Acc@5 92.780\n",
            "==> 37.92 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 68, lr: 0.020000000000000004 -----\n",
            "Epoch: [68][  0/391]\tTime  0.243 ( 0.243)\tLoss 5.7226e-01 (5.7226e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [68][ 30/391]\tTime  0.095 ( 0.095)\tLoss 2.3913e+00 (1.3972e+00)\tAcc@1  59.38 ( 72.38)\tAcc@5  82.81 ( 91.10)\n",
            "Epoch: [68][ 60/391]\tTime  0.091 ( 0.093)\tLoss 4.4240e-01 (1.3817e+00)\tAcc@1  87.50 ( 71.93)\tAcc@5  96.88 ( 91.36)\n",
            "Epoch: [68][ 90/391]\tTime  0.090 ( 0.092)\tLoss 5.0592e-01 (1.3731e+00)\tAcc@1  84.38 ( 72.00)\tAcc@5  98.44 ( 91.25)\n",
            "Epoch: [68][120/391]\tTime  0.093 ( 0.092)\tLoss 2.7797e+00 (1.3643e+00)\tAcc@1  24.22 ( 71.73)\tAcc@5  57.81 ( 91.07)\n",
            "Epoch: [68][150/391]\tTime  0.090 ( 0.092)\tLoss 5.0069e-01 (1.3729e+00)\tAcc@1  85.16 ( 70.74)\tAcc@5  96.88 ( 90.60)\n",
            "Epoch: [68][180/391]\tTime  0.091 ( 0.091)\tLoss 2.4262e+00 (1.4145e+00)\tAcc@1  68.75 ( 69.85)\tAcc@5  88.28 ( 90.09)\n",
            "Epoch: [68][210/391]\tTime  0.085 ( 0.091)\tLoss 5.3250e-01 (1.4016e+00)\tAcc@1  83.59 ( 69.85)\tAcc@5  99.22 ( 90.13)\n",
            "Epoch: [68][240/391]\tTime  0.091 ( 0.091)\tLoss 2.1822e+00 (1.4183e+00)\tAcc@1  75.00 ( 69.63)\tAcc@5  92.97 ( 89.96)\n",
            "Epoch: [68][270/391]\tTime  0.091 ( 0.091)\tLoss 2.5431e+00 (1.4162e+00)\tAcc@1  61.72 ( 69.70)\tAcc@5  87.50 ( 90.09)\n",
            "Epoch: [68][300/391]\tTime  0.090 ( 0.091)\tLoss 3.6083e-01 (1.4317e+00)\tAcc@1  91.41 ( 69.32)\tAcc@5  99.22 ( 89.94)\n",
            "Epoch: [68][330/391]\tTime  0.090 ( 0.091)\tLoss 4.2378e-01 (1.4139e+00)\tAcc@1  89.06 ( 69.90)\tAcc@5  97.66 ( 90.28)\n",
            "Epoch: [68][360/391]\tTime  0.090 ( 0.091)\tLoss 2.0694e+00 (1.4285e+00)\tAcc@1  76.56 ( 69.45)\tAcc@5  92.97 ( 90.08)\n",
            "Epoch: [68][390/391]\tTime  0.081 ( 0.091)\tLoss 3.5940e-01 (1.4369e+00)\tAcc@1  88.75 ( 69.34)\tAcc@5 100.00 ( 90.11)\n",
            "==> Train Accuracy: Acc@1 69.338 || Acc@5 90.110\n",
            "==> Test Accuracy:  Acc@1 71.420 || Acc@5 92.230\n",
            "==> 37.96 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 69, lr: 0.020000000000000004 -----\n",
            "Epoch: [69][  0/391]\tTime  0.240 ( 0.240)\tLoss 4.2896e-01 (4.2896e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [69][ 30/391]\tTime  0.091 ( 0.095)\tLoss 1.9593e+00 (1.2577e+00)\tAcc@1  78.12 ( 74.29)\tAcc@5  96.88 ( 93.09)\n",
            "Epoch: [69][ 60/391]\tTime  0.088 ( 0.093)\tLoss 5.1306e-01 (1.3579e+00)\tAcc@1  83.59 ( 69.93)\tAcc@5  96.88 ( 90.65)\n",
            "Epoch: [69][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.4877e+00 (1.4657e+00)\tAcc@1  59.38 ( 69.04)\tAcc@5  85.16 ( 89.88)\n",
            "Epoch: [69][120/391]\tTime  0.091 ( 0.092)\tLoss 2.4842e+00 (1.5041e+00)\tAcc@1  65.62 ( 68.62)\tAcc@5  89.84 ( 89.55)\n",
            "Epoch: [69][150/391]\tTime  0.090 ( 0.091)\tLoss 2.8551e+00 (1.4706e+00)\tAcc@1  41.41 ( 69.31)\tAcc@5  68.75 ( 89.81)\n",
            "Epoch: [69][180/391]\tTime  0.087 ( 0.091)\tLoss 2.4804e+00 (1.4627e+00)\tAcc@1  42.19 ( 68.92)\tAcc@5  77.34 ( 89.51)\n",
            "Epoch: [69][210/391]\tTime  0.091 ( 0.091)\tLoss 2.3889e+00 (1.4302e+00)\tAcc@1  52.34 ( 69.34)\tAcc@5  76.56 ( 89.70)\n",
            "Epoch: [69][240/391]\tTime  0.091 ( 0.091)\tLoss 2.6188e+00 (1.4558e+00)\tAcc@1  57.03 ( 69.15)\tAcc@5  87.50 ( 89.66)\n",
            "Epoch: [69][270/391]\tTime  0.090 ( 0.091)\tLoss 5.3568e-01 (1.4450e+00)\tAcc@1  85.16 ( 68.93)\tAcc@5  97.66 ( 89.54)\n",
            "Epoch: [69][300/391]\tTime  0.089 ( 0.091)\tLoss 3.6435e-01 (1.4347e+00)\tAcc@1  89.84 ( 69.18)\tAcc@5  99.22 ( 89.76)\n",
            "Epoch: [69][330/391]\tTime  0.090 ( 0.091)\tLoss 4.8843e-01 (1.4402e+00)\tAcc@1  83.59 ( 68.88)\tAcc@5  99.22 ( 89.60)\n",
            "Epoch: [69][360/391]\tTime  0.090 ( 0.091)\tLoss 4.9735e-01 (1.4027e+00)\tAcc@1  84.38 ( 69.48)\tAcc@5  97.66 ( 90.00)\n",
            "Epoch: [69][390/391]\tTime  0.082 ( 0.091)\tLoss 2.9681e+00 (1.4203e+00)\tAcc@1  51.25 ( 69.31)\tAcc@5  83.75 ( 89.92)\n",
            "==> Train Accuracy: Acc@1 69.314 || Acc@5 89.924\n",
            "==> Test Accuracy:  Acc@1 71.160 || Acc@5 92.460\n",
            "==> 37.91 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 70, lr: 0.020000000000000004 -----\n",
            "Epoch: [70][  0/391]\tTime  0.256 ( 0.256)\tLoss 2.3325e+00 (2.3325e+00)\tAcc@1  53.12 ( 53.12)\tAcc@5  79.69 ( 79.69)\n",
            "Epoch: [70][ 30/391]\tTime  0.091 ( 0.096)\tLoss 2.4447e+00 (1.5109e+00)\tAcc@1  53.91 ( 67.97)\tAcc@5  83.59 ( 90.10)\n",
            "Epoch: [70][ 60/391]\tTime  0.089 ( 0.093)\tLoss 4.8629e-01 (1.5912e+00)\tAcc@1  86.72 ( 66.30)\tAcc@5  97.66 ( 88.84)\n",
            "Epoch: [70][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.3257e-01 (1.5234e+00)\tAcc@1  88.28 ( 68.33)\tAcc@5  96.88 ( 89.66)\n",
            "Epoch: [70][120/391]\tTime  0.091 ( 0.092)\tLoss 2.6274e+00 (1.5178e+00)\tAcc@1  36.72 ( 69.24)\tAcc@5  71.88 ( 90.26)\n",
            "Epoch: [70][150/391]\tTime  0.090 ( 0.091)\tLoss 4.0945e-01 (1.5589e+00)\tAcc@1  89.06 ( 67.53)\tAcc@5  99.22 ( 89.21)\n",
            "Epoch: [70][180/391]\tTime  0.090 ( 0.091)\tLoss 2.4942e+00 (1.5649e+00)\tAcc@1  50.00 ( 67.30)\tAcc@5  78.91 ( 89.24)\n",
            "Epoch: [70][210/391]\tTime  0.090 ( 0.091)\tLoss 5.7994e-01 (1.5488e+00)\tAcc@1  81.25 ( 67.46)\tAcc@5  99.22 ( 89.29)\n",
            "Epoch: [70][240/391]\tTime  0.091 ( 0.091)\tLoss 2.3629e+00 (1.5059e+00)\tAcc@1  72.66 ( 68.49)\tAcc@5  94.53 ( 89.87)\n",
            "Epoch: [70][270/391]\tTime  0.090 ( 0.091)\tLoss 4.4024e-01 (1.5068e+00)\tAcc@1  90.62 ( 68.13)\tAcc@5  96.09 ( 89.63)\n",
            "Epoch: [70][300/391]\tTime  0.089 ( 0.091)\tLoss 4.0091e-01 (1.5152e+00)\tAcc@1  89.84 ( 67.82)\tAcc@5  98.44 ( 89.55)\n",
            "Epoch: [70][330/391]\tTime  0.090 ( 0.091)\tLoss 5.1451e-01 (1.5046e+00)\tAcc@1  85.94 ( 67.87)\tAcc@5  97.66 ( 89.55)\n",
            "Epoch: [70][360/391]\tTime  0.090 ( 0.091)\tLoss 3.4634e-01 (1.5266e+00)\tAcc@1  91.41 ( 67.54)\tAcc@5  99.22 ( 89.35)\n",
            "Epoch: [70][390/391]\tTime  0.083 ( 0.091)\tLoss 2.9389e+00 (1.5251e+00)\tAcc@1  17.50 ( 67.52)\tAcc@5  53.75 ( 89.35)\n",
            "==> Train Accuracy: Acc@1 67.516 || Acc@5 89.346\n",
            "==> Test Accuracy:  Acc@1 72.370 || Acc@5 93.080\n",
            "==> 37.94 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 71, lr: 0.020000000000000004 -----\n",
            "Epoch: [71][  0/391]\tTime  0.247 ( 0.247)\tLoss 4.4649e-01 (4.4649e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [71][ 30/391]\tTime  0.090 ( 0.095)\tLoss 4.4382e-01 (1.6040e+00)\tAcc@1  85.94 ( 67.21)\tAcc@5  98.44 ( 88.73)\n",
            "Epoch: [71][ 60/391]\tTime  0.090 ( 0.093)\tLoss 4.0491e-01 (1.3420e+00)\tAcc@1  88.28 ( 72.21)\tAcc@5  98.44 ( 91.47)\n",
            "Epoch: [71][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.4841e-01 (1.3027e+00)\tAcc@1  88.28 ( 72.79)\tAcc@5  97.66 ( 91.77)\n",
            "Epoch: [71][120/391]\tTime  0.090 ( 0.092)\tLoss 4.4908e-01 (1.3322e+00)\tAcc@1  85.94 ( 71.88)\tAcc@5  98.44 ( 91.21)\n",
            "Epoch: [71][150/391]\tTime  0.093 ( 0.091)\tLoss 5.5578e-01 (1.3403e+00)\tAcc@1  85.94 ( 71.84)\tAcc@5  99.22 ( 91.27)\n",
            "Epoch: [71][180/391]\tTime  0.091 ( 0.091)\tLoss 2.2194e+00 (1.3498e+00)\tAcc@1  64.06 ( 71.08)\tAcc@5  92.97 ( 90.82)\n",
            "Epoch: [71][210/391]\tTime  0.090 ( 0.091)\tLoss 2.1064e+00 (1.4078e+00)\tAcc@1  66.41 ( 69.59)\tAcc@5  92.19 ( 90.13)\n",
            "Epoch: [71][240/391]\tTime  0.090 ( 0.091)\tLoss 5.7484e-01 (1.3446e+00)\tAcc@1  80.47 ( 70.53)\tAcc@5  98.44 ( 90.63)\n",
            "Epoch: [71][270/391]\tTime  0.090 ( 0.091)\tLoss 6.5858e-01 (1.3379e+00)\tAcc@1  81.25 ( 70.70)\tAcc@5  95.31 ( 90.70)\n",
            "Epoch: [71][300/391]\tTime  0.090 ( 0.091)\tLoss 4.5551e-01 (1.3380e+00)\tAcc@1  86.72 ( 70.61)\tAcc@5  98.44 ( 90.59)\n",
            "Epoch: [71][330/391]\tTime  0.090 ( 0.091)\tLoss 4.5790e-01 (1.3688e+00)\tAcc@1  86.72 ( 70.29)\tAcc@5  97.66 ( 90.51)\n",
            "Epoch: [71][360/391]\tTime  0.090 ( 0.091)\tLoss 5.1740e-01 (1.4173e+00)\tAcc@1  82.03 ( 69.17)\tAcc@5  98.44 ( 89.97)\n",
            "Epoch: [71][390/391]\tTime  0.082 ( 0.091)\tLoss 7.8492e-01 (1.4509e+00)\tAcc@1  73.75 ( 68.60)\tAcc@5  92.50 ( 89.77)\n",
            "==> Train Accuracy: Acc@1 68.596 || Acc@5 89.766\n",
            "==> Test Accuracy:  Acc@1 71.160 || Acc@5 92.270\n",
            "==> 37.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 72, lr: 0.020000000000000004 -----\n",
            "Epoch: [72][  0/391]\tTime  0.244 ( 0.244)\tLoss 2.5476e+00 (2.5476e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  76.56 ( 76.56)\n",
            "Epoch: [72][ 30/391]\tTime  0.089 ( 0.095)\tLoss 4.3242e-01 (1.3605e+00)\tAcc@1  88.28 ( 69.41)\tAcc@5  98.44 ( 90.45)\n",
            "Epoch: [72][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.6078e+00 (1.4777e+00)\tAcc@1  66.41 ( 69.67)\tAcc@5  92.19 ( 90.68)\n",
            "Epoch: [72][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.6460e+00 (1.3949e+00)\tAcc@1  41.41 ( 71.92)\tAcc@5  77.34 ( 91.77)\n",
            "Epoch: [72][120/391]\tTime  0.090 ( 0.092)\tLoss 4.0061e-01 (1.4484e+00)\tAcc@1  87.50 ( 69.98)\tAcc@5 100.00 ( 90.95)\n",
            "Epoch: [72][150/391]\tTime  0.091 ( 0.092)\tLoss 2.7860e+00 (1.4111e+00)\tAcc@1  51.56 ( 70.41)\tAcc@5  82.81 ( 91.20)\n",
            "Epoch: [72][180/391]\tTime  0.090 ( 0.091)\tLoss 5.2175e-01 (1.3641e+00)\tAcc@1  84.38 ( 70.96)\tAcc@5  97.66 ( 91.44)\n",
            "Epoch: [72][210/391]\tTime  0.091 ( 0.091)\tLoss 2.5360e+00 (1.3741e+00)\tAcc@1  58.59 ( 70.99)\tAcc@5  88.28 ( 91.50)\n",
            "Epoch: [72][240/391]\tTime  0.091 ( 0.091)\tLoss 2.3491e+00 (1.3924e+00)\tAcc@1  45.31 ( 70.32)\tAcc@5  79.69 ( 91.09)\n",
            "Epoch: [72][270/391]\tTime  0.090 ( 0.091)\tLoss 4.7169e-01 (1.4208e+00)\tAcc@1  88.28 ( 70.21)\tAcc@5  98.44 ( 91.06)\n",
            "Epoch: [72][300/391]\tTime  0.091 ( 0.091)\tLoss 4.5420e-01 (1.4144e+00)\tAcc@1  86.72 ( 70.33)\tAcc@5  98.44 ( 91.02)\n",
            "Epoch: [72][330/391]\tTime  0.096 ( 0.091)\tLoss 2.3678e+00 (1.4336e+00)\tAcc@1  58.59 ( 69.90)\tAcc@5  84.38 ( 90.76)\n",
            "Epoch: [72][360/391]\tTime  0.090 ( 0.091)\tLoss 2.6886e+00 (1.4735e+00)\tAcc@1  50.00 ( 69.14)\tAcc@5  76.56 ( 90.38)\n",
            "Epoch: [72][390/391]\tTime  0.083 ( 0.091)\tLoss 2.3805e+00 (1.4756e+00)\tAcc@1  58.75 ( 69.18)\tAcc@5  86.25 ( 90.37)\n",
            "==> Train Accuracy: Acc@1 69.184 || Acc@5 90.368\n",
            "==> Test Accuracy:  Acc@1 71.130 || Acc@5 92.150\n",
            "==> 38.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 73, lr: 0.020000000000000004 -----\n",
            "Epoch: [73][  0/391]\tTime  0.257 ( 0.257)\tLoss 2.6294e+00 (2.6294e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [73][ 30/391]\tTime  0.090 ( 0.097)\tLoss 4.1300e-01 (1.5132e+00)\tAcc@1  90.62 ( 67.97)\tAcc@5  98.44 ( 89.84)\n",
            "Epoch: [73][ 60/391]\tTime  0.092 ( 0.094)\tLoss 3.2437e-01 (1.4528e+00)\tAcc@1  89.84 ( 69.08)\tAcc@5  97.66 ( 90.16)\n",
            "Epoch: [73][ 90/391]\tTime  0.090 ( 0.093)\tLoss 2.5680e+00 (1.4642e+00)\tAcc@1  26.56 ( 68.83)\tAcc@5  67.97 ( 90.09)\n",
            "Epoch: [73][120/391]\tTime  0.090 ( 0.092)\tLoss 2.6810e+00 (1.5365e+00)\tAcc@1  49.22 ( 66.49)\tAcc@5  79.69 ( 88.87)\n",
            "Epoch: [73][150/391]\tTime  0.088 ( 0.092)\tLoss 5.2895e-01 (1.5149e+00)\tAcc@1  83.59 ( 67.31)\tAcc@5  98.44 ( 89.42)\n",
            "Epoch: [73][180/391]\tTime  0.091 ( 0.092)\tLoss 2.6748e+00 (1.5306e+00)\tAcc@1  43.75 ( 67.26)\tAcc@5  74.22 ( 89.41)\n",
            "Epoch: [73][210/391]\tTime  0.092 ( 0.092)\tLoss 2.0437e+00 (1.4931e+00)\tAcc@1  79.69 ( 68.33)\tAcc@5  96.09 ( 89.96)\n",
            "Epoch: [73][240/391]\tTime  0.091 ( 0.091)\tLoss 2.4593e+00 (1.4778e+00)\tAcc@1  66.41 ( 68.98)\tAcc@5  92.19 ( 90.29)\n",
            "Epoch: [73][270/391]\tTime  0.091 ( 0.091)\tLoss 2.2100e+00 (1.4607e+00)\tAcc@1  72.66 ( 69.30)\tAcc@5  92.97 ( 90.41)\n",
            "Epoch: [73][300/391]\tTime  0.092 ( 0.091)\tLoss 2.5112e+00 (1.4576e+00)\tAcc@1  53.12 ( 69.46)\tAcc@5  78.91 ( 90.49)\n",
            "Epoch: [73][330/391]\tTime  0.090 ( 0.091)\tLoss 4.0710e-01 (1.4587e+00)\tAcc@1  86.72 ( 69.34)\tAcc@5  98.44 ( 90.31)\n",
            "Epoch: [73][360/391]\tTime  0.090 ( 0.091)\tLoss 5.0396e-01 (1.4704e+00)\tAcc@1  85.16 ( 68.98)\tAcc@5  96.88 ( 90.10)\n",
            "Epoch: [73][390/391]\tTime  0.082 ( 0.091)\tLoss 5.4797e-01 (1.4816e+00)\tAcc@1  82.50 ( 68.65)\tAcc@5 100.00 ( 89.88)\n",
            "==> Train Accuracy: Acc@1 68.646 || Acc@5 89.880\n",
            "==> Test Accuracy:  Acc@1 71.360 || Acc@5 92.300\n",
            "==> 38.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 74, lr: 0.020000000000000004 -----\n",
            "Epoch: [74][  0/391]\tTime  0.265 ( 0.265)\tLoss 2.8195e+00 (2.8195e+00)\tAcc@1  24.22 ( 24.22)\tAcc@5  60.94 ( 60.94)\n",
            "Epoch: [74][ 30/391]\tTime  0.091 ( 0.097)\tLoss 2.3049e-01 (1.6789e+00)\tAcc@1  92.97 ( 63.31)\tAcc@5 100.00 ( 86.82)\n",
            "Epoch: [74][ 60/391]\tTime  0.090 ( 0.094)\tLoss 3.5014e-01 (1.5321e+00)\tAcc@1  92.19 ( 66.34)\tAcc@5  98.44 ( 88.33)\n",
            "Epoch: [74][ 90/391]\tTime  0.091 ( 0.093)\tLoss 2.3353e+00 (1.4678e+00)\tAcc@1  67.19 ( 67.86)\tAcc@5  93.75 ( 89.24)\n",
            "Epoch: [74][120/391]\tTime  0.098 ( 0.092)\tLoss 2.5304e+00 (1.4365e+00)\tAcc@1  49.22 ( 68.31)\tAcc@5  80.47 ( 89.37)\n",
            "Epoch: [74][150/391]\tTime  0.092 ( 0.092)\tLoss 2.6145e+00 (1.4590e+00)\tAcc@1  57.03 ( 67.90)\tAcc@5  84.38 ( 89.36)\n",
            "Epoch: [74][180/391]\tTime  0.089 ( 0.092)\tLoss 2.3645e+00 (1.5160e+00)\tAcc@1  49.22 ( 66.96)\tAcc@5  84.38 ( 88.97)\n",
            "Epoch: [74][210/391]\tTime  0.089 ( 0.092)\tLoss 4.9694e-01 (1.5233e+00)\tAcc@1  85.16 ( 67.09)\tAcc@5  99.22 ( 89.24)\n",
            "Epoch: [74][240/391]\tTime  0.090 ( 0.092)\tLoss 5.2190e-01 (1.4708e+00)\tAcc@1  84.38 ( 68.10)\tAcc@5  99.22 ( 89.83)\n",
            "Epoch: [74][270/391]\tTime  0.090 ( 0.092)\tLoss 3.8523e-01 (1.4949e+00)\tAcc@1  88.28 ( 67.74)\tAcc@5  97.66 ( 89.62)\n",
            "Epoch: [74][300/391]\tTime  0.091 ( 0.092)\tLoss 2.6587e+00 (1.4640e+00)\tAcc@1  34.38 ( 68.06)\tAcc@5  71.88 ( 89.73)\n",
            "Epoch: [74][330/391]\tTime  0.090 ( 0.092)\tLoss 5.6444e-01 (1.4428e+00)\tAcc@1  85.16 ( 68.43)\tAcc@5  96.88 ( 89.86)\n",
            "Epoch: [74][360/391]\tTime  0.090 ( 0.091)\tLoss 4.1850e-01 (1.4406e+00)\tAcc@1  88.28 ( 68.45)\tAcc@5 100.00 ( 89.86)\n",
            "Epoch: [74][390/391]\tTime  0.081 ( 0.091)\tLoss 5.6494e-01 (1.4354e+00)\tAcc@1  78.75 ( 68.58)\tAcc@5  97.50 ( 89.95)\n",
            "==> Train Accuracy: Acc@1 68.582 || Acc@5 89.948\n",
            "==> Test Accuracy:  Acc@1 70.690 || Acc@5 92.300\n",
            "==> 38.20 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 75, lr: 0.020000000000000004 -----\n",
            "Epoch: [75][  0/391]\tTime  0.250 ( 0.250)\tLoss 3.6563e-01 (3.6563e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [75][ 30/391]\tTime  0.091 ( 0.096)\tLoss 2.2681e+00 (1.4087e+00)\tAcc@1  69.53 ( 72.08)\tAcc@5  93.75 ( 92.24)\n",
            "Epoch: [75][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.3161e+00 (1.5550e+00)\tAcc@1  72.66 ( 67.96)\tAcc@5  96.09 ( 90.06)\n",
            "Epoch: [75][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.5699e+00 (1.4138e+00)\tAcc@1  64.84 ( 71.09)\tAcc@5  87.50 ( 91.46)\n",
            "Epoch: [75][120/391]\tTime  0.091 ( 0.092)\tLoss 2.3830e+00 (1.3940e+00)\tAcc@1  47.66 ( 71.18)\tAcc@5  84.38 ( 91.66)\n",
            "Epoch: [75][150/391]\tTime  0.091 ( 0.092)\tLoss 1.9612e+00 (1.3574e+00)\tAcc@1  76.56 ( 71.68)\tAcc@5  92.97 ( 91.83)\n",
            "Epoch: [75][180/391]\tTime  0.095 ( 0.092)\tLoss 2.6448e+00 (1.4031e+00)\tAcc@1  40.62 ( 69.99)\tAcc@5  74.22 ( 90.77)\n",
            "Epoch: [75][210/391]\tTime  0.089 ( 0.092)\tLoss 2.5038e+00 (1.4143e+00)\tAcc@1  45.31 ( 69.79)\tAcc@5  85.16 ( 90.66)\n",
            "Epoch: [75][240/391]\tTime  0.095 ( 0.092)\tLoss 5.4938e-01 (1.4326e+00)\tAcc@1  82.81 ( 69.96)\tAcc@5  97.66 ( 90.78)\n",
            "Epoch: [75][270/391]\tTime  0.091 ( 0.092)\tLoss 2.6429e+00 (1.4549e+00)\tAcc@1  47.66 ( 69.29)\tAcc@5  70.31 ( 90.48)\n",
            "Epoch: [75][300/391]\tTime  0.091 ( 0.092)\tLoss 2.1975e+00 (1.4730e+00)\tAcc@1  75.00 ( 68.92)\tAcc@5  95.31 ( 90.40)\n",
            "Epoch: [75][330/391]\tTime  0.090 ( 0.092)\tLoss 2.5310e+00 (1.4769e+00)\tAcc@1  51.56 ( 68.83)\tAcc@5  82.03 ( 90.25)\n",
            "Epoch: [75][360/391]\tTime  0.090 ( 0.092)\tLoss 4.9018e-01 (1.4949e+00)\tAcc@1  85.16 ( 68.35)\tAcc@5  98.44 ( 89.99)\n",
            "Epoch: [75][390/391]\tTime  0.082 ( 0.092)\tLoss 5.8293e-01 (1.5176e+00)\tAcc@1  80.00 ( 67.96)\tAcc@5  97.50 ( 89.73)\n",
            "==> Train Accuracy: Acc@1 67.958 || Acc@5 89.730\n",
            "==> Test Accuracy:  Acc@1 71.920 || Acc@5 92.480\n",
            "==> 38.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 76, lr: 0.020000000000000004 -----\n",
            "Epoch: [76][  0/391]\tTime  0.245 ( 0.245)\tLoss 4.3816e-01 (4.3816e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [76][ 30/391]\tTime  0.090 ( 0.096)\tLoss 3.7626e-01 (1.5832e+00)\tAcc@1  92.19 ( 68.15)\tAcc@5  98.44 ( 89.62)\n",
            "Epoch: [76][ 60/391]\tTime  0.089 ( 0.094)\tLoss 3.9723e-01 (1.3760e+00)\tAcc@1  89.06 ( 70.89)\tAcc@5  98.44 ( 91.23)\n",
            "Epoch: [76][ 90/391]\tTime  0.100 ( 0.093)\tLoss 2.5271e+00 (1.4578e+00)\tAcc@1  42.97 ( 68.82)\tAcc@5  82.81 ( 90.31)\n",
            "Epoch: [76][120/391]\tTime  0.089 ( 0.093)\tLoss 3.9329e-01 (1.4850e+00)\tAcc@1  88.28 ( 68.21)\tAcc@5 100.00 ( 89.95)\n",
            "Epoch: [76][150/391]\tTime  0.090 ( 0.092)\tLoss 5.6242e-01 (1.4827e+00)\tAcc@1  82.03 ( 69.12)\tAcc@5  97.66 ( 90.30)\n",
            "Epoch: [76][180/391]\tTime  0.091 ( 0.092)\tLoss 2.6973e+00 (1.5299e+00)\tAcc@1  24.22 ( 67.81)\tAcc@5  60.16 ( 89.68)\n",
            "Epoch: [76][210/391]\tTime  0.091 ( 0.092)\tLoss 4.0289e-01 (1.5365e+00)\tAcc@1  87.50 ( 68.05)\tAcc@5 100.00 ( 89.76)\n",
            "Epoch: [76][240/391]\tTime  0.091 ( 0.092)\tLoss 2.3375e+00 (1.5227e+00)\tAcc@1  65.62 ( 68.43)\tAcc@5  93.75 ( 89.92)\n",
            "Epoch: [76][270/391]\tTime  0.099 ( 0.092)\tLoss 2.6481e+00 (1.4694e+00)\tAcc@1  53.12 ( 69.35)\tAcc@5  78.12 ( 90.35)\n",
            "Epoch: [76][300/391]\tTime  0.091 ( 0.092)\tLoss 2.7087e+00 (1.4782e+00)\tAcc@1  46.88 ( 69.07)\tAcc@5  74.22 ( 90.29)\n",
            "Epoch: [76][330/391]\tTime  0.091 ( 0.092)\tLoss 5.0025e-01 (1.5054e+00)\tAcc@1  84.38 ( 68.40)\tAcc@5  99.22 ( 89.93)\n",
            "Epoch: [76][360/391]\tTime  0.089 ( 0.092)\tLoss 2.4003e+00 (1.5270e+00)\tAcc@1  42.19 ( 67.94)\tAcc@5  78.91 ( 89.68)\n",
            "Epoch: [76][390/391]\tTime  0.082 ( 0.092)\tLoss 2.6613e+00 (1.5214e+00)\tAcc@1  58.75 ( 68.15)\tAcc@5  86.25 ( 89.84)\n",
            "==> Train Accuracy: Acc@1 68.152 || Acc@5 89.838\n",
            "==> Test Accuracy:  Acc@1 71.090 || Acc@5 92.520\n",
            "==> 38.63 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 77, lr: 0.020000000000000004 -----\n",
            "Epoch: [77][  0/391]\tTime  0.275 ( 0.275)\tLoss 2.1526e+00 (2.1526e+00)\tAcc@1  79.69 ( 79.69)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [77][ 30/391]\tTime  0.091 ( 0.097)\tLoss 2.6304e+00 (1.2925e+00)\tAcc@1  46.88 ( 74.52)\tAcc@5  75.78 ( 93.07)\n",
            "Epoch: [77][ 60/391]\tTime  0.088 ( 0.094)\tLoss 2.5493e+00 (1.3014e+00)\tAcc@1  47.66 ( 74.41)\tAcc@5  78.91 ( 92.69)\n",
            "Epoch: [77][ 90/391]\tTime  0.094 ( 0.093)\tLoss 3.4092e-01 (1.3873e+00)\tAcc@1  91.41 ( 71.45)\tAcc@5  99.22 ( 90.94)\n",
            "Epoch: [77][120/391]\tTime  0.090 ( 0.093)\tLoss 4.9119e-01 (1.4036e+00)\tAcc@1  82.03 ( 71.29)\tAcc@5  99.22 ( 91.04)\n",
            "Epoch: [77][150/391]\tTime  0.091 ( 0.092)\tLoss 2.6506e+00 (1.4429e+00)\tAcc@1  51.56 ( 70.61)\tAcc@5  85.94 ( 90.67)\n",
            "Epoch: [77][180/391]\tTime  0.090 ( 0.092)\tLoss 4.4432e-01 (1.3735e+00)\tAcc@1  85.94 ( 71.80)\tAcc@5 100.00 ( 91.26)\n",
            "Epoch: [77][210/391]\tTime  0.091 ( 0.092)\tLoss 4.7688e-01 (1.3565e+00)\tAcc@1  84.38 ( 71.73)\tAcc@5  98.44 ( 91.19)\n",
            "Epoch: [77][240/391]\tTime  0.092 ( 0.092)\tLoss 2.3634e+00 (1.3452e+00)\tAcc@1  41.41 ( 71.73)\tAcc@5  74.22 ( 91.13)\n",
            "Epoch: [77][270/391]\tTime  0.095 ( 0.092)\tLoss 2.7588e+00 (1.3533e+00)\tAcc@1  35.16 ( 71.50)\tAcc@5  78.12 ( 90.99)\n",
            "Epoch: [77][300/391]\tTime  0.091 ( 0.092)\tLoss 2.6190e+00 (1.3414e+00)\tAcc@1  33.59 ( 71.79)\tAcc@5  75.78 ( 91.24)\n",
            "Epoch: [77][330/391]\tTime  0.091 ( 0.092)\tLoss 5.0756e-01 (1.3441e+00)\tAcc@1  84.38 ( 71.88)\tAcc@5  96.88 ( 91.29)\n",
            "Epoch: [77][360/391]\tTime  0.091 ( 0.092)\tLoss 4.1408e-01 (1.3709e+00)\tAcc@1  87.50 ( 71.16)\tAcc@5  96.88 ( 90.89)\n",
            "Epoch: [77][390/391]\tTime  0.082 ( 0.092)\tLoss 2.1774e+00 (1.3614e+00)\tAcc@1  71.25 ( 71.29)\tAcc@5  93.75 ( 90.96)\n",
            "==> Train Accuracy: Acc@1 71.292 || Acc@5 90.956\n",
            "==> Test Accuracy:  Acc@1 72.320 || Acc@5 92.660\n",
            "==> 38.32 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 78, lr: 0.020000000000000004 -----\n",
            "Epoch: [78][  0/391]\tTime  0.238 ( 0.238)\tLoss 3.9218e-01 (3.9218e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [78][ 30/391]\tTime  0.089 ( 0.095)\tLoss 2.5511e+00 (1.1124e+00)\tAcc@1  21.09 ( 74.02)\tAcc@5  67.97 ( 91.81)\n",
            "Epoch: [78][ 60/391]\tTime  0.090 ( 0.093)\tLoss 4.2610e-01 (1.2291e+00)\tAcc@1  88.28 ( 72.62)\tAcc@5  99.22 ( 91.15)\n",
            "Epoch: [78][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.6871e+00 (1.2616e+00)\tAcc@1  37.50 ( 73.87)\tAcc@5  70.31 ( 92.02)\n",
            "Epoch: [78][120/391]\tTime  0.090 ( 0.092)\tLoss 5.0211e-01 (1.2976e+00)\tAcc@1  84.38 ( 73.20)\tAcc@5  98.44 ( 91.99)\n",
            "Epoch: [78][150/391]\tTime  0.091 ( 0.092)\tLoss 2.6567e+00 (1.2845e+00)\tAcc@1  26.56 ( 73.17)\tAcc@5  64.06 ( 91.85)\n",
            "Epoch: [78][180/391]\tTime  0.091 ( 0.092)\tLoss 2.3835e+00 (1.3780e+00)\tAcc@1  67.19 ( 71.06)\tAcc@5  89.84 ( 90.77)\n",
            "Epoch: [78][210/391]\tTime  0.092 ( 0.092)\tLoss 3.2301e-01 (1.4070e+00)\tAcc@1  86.72 ( 70.81)\tAcc@5 100.00 ( 90.65)\n",
            "Epoch: [78][240/391]\tTime  0.091 ( 0.092)\tLoss 4.4555e-01 (1.4194e+00)\tAcc@1  86.72 ( 70.65)\tAcc@5  98.44 ( 90.72)\n",
            "Epoch: [78][270/391]\tTime  0.092 ( 0.092)\tLoss 4.8793e-01 (1.4290e+00)\tAcc@1  85.94 ( 70.30)\tAcc@5  98.44 ( 90.65)\n",
            "Epoch: [78][300/391]\tTime  0.095 ( 0.092)\tLoss 2.5474e+00 (1.4534e+00)\tAcc@1  35.16 ( 69.49)\tAcc@5  68.75 ( 90.27)\n",
            "Epoch: [78][330/391]\tTime  0.090 ( 0.092)\tLoss 2.6342e+00 (1.4731e+00)\tAcc@1  41.41 ( 68.90)\tAcc@5  75.00 ( 89.89)\n",
            "Epoch: [78][360/391]\tTime  0.099 ( 0.092)\tLoss 2.4988e+00 (1.4974e+00)\tAcc@1  44.53 ( 68.47)\tAcc@5  82.81 ( 89.70)\n",
            "Epoch: [78][390/391]\tTime  0.082 ( 0.092)\tLoss 2.2163e+00 (1.4880e+00)\tAcc@1  71.25 ( 68.57)\tAcc@5 100.00 ( 89.75)\n",
            "==> Train Accuracy: Acc@1 68.570 || Acc@5 89.754\n",
            "==> Test Accuracy:  Acc@1 69.160 || Acc@5 91.330\n",
            "==> 38.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 79, lr: 0.020000000000000004 -----\n",
            "Epoch: [79][  0/391]\tTime  0.309 ( 0.309)\tLoss 2.3749e+00 (2.3749e+00)\tAcc@1  44.53 ( 44.53)\tAcc@5  82.03 ( 82.03)\n",
            "Epoch: [79][ 30/391]\tTime  0.092 ( 0.100)\tLoss 2.6830e+00 (1.5577e+00)\tAcc@1  27.34 ( 66.61)\tAcc@5  61.72 ( 89.14)\n",
            "Epoch: [79][ 60/391]\tTime  0.097 ( 0.096)\tLoss 2.4418e+00 (1.4746e+00)\tAcc@1  48.44 ( 67.69)\tAcc@5  85.94 ( 89.73)\n",
            "Epoch: [79][ 90/391]\tTime  0.093 ( 0.095)\tLoss 5.2148e-01 (1.4627e+00)\tAcc@1  84.38 ( 68.69)\tAcc@5  98.44 ( 90.55)\n",
            "Epoch: [79][120/391]\tTime  0.091 ( 0.094)\tLoss 3.7337e-01 (1.4267e+00)\tAcc@1  89.06 ( 69.64)\tAcc@5  99.22 ( 90.92)\n",
            "Epoch: [79][150/391]\tTime  0.093 ( 0.094)\tLoss 3.3177e-01 (1.4518e+00)\tAcc@1  92.97 ( 68.51)\tAcc@5 100.00 ( 90.22)\n",
            "Epoch: [79][180/391]\tTime  0.089 ( 0.094)\tLoss 2.5314e+00 (1.4653e+00)\tAcc@1  25.78 ( 67.90)\tAcc@5  62.50 ( 89.97)\n",
            "Epoch: [79][210/391]\tTime  0.091 ( 0.093)\tLoss 5.2438e-01 (1.4424e+00)\tAcc@1  84.38 ( 68.56)\tAcc@5  96.88 ( 90.34)\n",
            "Epoch: [79][240/391]\tTime  0.090 ( 0.093)\tLoss 5.1166e-01 (1.4474e+00)\tAcc@1  85.16 ( 68.65)\tAcc@5  98.44 ( 90.34)\n",
            "Epoch: [79][270/391]\tTime  0.092 ( 0.093)\tLoss 4.9507e-01 (1.4298e+00)\tAcc@1  86.72 ( 68.98)\tAcc@5  97.66 ( 90.43)\n",
            "Epoch: [79][300/391]\tTime  0.092 ( 0.093)\tLoss 2.7345e+00 (1.4159e+00)\tAcc@1  29.69 ( 69.19)\tAcc@5  63.28 ( 90.45)\n",
            "Epoch: [79][330/391]\tTime  0.093 ( 0.093)\tLoss 2.4973e+00 (1.4175e+00)\tAcc@1  46.88 ( 69.10)\tAcc@5  78.12 ( 90.38)\n",
            "Epoch: [79][360/391]\tTime  0.092 ( 0.093)\tLoss 2.5785e+00 (1.4341e+00)\tAcc@1  39.84 ( 68.68)\tAcc@5  77.34 ( 90.23)\n",
            "Epoch: [79][390/391]\tTime  0.081 ( 0.093)\tLoss 2.5668e+00 (1.4492e+00)\tAcc@1  58.75 ( 68.54)\tAcc@5  88.75 ( 90.07)\n",
            "==> Train Accuracy: Acc@1 68.540 || Acc@5 90.068\n",
            "==> Test Accuracy:  Acc@1 71.320 || Acc@5 92.220\n",
            "==> 38.88 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 80, lr: 0.020000000000000004 -----\n",
            "Epoch: [80][  0/391]\tTime  0.303 ( 0.303)\tLoss 2.8006e+00 (2.8006e+00)\tAcc@1  25.78 ( 25.78)\tAcc@5  61.72 ( 61.72)\n",
            "Epoch: [80][ 30/391]\tTime  0.090 ( 0.100)\tLoss 2.4896e+00 (1.3706e+00)\tAcc@1  38.28 ( 71.77)\tAcc@5  70.31 ( 91.41)\n",
            "Epoch: [80][ 60/391]\tTime  0.091 ( 0.096)\tLoss 3.5467e-01 (1.3562e+00)\tAcc@1  87.50 ( 72.02)\tAcc@5 100.00 ( 91.15)\n",
            "Epoch: [80][ 90/391]\tTime  0.094 ( 0.095)\tLoss 3.8142e-01 (1.3171e+00)\tAcc@1  90.62 ( 71.89)\tAcc@5  99.22 ( 91.26)\n",
            "Epoch: [80][120/391]\tTime  0.094 ( 0.094)\tLoss 2.8116e+00 (1.4271e+00)\tAcc@1  20.31 ( 69.78)\tAcc@5  57.81 ( 90.24)\n",
            "Epoch: [80][150/391]\tTime  0.088 ( 0.094)\tLoss 2.6295e+00 (1.4206e+00)\tAcc@1  44.53 ( 69.99)\tAcc@5  77.34 ( 90.27)\n",
            "Epoch: [80][180/391]\tTime  0.092 ( 0.094)\tLoss 4.2354e-01 (1.4396e+00)\tAcc@1  86.72 ( 70.14)\tAcc@5  99.22 ( 90.54)\n",
            "Epoch: [80][210/391]\tTime  0.093 ( 0.093)\tLoss 2.6629e+00 (1.4506e+00)\tAcc@1  41.41 ( 69.94)\tAcc@5  78.91 ( 90.56)\n",
            "Epoch: [80][240/391]\tTime  0.092 ( 0.093)\tLoss 3.8090e-01 (1.4782e+00)\tAcc@1  89.06 ( 68.99)\tAcc@5  99.22 ( 90.01)\n",
            "Epoch: [80][270/391]\tTime  0.092 ( 0.093)\tLoss 3.7230e-01 (1.4596e+00)\tAcc@1  89.06 ( 69.40)\tAcc@5  99.22 ( 90.25)\n",
            "Epoch: [80][300/391]\tTime  0.090 ( 0.093)\tLoss 3.2476e-01 (1.4437e+00)\tAcc@1  92.19 ( 69.57)\tAcc@5  98.44 ( 90.27)\n",
            "Epoch: [80][330/391]\tTime  0.090 ( 0.093)\tLoss 5.4039e-01 (1.4518e+00)\tAcc@1  82.81 ( 69.39)\tAcc@5  99.22 ( 90.27)\n",
            "Epoch: [80][360/391]\tTime  0.092 ( 0.093)\tLoss 3.9436e-01 (1.4459e+00)\tAcc@1  89.84 ( 69.61)\tAcc@5  99.22 ( 90.40)\n",
            "Epoch: [80][390/391]\tTime  0.083 ( 0.093)\tLoss 5.2708e-01 (1.4509e+00)\tAcc@1  86.25 ( 69.41)\tAcc@5  98.75 ( 90.30)\n",
            "==> Train Accuracy: Acc@1 69.406 || Acc@5 90.302\n",
            "==> Test Accuracy:  Acc@1 68.690 || Acc@5 90.820\n",
            "==> 38.89 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 81, lr: 0.020000000000000004 -----\n",
            "Epoch: [81][  0/391]\tTime  0.269 ( 0.269)\tLoss 1.9252e+00 (1.9252e+00)\tAcc@1  83.59 ( 83.59)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [81][ 30/391]\tTime  0.093 ( 0.098)\tLoss 3.7733e-01 (1.2515e+00)\tAcc@1  86.72 ( 72.51)\tAcc@5  99.22 ( 91.36)\n",
            "Epoch: [81][ 60/391]\tTime  0.099 ( 0.095)\tLoss 2.0454e+00 (1.2717e+00)\tAcc@1  70.31 ( 72.93)\tAcc@5  95.31 ( 91.85)\n",
            "Epoch: [81][ 90/391]\tTime  0.091 ( 0.094)\tLoss 2.5751e+00 (1.3918e+00)\tAcc@1  67.97 ( 70.49)\tAcc@5  90.62 ( 91.07)\n",
            "Epoch: [81][120/391]\tTime  0.093 ( 0.094)\tLoss 4.4384e-01 (1.4326e+00)\tAcc@1  86.72 ( 69.44)\tAcc@5  96.09 ( 90.44)\n",
            "Epoch: [81][150/391]\tTime  0.092 ( 0.093)\tLoss 2.3599e+00 (1.4683e+00)\tAcc@1  48.44 ( 69.71)\tAcc@5  78.91 ( 90.66)\n",
            "Epoch: [81][180/391]\tTime  0.090 ( 0.093)\tLoss 3.3266e-01 (1.4627e+00)\tAcc@1  91.41 ( 69.51)\tAcc@5  97.66 ( 90.47)\n",
            "Epoch: [81][210/391]\tTime  0.087 ( 0.093)\tLoss 2.6522e+00 (1.4744e+00)\tAcc@1  48.44 ( 69.50)\tAcc@5  82.03 ( 90.55)\n",
            "Epoch: [81][240/391]\tTime  0.091 ( 0.092)\tLoss 5.2144e-01 (1.4813e+00)\tAcc@1  82.03 ( 69.10)\tAcc@5  97.66 ( 90.39)\n",
            "Epoch: [81][270/391]\tTime  0.090 ( 0.092)\tLoss 4.6577e-01 (1.5100e+00)\tAcc@1  84.38 ( 68.48)\tAcc@5  99.22 ( 89.98)\n",
            "Epoch: [81][300/391]\tTime  0.089 ( 0.092)\tLoss 4.9951e-01 (1.5006e+00)\tAcc@1  86.72 ( 68.84)\tAcc@5  96.88 ( 90.16)\n",
            "Epoch: [81][330/391]\tTime  0.090 ( 0.092)\tLoss 3.8571e-01 (1.4786e+00)\tAcc@1  89.84 ( 69.19)\tAcc@5  99.22 ( 90.31)\n",
            "Epoch: [81][360/391]\tTime  0.090 ( 0.092)\tLoss 5.3190e-01 (1.4693e+00)\tAcc@1  79.69 ( 69.41)\tAcc@5  99.22 ( 90.46)\n",
            "Epoch: [81][390/391]\tTime  0.082 ( 0.092)\tLoss 2.5998e+00 (1.4817e+00)\tAcc@1  62.50 ( 69.20)\tAcc@5  81.25 ( 90.39)\n",
            "==> Train Accuracy: Acc@1 69.198 || Acc@5 90.388\n",
            "==> Test Accuracy:  Acc@1 71.070 || Acc@5 92.040\n",
            "==> 38.49 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 82, lr: 0.020000000000000004 -----\n",
            "Epoch: [82][  0/391]\tTime  0.263 ( 0.263)\tLoss 3.5023e-01 (3.5023e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [82][ 30/391]\tTime  0.090 ( 0.097)\tLoss 2.4267e+00 (1.6858e+00)\tAcc@1  42.97 ( 66.08)\tAcc@5  85.94 ( 88.43)\n",
            "Epoch: [82][ 60/391]\tTime  0.091 ( 0.094)\tLoss 2.7845e+00 (1.5996e+00)\tAcc@1  30.47 ( 66.83)\tAcc@5  75.00 ( 89.24)\n",
            "Epoch: [82][ 90/391]\tTime  0.091 ( 0.093)\tLoss 2.5552e+00 (1.5632e+00)\tAcc@1  43.75 ( 67.28)\tAcc@5  77.34 ( 89.33)\n",
            "Epoch: [82][120/391]\tTime  0.093 ( 0.093)\tLoss 2.5097e+00 (1.5731e+00)\tAcc@1  55.47 ( 67.39)\tAcc@5  85.94 ( 89.29)\n",
            "Epoch: [82][150/391]\tTime  0.090 ( 0.092)\tLoss 3.3546e-01 (1.5282e+00)\tAcc@1  88.28 ( 68.10)\tAcc@5 100.00 ( 89.71)\n",
            "Epoch: [82][180/391]\tTime  0.091 ( 0.092)\tLoss 2.3639e+00 (1.5281e+00)\tAcc@1  46.88 ( 68.15)\tAcc@5  83.59 ( 89.88)\n",
            "Epoch: [82][210/391]\tTime  0.091 ( 0.092)\tLoss 3.8852e-01 (1.4783e+00)\tAcc@1  83.59 ( 69.15)\tAcc@5  99.22 ( 90.25)\n",
            "Epoch: [82][240/391]\tTime  0.096 ( 0.092)\tLoss 3.5229e-01 (1.4518e+00)\tAcc@1  88.28 ( 69.55)\tAcc@5 100.00 ( 90.51)\n",
            "Epoch: [82][270/391]\tTime  0.090 ( 0.092)\tLoss 5.3146e-01 (1.4673e+00)\tAcc@1  83.59 ( 69.23)\tAcc@5  98.44 ( 90.32)\n",
            "Epoch: [82][300/391]\tTime  0.090 ( 0.092)\tLoss 4.9151e-01 (1.4537e+00)\tAcc@1  85.94 ( 69.78)\tAcc@5  99.22 ( 90.58)\n",
            "Epoch: [82][330/391]\tTime  0.088 ( 0.091)\tLoss 6.5322e-01 (1.4480e+00)\tAcc@1  81.25 ( 69.75)\tAcc@5  97.66 ( 90.59)\n",
            "Epoch: [82][360/391]\tTime  0.091 ( 0.091)\tLoss 2.3843e+00 (1.4400e+00)\tAcc@1  47.66 ( 69.97)\tAcc@5  82.03 ( 90.70)\n",
            "Epoch: [82][390/391]\tTime  0.083 ( 0.091)\tLoss 5.4344e-01 (1.4434e+00)\tAcc@1  82.50 ( 69.73)\tAcc@5  98.75 ( 90.53)\n",
            "==> Train Accuracy: Acc@1 69.730 || Acc@5 90.526\n",
            "==> Test Accuracy:  Acc@1 70.520 || Acc@5 91.590\n",
            "==> 38.21 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 83, lr: 0.020000000000000004 -----\n",
            "Epoch: [83][  0/391]\tTime  0.242 ( 0.242)\tLoss 4.7178e-01 (4.7178e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [83][ 30/391]\tTime  0.089 ( 0.096)\tLoss 2.8357e-01 (1.2219e+00)\tAcc@1  89.84 ( 73.66)\tAcc@5 100.00 ( 91.31)\n",
            "Epoch: [83][ 60/391]\tTime  0.093 ( 0.093)\tLoss 2.2011e+00 (1.3089e+00)\tAcc@1  75.78 ( 73.17)\tAcc@5  92.19 ( 91.64)\n",
            "Epoch: [83][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.3144e-01 (1.2591e+00)\tAcc@1  86.72 ( 74.00)\tAcc@5  98.44 ( 92.25)\n",
            "Epoch: [83][120/391]\tTime  0.091 ( 0.092)\tLoss 2.5300e+00 (1.3132e+00)\tAcc@1  52.34 ( 72.85)\tAcc@5  81.25 ( 91.58)\n",
            "Epoch: [83][150/391]\tTime  0.094 ( 0.092)\tLoss 2.0935e+00 (1.4122e+00)\tAcc@1  72.66 ( 71.02)\tAcc@5  93.75 ( 90.65)\n",
            "Epoch: [83][180/391]\tTime  0.090 ( 0.092)\tLoss 2.4847e+00 (1.4477e+00)\tAcc@1  38.28 ( 70.31)\tAcc@5  78.12 ( 90.28)\n",
            "Epoch: [83][210/391]\tTime  0.090 ( 0.091)\tLoss 4.2307e-01 (1.4591e+00)\tAcc@1  87.50 ( 70.17)\tAcc@5  99.22 ( 90.29)\n",
            "Epoch: [83][240/391]\tTime  0.091 ( 0.091)\tLoss 2.3480e+00 (1.4751e+00)\tAcc@1  63.28 ( 69.81)\tAcc@5  89.06 ( 90.14)\n",
            "Epoch: [83][270/391]\tTime  0.091 ( 0.091)\tLoss 2.1567e+00 (1.5097e+00)\tAcc@1  75.00 ( 69.32)\tAcc@5  96.88 ( 89.96)\n",
            "Epoch: [83][300/391]\tTime  0.090 ( 0.091)\tLoss 2.9158e-01 (1.4856e+00)\tAcc@1  91.41 ( 69.39)\tAcc@5 100.00 ( 90.04)\n",
            "Epoch: [83][330/391]\tTime  0.086 ( 0.091)\tLoss 7.2172e-01 (1.4673e+00)\tAcc@1  78.91 ( 69.32)\tAcc@5  95.31 ( 89.99)\n",
            "Epoch: [83][360/391]\tTime  0.089 ( 0.091)\tLoss 4.0997e-01 (1.4578e+00)\tAcc@1  89.06 ( 69.41)\tAcc@5  99.22 ( 90.05)\n",
            "Epoch: [83][390/391]\tTime  0.081 ( 0.091)\tLoss 6.1878e-01 (1.4167e+00)\tAcc@1  83.75 ( 70.35)\tAcc@5  97.50 ( 90.52)\n",
            "==> Train Accuracy: Acc@1 70.350 || Acc@5 90.518\n",
            "==> Test Accuracy:  Acc@1 71.100 || Acc@5 91.910\n",
            "==> 38.04 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 84, lr: 0.020000000000000004 -----\n",
            "Epoch: [84][  0/391]\tTime  0.272 ( 0.272)\tLoss 2.5870e+00 (2.5870e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  80.47 ( 80.47)\n",
            "Epoch: [84][ 30/391]\tTime  0.090 ( 0.096)\tLoss 2.5498e+00 (1.6328e+00)\tAcc@1  36.72 ( 69.43)\tAcc@5  71.88 ( 90.78)\n",
            "Epoch: [84][ 60/391]\tTime  0.091 ( 0.094)\tLoss 2.5927e+00 (1.5952e+00)\tAcc@1  35.16 ( 68.34)\tAcc@5  68.75 ( 89.64)\n",
            "Epoch: [84][ 90/391]\tTime  0.092 ( 0.093)\tLoss 2.2358e+00 (1.5430e+00)\tAcc@1  64.84 ( 69.30)\tAcc@5  92.19 ( 90.37)\n",
            "Epoch: [84][120/391]\tTime  0.091 ( 0.092)\tLoss 4.3186e-01 (1.5568e+00)\tAcc@1  88.28 ( 68.14)\tAcc@5  98.44 ( 89.60)\n",
            "Epoch: [84][150/391]\tTime  0.090 ( 0.092)\tLoss 4.4733e-01 (1.5310e+00)\tAcc@1  88.28 ( 68.59)\tAcc@5 100.00 ( 89.92)\n",
            "Epoch: [84][180/391]\tTime  0.091 ( 0.092)\tLoss 2.6273e+00 (1.4954e+00)\tAcc@1  24.22 ( 69.13)\tAcc@5  68.75 ( 90.24)\n",
            "Epoch: [84][210/391]\tTime  0.091 ( 0.092)\tLoss 3.8213e-01 (1.4838e+00)\tAcc@1  87.50 ( 69.05)\tAcc@5  98.44 ( 90.28)\n",
            "Epoch: [84][240/391]\tTime  0.090 ( 0.091)\tLoss 3.0763e-01 (1.4596e+00)\tAcc@1  91.41 ( 69.28)\tAcc@5 100.00 ( 90.40)\n",
            "Epoch: [84][270/391]\tTime  0.095 ( 0.091)\tLoss 2.4570e+00 (1.4436e+00)\tAcc@1  51.56 ( 69.47)\tAcc@5  83.59 ( 90.53)\n",
            "Epoch: [84][300/391]\tTime  0.094 ( 0.091)\tLoss 2.0798e+00 (1.4382e+00)\tAcc@1  76.56 ( 69.61)\tAcc@5  92.97 ( 90.63)\n",
            "Epoch: [84][330/391]\tTime  0.090 ( 0.091)\tLoss 3.6022e-01 (1.4186e+00)\tAcc@1  89.84 ( 70.11)\tAcc@5  98.44 ( 90.89)\n",
            "Epoch: [84][360/391]\tTime  0.090 ( 0.091)\tLoss 2.7431e+00 (1.4515e+00)\tAcc@1  31.25 ( 69.61)\tAcc@5  63.28 ( 90.61)\n",
            "Epoch: [84][390/391]\tTime  0.081 ( 0.091)\tLoss 4.0410e-01 (1.4446e+00)\tAcc@1  92.50 ( 69.73)\tAcc@5  98.75 ( 90.68)\n",
            "==> Train Accuracy: Acc@1 69.732 || Acc@5 90.676\n",
            "==> Test Accuracy:  Acc@1 72.080 || Acc@5 92.590\n",
            "==> 38.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 85, lr: 0.020000000000000004 -----\n",
            "Epoch: [85][  0/391]\tTime  0.229 ( 0.229)\tLoss 3.2715e-01 (3.2715e-01)\tAcc@1  93.75 ( 93.75)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [85][ 30/391]\tTime  0.090 ( 0.095)\tLoss 2.5169e+00 (1.3701e+00)\tAcc@1  60.94 ( 70.36)\tAcc@5  91.41 ( 90.15)\n",
            "Epoch: [85][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.4901e+00 (1.3209e+00)\tAcc@1  35.94 ( 70.99)\tAcc@5  72.66 ( 90.92)\n",
            "Epoch: [85][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.1882e-01 (1.3234e+00)\tAcc@1  89.84 ( 72.32)\tAcc@5 100.00 ( 91.85)\n",
            "Epoch: [85][120/391]\tTime  0.090 ( 0.092)\tLoss 4.1374e-01 (1.3366e+00)\tAcc@1  89.06 ( 72.53)\tAcc@5  96.88 ( 92.06)\n",
            "Epoch: [85][150/391]\tTime  0.089 ( 0.091)\tLoss 5.4853e-01 (1.3254e+00)\tAcc@1  81.25 ( 72.14)\tAcc@5  97.66 ( 92.02)\n",
            "Epoch: [85][180/391]\tTime  0.091 ( 0.091)\tLoss 2.5540e+00 (1.3069e+00)\tAcc@1  64.06 ( 72.13)\tAcc@5  90.62 ( 91.90)\n",
            "Epoch: [85][210/391]\tTime  0.091 ( 0.091)\tLoss 2.4591e+00 (1.3234e+00)\tAcc@1  57.03 ( 71.49)\tAcc@5  87.50 ( 91.61)\n",
            "Epoch: [85][240/391]\tTime  0.091 ( 0.091)\tLoss 2.4961e+00 (1.3404e+00)\tAcc@1  56.25 ( 71.17)\tAcc@5  84.38 ( 91.40)\n",
            "Epoch: [85][270/391]\tTime  0.090 ( 0.091)\tLoss 4.5057e-01 (1.3722e+00)\tAcc@1  85.16 ( 70.74)\tAcc@5  98.44 ( 91.24)\n",
            "Epoch: [85][300/391]\tTime  0.092 ( 0.091)\tLoss 2.6814e+00 (1.3958e+00)\tAcc@1  44.53 ( 70.26)\tAcc@5  75.00 ( 90.99)\n",
            "Epoch: [85][330/391]\tTime  0.091 ( 0.091)\tLoss 2.5697e+00 (1.3879e+00)\tAcc@1  64.06 ( 70.48)\tAcc@5  91.41 ( 91.15)\n",
            "Epoch: [85][360/391]\tTime  0.090 ( 0.091)\tLoss 3.4447e-01 (1.4103e+00)\tAcc@1  85.94 ( 70.15)\tAcc@5  99.22 ( 90.91)\n",
            "Epoch: [85][390/391]\tTime  0.082 ( 0.091)\tLoss 4.8136e-01 (1.4221e+00)\tAcc@1  85.00 ( 69.93)\tAcc@5 100.00 ( 90.78)\n",
            "==> Train Accuracy: Acc@1 69.932 || Acc@5 90.780\n",
            "==> Test Accuracy:  Acc@1 71.510 || Acc@5 91.950\n",
            "==> 38.06 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 86, lr: 0.020000000000000004 -----\n",
            "Epoch: [86][  0/391]\tTime  0.242 ( 0.242)\tLoss 4.0507e-01 (4.0507e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [86][ 30/391]\tTime  0.090 ( 0.095)\tLoss 3.0941e-01 (1.3652e+00)\tAcc@1  89.84 ( 67.82)\tAcc@5  99.22 ( 89.09)\n",
            "Epoch: [86][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.2430e+00 (1.3562e+00)\tAcc@1  59.38 ( 70.76)\tAcc@5  89.84 ( 91.27)\n",
            "Epoch: [86][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.3609e+00 (1.4294e+00)\tAcc@1  52.34 ( 69.09)\tAcc@5  78.91 ( 90.26)\n",
            "Epoch: [86][120/391]\tTime  0.090 ( 0.092)\tLoss 2.1433e+00 (1.3859e+00)\tAcc@1  67.19 ( 70.12)\tAcc@5  89.84 ( 90.53)\n",
            "Epoch: [86][150/391]\tTime  0.091 ( 0.091)\tLoss 2.6057e+00 (1.3694e+00)\tAcc@1  30.47 ( 70.27)\tAcc@5  67.19 ( 90.55)\n",
            "Epoch: [86][180/391]\tTime  0.090 ( 0.091)\tLoss 3.2345e-01 (1.4052e+00)\tAcc@1  92.19 ( 69.37)\tAcc@5  98.44 ( 89.94)\n",
            "Epoch: [86][210/391]\tTime  0.090 ( 0.091)\tLoss 2.7063e+00 (1.3992e+00)\tAcc@1  22.66 ( 69.53)\tAcc@5  63.28 ( 90.15)\n",
            "Epoch: [86][240/391]\tTime  0.091 ( 0.091)\tLoss 2.2047e+00 (1.3797e+00)\tAcc@1  73.44 ( 70.17)\tAcc@5  95.31 ( 90.66)\n",
            "Epoch: [86][270/391]\tTime  0.091 ( 0.091)\tLoss 2.6052e+00 (1.3703e+00)\tAcc@1  30.47 ( 70.58)\tAcc@5  70.31 ( 90.88)\n",
            "Epoch: [86][300/391]\tTime  0.093 ( 0.091)\tLoss 5.2052e-01 (1.3629e+00)\tAcc@1  82.03 ( 70.92)\tAcc@5  98.44 ( 91.13)\n",
            "Epoch: [86][330/391]\tTime  0.091 ( 0.091)\tLoss 2.4976e+00 (1.3712e+00)\tAcc@1  38.28 ( 70.41)\tAcc@5  75.78 ( 90.80)\n",
            "Epoch: [86][360/391]\tTime  0.091 ( 0.091)\tLoss 2.2757e+00 (1.4221e+00)\tAcc@1  71.88 ( 69.38)\tAcc@5  92.97 ( 90.26)\n",
            "Epoch: [86][390/391]\tTime  0.082 ( 0.091)\tLoss 4.9076e-01 (1.4183e+00)\tAcc@1  83.75 ( 69.47)\tAcc@5  96.25 ( 90.30)\n",
            "==> Train Accuracy: Acc@1 69.466 || Acc@5 90.304\n",
            "==> Test Accuracy:  Acc@1 71.420 || Acc@5 92.090\n",
            "==> 38.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 87, lr: 0.020000000000000004 -----\n",
            "Epoch: [87][  0/391]\tTime  0.268 ( 0.268)\tLoss 2.3891e+00 (2.3891e+00)\tAcc@1  30.47 ( 30.47)\tAcc@5  79.69 ( 79.69)\n",
            "Epoch: [87][ 30/391]\tTime  0.090 ( 0.096)\tLoss 4.5240e-01 (1.3696e+00)\tAcc@1  85.94 ( 70.94)\tAcc@5  96.88 ( 90.95)\n",
            "Epoch: [87][ 60/391]\tTime  0.093 ( 0.094)\tLoss 3.2815e-01 (1.3026e+00)\tAcc@1  91.41 ( 71.98)\tAcc@5  98.44 ( 91.36)\n",
            "Epoch: [87][ 90/391]\tTime  0.092 ( 0.093)\tLoss 2.6687e+00 (1.3112e+00)\tAcc@1  50.78 ( 72.06)\tAcc@5  82.03 ( 91.49)\n",
            "Epoch: [87][120/391]\tTime  0.090 ( 0.092)\tLoss 2.6693e-01 (1.2753e+00)\tAcc@1  93.75 ( 73.01)\tAcc@5 100.00 ( 91.87)\n",
            "Epoch: [87][150/391]\tTime  0.091 ( 0.092)\tLoss 2.3797e+00 (1.3239e+00)\tAcc@1  62.50 ( 72.64)\tAcc@5  89.84 ( 91.72)\n",
            "Epoch: [87][180/391]\tTime  0.091 ( 0.092)\tLoss 2.6803e+00 (1.3420e+00)\tAcc@1  26.56 ( 71.84)\tAcc@5  67.97 ( 91.36)\n",
            "Epoch: [87][210/391]\tTime  0.091 ( 0.092)\tLoss 2.7794e+00 (1.3565e+00)\tAcc@1  51.56 ( 71.84)\tAcc@5  79.69 ( 91.37)\n",
            "Epoch: [87][240/391]\tTime  0.094 ( 0.091)\tLoss 3.7208e-01 (1.3672e+00)\tAcc@1  89.84 ( 71.98)\tAcc@5  99.22 ( 91.46)\n",
            "Epoch: [87][270/391]\tTime  0.091 ( 0.091)\tLoss 2.5138e+00 (1.3473e+00)\tAcc@1  57.81 ( 71.98)\tAcc@5  88.28 ( 91.44)\n",
            "Epoch: [87][300/391]\tTime  0.090 ( 0.091)\tLoss 4.6038e-01 (1.3533e+00)\tAcc@1  86.72 ( 71.48)\tAcc@5  98.44 ( 91.21)\n",
            "Epoch: [87][330/391]\tTime  0.090 ( 0.091)\tLoss 3.2296e-01 (1.3692e+00)\tAcc@1  91.41 ( 71.00)\tAcc@5  99.22 ( 90.98)\n",
            "Epoch: [87][360/391]\tTime  0.090 ( 0.091)\tLoss 4.3884e-01 (1.3601e+00)\tAcc@1  86.72 ( 70.87)\tAcc@5 100.00 ( 90.96)\n",
            "Epoch: [87][390/391]\tTime  0.081 ( 0.091)\tLoss 4.2882e-01 (1.3520e+00)\tAcc@1  86.25 ( 71.07)\tAcc@5  98.75 ( 91.13)\n",
            "==> Train Accuracy: Acc@1 71.074 || Acc@5 91.134\n",
            "==> Test Accuracy:  Acc@1 70.630 || Acc@5 91.940\n",
            "==> 38.07 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 88, lr: 0.020000000000000004 -----\n",
            "Epoch: [88][  0/391]\tTime  0.271 ( 0.271)\tLoss 2.4073e+00 (2.4073e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [88][ 30/391]\tTime  0.091 ( 0.096)\tLoss 2.5261e+00 (1.5986e+00)\tAcc@1  35.94 ( 66.76)\tAcc@5  74.22 ( 89.39)\n",
            "Epoch: [88][ 60/391]\tTime  0.090 ( 0.094)\tLoss 2.9525e-01 (1.4723e+00)\tAcc@1  89.84 ( 70.38)\tAcc@5 100.00 ( 90.95)\n",
            "Epoch: [88][ 90/391]\tTime  0.090 ( 0.093)\tLoss 2.8032e-01 (1.5164e+00)\tAcc@1  91.41 ( 69.94)\tAcc@5 100.00 ( 90.80)\n",
            "Epoch: [88][120/391]\tTime  0.091 ( 0.092)\tLoss 4.5265e-01 (1.5180e+00)\tAcc@1  86.72 ( 69.61)\tAcc@5  96.88 ( 90.63)\n",
            "Epoch: [88][150/391]\tTime  0.090 ( 0.092)\tLoss 2.6938e+00 (1.4927e+00)\tAcc@1  41.41 ( 70.41)\tAcc@5  68.75 ( 90.87)\n",
            "Epoch: [88][180/391]\tTime  0.091 ( 0.092)\tLoss 2.4119e+00 (1.4210e+00)\tAcc@1  69.53 ( 71.51)\tAcc@5  85.94 ( 91.32)\n",
            "Epoch: [88][210/391]\tTime  0.090 ( 0.092)\tLoss 3.6069e-01 (1.4139e+00)\tAcc@1  88.28 ( 71.22)\tAcc@5  99.22 ( 91.15)\n",
            "Epoch: [88][240/391]\tTime  0.090 ( 0.091)\tLoss 2.5169e+00 (1.4043e+00)\tAcc@1  59.38 ( 71.23)\tAcc@5  87.50 ( 91.09)\n",
            "Epoch: [88][270/391]\tTime  0.091 ( 0.091)\tLoss 3.9342e-01 (1.3752e+00)\tAcc@1  86.72 ( 71.92)\tAcc@5  96.88 ( 91.46)\n",
            "Epoch: [88][300/391]\tTime  0.091 ( 0.091)\tLoss 2.0469e+00 (1.3763e+00)\tAcc@1  69.53 ( 71.49)\tAcc@5  93.75 ( 91.24)\n",
            "Epoch: [88][330/391]\tTime  0.090 ( 0.091)\tLoss 4.3464e-01 (1.3778e+00)\tAcc@1  85.94 ( 71.32)\tAcc@5  98.44 ( 91.14)\n",
            "Epoch: [88][360/391]\tTime  0.090 ( 0.091)\tLoss 5.0094e-01 (1.3656e+00)\tAcc@1  87.50 ( 71.54)\tAcc@5  98.44 ( 91.24)\n",
            "Epoch: [88][390/391]\tTime  0.082 ( 0.091)\tLoss 2.6200e+00 (1.3547e+00)\tAcc@1  51.25 ( 71.67)\tAcc@5  76.25 ( 91.36)\n",
            "==> Train Accuracy: Acc@1 71.674 || Acc@5 91.358\n",
            "==> Test Accuracy:  Acc@1 69.860 || Acc@5 91.930\n",
            "==> 38.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 89, lr: 0.020000000000000004 -----\n",
            "Epoch: [89][  0/391]\tTime  0.280 ( 0.280)\tLoss 2.6630e+00 (2.6630e+00)\tAcc@1  32.03 ( 32.03)\tAcc@5  67.97 ( 67.97)\n",
            "Epoch: [89][ 30/391]\tTime  0.091 ( 0.097)\tLoss 2.4833e+00 (1.1982e+00)\tAcc@1  53.91 ( 73.26)\tAcc@5  84.38 ( 91.63)\n",
            "Epoch: [89][ 60/391]\tTime  0.091 ( 0.094)\tLoss 2.3787e-01 (1.2642e+00)\tAcc@1  93.75 ( 71.75)\tAcc@5 100.00 ( 90.83)\n",
            "Epoch: [89][ 90/391]\tTime  0.091 ( 0.093)\tLoss 2.3299e+00 (1.3388e+00)\tAcc@1  50.78 ( 70.12)\tAcc@5  85.16 ( 90.30)\n",
            "Epoch: [89][120/391]\tTime  0.091 ( 0.093)\tLoss 2.2874e+00 (1.4175e+00)\tAcc@1  60.94 ( 69.59)\tAcc@5  86.72 ( 90.21)\n",
            "Epoch: [89][150/391]\tTime  0.091 ( 0.092)\tLoss 3.4643e-01 (1.3843e+00)\tAcc@1  90.62 ( 70.41)\tAcc@5  98.44 ( 90.50)\n",
            "Epoch: [89][180/391]\tTime  0.090 ( 0.092)\tLoss 2.4788e+00 (1.3836e+00)\tAcc@1  50.00 ( 70.62)\tAcc@5  78.91 ( 90.58)\n",
            "Epoch: [89][210/391]\tTime  0.091 ( 0.092)\tLoss 4.1523e-01 (1.3832e+00)\tAcc@1  85.94 ( 70.46)\tAcc@5  98.44 ( 90.58)\n",
            "Epoch: [89][240/391]\tTime  0.090 ( 0.092)\tLoss 3.3062e-01 (1.3643e+00)\tAcc@1  88.28 ( 70.69)\tAcc@5  99.22 ( 90.64)\n",
            "Epoch: [89][270/391]\tTime  0.091 ( 0.092)\tLoss 3.9015e-01 (1.3632e+00)\tAcc@1  88.28 ( 71.04)\tAcc@5 100.00 ( 90.86)\n",
            "Epoch: [89][300/391]\tTime  0.090 ( 0.092)\tLoss 4.3076e-01 (1.3766e+00)\tAcc@1  88.28 ( 70.85)\tAcc@5 100.00 ( 90.75)\n",
            "Epoch: [89][330/391]\tTime  0.094 ( 0.092)\tLoss 5.1909e-01 (1.3568e+00)\tAcc@1  84.38 ( 71.36)\tAcc@5  98.44 ( 90.99)\n",
            "Epoch: [89][360/391]\tTime  0.094 ( 0.091)\tLoss 5.7813e-01 (1.3592e+00)\tAcc@1  84.38 ( 71.21)\tAcc@5  96.88 ( 90.95)\n",
            "Epoch: [89][390/391]\tTime  0.082 ( 0.091)\tLoss 2.2625e+00 (1.3680e+00)\tAcc@1  50.00 ( 71.18)\tAcc@5  82.50 ( 90.98)\n",
            "==> Train Accuracy: Acc@1 71.182 || Acc@5 90.984\n",
            "==> Test Accuracy:  Acc@1 71.930 || Acc@5 92.550\n",
            "==> 38.21 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 90, lr: 0.004000000000000001 -----\n",
            "Epoch: [90][  0/391]\tTime  0.268 ( 0.268)\tLoss 2.4866e+00 (2.4866e+00)\tAcc@1  40.62 ( 40.62)\tAcc@5  76.56 ( 76.56)\n",
            "Epoch: [90][ 30/391]\tTime  0.091 ( 0.096)\tLoss 2.5676e+00 (1.4308e+00)\tAcc@1  44.53 ( 72.76)\tAcc@5  75.78 ( 91.76)\n",
            "Epoch: [90][ 60/391]\tTime  0.091 ( 0.094)\tLoss 2.6581e+00 (1.4790e+00)\tAcc@1  42.97 ( 71.71)\tAcc@5  73.44 ( 91.32)\n",
            "Epoch: [90][ 90/391]\tTime  0.090 ( 0.093)\tLoss 1.8340e+00 (1.4976e+00)\tAcc@1  79.69 ( 71.03)\tAcc@5  96.09 ( 91.11)\n",
            "Epoch: [90][120/391]\tTime  0.091 ( 0.092)\tLoss 1.4741e-01 (1.4274e+00)\tAcc@1  97.66 ( 72.09)\tAcc@5 100.00 ( 91.54)\n",
            "Epoch: [90][150/391]\tTime  0.090 ( 0.092)\tLoss 2.0230e+00 (1.3825e+00)\tAcc@1  68.75 ( 73.03)\tAcc@5  97.66 ( 91.96)\n",
            "Epoch: [90][180/391]\tTime  0.091 ( 0.092)\tLoss 2.1593e+00 (1.3689e+00)\tAcc@1  65.62 ( 73.17)\tAcc@5  89.06 ( 92.08)\n",
            "Epoch: [90][210/391]\tTime  0.090 ( 0.091)\tLoss 2.0604e-01 (1.3819e+00)\tAcc@1  94.53 ( 73.02)\tAcc@5 100.00 ( 92.07)\n",
            "Epoch: [90][240/391]\tTime  0.091 ( 0.091)\tLoss 2.5838e+00 (1.3658e+00)\tAcc@1  25.78 ( 73.30)\tAcc@5  67.19 ( 92.25)\n",
            "Epoch: [90][270/391]\tTime  0.090 ( 0.091)\tLoss 2.0724e-01 (1.3499e+00)\tAcc@1  95.31 ( 73.43)\tAcc@5 100.00 ( 92.29)\n",
            "Epoch: [90][300/391]\tTime  0.090 ( 0.091)\tLoss 1.3304e-01 (1.3198e+00)\tAcc@1  96.09 ( 74.07)\tAcc@5 100.00 ( 92.48)\n",
            "Epoch: [90][330/391]\tTime  0.095 ( 0.091)\tLoss 1.6885e-01 (1.2926e+00)\tAcc@1  96.09 ( 74.89)\tAcc@5  99.22 ( 92.85)\n",
            "Epoch: [90][360/391]\tTime  0.090 ( 0.091)\tLoss 3.6073e-01 (1.2790e+00)\tAcc@1  89.84 ( 75.13)\tAcc@5  98.44 ( 92.94)\n",
            "Epoch: [90][390/391]\tTime  0.082 ( 0.091)\tLoss 1.7903e-01 (1.2813e+00)\tAcc@1  93.75 ( 75.00)\tAcc@5 100.00 ( 92.87)\n",
            "==> Train Accuracy: Acc@1 74.998 || Acc@5 92.872\n",
            "==> Test Accuracy:  Acc@1 77.720 || Acc@5 94.600\n",
            "==> 38.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 91, lr: 0.004000000000000001 -----\n",
            "Epoch: [91][  0/391]\tTime  0.248 ( 0.248)\tLoss 2.3384e+00 (2.3384e+00)\tAcc@1  33.59 ( 33.59)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [91][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.7782e-01 (1.0313e+00)\tAcc@1  95.31 ( 81.70)\tAcc@5  99.22 ( 95.34)\n",
            "Epoch: [91][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.2075e+00 (9.7733e-01)\tAcc@1  39.06 ( 82.83)\tAcc@5  80.47 ( 95.90)\n",
            "Epoch: [91][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.0810e+00 (1.1116e+00)\tAcc@1  69.53 ( 80.58)\tAcc@5  93.75 ( 95.07)\n",
            "Epoch: [91][120/391]\tTime  0.091 ( 0.092)\tLoss 2.2620e+00 (1.0747e+00)\tAcc@1  53.91 ( 81.03)\tAcc@5  79.69 ( 95.07)\n",
            "Epoch: [91][150/391]\tTime  0.083 ( 0.092)\tLoss 2.0367e+00 (1.0407e+00)\tAcc@1  39.06 ( 81.27)\tAcc@5  85.16 ( 95.20)\n",
            "Epoch: [91][180/391]\tTime  0.090 ( 0.091)\tLoss 1.8393e-01 (1.0438e+00)\tAcc@1  93.75 ( 81.26)\tAcc@5 100.00 ( 95.36)\n",
            "Epoch: [91][210/391]\tTime  0.097 ( 0.091)\tLoss 1.7155e-01 (1.0137e+00)\tAcc@1  93.75 ( 81.93)\tAcc@5 100.00 ( 95.52)\n",
            "Epoch: [91][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1890e-01 (1.0487e+00)\tAcc@1  96.09 ( 81.22)\tAcc@5 100.00 ( 95.27)\n",
            "Epoch: [91][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6940e+00 (1.1037e+00)\tAcc@1  80.47 ( 80.09)\tAcc@5  96.09 ( 94.91)\n",
            "Epoch: [91][300/391]\tTime  0.091 ( 0.091)\tLoss 1.6031e-01 (1.1223e+00)\tAcc@1  96.09 ( 79.53)\tAcc@5 100.00 ( 94.71)\n",
            "Epoch: [91][330/391]\tTime  0.091 ( 0.091)\tLoss 2.4194e+00 (1.1233e+00)\tAcc@1  46.88 ( 78.95)\tAcc@5  82.03 ( 94.45)\n",
            "Epoch: [91][360/391]\tTime  0.091 ( 0.091)\tLoss 2.2607e+00 (1.1350e+00)\tAcc@1  42.19 ( 78.77)\tAcc@5  80.47 ( 94.41)\n",
            "Epoch: [91][390/391]\tTime  0.082 ( 0.091)\tLoss 2.2143e+00 (1.1319e+00)\tAcc@1  61.25 ( 78.88)\tAcc@5  91.25 ( 94.42)\n",
            "==> Train Accuracy: Acc@1 78.882 || Acc@5 94.418\n",
            "==> Test Accuracy:  Acc@1 77.580 || Acc@5 94.820\n",
            "==> 38.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 92, lr: 0.004000000000000001 -----\n",
            "Epoch: [92][  0/391]\tTime  0.232 ( 0.232)\tLoss 1.1003e-01 (1.1003e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [92][ 30/391]\tTime  0.091 ( 0.095)\tLoss 1.8229e+00 (1.3277e+00)\tAcc@1  91.41 ( 77.60)\tAcc@5  98.44 ( 94.05)\n",
            "Epoch: [92][ 60/391]\tTime  0.092 ( 0.093)\tLoss 2.2234e+00 (1.2934e+00)\tAcc@1  66.41 ( 76.14)\tAcc@5  94.53 ( 93.51)\n",
            "Epoch: [92][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.5534e-01 (1.1717e+00)\tAcc@1  94.53 ( 78.83)\tAcc@5 100.00 ( 94.46)\n",
            "Epoch: [92][120/391]\tTime  0.091 ( 0.092)\tLoss 1.8334e-01 (1.1620e+00)\tAcc@1  94.53 ( 78.56)\tAcc@5 100.00 ( 94.45)\n",
            "Epoch: [92][150/391]\tTime  0.091 ( 0.092)\tLoss 2.2605e+00 (1.1687e+00)\tAcc@1  66.41 ( 78.90)\tAcc@5  88.28 ( 94.50)\n",
            "Epoch: [92][180/391]\tTime  0.090 ( 0.091)\tLoss 8.2149e-02 (1.1332e+00)\tAcc@1  98.44 ( 79.92)\tAcc@5 100.00 ( 94.84)\n",
            "Epoch: [92][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5041e-01 (1.1521e+00)\tAcc@1  94.53 ( 79.33)\tAcc@5 100.00 ( 94.63)\n",
            "Epoch: [92][240/391]\tTime  0.091 ( 0.091)\tLoss 1.0452e-01 (1.1747e+00)\tAcc@1  98.44 ( 79.02)\tAcc@5 100.00 ( 94.52)\n",
            "Epoch: [92][270/391]\tTime  0.093 ( 0.091)\tLoss 2.0274e+00 (1.1956e+00)\tAcc@1  68.75 ( 78.19)\tAcc@5  92.97 ( 94.20)\n",
            "Epoch: [92][300/391]\tTime  0.097 ( 0.091)\tLoss 1.0295e-01 (1.2023e+00)\tAcc@1  96.88 ( 77.99)\tAcc@5 100.00 ( 94.15)\n",
            "Epoch: [92][330/391]\tTime  0.090 ( 0.091)\tLoss 8.8232e-02 (1.2104e+00)\tAcc@1  99.22 ( 77.73)\tAcc@5 100.00 ( 94.14)\n",
            "Epoch: [92][360/391]\tTime  0.094 ( 0.091)\tLoss 1.9485e+00 (1.2307e+00)\tAcc@1  78.91 ( 77.05)\tAcc@5  97.66 ( 93.89)\n",
            "Epoch: [92][390/391]\tTime  0.081 ( 0.091)\tLoss 2.5231e-01 (1.2374e+00)\tAcc@1  93.75 ( 76.72)\tAcc@5 100.00 ( 93.76)\n",
            "==> Train Accuracy: Acc@1 76.722 || Acc@5 93.758\n",
            "==> Test Accuracy:  Acc@1 77.850 || Acc@5 94.760\n",
            "==> 38.02 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 93, lr: 0.004000000000000001 -----\n",
            "Epoch: [93][  0/391]\tTime  0.224 ( 0.224)\tLoss 1.6554e-01 (1.6554e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][ 30/391]\tTime  0.090 ( 0.095)\tLoss 9.8727e-02 (9.7682e-01)\tAcc@1  98.44 ( 82.94)\tAcc@5 100.00 ( 95.74)\n",
            "Epoch: [93][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.3402e-01 (1.0926e+00)\tAcc@1  96.09 ( 79.48)\tAcc@5 100.00 ( 94.52)\n",
            "Epoch: [93][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.1978e-01 (1.0941e+00)\tAcc@1  96.88 ( 78.93)\tAcc@5 100.00 ( 94.44)\n",
            "Epoch: [93][120/391]\tTime  0.090 ( 0.092)\tLoss 2.1901e+00 (1.1040e+00)\tAcc@1  45.31 ( 78.48)\tAcc@5  82.81 ( 94.28)\n",
            "Epoch: [93][150/391]\tTime  0.091 ( 0.092)\tLoss 1.4491e-01 (1.0403e+00)\tAcc@1  96.09 ( 79.71)\tAcc@5 100.00 ( 94.63)\n",
            "Epoch: [93][180/391]\tTime  0.092 ( 0.091)\tLoss 2.0124e+00 (1.0751e+00)\tAcc@1  88.28 ( 79.14)\tAcc@5  96.88 ( 94.44)\n",
            "Epoch: [93][210/391]\tTime  0.090 ( 0.091)\tLoss 1.2670e-01 (1.0402e+00)\tAcc@1  97.66 ( 80.02)\tAcc@5 100.00 ( 94.74)\n",
            "Epoch: [93][240/391]\tTime  0.091 ( 0.091)\tLoss 2.2388e+00 (1.0388e+00)\tAcc@1  42.19 ( 80.01)\tAcc@5  81.25 ( 94.72)\n",
            "Epoch: [93][270/391]\tTime  0.091 ( 0.091)\tLoss 2.2582e+00 (1.0499e+00)\tAcc@1  57.81 ( 79.59)\tAcc@5  87.50 ( 94.55)\n",
            "Epoch: [93][300/391]\tTime  0.090 ( 0.091)\tLoss 1.1371e-01 (1.0418e+00)\tAcc@1  97.66 ( 79.80)\tAcc@5 100.00 ( 94.60)\n",
            "Epoch: [93][330/391]\tTime  0.093 ( 0.091)\tLoss 1.9588e+00 (1.0672e+00)\tAcc@1  82.03 ( 79.35)\tAcc@5  98.44 ( 94.55)\n",
            "Epoch: [93][360/391]\tTime  0.090 ( 0.091)\tLoss 9.5762e-02 (1.0696e+00)\tAcc@1  98.44 ( 78.96)\tAcc@5 100.00 ( 94.42)\n",
            "Epoch: [93][390/391]\tTime  0.081 ( 0.091)\tLoss 7.7487e-02 (1.0827e+00)\tAcc@1 100.00 ( 78.88)\tAcc@5 100.00 ( 94.37)\n",
            "==> Train Accuracy: Acc@1 78.884 || Acc@5 94.368\n",
            "==> Test Accuracy:  Acc@1 78.750 || Acc@5 94.900\n",
            "==> 38.07 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 94, lr: 0.004000000000000001 -----\n",
            "Epoch: [94][  0/391]\tTime  0.268 ( 0.268)\tLoss 2.4535e+00 (2.4535e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  83.59 ( 83.59)\n",
            "Epoch: [94][ 30/391]\tTime  0.092 ( 0.096)\tLoss 2.1628e+00 (1.0464e+00)\tAcc@1  42.97 ( 82.33)\tAcc@5  79.69 ( 95.94)\n",
            "Epoch: [94][ 60/391]\tTime  0.090 ( 0.094)\tLoss 5.8704e-02 (1.0360e+00)\tAcc@1  99.22 ( 80.05)\tAcc@5 100.00 ( 94.93)\n",
            "Epoch: [94][ 90/391]\tTime  0.090 ( 0.093)\tLoss 1.1830e-01 (9.4260e-01)\tAcc@1  98.44 ( 81.21)\tAcc@5  99.22 ( 95.32)\n",
            "Epoch: [94][120/391]\tTime  0.090 ( 0.092)\tLoss 1.9836e+00 (8.9299e-01)\tAcc@1  75.78 ( 82.98)\tAcc@5  97.66 ( 96.00)\n",
            "Epoch: [94][150/391]\tTime  0.091 ( 0.092)\tLoss 2.0294e+00 (9.6728e-01)\tAcc@1  43.75 ( 81.08)\tAcc@5  80.47 ( 95.55)\n",
            "Epoch: [94][180/391]\tTime  0.091 ( 0.092)\tLoss 1.8719e+00 (9.8491e-01)\tAcc@1  55.47 ( 80.91)\tAcc@5  92.97 ( 95.49)\n",
            "Epoch: [94][210/391]\tTime  0.091 ( 0.092)\tLoss 1.1662e-01 (1.0073e+00)\tAcc@1  96.88 ( 80.78)\tAcc@5 100.00 ( 95.41)\n",
            "Epoch: [94][240/391]\tTime  0.091 ( 0.091)\tLoss 2.1376e+00 (1.0288e+00)\tAcc@1  50.78 ( 80.52)\tAcc@5  85.16 ( 95.39)\n",
            "Epoch: [94][270/391]\tTime  0.091 ( 0.091)\tLoss 1.9219e+00 (1.0389e+00)\tAcc@1  77.34 ( 80.43)\tAcc@5  99.22 ( 95.31)\n",
            "Epoch: [94][300/391]\tTime  0.093 ( 0.091)\tLoss 1.6360e+00 (1.0176e+00)\tAcc@1  95.31 ( 81.01)\tAcc@5  99.22 ( 95.42)\n",
            "Epoch: [94][330/391]\tTime  0.090 ( 0.091)\tLoss 1.4343e-01 (9.9650e-01)\tAcc@1  96.09 ( 81.29)\tAcc@5 100.00 ( 95.50)\n",
            "Epoch: [94][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1479e-01 (9.8334e-01)\tAcc@1  96.88 ( 81.34)\tAcc@5 100.00 ( 95.50)\n",
            "Epoch: [94][390/391]\tTime  0.078 ( 0.091)\tLoss 2.2174e-01 (9.8264e-01)\tAcc@1  95.00 ( 81.23)\tAcc@5  98.75 ( 95.46)\n",
            "==> Train Accuracy: Acc@1 81.228 || Acc@5 95.456\n",
            "==> Test Accuracy:  Acc@1 78.730 || Acc@5 94.980\n",
            "==> 38.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 95, lr: 0.004000000000000001 -----\n",
            "Epoch: [95][  0/391]\tTime  0.261 ( 0.261)\tLoss 1.9283e+00 (1.9283e+00)\tAcc@1  71.09 ( 71.09)\tAcc@5  93.75 ( 93.75)\n",
            "Epoch: [95][ 30/391]\tTime  0.090 ( 0.096)\tLoss 2.2325e+00 (1.2069e+00)\tAcc@1  32.81 ( 73.06)\tAcc@5  79.69 ( 91.83)\n",
            "Epoch: [95][ 60/391]\tTime  0.095 ( 0.094)\tLoss 1.2136e-01 (1.0948e+00)\tAcc@1  96.88 ( 77.38)\tAcc@5 100.00 ( 93.87)\n",
            "Epoch: [95][ 90/391]\tTime  0.091 ( 0.093)\tLoss 1.6151e+00 (1.1147e+00)\tAcc@1  91.41 ( 77.66)\tAcc@5 100.00 ( 93.71)\n",
            "Epoch: [95][120/391]\tTime  0.091 ( 0.092)\tLoss 2.0222e+00 (1.1556e+00)\tAcc@1  49.22 ( 77.55)\tAcc@5  92.97 ( 93.95)\n",
            "Epoch: [95][150/391]\tTime  0.091 ( 0.092)\tLoss 2.1378e+00 (1.1804e+00)\tAcc@1  54.69 ( 77.17)\tAcc@5  90.62 ( 93.97)\n",
            "Epoch: [95][180/391]\tTime  0.091 ( 0.092)\tLoss 1.9091e+00 (1.1646e+00)\tAcc@1  67.97 ( 77.05)\tAcc@5  92.97 ( 93.95)\n",
            "Epoch: [95][210/391]\tTime  0.090 ( 0.092)\tLoss 2.2859e+00 (1.1098e+00)\tAcc@1  46.09 ( 77.99)\tAcc@5  85.16 ( 94.21)\n",
            "Epoch: [95][240/391]\tTime  0.091 ( 0.092)\tLoss 1.8798e+00 (1.1261e+00)\tAcc@1  64.06 ( 77.44)\tAcc@5  93.75 ( 94.02)\n",
            "Epoch: [95][270/391]\tTime  0.090 ( 0.091)\tLoss 1.1010e-01 (1.1404e+00)\tAcc@1  96.09 ( 77.46)\tAcc@5 100.00 ( 94.09)\n",
            "Epoch: [95][300/391]\tTime  0.091 ( 0.091)\tLoss 2.1978e+00 (1.1130e+00)\tAcc@1  60.94 ( 78.28)\tAcc@5  92.97 ( 94.40)\n",
            "Epoch: [95][330/391]\tTime  0.090 ( 0.091)\tLoss 1.0990e-01 (1.1186e+00)\tAcc@1  97.66 ( 78.29)\tAcc@5 100.00 ( 94.43)\n",
            "Epoch: [95][360/391]\tTime  0.090 ( 0.091)\tLoss 1.0337e-01 (1.1276e+00)\tAcc@1  96.88 ( 78.01)\tAcc@5 100.00 ( 94.34)\n",
            "Epoch: [95][390/391]\tTime  0.083 ( 0.091)\tLoss 2.0682e+00 (1.1169e+00)\tAcc@1  53.75 ( 78.43)\tAcc@5  91.25 ( 94.46)\n",
            "==> Train Accuracy: Acc@1 78.434 || Acc@5 94.458\n",
            "==> Test Accuracy:  Acc@1 78.600 || Acc@5 94.810\n",
            "==> 38.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 96, lr: 0.004000000000000001 -----\n",
            "Epoch: [96][  0/391]\tTime  0.256 ( 0.256)\tLoss 6.9307e-02 (6.9307e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][ 30/391]\tTime  0.086 ( 0.096)\tLoss 1.3791e-01 (1.1338e+00)\tAcc@1  95.31 ( 79.18)\tAcc@5 100.00 ( 94.28)\n",
            "Epoch: [96][ 60/391]\tTime  0.089 ( 0.093)\tLoss 8.4754e-02 (1.1114e+00)\tAcc@1  97.66 ( 79.24)\tAcc@5  99.22 ( 94.49)\n",
            "Epoch: [96][ 90/391]\tTime  0.088 ( 0.092)\tLoss 2.1061e+00 (1.2297e+00)\tAcc@1  65.62 ( 75.77)\tAcc@5  88.28 ( 93.60)\n",
            "Epoch: [96][120/391]\tTime  0.090 ( 0.092)\tLoss 1.9007e+00 (1.2163e+00)\tAcc@1  86.72 ( 76.36)\tAcc@5  96.88 ( 93.77)\n",
            "Epoch: [96][150/391]\tTime  0.090 ( 0.092)\tLoss 1.2296e-01 (1.1944e+00)\tAcc@1  96.09 ( 76.70)\tAcc@5 100.00 ( 93.97)\n",
            "Epoch: [96][180/391]\tTime  0.090 ( 0.092)\tLoss 1.0990e-01 (1.2051e+00)\tAcc@1  97.66 ( 76.02)\tAcc@5 100.00 ( 93.84)\n",
            "Epoch: [96][210/391]\tTime  0.090 ( 0.091)\tLoss 8.8845e-02 (1.1852e+00)\tAcc@1  98.44 ( 76.16)\tAcc@5 100.00 ( 93.82)\n",
            "Epoch: [96][240/391]\tTime  0.091 ( 0.091)\tLoss 1.1297e+00 (1.1651e+00)\tAcc@1  99.22 ( 76.61)\tAcc@5 100.00 ( 93.97)\n",
            "Epoch: [96][270/391]\tTime  0.091 ( 0.091)\tLoss 2.0906e+00 (1.1444e+00)\tAcc@1  39.84 ( 76.82)\tAcc@5  83.59 ( 93.99)\n",
            "Epoch: [96][300/391]\tTime  0.091 ( 0.091)\tLoss 6.9765e-02 (1.1372e+00)\tAcc@1  99.22 ( 77.17)\tAcc@5 100.00 ( 94.17)\n",
            "Epoch: [96][330/391]\tTime  0.091 ( 0.091)\tLoss 9.8629e-02 (1.1254e+00)\tAcc@1  97.66 ( 77.49)\tAcc@5 100.00 ( 94.25)\n",
            "Epoch: [96][360/391]\tTime  0.091 ( 0.091)\tLoss 1.9906e+00 (1.1379e+00)\tAcc@1  82.81 ( 77.48)\tAcc@5  96.88 ( 94.28)\n",
            "Epoch: [96][390/391]\tTime  0.082 ( 0.091)\tLoss 1.7106e-01 (1.1439e+00)\tAcc@1  96.25 ( 77.36)\tAcc@5  98.75 ( 94.26)\n",
            "==> Train Accuracy: Acc@1 77.360 || Acc@5 94.256\n",
            "==> Test Accuracy:  Acc@1 77.900 || Acc@5 94.670\n",
            "==> 38.07 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 97, lr: 0.004000000000000001 -----\n",
            "Epoch: [97][  0/391]\tTime  0.250 ( 0.250)\tLoss 1.5722e+00 (1.5722e+00)\tAcc@1  94.53 ( 94.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.1021e-01 (1.0084e+00)\tAcc@1  96.09 ( 81.15)\tAcc@5 100.00 ( 95.84)\n",
            "Epoch: [97][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.9547e+00 (9.5718e-01)\tAcc@1  51.56 ( 82.45)\tAcc@5  86.72 ( 95.97)\n",
            "Epoch: [97][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.1554e-01 (9.3207e-01)\tAcc@1  96.09 ( 83.09)\tAcc@5 100.00 ( 95.96)\n",
            "Epoch: [97][120/391]\tTime  0.090 ( 0.092)\tLoss 5.8255e-02 (9.3379e-01)\tAcc@1  99.22 ( 83.81)\tAcc@5 100.00 ( 96.13)\n",
            "Epoch: [97][150/391]\tTime  0.090 ( 0.092)\tLoss 9.0715e-02 (9.6881e-01)\tAcc@1  97.66 ( 82.69)\tAcc@5 100.00 ( 95.87)\n",
            "Epoch: [97][180/391]\tTime  0.093 ( 0.092)\tLoss 1.8654e+00 (9.9503e-01)\tAcc@1  69.53 ( 81.95)\tAcc@5  94.53 ( 95.57)\n",
            "Epoch: [97][210/391]\tTime  0.090 ( 0.092)\tLoss 8.9863e-02 (9.9156e-01)\tAcc@1  97.66 ( 82.33)\tAcc@5 100.00 ( 95.66)\n",
            "Epoch: [97][240/391]\tTime  0.092 ( 0.091)\tLoss 2.1518e+00 (1.0192e+00)\tAcc@1  64.84 ( 81.68)\tAcc@5  91.41 ( 95.52)\n",
            "Epoch: [97][270/391]\tTime  0.086 ( 0.091)\tLoss 1.7162e-01 (9.8552e-01)\tAcc@1  94.53 ( 82.17)\tAcc@5 100.00 ( 95.62)\n",
            "Epoch: [97][300/391]\tTime  0.091 ( 0.091)\tLoss 1.9175e+00 (9.9061e-01)\tAcc@1  40.62 ( 81.67)\tAcc@5  85.94 ( 95.44)\n",
            "Epoch: [97][330/391]\tTime  0.091 ( 0.091)\tLoss 1.5644e+00 (1.0108e+00)\tAcc@1  89.84 ( 81.35)\tAcc@5  99.22 ( 95.39)\n",
            "Epoch: [97][360/391]\tTime  0.091 ( 0.091)\tLoss 2.0214e+00 (1.0009e+00)\tAcc@1  83.59 ( 81.46)\tAcc@5  95.31 ( 95.43)\n",
            "Epoch: [97][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5622e-01 (1.0184e+00)\tAcc@1  93.75 ( 81.20)\tAcc@5 100.00 ( 95.37)\n",
            "==> Train Accuracy: Acc@1 81.202 || Acc@5 95.374\n",
            "==> Test Accuracy:  Acc@1 77.930 || Acc@5 94.740\n",
            "==> 38.07 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 98, lr: 0.004000000000000001 -----\n",
            "Epoch: [98][  0/391]\tTime  0.241 ( 0.241)\tLoss 1.5611e-01 (1.5611e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [98][ 30/391]\tTime  0.090 ( 0.095)\tLoss 8.1080e-02 (1.1455e+00)\tAcc@1  98.44 ( 79.36)\tAcc@5 100.00 ( 94.78)\n",
            "Epoch: [98][ 60/391]\tTime  0.090 ( 0.093)\tLoss 5.1354e-02 (1.0013e+00)\tAcc@1  99.22 ( 81.54)\tAcc@5 100.00 ( 95.68)\n",
            "Epoch: [98][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.5375e+00 (9.6955e-01)\tAcc@1  88.28 ( 83.23)\tAcc@5 100.00 ( 96.21)\n",
            "Epoch: [98][120/391]\tTime  0.090 ( 0.092)\tLoss 1.8005e+00 (9.7521e-01)\tAcc@1  42.19 ( 82.63)\tAcc@5  90.62 ( 96.05)\n",
            "Epoch: [98][150/391]\tTime  0.091 ( 0.092)\tLoss 1.8607e+00 (1.0070e+00)\tAcc@1  64.84 ( 81.36)\tAcc@5  93.75 ( 95.57)\n",
            "Epoch: [98][180/391]\tTime  0.090 ( 0.091)\tLoss 4.8097e-02 (1.0336e+00)\tAcc@1  99.22 ( 80.56)\tAcc@5 100.00 ( 95.26)\n",
            "Epoch: [98][210/391]\tTime  0.091 ( 0.091)\tLoss 2.0512e+00 (9.9445e-01)\tAcc@1  31.25 ( 81.03)\tAcc@5  75.00 ( 95.33)\n",
            "Epoch: [98][240/391]\tTime  0.091 ( 0.091)\tLoss 1.5920e+00 (9.9105e-01)\tAcc@1  92.19 ( 81.54)\tAcc@5  99.22 ( 95.48)\n",
            "Epoch: [98][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8327e+00 (1.0184e+00)\tAcc@1  89.84 ( 80.91)\tAcc@5 100.00 ( 95.31)\n",
            "Epoch: [98][300/391]\tTime  0.090 ( 0.091)\tLoss 8.7257e-02 (9.8263e-01)\tAcc@1  97.66 ( 81.74)\tAcc@5 100.00 ( 95.54)\n",
            "Epoch: [98][330/391]\tTime  0.090 ( 0.091)\tLoss 1.8585e+00 (1.0091e+00)\tAcc@1  71.88 ( 81.33)\tAcc@5  92.97 ( 95.39)\n",
            "Epoch: [98][360/391]\tTime  0.091 ( 0.091)\tLoss 2.0230e+00 (1.0305e+00)\tAcc@1  76.56 ( 81.02)\tAcc@5  97.66 ( 95.39)\n",
            "Epoch: [98][390/391]\tTime  0.086 ( 0.091)\tLoss 1.7939e-01 (1.0189e+00)\tAcc@1  95.00 ( 81.09)\tAcc@5 100.00 ( 95.42)\n",
            "==> Train Accuracy: Acc@1 81.094 || Acc@5 95.418\n",
            "==> Test Accuracy:  Acc@1 78.840 || Acc@5 95.000\n",
            "==> 38.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 99, lr: 0.004000000000000001 -----\n",
            "Epoch: [99][  0/391]\tTime  0.254 ( 0.254)\tLoss 2.0684e+00 (2.0684e+00)\tAcc@1  39.06 ( 39.06)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [99][ 30/391]\tTime  0.089 ( 0.096)\tLoss 6.0057e-02 (1.2218e+00)\tAcc@1  98.44 ( 78.63)\tAcc@5 100.00 ( 95.59)\n",
            "Epoch: [99][ 60/391]\tTime  0.091 ( 0.094)\tLoss 2.2652e+00 (1.2336e+00)\tAcc@1  39.06 ( 78.25)\tAcc@5  75.00 ( 95.25)\n",
            "Epoch: [99][ 90/391]\tTime  0.090 ( 0.093)\tLoss 7.1994e-02 (1.1903e+00)\tAcc@1  97.66 ( 78.15)\tAcc@5 100.00 ( 94.99)\n",
            "Epoch: [99][120/391]\tTime  0.091 ( 0.092)\tLoss 2.0533e+00 (1.1807e+00)\tAcc@1  39.84 ( 77.76)\tAcc@5  80.47 ( 94.92)\n",
            "Epoch: [99][150/391]\tTime  0.091 ( 0.092)\tLoss 1.0665e-01 (1.1563e+00)\tAcc@1  96.88 ( 77.85)\tAcc@5 100.00 ( 94.91)\n",
            "Epoch: [99][180/391]\tTime  0.093 ( 0.092)\tLoss 2.2861e+00 (1.1259e+00)\tAcc@1  49.22 ( 78.68)\tAcc@5  81.25 ( 95.18)\n",
            "Epoch: [99][210/391]\tTime  0.090 ( 0.092)\tLoss 1.0616e-01 (1.0952e+00)\tAcc@1  96.88 ( 79.02)\tAcc@5 100.00 ( 95.18)\n",
            "Epoch: [99][240/391]\tTime  0.090 ( 0.092)\tLoss 9.6355e-02 (1.0663e+00)\tAcc@1  99.22 ( 79.73)\tAcc@5 100.00 ( 95.38)\n",
            "Epoch: [99][270/391]\tTime  0.091 ( 0.091)\tLoss 7.8139e-02 (1.0575e+00)\tAcc@1  98.44 ( 79.90)\tAcc@5 100.00 ( 95.32)\n",
            "Epoch: [99][300/391]\tTime  0.095 ( 0.091)\tLoss 7.2500e-02 (1.0792e+00)\tAcc@1  96.88 ( 79.45)\tAcc@5 100.00 ( 95.16)\n",
            "Epoch: [99][330/391]\tTime  0.090 ( 0.091)\tLoss 7.7182e-02 (1.0767e+00)\tAcc@1  97.66 ( 79.64)\tAcc@5 100.00 ( 95.21)\n",
            "Epoch: [99][360/391]\tTime  0.090 ( 0.091)\tLoss 7.2661e-02 (1.0425e+00)\tAcc@1  98.44 ( 80.30)\tAcc@5 100.00 ( 95.43)\n",
            "Epoch: [99][390/391]\tTime  0.082 ( 0.091)\tLoss 1.8777e+00 (1.0138e+00)\tAcc@1  77.50 ( 80.88)\tAcc@5  98.75 ( 95.58)\n",
            "==> Train Accuracy: Acc@1 80.880 || Acc@5 95.582\n",
            "==> Test Accuracy:  Acc@1 78.670 || Acc@5 95.160\n",
            "==> 38.13 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 100, lr: 0.004000000000000001 -----\n",
            "Epoch: [100][  0/391]\tTime  0.249 ( 0.249)\tLoss 1.8770e+00 (1.8770e+00)\tAcc@1  90.62 ( 90.62)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [100][ 30/391]\tTime  0.091 ( 0.096)\tLoss 2.0457e+00 (8.2623e-01)\tAcc@1  81.25 ( 82.91)\tAcc@5  97.66 ( 95.06)\n",
            "Epoch: [100][ 60/391]\tTime  0.087 ( 0.093)\tLoss 2.0151e+00 (9.6097e-01)\tAcc@1  67.97 ( 82.17)\tAcc@5  93.75 ( 95.39)\n",
            "Epoch: [100][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.9279e+00 (9.3849e-01)\tAcc@1  69.53 ( 83.23)\tAcc@5  94.53 ( 95.81)\n",
            "Epoch: [100][120/391]\tTime  0.092 ( 0.092)\tLoss 9.0778e-02 (9.8817e-01)\tAcc@1  97.66 ( 82.00)\tAcc@5 100.00 ( 95.50)\n",
            "Epoch: [100][150/391]\tTime  0.091 ( 0.092)\tLoss 6.5581e-02 (9.8160e-01)\tAcc@1  98.44 ( 81.82)\tAcc@5 100.00 ( 95.62)\n",
            "Epoch: [100][180/391]\tTime  0.090 ( 0.092)\tLoss 7.4446e-02 (9.9126e-01)\tAcc@1  99.22 ( 81.45)\tAcc@5 100.00 ( 95.52)\n",
            "Epoch: [100][210/391]\tTime  0.091 ( 0.092)\tLoss 7.3054e-02 (9.7593e-01)\tAcc@1  98.44 ( 82.09)\tAcc@5 100.00 ( 95.74)\n",
            "Epoch: [100][240/391]\tTime  0.091 ( 0.091)\tLoss 6.7953e-02 (9.4859e-01)\tAcc@1  98.44 ( 82.59)\tAcc@5 100.00 ( 95.81)\n",
            "Epoch: [100][270/391]\tTime  0.091 ( 0.091)\tLoss 2.2584e+00 (9.7656e-01)\tAcc@1  42.19 ( 82.17)\tAcc@5  84.38 ( 95.68)\n",
            "Epoch: [100][300/391]\tTime  0.090 ( 0.091)\tLoss 5.3754e-02 (9.5657e-01)\tAcc@1 100.00 ( 82.63)\tAcc@5 100.00 ( 95.85)\n",
            "Epoch: [100][330/391]\tTime  0.091 ( 0.091)\tLoss 2.0854e+00 (9.8084e-01)\tAcc@1  64.06 ( 82.45)\tAcc@5  92.97 ( 95.92)\n",
            "Epoch: [100][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8184e+00 (9.8114e-01)\tAcc@1  55.47 ( 82.37)\tAcc@5  92.19 ( 95.89)\n",
            "Epoch: [100][390/391]\tTime  0.082 ( 0.091)\tLoss 2.1630e+00 (9.9301e-01)\tAcc@1  27.50 ( 81.70)\tAcc@5  71.25 ( 95.70)\n",
            "==> Train Accuracy: Acc@1 81.704 || Acc@5 95.700\n",
            "==> Test Accuracy:  Acc@1 78.520 || Acc@5 94.800\n",
            "==> 38.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 101, lr: 0.004000000000000001 -----\n",
            "Epoch: [101][  0/391]\tTime  0.222 ( 0.222)\tLoss 7.0812e-02 (7.0812e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][ 30/391]\tTime  0.091 ( 0.095)\tLoss 1.4761e+00 (7.1441e-01)\tAcc@1  95.31 ( 87.27)\tAcc@5 100.00 ( 96.85)\n",
            "Epoch: [101][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.0942e+00 (7.4052e-01)\tAcc@1  48.44 ( 86.74)\tAcc@5  90.62 ( 96.81)\n",
            "Epoch: [101][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.9900e+00 (9.0618e-01)\tAcc@1  64.84 ( 82.80)\tAcc@5  94.53 ( 95.90)\n",
            "Epoch: [101][120/391]\tTime  0.090 ( 0.092)\tLoss 1.1405e+00 (8.8872e-01)\tAcc@1  96.09 ( 82.86)\tAcc@5  99.22 ( 96.02)\n",
            "Epoch: [101][150/391]\tTime  0.090 ( 0.092)\tLoss 2.0916e+00 (9.1085e-01)\tAcc@1  56.25 ( 82.72)\tAcc@5  91.41 ( 95.99)\n",
            "Epoch: [101][180/391]\tTime  0.088 ( 0.091)\tLoss 9.4140e-02 (9.4957e-01)\tAcc@1  96.09 ( 81.70)\tAcc@5 100.00 ( 95.75)\n",
            "Epoch: [101][210/391]\tTime  0.089 ( 0.091)\tLoss 7.0878e-02 (9.4899e-01)\tAcc@1  97.66 ( 82.10)\tAcc@5 100.00 ( 95.88)\n",
            "Epoch: [101][240/391]\tTime  0.091 ( 0.091)\tLoss 2.1076e+00 (9.9287e-01)\tAcc@1  52.34 ( 81.30)\tAcc@5  85.16 ( 95.70)\n",
            "Epoch: [101][270/391]\tTime  0.091 ( 0.091)\tLoss 2.0673e+00 (1.0116e+00)\tAcc@1  57.81 ( 80.79)\tAcc@5  86.72 ( 95.44)\n",
            "Epoch: [101][300/391]\tTime  0.092 ( 0.091)\tLoss 8.8066e-02 (9.8867e-01)\tAcc@1  96.88 ( 81.16)\tAcc@5 100.00 ( 95.52)\n",
            "Epoch: [101][330/391]\tTime  0.090 ( 0.091)\tLoss 1.3169e-01 (1.0072e+00)\tAcc@1  94.53 ( 80.92)\tAcc@5  99.22 ( 95.49)\n",
            "Epoch: [101][360/391]\tTime  0.091 ( 0.091)\tLoss 1.9402e+00 (1.0030e+00)\tAcc@1  59.38 ( 80.90)\tAcc@5  90.62 ( 95.47)\n",
            "Epoch: [101][390/391]\tTime  0.081 ( 0.091)\tLoss 2.3711e+00 (1.0116e+00)\tAcc@1  52.50 ( 80.22)\tAcc@5  90.00 ( 95.27)\n",
            "==> Train Accuracy: Acc@1 80.224 || Acc@5 95.272\n",
            "==> Test Accuracy:  Acc@1 78.860 || Acc@5 94.870\n",
            "==> 38.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 102, lr: 0.004000000000000001 -----\n",
            "Epoch: [102][  0/391]\tTime  0.271 ( 0.271)\tLoss 5.5285e-02 (5.5285e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.8405e+00 (7.2873e-01)\tAcc@1  85.94 ( 90.02)\tAcc@5  99.22 ( 98.19)\n",
            "Epoch: [102][ 60/391]\tTime  0.091 ( 0.094)\tLoss 1.8156e+00 (7.3630e-01)\tAcc@1  53.91 ( 88.46)\tAcc@5  94.53 ( 97.61)\n",
            "Epoch: [102][ 90/391]\tTime  0.096 ( 0.093)\tLoss 5.4372e-02 (8.5922e-01)\tAcc@1  99.22 ( 84.73)\tAcc@5 100.00 ( 96.81)\n",
            "Epoch: [102][120/391]\tTime  0.091 ( 0.092)\tLoss 5.0272e-02 (9.0572e-01)\tAcc@1  99.22 ( 83.88)\tAcc@5  99.22 ( 96.35)\n",
            "Epoch: [102][150/391]\tTime  0.085 ( 0.092)\tLoss 8.6308e-02 (9.2601e-01)\tAcc@1  97.66 ( 83.56)\tAcc@5 100.00 ( 96.29)\n",
            "Epoch: [102][180/391]\tTime  0.104 ( 0.092)\tLoss 3.6851e-02 (9.0621e-01)\tAcc@1 100.00 ( 83.69)\tAcc@5 100.00 ( 96.28)\n",
            "Epoch: [102][210/391]\tTime  0.091 ( 0.092)\tLoss 2.0287e+00 (9.2476e-01)\tAcc@1  61.72 ( 83.36)\tAcc@5  92.97 ( 96.16)\n",
            "Epoch: [102][240/391]\tTime  0.090 ( 0.091)\tLoss 2.0144e+00 (9.2612e-01)\tAcc@1  56.25 ( 83.08)\tAcc@5  96.09 ( 96.04)\n",
            "Epoch: [102][270/391]\tTime  0.087 ( 0.091)\tLoss 3.5215e-02 (9.1005e-01)\tAcc@1 100.00 ( 83.20)\tAcc@5 100.00 ( 96.11)\n",
            "Epoch: [102][300/391]\tTime  0.089 ( 0.091)\tLoss 2.0299e+00 (9.2190e-01)\tAcc@1  58.59 ( 83.27)\tAcc@5  91.41 ( 96.08)\n",
            "Epoch: [102][330/391]\tTime  0.090 ( 0.091)\tLoss 8.9949e-02 (9.2043e-01)\tAcc@1  97.66 ( 82.97)\tAcc@5  99.22 ( 95.93)\n",
            "Epoch: [102][360/391]\tTime  0.090 ( 0.091)\tLoss 1.7503e+00 (9.1677e-01)\tAcc@1  77.34 ( 83.08)\tAcc@5  98.44 ( 96.01)\n",
            "Epoch: [102][390/391]\tTime  0.082 ( 0.091)\tLoss 2.0835e+00 (9.2500e-01)\tAcc@1  57.50 ( 82.56)\tAcc@5  90.00 ( 95.83)\n",
            "==> Train Accuracy: Acc@1 82.558 || Acc@5 95.826\n",
            "==> Test Accuracy:  Acc@1 79.560 || Acc@5 95.130\n",
            "==> 38.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 103, lr: 0.004000000000000001 -----\n",
            "Epoch: [103][  0/391]\tTime  0.247 ( 0.247)\tLoss 6.8037e-02 (6.8037e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 30/391]\tTime  0.092 ( 0.096)\tLoss 2.0370e+00 (1.0457e+00)\tAcc@1  51.56 ( 78.78)\tAcc@5  93.75 ( 95.36)\n",
            "Epoch: [103][ 60/391]\tTime  0.092 ( 0.093)\tLoss 3.3175e-02 (1.0131e+00)\tAcc@1  99.22 ( 81.42)\tAcc@5 100.00 ( 96.07)\n",
            "Epoch: [103][ 90/391]\tTime  0.090 ( 0.092)\tLoss 6.6188e-02 (9.7285e-01)\tAcc@1  98.44 ( 81.47)\tAcc@5 100.00 ( 96.02)\n",
            "Epoch: [103][120/391]\tTime  0.091 ( 0.092)\tLoss 8.0239e-02 (9.8585e-01)\tAcc@1  99.22 ( 80.79)\tAcc@5 100.00 ( 95.88)\n",
            "Epoch: [103][150/391]\tTime  0.090 ( 0.092)\tLoss 6.8152e-02 (9.4102e-01)\tAcc@1  98.44 ( 82.04)\tAcc@5 100.00 ( 96.12)\n",
            "Epoch: [103][180/391]\tTime  0.090 ( 0.092)\tLoss 9.8894e-02 (1.0221e+00)\tAcc@1  97.66 ( 80.71)\tAcc@5 100.00 ( 95.94)\n",
            "Epoch: [103][210/391]\tTime  0.090 ( 0.091)\tLoss 6.3179e-02 (1.0126e+00)\tAcc@1  99.22 ( 80.99)\tAcc@5 100.00 ( 95.90)\n",
            "Epoch: [103][240/391]\tTime  0.090 ( 0.091)\tLoss 4.5356e-02 (1.0167e+00)\tAcc@1  99.22 ( 80.78)\tAcc@5 100.00 ( 95.74)\n",
            "Epoch: [103][270/391]\tTime  0.091 ( 0.091)\tLoss 1.9956e+00 (1.0147e+00)\tAcc@1  57.03 ( 81.15)\tAcc@5  91.41 ( 95.88)\n",
            "Epoch: [103][300/391]\tTime  0.091 ( 0.091)\tLoss 2.1553e+00 (1.0371e+00)\tAcc@1  50.78 ( 80.74)\tAcc@5  84.38 ( 95.79)\n",
            "Epoch: [103][330/391]\tTime  0.096 ( 0.091)\tLoss 7.2321e-02 (1.0172e+00)\tAcc@1  99.22 ( 80.92)\tAcc@5 100.00 ( 95.78)\n",
            "Epoch: [103][360/391]\tTime  0.091 ( 0.091)\tLoss 2.1692e+00 (1.0302e+00)\tAcc@1  37.50 ( 80.52)\tAcc@5  76.56 ( 95.62)\n",
            "Epoch: [103][390/391]\tTime  0.081 ( 0.091)\tLoss 7.9774e-02 (1.0084e+00)\tAcc@1  97.50 ( 80.91)\tAcc@5 100.00 ( 95.73)\n",
            "==> Train Accuracy: Acc@1 80.906 || Acc@5 95.726\n",
            "==> Test Accuracy:  Acc@1 79.150 || Acc@5 95.100\n",
            "==> 38.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 104, lr: 0.004000000000000001 -----\n",
            "Epoch: [104][  0/391]\tTime  0.268 ( 0.268)\tLoss 1.8518e+00 (1.8518e+00)\tAcc@1  74.22 ( 74.22)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [104][ 30/391]\tTime  0.091 ( 0.096)\tLoss 2.0152e+00 (8.8302e-01)\tAcc@1  67.97 ( 85.84)\tAcc@5  96.09 ( 97.10)\n",
            "Epoch: [104][ 60/391]\tTime  0.090 ( 0.093)\tLoss 3.6928e-02 (9.9339e-01)\tAcc@1 100.00 ( 82.01)\tAcc@5 100.00 ( 95.89)\n",
            "Epoch: [104][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.4323e-02 (9.1985e-01)\tAcc@1  99.22 ( 82.73)\tAcc@5 100.00 ( 96.11)\n",
            "Epoch: [104][120/391]\tTime  0.096 ( 0.092)\tLoss 1.8091e+00 (9.5298e-01)\tAcc@1  74.22 ( 82.19)\tAcc@5  94.53 ( 96.06)\n",
            "Epoch: [104][150/391]\tTime  0.090 ( 0.092)\tLoss 8.6189e-02 (9.2657e-01)\tAcc@1  96.88 ( 83.22)\tAcc@5 100.00 ( 96.35)\n",
            "Epoch: [104][180/391]\tTime  0.090 ( 0.091)\tLoss 7.1636e-02 (9.6645e-01)\tAcc@1  96.88 ( 82.15)\tAcc@5 100.00 ( 95.98)\n",
            "Epoch: [104][210/391]\tTime  0.090 ( 0.091)\tLoss 7.4139e-02 (9.3525e-01)\tAcc@1  98.44 ( 82.71)\tAcc@5 100.00 ( 96.06)\n",
            "Epoch: [104][240/391]\tTime  0.097 ( 0.091)\tLoss 6.1722e-02 (9.5530e-01)\tAcc@1  99.22 ( 81.56)\tAcc@5 100.00 ( 95.72)\n",
            "Epoch: [104][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8695e+00 (9.4417e-01)\tAcc@1  44.53 ( 81.39)\tAcc@5  87.50 ( 95.69)\n",
            "Epoch: [104][300/391]\tTime  0.091 ( 0.091)\tLoss 1.8594e+00 (9.6574e-01)\tAcc@1  78.91 ( 80.93)\tAcc@5  96.09 ( 95.50)\n",
            "Epoch: [104][330/391]\tTime  0.088 ( 0.091)\tLoss 2.0865e+00 (1.0117e+00)\tAcc@1  23.44 ( 80.04)\tAcc@5  73.44 ( 95.26)\n",
            "Epoch: [104][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1598e-01 (9.8609e-01)\tAcc@1  96.09 ( 80.76)\tAcc@5 100.00 ( 95.49)\n",
            "Epoch: [104][390/391]\tTime  0.081 ( 0.091)\tLoss 1.2258e-01 (9.8978e-01)\tAcc@1  96.25 ( 80.58)\tAcc@5 100.00 ( 95.41)\n",
            "==> Train Accuracy: Acc@1 80.582 || Acc@5 95.414\n",
            "==> Test Accuracy:  Acc@1 79.110 || Acc@5 95.270\n",
            "==> 38.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 105, lr: 0.004000000000000001 -----\n",
            "Epoch: [105][  0/391]\tTime  0.235 ( 0.235)\tLoss 4.3085e-02 (4.3085e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][ 30/391]\tTime  0.090 ( 0.095)\tLoss 5.0989e-02 (8.7241e-01)\tAcc@1  98.44 ( 85.86)\tAcc@5 100.00 ( 97.45)\n",
            "Epoch: [105][ 60/391]\tTime  0.086 ( 0.093)\tLoss 5.0190e-02 (9.3871e-01)\tAcc@1  98.44 ( 83.21)\tAcc@5 100.00 ( 96.38)\n",
            "Epoch: [105][ 90/391]\tTime  0.090 ( 0.092)\tLoss 9.1384e-02 (9.6772e-01)\tAcc@1  96.88 ( 83.68)\tAcc@5 100.00 ( 96.60)\n",
            "Epoch: [105][120/391]\tTime  0.091 ( 0.092)\tLoss 1.9516e+00 (8.0665e-01)\tAcc@1  55.47 ( 86.10)\tAcc@5  85.16 ( 97.07)\n",
            "Epoch: [105][150/391]\tTime  0.090 ( 0.092)\tLoss 5.8279e-02 (8.4850e-01)\tAcc@1  99.22 ( 85.39)\tAcc@5 100.00 ( 96.94)\n",
            "Epoch: [105][180/391]\tTime  0.091 ( 0.091)\tLoss 2.0983e+00 (8.7400e-01)\tAcc@1  45.31 ( 84.82)\tAcc@5  81.25 ( 96.60)\n",
            "Epoch: [105][210/391]\tTime  0.090 ( 0.091)\tLoss 5.9121e-02 (8.3978e-01)\tAcc@1  98.44 ( 85.06)\tAcc@5 100.00 ( 96.66)\n",
            "Epoch: [105][240/391]\tTime  0.091 ( 0.091)\tLoss 1.9095e+00 (8.3410e-01)\tAcc@1  42.19 ( 84.97)\tAcc@5  87.50 ( 96.63)\n",
            "Epoch: [105][270/391]\tTime  0.091 ( 0.091)\tLoss 2.1133e+00 (8.3598e-01)\tAcc@1  80.47 ( 84.70)\tAcc@5  93.75 ( 96.45)\n",
            "Epoch: [105][300/391]\tTime  0.090 ( 0.091)\tLoss 1.8491e+00 (8.4292e-01)\tAcc@1  92.19 ( 84.23)\tAcc@5  98.44 ( 96.32)\n",
            "Epoch: [105][330/391]\tTime  0.090 ( 0.091)\tLoss 6.1684e-02 (8.6621e-01)\tAcc@1  97.66 ( 83.87)\tAcc@5 100.00 ( 96.24)\n",
            "Epoch: [105][360/391]\tTime  0.091 ( 0.091)\tLoss 4.6913e-02 (8.8176e-01)\tAcc@1 100.00 ( 83.81)\tAcc@5 100.00 ( 96.29)\n",
            "Epoch: [105][390/391]\tTime  0.083 ( 0.091)\tLoss 1.2289e+00 (9.0218e-01)\tAcc@1  95.00 ( 83.67)\tAcc@5 100.00 ( 96.22)\n",
            "==> Train Accuracy: Acc@1 83.672 || Acc@5 96.218\n",
            "==> Test Accuracy:  Acc@1 78.900 || Acc@5 94.690\n",
            "==> 38.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 106, lr: 0.004000000000000001 -----\n",
            "Epoch: [106][  0/391]\tTime  0.248 ( 0.248)\tLoss 4.4231e-02 (4.4231e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][ 30/391]\tTime  0.091 ( 0.097)\tLoss 1.9764e+00 (1.1696e+00)\tAcc@1  50.00 ( 76.03)\tAcc@5  89.84 ( 94.48)\n",
            "Epoch: [106][ 60/391]\tTime  0.091 ( 0.094)\tLoss 2.0280e+00 (1.0769e+00)\tAcc@1  57.81 ( 79.00)\tAcc@5  89.84 ( 95.49)\n",
            "Epoch: [106][ 90/391]\tTime  0.090 ( 0.093)\tLoss 4.2945e-02 (1.1307e+00)\tAcc@1 100.00 ( 78.92)\tAcc@5 100.00 ( 95.66)\n",
            "Epoch: [106][120/391]\tTime  0.090 ( 0.092)\tLoss 2.0247e+00 (1.0952e+00)\tAcc@1  42.97 ( 79.64)\tAcc@5  83.59 ( 95.72)\n",
            "Epoch: [106][150/391]\tTime  0.090 ( 0.092)\tLoss 4.7155e-02 (1.0865e+00)\tAcc@1  98.44 ( 79.73)\tAcc@5 100.00 ( 95.78)\n",
            "Epoch: [106][180/391]\tTime  0.090 ( 0.092)\tLoss 1.1715e-01 (1.0074e+00)\tAcc@1  96.88 ( 81.06)\tAcc@5 100.00 ( 95.96)\n",
            "Epoch: [106][210/391]\tTime  0.093 ( 0.092)\tLoss 2.1310e+00 (1.0356e+00)\tAcc@1  71.09 ( 80.19)\tAcc@5  97.66 ( 95.68)\n",
            "Epoch: [106][240/391]\tTime  0.091 ( 0.091)\tLoss 1.6317e+00 (1.0901e+00)\tAcc@1  82.81 ( 79.01)\tAcc@5  99.22 ( 95.41)\n",
            "Epoch: [106][270/391]\tTime  0.092 ( 0.091)\tLoss 5.8278e-02 (1.0894e+00)\tAcc@1  97.66 ( 78.80)\tAcc@5 100.00 ( 95.24)\n",
            "Epoch: [106][300/391]\tTime  0.092 ( 0.091)\tLoss 1.9466e+00 (1.0743e+00)\tAcc@1  46.09 ( 79.41)\tAcc@5  84.38 ( 95.41)\n",
            "Epoch: [106][330/391]\tTime  0.091 ( 0.091)\tLoss 2.2481e+00 (1.0780e+00)\tAcc@1  53.91 ( 79.18)\tAcc@5  86.72 ( 95.33)\n",
            "Epoch: [106][360/391]\tTime  0.090 ( 0.091)\tLoss 5.9589e-02 (1.0678e+00)\tAcc@1  99.22 ( 79.15)\tAcc@5 100.00 ( 95.28)\n",
            "Epoch: [106][390/391]\tTime  0.082 ( 0.091)\tLoss 1.9047e+00 (1.0776e+00)\tAcc@1  86.25 ( 79.18)\tAcc@5  97.50 ( 95.32)\n",
            "==> Train Accuracy: Acc@1 79.182 || Acc@5 95.320\n",
            "==> Test Accuracy:  Acc@1 78.900 || Acc@5 94.820\n",
            "==> 38.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 107, lr: 0.004000000000000001 -----\n",
            "Epoch: [107][  0/391]\tTime  0.240 ( 0.240)\tLoss 2.1571e+00 (2.1571e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [107][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.8337e+00 (1.3039e+00)\tAcc@1  75.00 ( 73.54)\tAcc@5  96.09 ( 93.72)\n",
            "Epoch: [107][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.7785e+00 (1.1192e+00)\tAcc@1  67.19 ( 77.13)\tAcc@5  92.19 ( 94.85)\n",
            "Epoch: [107][ 90/391]\tTime  0.095 ( 0.093)\tLoss 5.8487e-02 (1.1419e+00)\tAcc@1  98.44 ( 77.34)\tAcc@5 100.00 ( 94.88)\n",
            "Epoch: [107][120/391]\tTime  0.090 ( 0.092)\tLoss 5.8633e-02 (1.1413e+00)\tAcc@1  97.66 ( 78.78)\tAcc@5 100.00 ( 95.22)\n",
            "Epoch: [107][150/391]\tTime  0.091 ( 0.092)\tLoss 1.7964e+00 (1.0930e+00)\tAcc@1  77.34 ( 79.52)\tAcc@5  96.88 ( 95.54)\n",
            "Epoch: [107][180/391]\tTime  0.089 ( 0.092)\tLoss 4.8929e-02 (1.0402e+00)\tAcc@1  99.22 ( 80.65)\tAcc@5 100.00 ( 95.85)\n",
            "Epoch: [107][210/391]\tTime  0.091 ( 0.092)\tLoss 1.7588e+00 (1.0490e+00)\tAcc@1  73.44 ( 80.97)\tAcc@5  92.97 ( 95.92)\n",
            "Epoch: [107][240/391]\tTime  0.099 ( 0.092)\tLoss 4.2264e-02 (1.0953e+00)\tAcc@1 100.00 ( 79.74)\tAcc@5 100.00 ( 95.46)\n",
            "Epoch: [107][270/391]\tTime  0.093 ( 0.091)\tLoss 1.7999e+00 (1.0613e+00)\tAcc@1  75.00 ( 80.47)\tAcc@5  93.75 ( 95.66)\n",
            "Epoch: [107][300/391]\tTime  0.090 ( 0.091)\tLoss 3.8363e-02 (1.0418e+00)\tAcc@1  99.22 ( 81.02)\tAcc@5 100.00 ( 95.83)\n",
            "Epoch: [107][330/391]\tTime  0.090 ( 0.091)\tLoss 4.0045e-02 (1.0355e+00)\tAcc@1  99.22 ( 80.82)\tAcc@5 100.00 ( 95.67)\n",
            "Epoch: [107][360/391]\tTime  0.085 ( 0.091)\tLoss 1.0694e-01 (1.0313e+00)\tAcc@1  97.66 ( 80.81)\tAcc@5 100.00 ( 95.69)\n",
            "Epoch: [107][390/391]\tTime  0.082 ( 0.091)\tLoss 1.8755e+00 (1.0464e+00)\tAcc@1  65.00 ( 80.12)\tAcc@5  91.25 ( 95.49)\n",
            "==> Train Accuracy: Acc@1 80.118 || Acc@5 95.492\n",
            "==> Test Accuracy:  Acc@1 78.660 || Acc@5 94.780\n",
            "==> 38.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 108, lr: 0.004000000000000001 -----\n",
            "Epoch: [108][  0/391]\tTime  0.237 ( 0.237)\tLoss 4.5740e-02 (4.5740e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][ 30/391]\tTime  0.090 ( 0.096)\tLoss 2.1246e+00 (1.0321e+00)\tAcc@1  61.72 ( 82.46)\tAcc@5  91.41 ( 96.47)\n",
            "Epoch: [108][ 60/391]\tTime  0.090 ( 0.093)\tLoss 8.2643e-02 (9.9063e-01)\tAcc@1  96.88 ( 82.31)\tAcc@5 100.00 ( 96.02)\n",
            "Epoch: [108][ 90/391]\tTime  0.090 ( 0.092)\tLoss 5.3066e-02 (9.8414e-01)\tAcc@1  98.44 ( 81.41)\tAcc@5 100.00 ( 95.78)\n",
            "Epoch: [108][120/391]\tTime  0.091 ( 0.092)\tLoss 1.8792e+00 (9.3440e-01)\tAcc@1  53.12 ( 81.86)\tAcc@5  93.75 ( 95.85)\n",
            "Epoch: [108][150/391]\tTime  0.092 ( 0.092)\tLoss 8.7303e-02 (8.9238e-01)\tAcc@1  96.88 ( 82.46)\tAcc@5 100.00 ( 95.94)\n",
            "Epoch: [108][180/391]\tTime  0.091 ( 0.092)\tLoss 1.7491e+00 (9.2610e-01)\tAcc@1  83.59 ( 81.80)\tAcc@5  98.44 ( 95.86)\n",
            "Epoch: [108][210/391]\tTime  0.090 ( 0.091)\tLoss 2.2584e-02 (9.2625e-01)\tAcc@1 100.00 ( 82.25)\tAcc@5 100.00 ( 96.03)\n",
            "Epoch: [108][240/391]\tTime  0.091 ( 0.091)\tLoss 1.8067e+00 (9.4231e-01)\tAcc@1  91.41 ( 81.91)\tAcc@5  99.22 ( 96.01)\n",
            "Epoch: [108][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8144e+00 (9.1814e-01)\tAcc@1  82.03 ( 82.37)\tAcc@5  97.66 ( 96.11)\n",
            "Epoch: [108][300/391]\tTime  0.091 ( 0.091)\tLoss 3.8113e-02 (9.2837e-01)\tAcc@1 100.00 ( 82.39)\tAcc@5 100.00 ( 96.07)\n",
            "Epoch: [108][330/391]\tTime  0.092 ( 0.091)\tLoss 1.3390e+00 (9.5691e-01)\tAcc@1  96.88 ( 81.65)\tAcc@5 100.00 ( 95.84)\n",
            "Epoch: [108][360/391]\tTime  0.091 ( 0.091)\tLoss 9.1172e-02 (9.4849e-01)\tAcc@1  96.88 ( 81.88)\tAcc@5 100.00 ( 95.93)\n",
            "Epoch: [108][390/391]\tTime  0.083 ( 0.091)\tLoss 1.9032e+00 (9.7123e-01)\tAcc@1  62.50 ( 81.50)\tAcc@5  93.75 ( 95.85)\n",
            "==> Train Accuracy: Acc@1 81.502 || Acc@5 95.852\n",
            "==> Test Accuracy:  Acc@1 78.880 || Acc@5 94.820\n",
            "==> 38.18 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 109, lr: 0.004000000000000001 -----\n",
            "Epoch: [109][  0/391]\tTime  0.249 ( 0.249)\tLoss 1.6983e+00 (1.6983e+00)\tAcc@1  78.91 ( 78.91)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [109][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.9511e+00 (6.8518e-01)\tAcc@1  63.28 ( 88.71)\tAcc@5  88.28 ( 97.78)\n",
            "Epoch: [109][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.9613e+00 (8.2710e-01)\tAcc@1  43.75 ( 83.81)\tAcc@5  81.25 ( 96.44)\n",
            "Epoch: [109][ 90/391]\tTime  0.090 ( 0.093)\tLoss 7.1845e-02 (8.5870e-01)\tAcc@1  99.22 ( 83.29)\tAcc@5 100.00 ( 96.34)\n",
            "Epoch: [109][120/391]\tTime  0.091 ( 0.092)\tLoss 2.0886e+00 (9.2896e-01)\tAcc@1  53.12 ( 81.08)\tAcc@5  91.41 ( 95.84)\n",
            "Epoch: [109][150/391]\tTime  0.090 ( 0.092)\tLoss 6.3414e-02 (9.5577e-01)\tAcc@1  97.66 ( 81.01)\tAcc@5 100.00 ( 95.81)\n",
            "Epoch: [109][180/391]\tTime  0.090 ( 0.092)\tLoss 1.8069e+00 (9.7058e-01)\tAcc@1  83.59 ( 81.18)\tAcc@5  98.44 ( 95.91)\n",
            "Epoch: [109][210/391]\tTime  0.091 ( 0.092)\tLoss 1.0840e+00 (9.9478e-01)\tAcc@1  98.44 ( 81.10)\tAcc@5 100.00 ( 95.85)\n",
            "Epoch: [109][240/391]\tTime  0.090 ( 0.091)\tLoss 4.1668e-02 (9.8168e-01)\tAcc@1 100.00 ( 81.53)\tAcc@5 100.00 ( 95.99)\n",
            "Epoch: [109][270/391]\tTime  0.091 ( 0.091)\tLoss 1.9208e+00 (9.8746e-01)\tAcc@1  52.34 ( 81.46)\tAcc@5  86.72 ( 95.93)\n",
            "Epoch: [109][300/391]\tTime  0.091 ( 0.091)\tLoss 1.6424e+00 (1.0151e+00)\tAcc@1  92.97 ( 80.55)\tAcc@5  99.22 ( 95.64)\n",
            "Epoch: [109][330/391]\tTime  0.091 ( 0.091)\tLoss 2.1320e+00 (1.0293e+00)\tAcc@1  40.62 ( 80.02)\tAcc@5  78.91 ( 95.46)\n",
            "Epoch: [109][360/391]\tTime  0.089 ( 0.091)\tLoss 1.7938e+00 (1.0267e+00)\tAcc@1  53.12 ( 79.97)\tAcc@5  92.19 ( 95.46)\n",
            "Epoch: [109][390/391]\tTime  0.083 ( 0.091)\tLoss 6.0525e-02 (1.0359e+00)\tAcc@1  98.75 ( 79.70)\tAcc@5 100.00 ( 95.39)\n",
            "==> Train Accuracy: Acc@1 79.696 || Acc@5 95.394\n",
            "==> Test Accuracy:  Acc@1 78.700 || Acc@5 95.010\n",
            "==> 38.14 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 110, lr: 0.004000000000000001 -----\n",
            "Epoch: [110][  0/391]\tTime  0.267 ( 0.267)\tLoss 5.7345e-02 (5.7345e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][ 30/391]\tTime  0.090 ( 0.096)\tLoss 5.3243e-02 (9.1529e-01)\tAcc@1  97.66 ( 88.41)\tAcc@5 100.00 ( 97.91)\n",
            "Epoch: [110][ 60/391]\tTime  0.091 ( 0.094)\tLoss 2.0720e+00 (9.3543e-01)\tAcc@1  42.19 ( 85.25)\tAcc@5  82.03 ( 96.90)\n",
            "Epoch: [110][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.5964e-02 (8.8818e-01)\tAcc@1 100.00 ( 83.89)\tAcc@5 100.00 ( 96.18)\n",
            "Epoch: [110][120/391]\tTime  0.091 ( 0.092)\tLoss 2.2013e+00 (9.9071e-01)\tAcc@1  66.41 ( 80.91)\tAcc@5  93.75 ( 95.50)\n",
            "Epoch: [110][150/391]\tTime  0.087 ( 0.092)\tLoss 5.9942e-02 (9.6605e-01)\tAcc@1  99.22 ( 81.04)\tAcc@5 100.00 ( 95.52)\n",
            "Epoch: [110][180/391]\tTime  0.090 ( 0.092)\tLoss 2.3819e-02 (9.3669e-01)\tAcc@1 100.00 ( 81.72)\tAcc@5 100.00 ( 95.76)\n",
            "Epoch: [110][210/391]\tTime  0.090 ( 0.091)\tLoss 4.6812e-02 (9.2315e-01)\tAcc@1  99.22 ( 81.98)\tAcc@5 100.00 ( 95.82)\n",
            "Epoch: [110][240/391]\tTime  0.086 ( 0.091)\tLoss 8.7791e-02 (9.1122e-01)\tAcc@1  97.66 ( 82.13)\tAcc@5 100.00 ( 95.85)\n",
            "Epoch: [110][270/391]\tTime  0.091 ( 0.091)\tLoss 1.9507e+00 (9.2686e-01)\tAcc@1  66.41 ( 81.85)\tAcc@5  92.97 ( 95.83)\n",
            "Epoch: [110][300/391]\tTime  0.092 ( 0.091)\tLoss 2.1048e+00 (9.4029e-01)\tAcc@1  42.97 ( 81.99)\tAcc@5  80.47 ( 95.83)\n",
            "Epoch: [110][330/391]\tTime  0.090 ( 0.091)\tLoss 3.4698e-02 (9.5337e-01)\tAcc@1 100.00 ( 81.74)\tAcc@5 100.00 ( 95.73)\n",
            "Epoch: [110][360/391]\tTime  0.090 ( 0.091)\tLoss 8.5203e-02 (9.4603e-01)\tAcc@1  97.66 ( 81.82)\tAcc@5 100.00 ( 95.76)\n",
            "Epoch: [110][390/391]\tTime  0.082 ( 0.091)\tLoss 1.7983e+00 (9.5497e-01)\tAcc@1  80.00 ( 81.68)\tAcc@5  96.25 ( 95.71)\n",
            "==> Train Accuracy: Acc@1 81.684 || Acc@5 95.714\n",
            "==> Test Accuracy:  Acc@1 78.280 || Acc@5 94.730\n",
            "==> 38.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 111, lr: 0.004000000000000001 -----\n",
            "Epoch: [111][  0/391]\tTime  0.254 ( 0.254)\tLoss 2.0255e+00 (2.0255e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [111][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.8672e+00 (1.3002e+00)\tAcc@1  88.28 ( 78.18)\tAcc@5  98.44 ( 95.41)\n",
            "Epoch: [111][ 60/391]\tTime  0.090 ( 0.093)\tLoss 4.3025e-02 (1.0889e+00)\tAcc@1  99.22 ( 80.35)\tAcc@5 100.00 ( 95.62)\n",
            "Epoch: [111][ 90/391]\tTime  0.090 ( 0.092)\tLoss 8.5075e-02 (9.6427e-01)\tAcc@1  97.66 ( 83.00)\tAcc@5 100.00 ( 96.29)\n",
            "Epoch: [111][120/391]\tTime  0.090 ( 0.092)\tLoss 6.3013e-02 (9.2151e-01)\tAcc@1  98.44 ( 83.56)\tAcc@5 100.00 ( 96.51)\n",
            "Epoch: [111][150/391]\tTime  0.090 ( 0.092)\tLoss 2.0665e+00 (9.5534e-01)\tAcc@1  34.38 ( 82.90)\tAcc@5  79.69 ( 96.34)\n",
            "Epoch: [111][180/391]\tTime  0.091 ( 0.091)\tLoss 1.8592e+00 (9.6725e-01)\tAcc@1  50.00 ( 82.35)\tAcc@5  90.62 ( 96.28)\n",
            "Epoch: [111][210/391]\tTime  0.091 ( 0.091)\tLoss 7.3347e-02 (9.5113e-01)\tAcc@1  97.66 ( 81.94)\tAcc@5 100.00 ( 96.11)\n",
            "Epoch: [111][240/391]\tTime  0.090 ( 0.091)\tLoss 5.6007e-02 (9.6847e-01)\tAcc@1  99.22 ( 81.76)\tAcc@5 100.00 ( 96.15)\n",
            "Epoch: [111][270/391]\tTime  0.090 ( 0.091)\tLoss 2.2660e+00 (9.7691e-01)\tAcc@1  53.91 ( 81.76)\tAcc@5  85.16 ( 96.18)\n",
            "Epoch: [111][300/391]\tTime  0.092 ( 0.091)\tLoss 9.6068e-02 (9.8107e-01)\tAcc@1  95.31 ( 81.43)\tAcc@5 100.00 ( 95.99)\n",
            "Epoch: [111][330/391]\tTime  0.090 ( 0.091)\tLoss 5.0907e-02 (9.7674e-01)\tAcc@1  98.44 ( 81.48)\tAcc@5 100.00 ( 96.01)\n",
            "Epoch: [111][360/391]\tTime  0.092 ( 0.091)\tLoss 2.0261e+00 (9.6209e-01)\tAcc@1  51.56 ( 81.67)\tAcc@5  85.94 ( 96.02)\n",
            "Epoch: [111][390/391]\tTime  0.081 ( 0.091)\tLoss 8.3809e-02 (9.6453e-01)\tAcc@1  97.50 ( 81.61)\tAcc@5 100.00 ( 96.08)\n",
            "==> Train Accuracy: Acc@1 81.610 || Acc@5 96.084\n",
            "==> Test Accuracy:  Acc@1 78.850 || Acc@5 94.860\n",
            "==> 38.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 112, lr: 0.004000000000000001 -----\n",
            "Epoch: [112][  0/391]\tTime  0.252 ( 0.252)\tLoss 3.4790e-02 (3.4790e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][ 30/391]\tTime  0.090 ( 0.096)\tLoss 6.0084e-02 (1.2850e+00)\tAcc@1  99.22 ( 72.53)\tAcc@5 100.00 ( 93.95)\n",
            "Epoch: [112][ 60/391]\tTime  0.091 ( 0.094)\tLoss 1.6383e+00 (1.1765e+00)\tAcc@1  91.41 ( 77.70)\tAcc@5 100.00 ( 95.26)\n",
            "Epoch: [112][ 90/391]\tTime  0.091 ( 0.093)\tLoss 7.0126e-02 (1.0871e+00)\tAcc@1  98.44 ( 80.06)\tAcc@5 100.00 ( 95.80)\n",
            "Epoch: [112][120/391]\tTime  0.091 ( 0.092)\tLoss 1.6497e+00 (1.1354e+00)\tAcc@1  96.88 ( 78.51)\tAcc@5 100.00 ( 95.32)\n",
            "Epoch: [112][150/391]\tTime  0.091 ( 0.092)\tLoss 1.9607e+00 (1.1500e+00)\tAcc@1  81.25 ( 78.43)\tAcc@5  95.31 ( 95.23)\n",
            "Epoch: [112][180/391]\tTime  0.093 ( 0.092)\tLoss 3.4615e-02 (1.1567e+00)\tAcc@1  99.22 ( 77.69)\tAcc@5 100.00 ( 94.80)\n",
            "Epoch: [112][210/391]\tTime  0.092 ( 0.092)\tLoss 4.3443e-02 (1.1344e+00)\tAcc@1  99.22 ( 78.15)\tAcc@5 100.00 ( 94.96)\n",
            "Epoch: [112][240/391]\tTime  0.091 ( 0.091)\tLoss 1.9761e+00 (1.1471e+00)\tAcc@1  65.62 ( 77.50)\tAcc@5  95.31 ( 94.85)\n",
            "Epoch: [112][270/391]\tTime  0.091 ( 0.091)\tLoss 2.1830e+00 (1.1570e+00)\tAcc@1  41.41 ( 77.27)\tAcc@5  86.72 ( 94.84)\n",
            "Epoch: [112][300/391]\tTime  0.090 ( 0.091)\tLoss 5.9732e-02 (1.1039e+00)\tAcc@1  97.66 ( 78.26)\tAcc@5 100.00 ( 95.07)\n",
            "Epoch: [112][330/391]\tTime  0.090 ( 0.091)\tLoss 2.1363e+00 (1.0953e+00)\tAcc@1  60.16 ( 78.56)\tAcc@5  86.72 ( 95.15)\n",
            "Epoch: [112][360/391]\tTime  0.091 ( 0.091)\tLoss 4.4372e-02 (1.0901e+00)\tAcc@1  98.44 ( 78.81)\tAcc@5 100.00 ( 95.23)\n",
            "Epoch: [112][390/391]\tTime  0.082 ( 0.091)\tLoss 2.1863e+00 (1.0865e+00)\tAcc@1  41.25 ( 78.83)\tAcc@5  81.25 ( 95.18)\n",
            "==> Train Accuracy: Acc@1 78.826 || Acc@5 95.176\n",
            "==> Test Accuracy:  Acc@1 78.580 || Acc@5 94.550\n",
            "==> 38.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 113, lr: 0.004000000000000001 -----\n",
            "Epoch: [113][  0/391]\tTime  0.240 ( 0.240)\tLoss 6.3175e-02 (6.3175e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][ 30/391]\tTime  0.100 ( 0.096)\tLoss 1.8986e+00 (8.6664e-01)\tAcc@1  58.59 ( 84.10)\tAcc@5  92.19 ( 97.18)\n",
            "Epoch: [113][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.6939e+00 (9.8414e-01)\tAcc@1  71.09 ( 81.56)\tAcc@5  95.31 ( 96.50)\n",
            "Epoch: [113][ 90/391]\tTime  0.090 ( 0.093)\tLoss 1.5580e+00 (1.0015e+00)\tAcc@1  80.47 ( 81.10)\tAcc@5 100.00 ( 96.34)\n",
            "Epoch: [113][120/391]\tTime  0.089 ( 0.092)\tLoss 2.1741e+00 (1.0390e+00)\tAcc@1  32.81 ( 79.53)\tAcc@5  76.56 ( 95.87)\n",
            "Epoch: [113][150/391]\tTime  0.091 ( 0.092)\tLoss 2.0751e+00 (1.0481e+00)\tAcc@1  45.31 ( 79.58)\tAcc@5  89.84 ( 95.91)\n",
            "Epoch: [113][180/391]\tTime  0.091 ( 0.092)\tLoss 2.0220e+00 (1.0489e+00)\tAcc@1  36.72 ( 79.69)\tAcc@5  82.03 ( 95.91)\n",
            "Epoch: [113][210/391]\tTime  0.088 ( 0.092)\tLoss 7.7378e-02 (1.0131e+00)\tAcc@1  98.44 ( 80.29)\tAcc@5 100.00 ( 96.03)\n",
            "Epoch: [113][240/391]\tTime  0.090 ( 0.091)\tLoss 1.7180e-02 (9.9172e-01)\tAcc@1 100.00 ( 80.74)\tAcc@5 100.00 ( 96.11)\n",
            "Epoch: [113][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8416e+00 (1.0099e+00)\tAcc@1  50.78 ( 80.58)\tAcc@5  90.62 ( 96.09)\n",
            "Epoch: [113][300/391]\tTime  0.090 ( 0.091)\tLoss 3.6202e-02 (9.8727e-01)\tAcc@1  99.22 ( 80.99)\tAcc@5 100.00 ( 96.18)\n",
            "Epoch: [113][330/391]\tTime  0.091 ( 0.091)\tLoss 1.8398e+00 (9.8494e-01)\tAcc@1  89.06 ( 81.03)\tAcc@5  99.22 ( 96.16)\n",
            "Epoch: [113][360/391]\tTime  0.090 ( 0.091)\tLoss 3.8962e-02 (1.0012e+00)\tAcc@1 100.00 ( 80.90)\tAcc@5 100.00 ( 96.06)\n",
            "Epoch: [113][390/391]\tTime  0.082 ( 0.091)\tLoss 2.0929e+00 (1.0091e+00)\tAcc@1  51.25 ( 80.72)\tAcc@5  92.50 ( 96.01)\n",
            "==> Train Accuracy: Acc@1 80.716 || Acc@5 96.012\n",
            "==> Test Accuracy:  Acc@1 78.210 || Acc@5 94.560\n",
            "==> 38.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 114, lr: 0.004000000000000001 -----\n",
            "Epoch: [114][  0/391]\tTime  0.232 ( 0.232)\tLoss 7.7938e-02 (7.7938e-02)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 30/391]\tTime  0.090 ( 0.095)\tLoss 4.9902e-02 (7.4314e-01)\tAcc@1  97.66 ( 83.92)\tAcc@5 100.00 ( 96.70)\n",
            "Epoch: [114][ 60/391]\tTime  0.089 ( 0.093)\tLoss 6.6438e-02 (7.4279e-01)\tAcc@1  97.66 ( 84.55)\tAcc@5 100.00 ( 96.64)\n",
            "Epoch: [114][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.2147e+00 (9.5629e-01)\tAcc@1  55.47 ( 81.96)\tAcc@5  88.28 ( 96.26)\n",
            "Epoch: [114][120/391]\tTime  0.090 ( 0.092)\tLoss 1.8187e+00 (1.0043e+00)\tAcc@1  60.16 ( 81.26)\tAcc@5  94.53 ( 96.11)\n",
            "Epoch: [114][150/391]\tTime  0.091 ( 0.091)\tLoss 2.0579e+00 (9.7349e-01)\tAcc@1  75.00 ( 82.37)\tAcc@5  96.88 ( 96.32)\n",
            "Epoch: [114][180/391]\tTime  0.091 ( 0.091)\tLoss 2.0834e+00 (9.0252e-01)\tAcc@1  39.84 ( 83.33)\tAcc@5  84.38 ( 96.51)\n",
            "Epoch: [114][210/391]\tTime  0.091 ( 0.091)\tLoss 1.7317e+00 (9.1373e-01)\tAcc@1  90.62 ( 82.91)\tAcc@5  99.22 ( 96.33)\n",
            "Epoch: [114][240/391]\tTime  0.090 ( 0.091)\tLoss 6.1840e-02 (8.9820e-01)\tAcc@1  98.44 ( 83.20)\tAcc@5 100.00 ( 96.39)\n",
            "Epoch: [114][270/391]\tTime  0.090 ( 0.091)\tLoss 1.0479e-01 (9.1651e-01)\tAcc@1  96.09 ( 82.31)\tAcc@5 100.00 ( 96.11)\n",
            "Epoch: [114][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7762e+00 (9.0775e-01)\tAcc@1  70.31 ( 82.68)\tAcc@5  91.41 ( 96.20)\n",
            "Epoch: [114][330/391]\tTime  0.091 ( 0.091)\tLoss 1.6880e+00 (9.1153e-01)\tAcc@1  92.97 ( 82.82)\tAcc@5  97.66 ( 96.25)\n",
            "Epoch: [114][360/391]\tTime  0.092 ( 0.091)\tLoss 2.9325e-02 (8.8996e-01)\tAcc@1 100.00 ( 83.28)\tAcc@5 100.00 ( 96.39)\n",
            "Epoch: [114][390/391]\tTime  0.081 ( 0.091)\tLoss 5.8755e-02 (8.7103e-01)\tAcc@1  98.75 ( 83.50)\tAcc@5 100.00 ( 96.42)\n",
            "==> Train Accuracy: Acc@1 83.500 || Acc@5 96.416\n",
            "==> Test Accuracy:  Acc@1 79.000 || Acc@5 95.150\n",
            "==> 38.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 115, lr: 0.004000000000000001 -----\n",
            "Epoch: [115][  0/391]\tTime  0.230 ( 0.230)\tLoss 8.3614e-02 (8.3614e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 30/391]\tTime  0.094 ( 0.095)\tLoss 2.5838e-02 (8.7646e-01)\tAcc@1 100.00 ( 86.06)\tAcc@5 100.00 ( 97.35)\n",
            "Epoch: [115][ 60/391]\tTime  0.089 ( 0.093)\tLoss 2.3406e-02 (9.8314e-01)\tAcc@1 100.00 ( 82.98)\tAcc@5 100.00 ( 96.84)\n",
            "Epoch: [115][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.6623e+00 (1.0645e+00)\tAcc@1  74.22 ( 81.61)\tAcc@5  98.44 ( 96.53)\n",
            "Epoch: [115][120/391]\tTime  0.088 ( 0.092)\tLoss 4.6869e-02 (1.0607e+00)\tAcc@1  99.22 ( 81.79)\tAcc@5 100.00 ( 96.56)\n",
            "Epoch: [115][150/391]\tTime  0.090 ( 0.091)\tLoss 3.7676e-02 (9.7386e-01)\tAcc@1  99.22 ( 83.08)\tAcc@5 100.00 ( 96.75)\n",
            "Epoch: [115][180/391]\tTime  0.090 ( 0.091)\tLoss 3.5298e-02 (9.8377e-01)\tAcc@1 100.00 ( 82.79)\tAcc@5 100.00 ( 96.72)\n",
            "Epoch: [115][210/391]\tTime  0.090 ( 0.091)\tLoss 4.6875e-02 (9.6490e-01)\tAcc@1 100.00 ( 82.91)\tAcc@5 100.00 ( 96.70)\n",
            "Epoch: [115][240/391]\tTime  0.091 ( 0.091)\tLoss 1.4649e+00 (9.5664e-01)\tAcc@1  93.75 ( 83.11)\tAcc@5  99.22 ( 96.68)\n",
            "Epoch: [115][270/391]\tTime  0.091 ( 0.091)\tLoss 1.9370e+00 (9.9676e-01)\tAcc@1  62.50 ( 81.87)\tAcc@5  95.31 ( 96.37)\n",
            "Epoch: [115][300/391]\tTime  0.091 ( 0.091)\tLoss 2.1184e+00 (9.7955e-01)\tAcc@1  41.41 ( 81.79)\tAcc@5  77.34 ( 96.28)\n",
            "Epoch: [115][330/391]\tTime  0.091 ( 0.091)\tLoss 1.8834e+00 (9.9278e-01)\tAcc@1  83.59 ( 81.80)\tAcc@5  97.66 ( 96.32)\n",
            "Epoch: [115][360/391]\tTime  0.091 ( 0.091)\tLoss 2.0561e+00 (9.8710e-01)\tAcc@1  62.50 ( 81.99)\tAcc@5  89.06 ( 96.37)\n",
            "Epoch: [115][390/391]\tTime  0.082 ( 0.091)\tLoss 1.9723e+00 (9.9165e-01)\tAcc@1  51.25 ( 81.84)\tAcc@5  90.00 ( 96.27)\n",
            "==> Train Accuracy: Acc@1 81.838 || Acc@5 96.272\n",
            "==> Test Accuracy:  Acc@1 78.580 || Acc@5 94.660\n",
            "==> 37.96 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 116, lr: 0.004000000000000001 -----\n",
            "Epoch: [116][  0/391]\tTime  0.237 ( 0.237)\tLoss 5.3919e-02 (5.3919e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][ 30/391]\tTime  0.091 ( 0.095)\tLoss 1.7186e+00 (7.6253e-01)\tAcc@1  89.84 ( 83.82)\tAcc@5  97.66 ( 96.62)\n",
            "Epoch: [116][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.9968e+00 (7.6153e-01)\tAcc@1  62.50 ( 85.58)\tAcc@5  90.62 ( 97.14)\n",
            "Epoch: [116][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.4977e-02 (9.2414e-01)\tAcc@1  99.22 ( 82.37)\tAcc@5 100.00 ( 96.53)\n",
            "Epoch: [116][120/391]\tTime  0.091 ( 0.092)\tLoss 1.4713e+00 (9.8403e-01)\tAcc@1  97.66 ( 81.23)\tAcc@5  98.44 ( 96.09)\n",
            "Epoch: [116][150/391]\tTime  0.091 ( 0.092)\tLoss 1.7487e+00 (1.0053e+00)\tAcc@1  61.72 ( 79.78)\tAcc@5  98.44 ( 95.70)\n",
            "Epoch: [116][180/391]\tTime  0.092 ( 0.092)\tLoss 1.9716e+00 (1.0346e+00)\tAcc@1  42.97 ( 79.75)\tAcc@5  84.38 ( 95.63)\n",
            "Epoch: [116][210/391]\tTime  0.091 ( 0.092)\tLoss 1.7633e+00 (1.0445e+00)\tAcc@1  87.50 ( 79.51)\tAcc@5  99.22 ( 95.54)\n",
            "Epoch: [116][240/391]\tTime  0.091 ( 0.091)\tLoss 1.7199e+00 (1.0660e+00)\tAcc@1  89.84 ( 79.19)\tAcc@5  99.22 ( 95.44)\n",
            "Epoch: [116][270/391]\tTime  0.094 ( 0.091)\tLoss 1.5628e+00 (1.0308e+00)\tAcc@1  90.62 ( 80.15)\tAcc@5  98.44 ( 95.70)\n",
            "Epoch: [116][300/391]\tTime  0.094 ( 0.091)\tLoss 1.7524e+00 (1.0289e+00)\tAcc@1  90.62 ( 79.95)\tAcc@5  98.44 ( 95.66)\n",
            "Epoch: [116][330/391]\tTime  0.091 ( 0.091)\tLoss 1.5687e+00 (1.0131e+00)\tAcc@1  85.94 ( 80.52)\tAcc@5  96.88 ( 95.76)\n",
            "Epoch: [116][360/391]\tTime  0.091 ( 0.091)\tLoss 1.9867e+00 (9.8809e-01)\tAcc@1  52.34 ( 81.28)\tAcc@5  88.28 ( 95.94)\n",
            "Epoch: [116][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5209e-01 (9.7726e-01)\tAcc@1  96.25 ( 81.65)\tAcc@5 100.00 ( 96.03)\n",
            "==> Train Accuracy: Acc@1 81.650 || Acc@5 96.032\n",
            "==> Test Accuracy:  Acc@1 79.040 || Acc@5 94.940\n",
            "==> 38.03 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 117, lr: 0.004000000000000001 -----\n",
            "Epoch: [117][  0/391]\tTime  0.253 ( 0.253)\tLoss 1.9826e+00 (1.9826e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [117][ 30/391]\tTime  0.093 ( 0.095)\tLoss 3.8871e-02 (9.1083e-01)\tAcc@1  99.22 ( 82.79)\tAcc@5 100.00 ( 96.65)\n",
            "Epoch: [117][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.9230e+00 (9.7339e-01)\tAcc@1  57.03 ( 80.74)\tAcc@5  92.97 ( 96.04)\n",
            "Epoch: [117][ 90/391]\tTime  0.090 ( 0.092)\tLoss 5.4577e-02 (9.9416e-01)\tAcc@1  98.44 ( 80.18)\tAcc@5 100.00 ( 95.95)\n",
            "Epoch: [117][120/391]\tTime  0.090 ( 0.092)\tLoss 3.4082e-02 (1.0315e+00)\tAcc@1  99.22 ( 78.91)\tAcc@5 100.00 ( 95.54)\n",
            "Epoch: [117][150/391]\tTime  0.090 ( 0.092)\tLoss 1.6718e+00 (9.8857e-01)\tAcc@1  62.50 ( 79.84)\tAcc@5  95.31 ( 95.64)\n",
            "Epoch: [117][180/391]\tTime  0.092 ( 0.092)\tLoss 1.7876e+00 (9.9600e-01)\tAcc@1  71.09 ( 79.66)\tAcc@5  93.75 ( 95.58)\n",
            "Epoch: [117][210/391]\tTime  0.090 ( 0.091)\tLoss 6.6991e-02 (1.0315e+00)\tAcc@1  97.66 ( 78.93)\tAcc@5 100.00 ( 95.48)\n",
            "Epoch: [117][240/391]\tTime  0.091 ( 0.091)\tLoss 2.0636e+00 (1.0168e+00)\tAcc@1  32.03 ( 79.17)\tAcc@5  74.22 ( 95.52)\n",
            "Epoch: [117][270/391]\tTime  0.090 ( 0.091)\tLoss 3.8638e-02 (1.0184e+00)\tAcc@1 100.00 ( 79.33)\tAcc@5 100.00 ( 95.57)\n",
            "Epoch: [117][300/391]\tTime  0.090 ( 0.091)\tLoss 1.9043e+00 (9.9983e-01)\tAcc@1  77.34 ( 80.18)\tAcc@5  97.66 ( 95.77)\n",
            "Epoch: [117][330/391]\tTime  0.090 ( 0.091)\tLoss 7.0445e-02 (1.0193e+00)\tAcc@1  97.66 ( 79.67)\tAcc@5 100.00 ( 95.63)\n",
            "Epoch: [117][360/391]\tTime  0.089 ( 0.091)\tLoss 7.9146e-02 (1.0265e+00)\tAcc@1  97.66 ( 79.72)\tAcc@5 100.00 ( 95.61)\n",
            "Epoch: [117][390/391]\tTime  0.082 ( 0.091)\tLoss 2.0019e+00 (9.9730e-01)\tAcc@1  71.25 ( 80.39)\tAcc@5  96.25 ( 95.76)\n",
            "==> Train Accuracy: Acc@1 80.386 || Acc@5 95.762\n",
            "==> Test Accuracy:  Acc@1 79.100 || Acc@5 95.080\n",
            "==> 38.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 118, lr: 0.004000000000000001 -----\n",
            "Epoch: [118][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.8046e+00 (1.8046e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [118][ 30/391]\tTime  0.091 ( 0.096)\tLoss 2.0110e+00 (9.4254e-01)\tAcc@1  58.59 ( 81.55)\tAcc@5  85.94 ( 96.07)\n",
            "Epoch: [118][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.7944e+00 (1.0228e+00)\tAcc@1  86.72 ( 82.07)\tAcc@5  99.22 ( 96.18)\n",
            "Epoch: [118][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.7745e+00 (9.6004e-01)\tAcc@1  89.84 ( 83.04)\tAcc@5 100.00 ( 96.49)\n",
            "Epoch: [118][120/391]\tTime  0.091 ( 0.092)\tLoss 2.0764e+00 (9.1507e-01)\tAcc@1  33.59 ( 83.89)\tAcc@5  82.81 ( 96.63)\n",
            "Epoch: [118][150/391]\tTime  0.090 ( 0.092)\tLoss 3.4489e-02 (8.7138e-01)\tAcc@1  99.22 ( 84.64)\tAcc@5 100.00 ( 96.96)\n",
            "Epoch: [118][180/391]\tTime  0.090 ( 0.091)\tLoss 7.1135e-02 (8.7813e-01)\tAcc@1  98.44 ( 84.35)\tAcc@5 100.00 ( 96.73)\n",
            "Epoch: [118][210/391]\tTime  0.090 ( 0.091)\tLoss 5.2634e-02 (8.9878e-01)\tAcc@1  98.44 ( 83.71)\tAcc@5 100.00 ( 96.57)\n",
            "Epoch: [118][240/391]\tTime  0.091 ( 0.091)\tLoss 1.7141e+00 (9.1749e-01)\tAcc@1  75.78 ( 83.51)\tAcc@5  96.88 ( 96.51)\n",
            "Epoch: [118][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8165e+00 (9.0220e-01)\tAcc@1  54.69 ( 83.57)\tAcc@5  91.41 ( 96.48)\n",
            "Epoch: [118][300/391]\tTime  0.091 ( 0.091)\tLoss 1.9042e+00 (8.9918e-01)\tAcc@1  78.12 ( 83.73)\tAcc@5  96.09 ( 96.50)\n",
            "Epoch: [118][330/391]\tTime  0.090 ( 0.091)\tLoss 3.6744e-02 (9.1452e-01)\tAcc@1 100.00 ( 83.21)\tAcc@5 100.00 ( 96.42)\n",
            "Epoch: [118][360/391]\tTime  0.092 ( 0.091)\tLoss 1.9730e+00 (9.2742e-01)\tAcc@1  50.00 ( 83.04)\tAcc@5  89.84 ( 96.41)\n",
            "Epoch: [118][390/391]\tTime  0.082 ( 0.091)\tLoss 1.9599e+00 (9.2606e-01)\tAcc@1  71.25 ( 82.80)\tAcc@5  98.75 ( 96.27)\n",
            "==> Train Accuracy: Acc@1 82.796 || Acc@5 96.272\n",
            "==> Test Accuracy:  Acc@1 78.670 || Acc@5 94.720\n",
            "==> 38.00 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 119, lr: 0.004000000000000001 -----\n",
            "Epoch: [119][  0/391]\tTime  0.237 ( 0.237)\tLoss 3.7598e-02 (3.7598e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 30/391]\tTime  0.091 ( 0.095)\tLoss 2.1851e-02 (8.3028e-01)\tAcc@1 100.00 ( 81.88)\tAcc@5 100.00 ( 96.40)\n",
            "Epoch: [119][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.8834e+00 (8.6198e-01)\tAcc@1  72.66 ( 82.10)\tAcc@5  95.31 ( 96.26)\n",
            "Epoch: [119][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.5341e-02 (8.4775e-01)\tAcc@1 100.00 ( 82.13)\tAcc@5 100.00 ( 96.13)\n",
            "Epoch: [119][120/391]\tTime  0.098 ( 0.092)\tLoss 5.1932e-02 (8.2820e-01)\tAcc@1  98.44 ( 83.06)\tAcc@5 100.00 ( 96.46)\n",
            "Epoch: [119][150/391]\tTime  0.091 ( 0.092)\tLoss 1.8809e+00 (8.3854e-01)\tAcc@1  57.03 ( 83.28)\tAcc@5  96.09 ( 96.57)\n",
            "Epoch: [119][180/391]\tTime  0.091 ( 0.092)\tLoss 2.1798e+00 (8.3054e-01)\tAcc@1  50.78 ( 83.71)\tAcc@5  93.75 ( 96.72)\n",
            "Epoch: [119][210/391]\tTime  0.089 ( 0.091)\tLoss 2.8833e-02 (8.2085e-01)\tAcc@1  99.22 ( 84.26)\tAcc@5 100.00 ( 96.79)\n",
            "Epoch: [119][240/391]\tTime  0.090 ( 0.091)\tLoss 5.5694e-02 (8.4059e-01)\tAcc@1  98.44 ( 83.62)\tAcc@5 100.00 ( 96.56)\n",
            "Epoch: [119][270/391]\tTime  0.090 ( 0.091)\tLoss 5.9144e-02 (8.6322e-01)\tAcc@1  98.44 ( 83.23)\tAcc@5 100.00 ( 96.48)\n",
            "Epoch: [119][300/391]\tTime  0.090 ( 0.091)\tLoss 5.9457e-02 (8.6197e-01)\tAcc@1  98.44 ( 83.13)\tAcc@5 100.00 ( 96.47)\n",
            "Epoch: [119][330/391]\tTime  0.091 ( 0.091)\tLoss 1.7580e+00 (8.6987e-01)\tAcc@1  48.44 ( 83.12)\tAcc@5  89.84 ( 96.52)\n",
            "Epoch: [119][360/391]\tTime  0.091 ( 0.091)\tLoss 4.4667e-02 (8.6907e-01)\tAcc@1  98.44 ( 83.10)\tAcc@5 100.00 ( 96.47)\n",
            "Epoch: [119][390/391]\tTime  0.082 ( 0.091)\tLoss 2.0809e+00 (8.9173e-01)\tAcc@1  51.25 ( 82.74)\tAcc@5  90.00 ( 96.35)\n",
            "==> Train Accuracy: Acc@1 82.742 || Acc@5 96.346\n",
            "==> Test Accuracy:  Acc@1 78.270 || Acc@5 94.430\n",
            "==> 38.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 120, lr: 0.0008000000000000003 -----\n",
            "Epoch: [120][  0/391]\tTime  0.232 ( 0.232)\tLoss 4.3877e-02 (4.3877e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][ 30/391]\tTime  0.091 ( 0.095)\tLoss 1.6276e+00 (9.1871e-01)\tAcc@1  94.53 ( 85.18)\tAcc@5  99.22 ( 97.40)\n",
            "Epoch: [120][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.8487e+00 (9.2710e-01)\tAcc@1  57.81 ( 84.68)\tAcc@5  92.97 ( 97.34)\n",
            "Epoch: [120][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.7003e-02 (8.3649e-01)\tAcc@1  99.22 ( 86.02)\tAcc@5 100.00 ( 97.49)\n",
            "Epoch: [120][120/391]\tTime  0.090 ( 0.092)\tLoss 1.3436e-02 (8.5780e-01)\tAcc@1 100.00 ( 85.78)\tAcc@5 100.00 ( 97.39)\n",
            "Epoch: [120][150/391]\tTime  0.091 ( 0.091)\tLoss 2.1149e+00 (8.4495e-01)\tAcc@1  42.97 ( 85.91)\tAcc@5  90.62 ( 97.39)\n",
            "Epoch: [120][180/391]\tTime  0.090 ( 0.091)\tLoss 1.6391e+00 (8.5291e-01)\tAcc@1  82.03 ( 85.58)\tAcc@5  92.97 ( 97.27)\n",
            "Epoch: [120][210/391]\tTime  0.090 ( 0.091)\tLoss 1.9542e+00 (9.0867e-01)\tAcc@1  82.81 ( 84.21)\tAcc@5  99.22 ( 97.02)\n",
            "Epoch: [120][240/391]\tTime  0.090 ( 0.091)\tLoss 2.1452e-02 (8.8140e-01)\tAcc@1 100.00 ( 84.34)\tAcc@5 100.00 ( 97.00)\n",
            "Epoch: [120][270/391]\tTime  0.092 ( 0.091)\tLoss 1.8300e-02 (8.9132e-01)\tAcc@1 100.00 ( 84.05)\tAcc@5 100.00 ( 96.92)\n",
            "Epoch: [120][300/391]\tTime  0.091 ( 0.091)\tLoss 1.8724e+00 (8.6389e-01)\tAcc@1  58.59 ( 84.50)\tAcc@5  91.41 ( 96.99)\n",
            "Epoch: [120][330/391]\tTime  0.090 ( 0.091)\tLoss 2.0598e-02 (8.6119e-01)\tAcc@1 100.00 ( 84.51)\tAcc@5 100.00 ( 97.00)\n",
            "Epoch: [120][360/391]\tTime  0.090 ( 0.091)\tLoss 4.6733e-02 (8.5706e-01)\tAcc@1  99.22 ( 84.46)\tAcc@5 100.00 ( 96.99)\n",
            "Epoch: [120][390/391]\tTime  0.082 ( 0.091)\tLoss 1.6144e+00 (8.4856e-01)\tAcc@1  92.50 ( 84.56)\tAcc@5  98.75 ( 96.97)\n",
            "==> Train Accuracy: Acc@1 84.558 || Acc@5 96.972\n",
            "==> Test Accuracy:  Acc@1 80.300 || Acc@5 95.340\n",
            "==> 37.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 121, lr: 0.0008000000000000003 -----\n",
            "Epoch: [121][  0/391]\tTime  0.267 ( 0.267)\tLoss 1.8691e+00 (1.8691e+00)\tAcc@1  36.72 ( 36.72)\tAcc@5  86.72 ( 86.72)\n",
            "Epoch: [121][ 30/391]\tTime  0.085 ( 0.096)\tLoss 1.9226e-02 (9.5979e-01)\tAcc@1 100.00 ( 82.03)\tAcc@5 100.00 ( 96.50)\n",
            "Epoch: [121][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.2095e-02 (8.1340e-01)\tAcc@1 100.00 ( 87.23)\tAcc@5 100.00 ( 97.76)\n",
            "Epoch: [121][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.5608e+00 (8.2669e-01)\tAcc@1  92.97 ( 86.21)\tAcc@5 100.00 ( 97.62)\n",
            "Epoch: [121][120/391]\tTime  0.090 ( 0.092)\tLoss 3.0390e-02 (8.3335e-01)\tAcc@1 100.00 ( 85.49)\tAcc@5 100.00 ( 97.37)\n",
            "Epoch: [121][150/391]\tTime  0.090 ( 0.092)\tLoss 1.8570e-02 (8.1683e-01)\tAcc@1 100.00 ( 86.08)\tAcc@5 100.00 ( 97.55)\n",
            "Epoch: [121][180/391]\tTime  0.090 ( 0.091)\tLoss 4.6361e-02 (8.0090e-01)\tAcc@1  99.22 ( 86.27)\tAcc@5 100.00 ( 97.50)\n",
            "Epoch: [121][210/391]\tTime  0.090 ( 0.091)\tLoss 2.7710e-02 (8.2221e-01)\tAcc@1  99.22 ( 85.67)\tAcc@5 100.00 ( 97.37)\n",
            "Epoch: [121][240/391]\tTime  0.090 ( 0.091)\tLoss 1.8338e-02 (8.1062e-01)\tAcc@1 100.00 ( 86.01)\tAcc@5 100.00 ( 97.44)\n",
            "Epoch: [121][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8190e+00 (8.2039e-01)\tAcc@1  54.69 ( 85.97)\tAcc@5  89.06 ( 97.44)\n",
            "Epoch: [121][300/391]\tTime  0.090 ( 0.091)\tLoss 1.9544e-02 (8.1653e-01)\tAcc@1 100.00 ( 85.99)\tAcc@5 100.00 ( 97.43)\n",
            "Epoch: [121][330/391]\tTime  0.090 ( 0.091)\tLoss 2.1926e-02 (8.2915e-01)\tAcc@1 100.00 ( 85.88)\tAcc@5 100.00 ( 97.42)\n",
            "Epoch: [121][360/391]\tTime  0.091 ( 0.091)\tLoss 2.7657e-02 (8.2530e-01)\tAcc@1 100.00 ( 85.55)\tAcc@5 100.00 ( 97.32)\n",
            "Epoch: [121][390/391]\tTime  0.082 ( 0.091)\tLoss 4.8454e-02 (8.3208e-01)\tAcc@1  98.75 ( 85.16)\tAcc@5 100.00 ( 97.27)\n",
            "==> Train Accuracy: Acc@1 85.164 || Acc@5 97.266\n",
            "==> Test Accuracy:  Acc@1 80.040 || Acc@5 95.380\n",
            "==> 38.07 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 122, lr: 0.0008000000000000003 -----\n",
            "Epoch: [122][  0/391]\tTime  0.256 ( 0.256)\tLoss 2.3946e-02 (2.3946e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.6555e+00 (7.3058e-01)\tAcc@1  53.12 ( 83.64)\tAcc@5  95.31 ( 97.18)\n",
            "Epoch: [122][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.7871e-02 (9.3128e-01)\tAcc@1  98.44 ( 80.48)\tAcc@5 100.00 ( 96.38)\n",
            "Epoch: [122][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.6936e-02 (8.6087e-01)\tAcc@1 100.00 ( 82.13)\tAcc@5 100.00 ( 96.75)\n",
            "Epoch: [122][120/391]\tTime  0.090 ( 0.092)\tLoss 1.3265e-02 (9.0342e-01)\tAcc@1 100.00 ( 81.45)\tAcc@5 100.00 ( 96.39)\n",
            "Epoch: [122][150/391]\tTime  0.091 ( 0.092)\tLoss 1.7624e+00 (9.1051e-01)\tAcc@1  66.41 ( 81.54)\tAcc@5  97.66 ( 96.44)\n",
            "Epoch: [122][180/391]\tTime  0.093 ( 0.091)\tLoss 1.6766e+00 (8.8617e-01)\tAcc@1  71.09 ( 81.79)\tAcc@5  95.31 ( 96.52)\n",
            "Epoch: [122][210/391]\tTime  0.090 ( 0.091)\tLoss 3.4223e-02 (8.6158e-01)\tAcc@1  98.44 ( 83.10)\tAcc@5 100.00 ( 96.79)\n",
            "Epoch: [122][240/391]\tTime  0.091 ( 0.091)\tLoss 2.3807e-02 (8.4287e-01)\tAcc@1 100.00 ( 83.55)\tAcc@5 100.00 ( 96.87)\n",
            "Epoch: [122][270/391]\tTime  0.090 ( 0.091)\tLoss 1.8483e+00 (8.4221e-01)\tAcc@1  43.75 ( 83.63)\tAcc@5  86.72 ( 96.91)\n",
            "Epoch: [122][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7932e+00 (8.3975e-01)\tAcc@1  71.88 ( 83.50)\tAcc@5  96.88 ( 96.89)\n",
            "Epoch: [122][330/391]\tTime  0.090 ( 0.091)\tLoss 9.9893e-03 (8.6722e-01)\tAcc@1 100.00 ( 83.53)\tAcc@5 100.00 ( 96.92)\n",
            "Epoch: [122][360/391]\tTime  0.090 ( 0.091)\tLoss 3.7359e-02 (8.5673e-01)\tAcc@1  99.22 ( 84.02)\tAcc@5 100.00 ( 97.00)\n",
            "Epoch: [122][390/391]\tTime  0.081 ( 0.091)\tLoss 2.4250e-02 (8.7700e-01)\tAcc@1 100.00 ( 83.55)\tAcc@5 100.00 ( 96.85)\n",
            "==> Train Accuracy: Acc@1 83.552 || Acc@5 96.848\n",
            "==> Test Accuracy:  Acc@1 80.400 || Acc@5 95.440\n",
            "==> 38.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 123, lr: 0.0008000000000000003 -----\n",
            "Epoch: [123][  0/391]\tTime  0.259 ( 0.259)\tLoss 1.8959e+00 (1.8959e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [123][ 30/391]\tTime  0.091 ( 0.097)\tLoss 2.1325e-02 (9.0381e-01)\tAcc@1 100.00 ( 82.43)\tAcc@5 100.00 ( 96.22)\n",
            "Epoch: [123][ 60/391]\tTime  0.094 ( 0.094)\tLoss 3.4230e-02 (8.9927e-01)\tAcc@1  99.22 ( 82.94)\tAcc@5 100.00 ( 96.57)\n",
            "Epoch: [123][ 90/391]\tTime  0.091 ( 0.093)\tLoss 8.1143e-03 (8.4040e-01)\tAcc@1 100.00 ( 84.24)\tAcc@5 100.00 ( 96.82)\n",
            "Epoch: [123][120/391]\tTime  0.090 ( 0.092)\tLoss 1.6844e+00 (8.9462e-01)\tAcc@1  93.75 ( 83.15)\tAcc@5 100.00 ( 96.58)\n",
            "Epoch: [123][150/391]\tTime  0.092 ( 0.092)\tLoss 1.8038e+00 (9.3074e-01)\tAcc@1  64.84 ( 82.40)\tAcc@5  93.75 ( 96.49)\n",
            "Epoch: [123][180/391]\tTime  0.090 ( 0.092)\tLoss 1.5976e-02 (9.3000e-01)\tAcc@1 100.00 ( 82.42)\tAcc@5 100.00 ( 96.55)\n",
            "Epoch: [123][210/391]\tTime  0.090 ( 0.092)\tLoss 2.8424e-02 (9.2183e-01)\tAcc@1 100.00 ( 82.12)\tAcc@5 100.00 ( 96.49)\n",
            "Epoch: [123][240/391]\tTime  0.089 ( 0.091)\tLoss 1.8635e+00 (9.3498e-01)\tAcc@1  57.81 ( 81.43)\tAcc@5  93.75 ( 96.33)\n",
            "Epoch: [123][270/391]\tTime  0.090 ( 0.091)\tLoss 1.7400e-02 (9.4767e-01)\tAcc@1 100.00 ( 81.58)\tAcc@5 100.00 ( 96.41)\n",
            "Epoch: [123][300/391]\tTime  0.090 ( 0.091)\tLoss 1.7548e-02 (9.1841e-01)\tAcc@1 100.00 ( 82.12)\tAcc@5 100.00 ( 96.54)\n",
            "Epoch: [123][330/391]\tTime  0.090 ( 0.091)\tLoss 1.5490e+00 (8.9976e-01)\tAcc@1  82.03 ( 82.45)\tAcc@5  96.09 ( 96.58)\n",
            "Epoch: [123][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8659e-02 (8.9456e-01)\tAcc@1 100.00 ( 82.46)\tAcc@5 100.00 ( 96.62)\n",
            "Epoch: [123][390/391]\tTime  0.082 ( 0.091)\tLoss 5.4274e-02 (8.7811e-01)\tAcc@1  98.75 ( 82.97)\tAcc@5 100.00 ( 96.75)\n",
            "==> Train Accuracy: Acc@1 82.974 || Acc@5 96.748\n",
            "==> Test Accuracy:  Acc@1 80.470 || Acc@5 95.570\n",
            "==> 38.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 124, lr: 0.0008000000000000003 -----\n",
            "Epoch: [124][  0/391]\tTime  0.280 ( 0.280)\tLoss 9.7181e-01 (9.7181e-01)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][ 30/391]\tTime  0.090 ( 0.097)\tLoss 1.7893e+00 (8.6597e-01)\tAcc@1  50.00 ( 85.51)\tAcc@5  89.84 ( 97.91)\n",
            "Epoch: [124][ 60/391]\tTime  0.090 ( 0.094)\tLoss 1.8940e+00 (8.3143e-01)\tAcc@1  70.31 ( 86.90)\tAcc@5  96.88 ( 98.22)\n",
            "Epoch: [124][ 90/391]\tTime  0.090 ( 0.093)\tLoss 2.2971e-02 (8.2544e-01)\tAcc@1 100.00 ( 84.98)\tAcc@5 100.00 ( 97.68)\n",
            "Epoch: [124][120/391]\tTime  0.090 ( 0.092)\tLoss 1.7780e+00 (8.1557e-01)\tAcc@1  47.66 ( 84.17)\tAcc@5  88.28 ( 97.30)\n",
            "Epoch: [124][150/391]\tTime  0.091 ( 0.092)\tLoss 1.7281e+00 (7.9661e-01)\tAcc@1  31.25 ( 85.18)\tAcc@5  85.94 ( 97.50)\n",
            "Epoch: [124][180/391]\tTime  0.091 ( 0.092)\tLoss 2.8701e-02 (8.2183e-01)\tAcc@1 100.00 ( 83.80)\tAcc@5 100.00 ( 97.22)\n",
            "Epoch: [124][210/391]\tTime  0.091 ( 0.092)\tLoss 1.3596e+00 (8.3347e-01)\tAcc@1  99.22 ( 83.77)\tAcc@5 100.00 ( 97.13)\n",
            "Epoch: [124][240/391]\tTime  0.091 ( 0.091)\tLoss 1.6106e+00 (8.1653e-01)\tAcc@1  88.28 ( 84.18)\tAcc@5 100.00 ( 97.23)\n",
            "Epoch: [124][270/391]\tTime  0.091 ( 0.091)\tLoss 1.4967e+00 (8.1754e-01)\tAcc@1  85.94 ( 84.35)\tAcc@5  96.88 ( 97.28)\n",
            "Epoch: [124][300/391]\tTime  0.091 ( 0.091)\tLoss 1.9391e+00 (8.1078e-01)\tAcc@1  74.22 ( 84.69)\tAcc@5  96.09 ( 97.37)\n",
            "Epoch: [124][330/391]\tTime  0.091 ( 0.091)\tLoss 1.9843e+00 (8.4309e-01)\tAcc@1  41.41 ( 84.05)\tAcc@5  84.38 ( 97.24)\n",
            "Epoch: [124][360/391]\tTime  0.090 ( 0.091)\tLoss 1.8335e+00 (8.5568e-01)\tAcc@1  73.44 ( 83.73)\tAcc@5  96.09 ( 97.16)\n",
            "Epoch: [124][390/391]\tTime  0.081 ( 0.091)\tLoss 4.1223e-02 (8.4653e-01)\tAcc@1  98.75 ( 83.93)\tAcc@5 100.00 ( 97.16)\n",
            "==> Train Accuracy: Acc@1 83.930 || Acc@5 97.156\n",
            "==> Test Accuracy:  Acc@1 80.190 || Acc@5 95.400\n",
            "==> 38.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 125, lr: 0.0008000000000000003 -----\n",
            "Epoch: [125][  0/391]\tTime  0.250 ( 0.250)\tLoss 1.6638e+00 (1.6638e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [125][ 30/391]\tTime  0.090 ( 0.095)\tLoss 9.1061e-03 (7.4941e-01)\tAcc@1 100.00 ( 87.63)\tAcc@5 100.00 ( 97.38)\n",
            "Epoch: [125][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.8669e+00 (6.9887e-01)\tAcc@1  63.28 ( 88.47)\tAcc@5  96.88 ( 97.82)\n",
            "Epoch: [125][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.4043e-02 (7.1833e-01)\tAcc@1 100.00 ( 86.77)\tAcc@5 100.00 ( 97.37)\n",
            "Epoch: [125][120/391]\tTime  0.090 ( 0.092)\tLoss 2.0021e-02 (7.1687e-01)\tAcc@1 100.00 ( 86.33)\tAcc@5 100.00 ( 97.29)\n",
            "Epoch: [125][150/391]\tTime  0.091 ( 0.091)\tLoss 1.6178e+00 (7.3848e-01)\tAcc@1  35.94 ( 84.88)\tAcc@5  89.84 ( 96.90)\n",
            "Epoch: [125][180/391]\tTime  0.095 ( 0.091)\tLoss 1.8569e+00 (7.8495e-01)\tAcc@1  54.69 ( 83.86)\tAcc@5  89.06 ( 96.76)\n",
            "Epoch: [125][210/391]\tTime  0.090 ( 0.091)\tLoss 1.8682e-02 (7.9813e-01)\tAcc@1 100.00 ( 84.35)\tAcc@5 100.00 ( 96.91)\n",
            "Epoch: [125][240/391]\tTime  0.090 ( 0.091)\tLoss 1.3854e-02 (7.8080e-01)\tAcc@1 100.00 ( 84.17)\tAcc@5 100.00 ( 96.82)\n",
            "Epoch: [125][270/391]\tTime  0.098 ( 0.091)\tLoss 2.7152e-02 (7.9681e-01)\tAcc@1 100.00 ( 84.05)\tAcc@5 100.00 ( 96.88)\n",
            "Epoch: [125][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7871e+00 (8.2620e-01)\tAcc@1  57.81 ( 83.46)\tAcc@5  92.97 ( 96.83)\n",
            "Epoch: [125][330/391]\tTime  0.087 ( 0.091)\tLoss 2.8702e-02 (8.1300e-01)\tAcc@1  99.22 ( 83.62)\tAcc@5 100.00 ( 96.80)\n",
            "Epoch: [125][360/391]\tTime  0.090 ( 0.091)\tLoss 1.8339e-02 (8.2990e-01)\tAcc@1 100.00 ( 83.04)\tAcc@5 100.00 ( 96.66)\n",
            "Epoch: [125][390/391]\tTime  0.081 ( 0.091)\tLoss 1.7072e-02 (8.2735e-01)\tAcc@1 100.00 ( 83.15)\tAcc@5 100.00 ( 96.67)\n",
            "==> Train Accuracy: Acc@1 83.148 || Acc@5 96.674\n",
            "==> Test Accuracy:  Acc@1 80.620 || Acc@5 95.430\n",
            "==> 38.02 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 126, lr: 0.0008000000000000003 -----\n",
            "Epoch: [126][  0/391]\tTime  0.222 ( 0.222)\tLoss 9.6557e-03 (9.6557e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 30/391]\tTime  0.091 ( 0.095)\tLoss 1.6345e+00 (8.2260e-01)\tAcc@1  85.16 ( 89.16)\tAcc@5  96.88 ( 98.24)\n",
            "Epoch: [126][ 60/391]\tTime  0.091 ( 0.093)\tLoss 2.0010e+00 (9.5002e-01)\tAcc@1  35.94 ( 81.61)\tAcc@5  82.81 ( 96.57)\n",
            "Epoch: [126][ 90/391]\tTime  0.090 ( 0.092)\tLoss 3.0353e-02 (8.9992e-01)\tAcc@1 100.00 ( 82.12)\tAcc@5 100.00 ( 96.66)\n",
            "Epoch: [126][120/391]\tTime  0.090 ( 0.092)\tLoss 7.4728e-03 (9.2041e-01)\tAcc@1 100.00 ( 82.50)\tAcc@5 100.00 ( 96.79)\n",
            "Epoch: [126][150/391]\tTime  0.090 ( 0.092)\tLoss 1.6076e-02 (9.3128e-01)\tAcc@1 100.00 ( 82.19)\tAcc@5 100.00 ( 96.77)\n",
            "Epoch: [126][180/391]\tTime  0.090 ( 0.091)\tLoss 4.9347e-02 (9.5423e-01)\tAcc@1  98.44 ( 81.62)\tAcc@5 100.00 ( 96.60)\n",
            "Epoch: [126][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5518e-02 (9.5249e-01)\tAcc@1 100.00 ( 82.26)\tAcc@5 100.00 ( 96.73)\n",
            "Epoch: [126][240/391]\tTime  0.091 ( 0.091)\tLoss 1.9562e+00 (9.1515e-01)\tAcc@1  47.66 ( 83.14)\tAcc@5  91.41 ( 96.88)\n",
            "Epoch: [126][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8829e+00 (9.0888e-01)\tAcc@1  47.66 ( 83.40)\tAcc@5  84.38 ( 96.87)\n",
            "Epoch: [126][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7783e+00 (9.2123e-01)\tAcc@1  62.50 ( 83.33)\tAcc@5  95.31 ( 96.90)\n",
            "Epoch: [126][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9297e-02 (9.1503e-01)\tAcc@1 100.00 ( 82.99)\tAcc@5 100.00 ( 96.77)\n",
            "Epoch: [126][360/391]\tTime  0.090 ( 0.091)\tLoss 1.0804e-02 (9.1189e-01)\tAcc@1 100.00 ( 83.19)\tAcc@5 100.00 ( 96.82)\n",
            "Epoch: [126][390/391]\tTime  0.083 ( 0.091)\tLoss 1.8058e+00 (9.3517e-01)\tAcc@1  51.25 ( 83.04)\tAcc@5  91.25 ( 96.88)\n",
            "==> Train Accuracy: Acc@1 83.044 || Acc@5 96.878\n",
            "==> Test Accuracy:  Acc@1 80.170 || Acc@5 95.350\n",
            "==> 38.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 127, lr: 0.0008000000000000003 -----\n",
            "Epoch: [127][  0/391]\tTime  0.258 ( 0.258)\tLoss 3.8470e-02 (3.8470e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.6820e+00 (8.7083e-01)\tAcc@1  39.84 ( 82.86)\tAcc@5  90.62 ( 97.03)\n",
            "Epoch: [127][ 60/391]\tTime  0.091 ( 0.094)\tLoss 1.4071e-02 (7.8385e-01)\tAcc@1 100.00 ( 84.53)\tAcc@5 100.00 ( 97.14)\n",
            "Epoch: [127][ 90/391]\tTime  0.091 ( 0.093)\tLoss 1.7435e+00 (8.7350e-01)\tAcc@1  57.03 ( 82.62)\tAcc@5  91.41 ( 96.78)\n",
            "Epoch: [127][120/391]\tTime  0.090 ( 0.092)\tLoss 3.0343e-02 (8.9633e-01)\tAcc@1  99.22 ( 82.13)\tAcc@5 100.00 ( 96.62)\n",
            "Epoch: [127][150/391]\tTime  0.090 ( 0.092)\tLoss 2.0808e-02 (8.7735e-01)\tAcc@1 100.00 ( 82.65)\tAcc@5 100.00 ( 96.74)\n",
            "Epoch: [127][180/391]\tTime  0.091 ( 0.092)\tLoss 1.1745e+00 (8.9573e-01)\tAcc@1  99.22 ( 82.58)\tAcc@5 100.00 ( 96.80)\n",
            "Epoch: [127][210/391]\tTime  0.090 ( 0.092)\tLoss 2.3508e-02 (8.7027e-01)\tAcc@1  99.22 ( 83.40)\tAcc@5 100.00 ( 97.03)\n",
            "Epoch: [127][240/391]\tTime  0.089 ( 0.091)\tLoss 2.9913e-02 (8.7162e-01)\tAcc@1  99.22 ( 83.59)\tAcc@5 100.00 ( 97.10)\n",
            "Epoch: [127][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6570e+00 (8.6286e-01)\tAcc@1  92.97 ( 83.92)\tAcc@5  99.22 ( 97.15)\n",
            "Epoch: [127][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7907e+00 (8.4479e-01)\tAcc@1  78.91 ( 84.09)\tAcc@5  96.88 ( 97.14)\n",
            "Epoch: [127][330/391]\tTime  0.090 ( 0.091)\tLoss 2.4603e-02 (8.5109e-01)\tAcc@1  99.22 ( 84.06)\tAcc@5 100.00 ( 97.14)\n",
            "Epoch: [127][360/391]\tTime  0.090 ( 0.091)\tLoss 1.6368e+00 (8.7255e-01)\tAcc@1  82.03 ( 83.61)\tAcc@5  97.66 ( 97.05)\n",
            "Epoch: [127][390/391]\tTime  0.082 ( 0.091)\tLoss 4.7442e-02 (8.7775e-01)\tAcc@1  98.75 ( 83.55)\tAcc@5 100.00 ( 97.08)\n",
            "==> Train Accuracy: Acc@1 83.552 || Acc@5 97.082\n",
            "==> Test Accuracy:  Acc@1 80.150 || Acc@5 95.490\n",
            "==> 38.23 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 128, lr: 0.0008000000000000003 -----\n",
            "Epoch: [128][  0/391]\tTime  0.252 ( 0.252)\tLoss 1.3475e-02 (1.3475e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.7137e+00 (8.0442e-01)\tAcc@1  56.25 ( 84.93)\tAcc@5  89.84 ( 97.30)\n",
            "Epoch: [128][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.7285e+00 (8.4132e-01)\tAcc@1  54.69 ( 84.46)\tAcc@5  90.62 ( 97.34)\n",
            "Epoch: [128][ 90/391]\tTime  0.090 ( 0.092)\tLoss 4.1342e-02 (8.1663e-01)\tAcc@1  98.44 ( 84.59)\tAcc@5 100.00 ( 97.36)\n",
            "Epoch: [128][120/391]\tTime  0.090 ( 0.092)\tLoss 1.4658e-02 (8.6151e-01)\tAcc@1 100.00 ( 82.73)\tAcc@5 100.00 ( 97.03)\n",
            "Epoch: [128][150/391]\tTime  0.090 ( 0.092)\tLoss 1.5053e-02 (9.0179e-01)\tAcc@1 100.00 ( 80.94)\tAcc@5 100.00 ( 96.47)\n",
            "Epoch: [128][180/391]\tTime  0.091 ( 0.092)\tLoss 1.9809e+00 (9.0135e-01)\tAcc@1  81.25 ( 81.11)\tAcc@5  97.66 ( 96.62)\n",
            "Epoch: [128][210/391]\tTime  0.091 ( 0.091)\tLoss 1.9592e+00 (9.1539e-01)\tAcc@1  33.59 ( 80.83)\tAcc@5  73.44 ( 96.47)\n",
            "Epoch: [128][240/391]\tTime  0.090 ( 0.091)\tLoss 1.8987e-02 (8.9442e-01)\tAcc@1 100.00 ( 81.64)\tAcc@5 100.00 ( 96.67)\n",
            "Epoch: [128][270/391]\tTime  0.090 ( 0.091)\tLoss 4.1451e-02 (8.8462e-01)\tAcc@1  99.22 ( 82.47)\tAcc@5 100.00 ( 96.84)\n",
            "Epoch: [128][300/391]\tTime  0.090 ( 0.091)\tLoss 1.9763e-02 (8.6957e-01)\tAcc@1  99.22 ( 82.88)\tAcc@5 100.00 ( 96.88)\n",
            "Epoch: [128][330/391]\tTime  0.091 ( 0.091)\tLoss 1.9423e+00 (8.6663e-01)\tAcc@1  74.22 ( 83.04)\tAcc@5  95.31 ( 96.92)\n",
            "Epoch: [128][360/391]\tTime  0.091 ( 0.091)\tLoss 1.6163e+00 (8.8024e-01)\tAcc@1  69.53 ( 82.93)\tAcc@5  94.53 ( 96.87)\n",
            "Epoch: [128][390/391]\tTime  0.081 ( 0.091)\tLoss 2.5034e-02 (8.6931e-01)\tAcc@1 100.00 ( 83.18)\tAcc@5 100.00 ( 96.95)\n",
            "==> Train Accuracy: Acc@1 83.184 || Acc@5 96.946\n",
            "==> Test Accuracy:  Acc@1 80.100 || Acc@5 95.380\n",
            "==> 38.02 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 129, lr: 0.0008000000000000003 -----\n",
            "Epoch: [129][  0/391]\tTime  0.240 ( 0.240)\tLoss 1.7322e+00 (1.7322e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [129][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.8257e-02 (8.5385e-01)\tAcc@1 100.00 ( 84.05)\tAcc@5 100.00 ( 97.40)\n",
            "Epoch: [129][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.6979e-02 (8.3658e-01)\tAcc@1  99.22 ( 83.91)\tAcc@5 100.00 ( 96.98)\n",
            "Epoch: [129][ 90/391]\tTime  0.091 ( 0.092)\tLoss 2.7276e-02 (7.7504e-01)\tAcc@1  99.22 ( 85.47)\tAcc@5 100.00 ( 97.37)\n",
            "Epoch: [129][120/391]\tTime  0.094 ( 0.092)\tLoss 1.3867e-02 (7.6937e-01)\tAcc@1 100.00 ( 85.79)\tAcc@5 100.00 ( 97.46)\n",
            "Epoch: [129][150/391]\tTime  0.090 ( 0.091)\tLoss 2.2076e-02 (7.4937e-01)\tAcc@1 100.00 ( 85.77)\tAcc@5 100.00 ( 97.50)\n",
            "Epoch: [129][180/391]\tTime  0.091 ( 0.091)\tLoss 2.0372e+00 (7.3300e-01)\tAcc@1  71.09 ( 86.58)\tAcc@5  94.53 ( 97.65)\n",
            "Epoch: [129][210/391]\tTime  0.091 ( 0.091)\tLoss 1.6204e+00 (7.7815e-01)\tAcc@1  88.28 ( 85.89)\tAcc@5 100.00 ( 97.58)\n",
            "Epoch: [129][240/391]\tTime  0.091 ( 0.091)\tLoss 1.8812e+00 (8.0946e-01)\tAcc@1  75.78 ( 85.17)\tAcc@5  97.66 ( 97.40)\n",
            "Epoch: [129][270/391]\tTime  0.090 ( 0.091)\tLoss 1.3158e-02 (8.3026e-01)\tAcc@1 100.00 ( 85.04)\tAcc@5 100.00 ( 97.35)\n",
            "Epoch: [129][300/391]\tTime  0.092 ( 0.091)\tLoss 2.6651e-02 (8.1259e-01)\tAcc@1  99.22 ( 85.36)\tAcc@5 100.00 ( 97.40)\n",
            "Epoch: [129][330/391]\tTime  0.091 ( 0.091)\tLoss 1.8465e+00 (8.2613e-01)\tAcc@1  43.75 ( 85.20)\tAcc@5  82.03 ( 97.35)\n",
            "Epoch: [129][360/391]\tTime  0.091 ( 0.091)\tLoss 1.7231e+00 (8.4851e-01)\tAcc@1  78.91 ( 84.84)\tAcc@5  95.31 ( 97.27)\n",
            "Epoch: [129][390/391]\tTime  0.081 ( 0.091)\tLoss 1.5898e+00 (8.4844e-01)\tAcc@1  43.75 ( 84.99)\tAcc@5  93.75 ( 97.31)\n",
            "==> Train Accuracy: Acc@1 84.988 || Acc@5 97.308\n",
            "==> Test Accuracy:  Acc@1 80.030 || Acc@5 95.420\n",
            "==> 37.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 130, lr: 0.0008000000000000003 -----\n",
            "Epoch: [130][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.9356e+00 (1.9356e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  77.34 ( 77.34)\n",
            "Epoch: [130][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.6161e+00 (9.0023e-01)\tAcc@1  39.84 ( 84.70)\tAcc@5  89.06 ( 96.37)\n",
            "Epoch: [130][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.6876e+00 (9.2592e-01)\tAcc@1  87.50 ( 83.57)\tAcc@5  98.44 ( 96.75)\n",
            "Epoch: [130][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.6639e+00 (8.8162e-01)\tAcc@1  79.69 ( 84.28)\tAcc@5  96.09 ( 97.07)\n",
            "Epoch: [130][120/391]\tTime  0.091 ( 0.092)\tLoss 1.7282e+00 (9.4347e-01)\tAcc@1  64.06 ( 83.10)\tAcc@5  92.97 ( 97.01)\n",
            "Epoch: [130][150/391]\tTime  0.090 ( 0.092)\tLoss 1.7687e+00 (9.3691e-01)\tAcc@1  61.72 ( 82.81)\tAcc@5  90.62 ( 97.04)\n",
            "Epoch: [130][180/391]\tTime  0.090 ( 0.091)\tLoss 1.7554e+00 (9.6094e-01)\tAcc@1  64.84 ( 82.27)\tAcc@5  94.53 ( 97.00)\n",
            "Epoch: [130][210/391]\tTime  0.089 ( 0.091)\tLoss 2.6911e-02 (9.1569e-01)\tAcc@1  99.22 ( 83.09)\tAcc@5 100.00 ( 97.10)\n",
            "Epoch: [130][240/391]\tTime  0.090 ( 0.091)\tLoss 9.8355e-03 (9.3383e-01)\tAcc@1 100.00 ( 82.24)\tAcc@5 100.00 ( 96.90)\n",
            "Epoch: [130][270/391]\tTime  0.090 ( 0.091)\tLoss 1.6961e+00 (9.4325e-01)\tAcc@1  56.25 ( 82.12)\tAcc@5  95.31 ( 96.92)\n",
            "Epoch: [130][300/391]\tTime  0.090 ( 0.091)\tLoss 1.2014e-02 (9.3943e-01)\tAcc@1 100.00 ( 81.93)\tAcc@5 100.00 ( 96.88)\n",
            "Epoch: [130][330/391]\tTime  0.091 ( 0.091)\tLoss 1.8487e+00 (9.1392e-01)\tAcc@1  59.38 ( 82.34)\tAcc@5  92.19 ( 96.90)\n",
            "Epoch: [130][360/391]\tTime  0.089 ( 0.091)\tLoss 1.4597e-02 (9.2049e-01)\tAcc@1 100.00 ( 82.17)\tAcc@5 100.00 ( 96.86)\n",
            "Epoch: [130][390/391]\tTime  0.082 ( 0.091)\tLoss 3.0940e-02 (9.2423e-01)\tAcc@1 100.00 ( 82.27)\tAcc@5 100.00 ( 96.93)\n",
            "==> Train Accuracy: Acc@1 82.274 || Acc@5 96.926\n",
            "==> Test Accuracy:  Acc@1 80.350 || Acc@5 95.460\n",
            "==> 38.13 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 131, lr: 0.0008000000000000003 -----\n",
            "Epoch: [131][  0/391]\tTime  0.256 ( 0.256)\tLoss 1.7326e+00 (1.7326e+00)\tAcc@1  76.56 ( 76.56)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [131][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.2382e-02 (7.8678e-01)\tAcc@1 100.00 ( 84.50)\tAcc@5 100.00 ( 97.58)\n",
            "Epoch: [131][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.3312e+00 (8.5987e-01)\tAcc@1  98.44 ( 83.73)\tAcc@5 100.00 ( 97.41)\n",
            "Epoch: [131][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.6462e+00 (8.4246e-01)\tAcc@1  91.41 ( 83.61)\tAcc@5 100.00 ( 97.34)\n",
            "Epoch: [131][120/391]\tTime  0.093 ( 0.092)\tLoss 1.8590e+00 (8.0782e-01)\tAcc@1  56.25 ( 84.34)\tAcc@5  89.84 ( 97.40)\n",
            "Epoch: [131][150/391]\tTime  0.090 ( 0.092)\tLoss 1.5255e-02 (8.4207e-01)\tAcc@1 100.00 ( 83.96)\tAcc@5 100.00 ( 97.28)\n",
            "Epoch: [131][180/391]\tTime  0.090 ( 0.091)\tLoss 1.9035e+00 (8.4850e-01)\tAcc@1  83.59 ( 84.45)\tAcc@5  97.66 ( 97.40)\n",
            "Epoch: [131][210/391]\tTime  0.086 ( 0.091)\tLoss 1.0100e-02 (8.3498e-01)\tAcc@1 100.00 ( 84.74)\tAcc@5 100.00 ( 97.45)\n",
            "Epoch: [131][240/391]\tTime  0.091 ( 0.091)\tLoss 1.5438e+00 (8.3065e-01)\tAcc@1  74.22 ( 84.78)\tAcc@5  94.53 ( 97.38)\n",
            "Epoch: [131][270/391]\tTime  0.090 ( 0.091)\tLoss 1.5334e-02 (8.0741e-01)\tAcc@1 100.00 ( 85.06)\tAcc@5 100.00 ( 97.45)\n",
            "Epoch: [131][300/391]\tTime  0.090 ( 0.091)\tLoss 9.0585e-03 (8.0466e-01)\tAcc@1 100.00 ( 84.92)\tAcc@5 100.00 ( 97.40)\n",
            "Epoch: [131][330/391]\tTime  0.090 ( 0.091)\tLoss 9.2787e-03 (8.2897e-01)\tAcc@1 100.00 ( 84.55)\tAcc@5 100.00 ( 97.31)\n",
            "Epoch: [131][360/391]\tTime  0.091 ( 0.091)\tLoss 1.7343e+00 (8.3565e-01)\tAcc@1  91.41 ( 84.60)\tAcc@5  99.22 ( 97.29)\n",
            "Epoch: [131][390/391]\tTime  0.081 ( 0.091)\tLoss 2.3913e-02 (8.3558e-01)\tAcc@1 100.00 ( 84.60)\tAcc@5 100.00 ( 97.30)\n",
            "==> Train Accuracy: Acc@1 84.596 || Acc@5 97.296\n",
            "==> Test Accuracy:  Acc@1 80.440 || Acc@5 95.370\n",
            "==> 38.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 132, lr: 0.0008000000000000003 -----\n",
            "Epoch: [132][  0/391]\tTime  0.259 ( 0.259)\tLoss 1.1796e-02 (1.1796e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][ 30/391]\tTime  0.089 ( 0.096)\tLoss 1.9156e-02 (7.2515e-01)\tAcc@1 100.00 ( 86.21)\tAcc@5 100.00 ( 97.96)\n",
            "Epoch: [132][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.4697e-02 (9.0226e-01)\tAcc@1 100.00 ( 82.63)\tAcc@5 100.00 ( 97.21)\n",
            "Epoch: [132][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.8403e+00 (9.0479e-01)\tAcc@1  57.03 ( 82.00)\tAcc@5  96.88 ( 97.02)\n",
            "Epoch: [132][120/391]\tTime  0.090 ( 0.092)\tLoss 1.3982e+00 (9.0663e-01)\tAcc@1  89.84 ( 81.33)\tAcc@5  99.22 ( 96.77)\n",
            "Epoch: [132][150/391]\tTime  0.090 ( 0.092)\tLoss 8.4184e-03 (8.6376e-01)\tAcc@1 100.00 ( 82.77)\tAcc@5 100.00 ( 97.03)\n",
            "Epoch: [132][180/391]\tTime  0.090 ( 0.091)\tLoss 8.1641e-03 (8.7321e-01)\tAcc@1 100.00 ( 82.70)\tAcc@5 100.00 ( 96.96)\n",
            "Epoch: [132][210/391]\tTime  0.090 ( 0.091)\tLoss 1.6533e+00 (8.7475e-01)\tAcc@1  64.84 ( 82.87)\tAcc@5  94.53 ( 97.02)\n",
            "Epoch: [132][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1189e-02 (8.6623e-01)\tAcc@1 100.00 ( 83.05)\tAcc@5 100.00 ( 97.06)\n",
            "Epoch: [132][270/391]\tTime  0.095 ( 0.091)\tLoss 1.5486e+00 (8.6328e-01)\tAcc@1  80.47 ( 83.22)\tAcc@5  96.88 ( 97.11)\n",
            "Epoch: [132][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7664e+00 (8.4760e-01)\tAcc@1  82.81 ( 83.79)\tAcc@5  99.22 ( 97.25)\n",
            "Epoch: [132][330/391]\tTime  0.090 ( 0.091)\tLoss 1.9463e-02 (8.2946e-01)\tAcc@1 100.00 ( 84.13)\tAcc@5 100.00 ( 97.29)\n",
            "Epoch: [132][360/391]\tTime  0.090 ( 0.091)\tLoss 1.2184e-02 (8.2508e-01)\tAcc@1 100.00 ( 84.28)\tAcc@5 100.00 ( 97.33)\n",
            "Epoch: [132][390/391]\tTime  0.082 ( 0.091)\tLoss 1.8750e+00 (8.1880e-01)\tAcc@1  61.25 ( 84.61)\tAcc@5  92.50 ( 97.44)\n",
            "==> Train Accuracy: Acc@1 84.606 || Acc@5 97.442\n",
            "==> Test Accuracy:  Acc@1 80.340 || Acc@5 95.350\n",
            "==> 38.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 133, lr: 0.0008000000000000003 -----\n",
            "Epoch: [133][  0/391]\tTime  0.257 ( 0.257)\tLoss 1.8555e+00 (1.8555e+00)\tAcc@1  71.88 ( 71.88)\tAcc@5  95.31 ( 95.31)\n",
            "Epoch: [133][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.2347e-02 (7.0135e-01)\tAcc@1 100.00 ( 90.22)\tAcc@5 100.00 ( 98.29)\n",
            "Epoch: [133][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.7931e+00 (8.1983e-01)\tAcc@1  49.22 ( 85.49)\tAcc@5  85.16 ( 97.49)\n",
            "Epoch: [133][ 90/391]\tTime  0.090 ( 0.093)\tLoss 1.4060e-02 (7.6315e-01)\tAcc@1 100.00 ( 85.57)\tAcc@5 100.00 ( 97.32)\n",
            "Epoch: [133][120/391]\tTime  0.089 ( 0.092)\tLoss 1.7738e+00 (7.2807e-01)\tAcc@1  65.62 ( 86.80)\tAcc@5  96.09 ( 97.56)\n",
            "Epoch: [133][150/391]\tTime  0.091 ( 0.092)\tLoss 1.5926e-02 (7.1733e-01)\tAcc@1 100.00 ( 87.11)\tAcc@5 100.00 ( 97.65)\n",
            "Epoch: [133][180/391]\tTime  0.090 ( 0.092)\tLoss 1.2402e-02 (7.3827e-01)\tAcc@1 100.00 ( 85.92)\tAcc@5 100.00 ( 97.47)\n",
            "Epoch: [133][210/391]\tTime  0.090 ( 0.092)\tLoss 8.1954e-03 (7.2095e-01)\tAcc@1 100.00 ( 86.09)\tAcc@5 100.00 ( 97.51)\n",
            "Epoch: [133][240/391]\tTime  0.091 ( 0.092)\tLoss 1.7086e+00 (7.2429e-01)\tAcc@1  51.56 ( 85.67)\tAcc@5  87.50 ( 97.47)\n",
            "Epoch: [133][270/391]\tTime  0.090 ( 0.091)\tLoss 1.0661e-02 (7.6976e-01)\tAcc@1 100.00 ( 84.98)\tAcc@5 100.00 ( 97.40)\n",
            "Epoch: [133][300/391]\tTime  0.090 ( 0.091)\tLoss 1.7284e+00 (7.7954e-01)\tAcc@1  60.94 ( 84.63)\tAcc@5  93.75 ( 97.32)\n",
            "Epoch: [133][330/391]\tTime  0.090 ( 0.091)\tLoss 1.2549e-02 (7.8973e-01)\tAcc@1 100.00 ( 84.45)\tAcc@5 100.00 ( 97.31)\n",
            "Epoch: [133][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8928e+00 (8.0753e-01)\tAcc@1  79.69 ( 84.19)\tAcc@5  95.31 ( 97.24)\n",
            "Epoch: [133][390/391]\tTime  0.082 ( 0.091)\tLoss 1.7454e+00 (8.1253e-01)\tAcc@1  42.50 ( 83.74)\tAcc@5  86.25 ( 97.12)\n",
            "==> Train Accuracy: Acc@1 83.736 || Acc@5 97.116\n",
            "==> Test Accuracy:  Acc@1 80.210 || Acc@5 95.380\n",
            "==> 38.14 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 134, lr: 0.0008000000000000003 -----\n",
            "Epoch: [134][  0/391]\tTime  0.229 ( 0.229)\tLoss 1.8997e-02 (1.8997e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.7424e+00 (9.0434e-01)\tAcc@1  49.22 ( 81.68)\tAcc@5  92.19 ( 97.13)\n",
            "Epoch: [134][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.8679e+00 (8.4989e-01)\tAcc@1  64.84 ( 83.32)\tAcc@5  95.31 ( 97.12)\n",
            "Epoch: [134][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.8696e+00 (8.8702e-01)\tAcc@1  35.16 ( 82.10)\tAcc@5  85.94 ( 96.76)\n",
            "Epoch: [134][120/391]\tTime  0.091 ( 0.092)\tLoss 1.7903e+00 (8.8736e-01)\tAcc@1  62.50 ( 81.83)\tAcc@5  93.75 ( 96.73)\n",
            "Epoch: [134][150/391]\tTime  0.090 ( 0.092)\tLoss 1.8900e-02 (8.9399e-01)\tAcc@1 100.00 ( 82.55)\tAcc@5 100.00 ( 96.85)\n",
            "Epoch: [134][180/391]\tTime  0.091 ( 0.092)\tLoss 1.6406e+00 (8.7290e-01)\tAcc@1  53.12 ( 83.28)\tAcc@5  91.41 ( 97.00)\n",
            "Epoch: [134][210/391]\tTime  0.089 ( 0.091)\tLoss 1.2695e-02 (8.9706e-01)\tAcc@1 100.00 ( 81.98)\tAcc@5 100.00 ( 96.78)\n",
            "Epoch: [134][240/391]\tTime  0.091 ( 0.091)\tLoss 1.9240e+00 (8.6288e-01)\tAcc@1  67.19 ( 82.92)\tAcc@5  96.09 ( 96.97)\n",
            "Epoch: [134][270/391]\tTime  0.091 ( 0.091)\tLoss 1.5310e+00 (8.8689e-01)\tAcc@1  77.34 ( 82.73)\tAcc@5  98.44 ( 97.01)\n",
            "Epoch: [134][300/391]\tTime  0.091 ( 0.091)\tLoss 9.6506e-03 (8.8423e-01)\tAcc@1 100.00 ( 83.00)\tAcc@5 100.00 ( 97.03)\n",
            "Epoch: [134][330/391]\tTime  0.090 ( 0.091)\tLoss 1.8108e-02 (8.8150e-01)\tAcc@1 100.00 ( 83.11)\tAcc@5 100.00 ( 97.08)\n",
            "Epoch: [134][360/391]\tTime  0.090 ( 0.091)\tLoss 2.2444e-02 (8.8923e-01)\tAcc@1  99.22 ( 82.96)\tAcc@5 100.00 ( 97.03)\n",
            "Epoch: [134][390/391]\tTime  0.081 ( 0.091)\tLoss 4.7010e-02 (8.8969e-01)\tAcc@1  98.75 ( 82.83)\tAcc@5 100.00 ( 96.98)\n",
            "==> Train Accuracy: Acc@1 82.828 || Acc@5 96.980\n",
            "==> Test Accuracy:  Acc@1 80.400 || Acc@5 95.450\n",
            "==> 38.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 135, lr: 0.0008000000000000003 -----\n",
            "Epoch: [135][  0/391]\tTime  0.247 ( 0.247)\tLoss 1.0923e-02 (1.0923e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 30/391]\tTime  0.090 ( 0.095)\tLoss 9.9420e-03 (7.9892e-01)\tAcc@1 100.00 ( 81.38)\tAcc@5 100.00 ( 96.17)\n",
            "Epoch: [135][ 60/391]\tTime  0.090 ( 0.093)\tLoss 9.8124e-03 (8.5039e-01)\tAcc@1 100.00 ( 82.52)\tAcc@5 100.00 ( 96.75)\n",
            "Epoch: [135][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.6510e+00 (6.9808e-01)\tAcc@1  35.94 ( 85.04)\tAcc@5  89.84 ( 97.12)\n",
            "Epoch: [135][120/391]\tTime  0.089 ( 0.092)\tLoss 8.0617e-03 (7.2310e-01)\tAcc@1 100.00 ( 84.72)\tAcc@5 100.00 ( 97.12)\n",
            "Epoch: [135][150/391]\tTime  0.090 ( 0.092)\tLoss 1.6898e-02 (7.2890e-01)\tAcc@1 100.00 ( 84.75)\tAcc@5 100.00 ( 97.26)\n",
            "Epoch: [135][180/391]\tTime  0.090 ( 0.091)\tLoss 2.0904e-02 (7.2755e-01)\tAcc@1 100.00 ( 85.13)\tAcc@5 100.00 ( 97.43)\n",
            "Epoch: [135][210/391]\tTime  0.089 ( 0.091)\tLoss 1.7072e-02 (7.5066e-01)\tAcc@1 100.00 ( 84.83)\tAcc@5 100.00 ( 97.33)\n",
            "Epoch: [135][240/391]\tTime  0.096 ( 0.091)\tLoss 1.9549e-02 (7.2149e-01)\tAcc@1 100.00 ( 85.61)\tAcc@5 100.00 ( 97.50)\n",
            "Epoch: [135][270/391]\tTime  0.091 ( 0.091)\tLoss 1.5510e+00 (7.1742e-01)\tAcc@1  80.47 ( 85.71)\tAcc@5  99.22 ( 97.49)\n",
            "Epoch: [135][300/391]\tTime  0.091 ( 0.091)\tLoss 1.3960e+00 (7.2767e-01)\tAcc@1  82.81 ( 85.45)\tAcc@5  99.22 ( 97.41)\n",
            "Epoch: [135][330/391]\tTime  0.092 ( 0.091)\tLoss 1.5471e-02 (7.5975e-01)\tAcc@1 100.00 ( 84.40)\tAcc@5 100.00 ( 97.22)\n",
            "Epoch: [135][360/391]\tTime  0.090 ( 0.091)\tLoss 2.0880e-02 (7.7732e-01)\tAcc@1 100.00 ( 84.30)\tAcc@5 100.00 ( 97.21)\n",
            "Epoch: [135][390/391]\tTime  0.082 ( 0.091)\tLoss 1.8986e+00 (7.6220e-01)\tAcc@1  51.25 ( 84.69)\tAcc@5  88.75 ( 97.26)\n",
            "==> Train Accuracy: Acc@1 84.692 || Acc@5 97.258\n",
            "==> Test Accuracy:  Acc@1 80.370 || Acc@5 95.420\n",
            "==> 38.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 136, lr: 0.0008000000000000003 -----\n",
            "Epoch: [136][  0/391]\tTime  0.233 ( 0.233)\tLoss 1.3022e-02 (1.3022e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 30/391]\tTime  0.091 ( 0.095)\tLoss 1.6026e+00 (8.0949e-01)\tAcc@1  52.34 ( 80.92)\tAcc@5  96.09 ( 96.40)\n",
            "Epoch: [136][ 60/391]\tTime  0.092 ( 0.093)\tLoss 1.7966e-02 (8.6995e-01)\tAcc@1 100.00 ( 82.95)\tAcc@5 100.00 ( 96.91)\n",
            "Epoch: [136][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.7678e-02 (9.0261e-01)\tAcc@1 100.00 ( 84.26)\tAcc@5 100.00 ( 97.25)\n",
            "Epoch: [136][120/391]\tTime  0.090 ( 0.092)\tLoss 1.6801e+00 (9.1045e-01)\tAcc@1  62.50 ( 83.03)\tAcc@5  90.62 ( 96.88)\n",
            "Epoch: [136][150/391]\tTime  0.090 ( 0.092)\tLoss 1.3416e-02 (9.7480e-01)\tAcc@1 100.00 ( 81.14)\tAcc@5 100.00 ( 96.63)\n",
            "Epoch: [136][180/391]\tTime  0.090 ( 0.091)\tLoss 1.4748e-02 (9.4496e-01)\tAcc@1 100.00 ( 82.21)\tAcc@5 100.00 ( 96.86)\n",
            "Epoch: [136][210/391]\tTime  0.090 ( 0.091)\tLoss 1.9246e-02 (9.1404e-01)\tAcc@1  99.22 ( 82.08)\tAcc@5 100.00 ( 96.88)\n",
            "Epoch: [136][240/391]\tTime  0.090 ( 0.091)\tLoss 1.6222e-02 (8.9665e-01)\tAcc@1 100.00 ( 81.90)\tAcc@5 100.00 ( 96.78)\n",
            "Epoch: [136][270/391]\tTime  0.086 ( 0.091)\tLoss 2.2457e-02 (8.9297e-01)\tAcc@1  99.22 ( 82.02)\tAcc@5 100.00 ( 96.83)\n",
            "Epoch: [136][300/391]\tTime  0.090 ( 0.091)\tLoss 1.7501e-02 (8.9677e-01)\tAcc@1 100.00 ( 81.69)\tAcc@5 100.00 ( 96.76)\n",
            "Epoch: [136][330/391]\tTime  0.091 ( 0.091)\tLoss 1.7704e+00 (9.1331e-01)\tAcc@1  71.88 ( 81.39)\tAcc@5  96.88 ( 96.75)\n",
            "Epoch: [136][360/391]\tTime  0.089 ( 0.091)\tLoss 1.8236e+00 (9.0208e-01)\tAcc@1  78.91 ( 81.60)\tAcc@5  96.88 ( 96.75)\n",
            "Epoch: [136][390/391]\tTime  0.083 ( 0.091)\tLoss 2.1887e+00 (8.9339e-01)\tAcc@1  50.00 ( 81.88)\tAcc@5  86.25 ( 96.79)\n",
            "==> Train Accuracy: Acc@1 81.878 || Acc@5 96.788\n",
            "==> Test Accuracy:  Acc@1 80.250 || Acc@5 95.320\n",
            "==> 38.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 137, lr: 0.0008000000000000003 -----\n",
            "Epoch: [137][  0/391]\tTime  0.246 ( 0.246)\tLoss 1.7951e-02 (1.7951e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 30/391]\tTime  0.090 ( 0.095)\tLoss 2.2698e-02 (1.0337e+00)\tAcc@1  99.22 ( 83.11)\tAcc@5 100.00 ( 96.77)\n",
            "Epoch: [137][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.8908e+00 (9.2183e-01)\tAcc@1  32.03 ( 82.95)\tAcc@5  85.16 ( 96.84)\n",
            "Epoch: [137][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.3978e+00 (9.1093e-01)\tAcc@1  96.88 ( 83.83)\tAcc@5 100.00 ( 97.20)\n",
            "Epoch: [137][120/391]\tTime  0.090 ( 0.092)\tLoss 2.9032e-02 (8.8453e-01)\tAcc@1  99.22 ( 84.29)\tAcc@5 100.00 ( 97.29)\n",
            "Epoch: [137][150/391]\tTime  0.090 ( 0.091)\tLoss 2.0139e-02 (8.5585e-01)\tAcc@1 100.00 ( 84.89)\tAcc@5 100.00 ( 97.40)\n",
            "Epoch: [137][180/391]\tTime  0.093 ( 0.091)\tLoss 1.7307e+00 (8.8783e-01)\tAcc@1  75.78 ( 83.89)\tAcc@5  97.66 ( 97.30)\n",
            "Epoch: [137][210/391]\tTime  0.091 ( 0.091)\tLoss 1.4853e+00 (9.0751e-01)\tAcc@1  75.78 ( 83.75)\tAcc@5  97.66 ( 97.26)\n",
            "Epoch: [137][240/391]\tTime  0.096 ( 0.091)\tLoss 1.5664e+00 (8.9775e-01)\tAcc@1  94.53 ( 84.03)\tAcc@5  99.22 ( 97.31)\n",
            "Epoch: [137][270/391]\tTime  0.091 ( 0.091)\tLoss 1.5355e+00 (8.7925e-01)\tAcc@1  83.59 ( 84.64)\tAcc@5  99.22 ( 97.44)\n",
            "Epoch: [137][300/391]\tTime  0.091 ( 0.091)\tLoss 1.5664e+00 (8.9031e-01)\tAcc@1  64.06 ( 84.76)\tAcc@5  94.53 ( 97.47)\n",
            "Epoch: [137][330/391]\tTime  0.094 ( 0.091)\tLoss 1.6264e+00 (8.8152e-01)\tAcc@1  64.06 ( 84.88)\tAcc@5  93.75 ( 97.53)\n",
            "Epoch: [137][360/391]\tTime  0.091 ( 0.091)\tLoss 1.6290e+00 (8.8953e-01)\tAcc@1  85.16 ( 84.35)\tAcc@5  98.44 ( 97.41)\n",
            "Epoch: [137][390/391]\tTime  0.082 ( 0.091)\tLoss 1.5960e+00 (8.7778e-01)\tAcc@1  83.75 ( 84.45)\tAcc@5  98.75 ( 97.44)\n",
            "==> Train Accuracy: Acc@1 84.452 || Acc@5 97.444\n",
            "==> Test Accuracy:  Acc@1 80.280 || Acc@5 95.450\n",
            "==> 38.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 138, lr: 0.0008000000000000003 -----\n",
            "Epoch: [138][  0/391]\tTime  0.261 ( 0.261)\tLoss 2.3552e-02 (2.3552e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.4725e+00 (9.6275e-01)\tAcc@1  97.66 ( 83.14)\tAcc@5 100.00 ( 97.18)\n",
            "Epoch: [138][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.7213e-02 (8.5785e-01)\tAcc@1 100.00 ( 83.58)\tAcc@5 100.00 ( 97.22)\n",
            "Epoch: [138][ 90/391]\tTime  0.091 ( 0.092)\tLoss 1.4180e+00 (9.3279e-01)\tAcc@1  96.09 ( 81.35)\tAcc@5 100.00 ( 96.40)\n",
            "Epoch: [138][120/391]\tTime  0.090 ( 0.092)\tLoss 1.6345e+00 (9.0715e-01)\tAcc@1  80.47 ( 81.50)\tAcc@5  97.66 ( 96.60)\n",
            "Epoch: [138][150/391]\tTime  0.090 ( 0.092)\tLoss 1.9980e-02 (8.8328e-01)\tAcc@1 100.00 ( 82.72)\tAcc@5 100.00 ( 96.89)\n",
            "Epoch: [138][180/391]\tTime  0.090 ( 0.091)\tLoss 1.0503e-02 (8.9913e-01)\tAcc@1 100.00 ( 82.40)\tAcc@5 100.00 ( 96.86)\n",
            "Epoch: [138][210/391]\tTime  0.090 ( 0.091)\tLoss 1.0861e-02 (9.1410e-01)\tAcc@1 100.00 ( 81.75)\tAcc@5 100.00 ( 96.70)\n",
            "Epoch: [138][240/391]\tTime  0.091 ( 0.091)\tLoss 1.5044e-02 (8.6800e-01)\tAcc@1 100.00 ( 82.57)\tAcc@5 100.00 ( 96.84)\n",
            "Epoch: [138][270/391]\tTime  0.091 ( 0.091)\tLoss 2.8210e-02 (8.4274e-01)\tAcc@1  99.22 ( 83.23)\tAcc@5 100.00 ( 96.97)\n",
            "Epoch: [138][300/391]\tTime  0.091 ( 0.091)\tLoss 2.0004e-02 (8.6368e-01)\tAcc@1 100.00 ( 82.87)\tAcc@5 100.00 ( 96.80)\n",
            "Epoch: [138][330/391]\tTime  0.094 ( 0.091)\tLoss 1.1933e-02 (8.5312e-01)\tAcc@1 100.00 ( 83.18)\tAcc@5 100.00 ( 96.89)\n",
            "Epoch: [138][360/391]\tTime  0.091 ( 0.091)\tLoss 1.4546e+00 (8.4496e-01)\tAcc@1  89.06 ( 83.34)\tAcc@5  99.22 ( 96.92)\n",
            "Epoch: [138][390/391]\tTime  0.081 ( 0.091)\tLoss 3.2860e-02 (8.4962e-01)\tAcc@1  98.75 ( 83.13)\tAcc@5 100.00 ( 96.92)\n",
            "==> Train Accuracy: Acc@1 83.126 || Acc@5 96.920\n",
            "==> Test Accuracy:  Acc@1 80.410 || Acc@5 95.500\n",
            "==> 38.06 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 139, lr: 0.0008000000000000003 -----\n",
            "Epoch: [139][  0/391]\tTime  0.239 ( 0.239)\tLoss 1.6620e+00 (1.6620e+00)\tAcc@1  84.38 ( 84.38)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [139][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.9074e+00 (7.9901e-01)\tAcc@1  86.72 ( 86.34)\tAcc@5  99.22 ( 97.71)\n",
            "Epoch: [139][ 60/391]\tTime  0.094 ( 0.093)\tLoss 1.6662e-02 (8.2736e-01)\tAcc@1  99.22 ( 84.61)\tAcc@5 100.00 ( 97.07)\n",
            "Epoch: [139][ 90/391]\tTime  0.090 ( 0.092)\tLoss 8.8708e-03 (8.7091e-01)\tAcc@1 100.00 ( 84.10)\tAcc@5 100.00 ( 97.00)\n",
            "Epoch: [139][120/391]\tTime  0.091 ( 0.092)\tLoss 1.3122e+00 (9.2512e-01)\tAcc@1  97.66 ( 82.99)\tAcc@5 100.00 ( 97.07)\n",
            "Epoch: [139][150/391]\tTime  0.091 ( 0.092)\tLoss 1.9045e-02 (8.8179e-01)\tAcc@1 100.00 ( 83.79)\tAcc@5 100.00 ( 97.25)\n",
            "Epoch: [139][180/391]\tTime  0.090 ( 0.092)\tLoss 1.0187e-02 (8.6669e-01)\tAcc@1 100.00 ( 83.64)\tAcc@5 100.00 ( 97.16)\n",
            "Epoch: [139][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5969e+00 (9.0428e-01)\tAcc@1  80.47 ( 82.95)\tAcc@5  97.66 ( 97.02)\n",
            "Epoch: [139][240/391]\tTime  0.092 ( 0.091)\tLoss 3.2214e-02 (8.6268e-01)\tAcc@1  99.22 ( 83.59)\tAcc@5 100.00 ( 97.19)\n",
            "Epoch: [139][270/391]\tTime  0.090 ( 0.091)\tLoss 1.6935e+00 (8.5203e-01)\tAcc@1  70.31 ( 83.87)\tAcc@5  94.53 ( 97.25)\n",
            "Epoch: [139][300/391]\tTime  0.090 ( 0.091)\tLoss 9.1311e-03 (8.5244e-01)\tAcc@1 100.00 ( 83.99)\tAcc@5 100.00 ( 97.25)\n",
            "Epoch: [139][330/391]\tTime  0.089 ( 0.091)\tLoss 1.7168e-02 (8.3773e-01)\tAcc@1 100.00 ( 84.07)\tAcc@5 100.00 ( 97.27)\n",
            "Epoch: [139][360/391]\tTime  0.091 ( 0.091)\tLoss 1.7876e+00 (8.3933e-01)\tAcc@1  61.72 ( 83.71)\tAcc@5  95.31 ( 97.20)\n",
            "Epoch: [139][390/391]\tTime  0.082 ( 0.091)\tLoss 1.6367e+00 (8.3695e-01)\tAcc@1  98.75 ( 83.41)\tAcc@5 100.00 ( 97.10)\n",
            "==> Train Accuracy: Acc@1 83.406 || Acc@5 97.100\n",
            "==> Test Accuracy:  Acc@1 80.170 || Acc@5 95.480\n",
            "==> 38.02 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 140, lr: 0.0008000000000000003 -----\n",
            "Epoch: [140][  0/391]\tTime  0.253 ( 0.253)\tLoss 1.1669e-02 (1.1669e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.2191e-02 (1.0337e+00)\tAcc@1 100.00 ( 78.50)\tAcc@5 100.00 ( 96.04)\n",
            "Epoch: [140][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.5827e+00 (8.5727e-01)\tAcc@1  96.09 ( 83.06)\tAcc@5 100.00 ( 96.98)\n",
            "Epoch: [140][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.7247e-02 (8.1490e-01)\tAcc@1 100.00 ( 83.57)\tAcc@5 100.00 ( 97.14)\n",
            "Epoch: [140][120/391]\tTime  0.090 ( 0.092)\tLoss 1.2492e-02 (7.6521e-01)\tAcc@1 100.00 ( 83.37)\tAcc@5 100.00 ( 96.97)\n",
            "Epoch: [140][150/391]\tTime  0.090 ( 0.092)\tLoss 2.9810e-02 (7.7485e-01)\tAcc@1  99.22 ( 83.80)\tAcc@5 100.00 ( 97.13)\n",
            "Epoch: [140][180/391]\tTime  0.091 ( 0.092)\tLoss 1.8445e+00 (7.8939e-01)\tAcc@1  75.78 ( 83.52)\tAcc@5  94.53 ( 97.06)\n",
            "Epoch: [140][210/391]\tTime  0.090 ( 0.091)\tLoss 1.5913e+00 (7.6428e-01)\tAcc@1  71.88 ( 84.13)\tAcc@5  94.53 ( 97.22)\n",
            "Epoch: [140][240/391]\tTime  0.090 ( 0.091)\tLoss 1.1920e-02 (7.6770e-01)\tAcc@1 100.00 ( 84.03)\tAcc@5 100.00 ( 97.22)\n",
            "Epoch: [140][270/391]\tTime  0.090 ( 0.091)\tLoss 1.0939e-02 (7.9421e-01)\tAcc@1 100.00 ( 83.64)\tAcc@5 100.00 ( 97.20)\n",
            "Epoch: [140][300/391]\tTime  0.090 ( 0.091)\tLoss 1.7775e-02 (8.2462e-01)\tAcc@1 100.00 ( 83.45)\tAcc@5 100.00 ( 97.20)\n",
            "Epoch: [140][330/391]\tTime  0.090 ( 0.091)\tLoss 1.6802e-02 (8.3795e-01)\tAcc@1 100.00 ( 83.57)\tAcc@5 100.00 ( 97.19)\n",
            "Epoch: [140][360/391]\tTime  0.090 ( 0.091)\tLoss 1.4834e-02 (8.4269e-01)\tAcc@1 100.00 ( 83.58)\tAcc@5 100.00 ( 97.18)\n",
            "Epoch: [140][390/391]\tTime  0.082 ( 0.091)\tLoss 1.1923e-02 (8.7730e-01)\tAcc@1 100.00 ( 82.68)\tAcc@5 100.00 ( 96.97)\n",
            "==> Train Accuracy: Acc@1 82.684 || Acc@5 96.974\n",
            "==> Test Accuracy:  Acc@1 79.660 || Acc@5 95.230\n",
            "==> 38.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 141, lr: 0.0008000000000000003 -----\n",
            "Epoch: [141][  0/391]\tTime  0.248 ( 0.248)\tLoss 6.9582e-03 (6.9582e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 30/391]\tTime  0.092 ( 0.096)\tLoss 1.7354e+00 (6.0624e-01)\tAcc@1  74.22 ( 91.46)\tAcc@5  96.09 ( 98.64)\n",
            "Epoch: [141][ 60/391]\tTime  0.092 ( 0.093)\tLoss 1.8531e+00 (8.3680e-01)\tAcc@1  79.69 ( 87.21)\tAcc@5  97.66 ( 97.89)\n",
            "Epoch: [141][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.7191e-02 (7.8630e-01)\tAcc@1  99.22 ( 87.72)\tAcc@5 100.00 ( 98.01)\n",
            "Epoch: [141][120/391]\tTime  0.090 ( 0.092)\tLoss 2.0697e-02 (8.4362e-01)\tAcc@1  99.22 ( 86.19)\tAcc@5 100.00 ( 97.66)\n",
            "Epoch: [141][150/391]\tTime  0.091 ( 0.092)\tLoss 1.7599e+00 (8.5794e-01)\tAcc@1  67.97 ( 85.11)\tAcc@5  99.22 ( 97.52)\n",
            "Epoch: [141][180/391]\tTime  0.092 ( 0.092)\tLoss 1.8509e+00 (8.6377e-01)\tAcc@1  77.34 ( 84.53)\tAcc@5  96.88 ( 97.42)\n",
            "Epoch: [141][210/391]\tTime  0.091 ( 0.092)\tLoss 1.8052e+00 (8.5696e-01)\tAcc@1  62.50 ( 84.40)\tAcc@5  92.19 ( 97.37)\n",
            "Epoch: [141][240/391]\tTime  0.090 ( 0.091)\tLoss 2.0811e-02 (8.6383e-01)\tAcc@1 100.00 ( 84.18)\tAcc@5 100.00 ( 97.35)\n",
            "Epoch: [141][270/391]\tTime  0.091 ( 0.091)\tLoss 1.9264e+00 (8.6454e-01)\tAcc@1  45.31 ( 83.91)\tAcc@5  89.84 ( 97.30)\n",
            "Epoch: [141][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7526e+00 (8.5635e-01)\tAcc@1  54.69 ( 84.00)\tAcc@5  91.41 ( 97.30)\n",
            "Epoch: [141][330/391]\tTime  0.090 ( 0.091)\tLoss 1.1550e-02 (8.4100e-01)\tAcc@1 100.00 ( 84.27)\tAcc@5 100.00 ( 97.34)\n",
            "Epoch: [141][360/391]\tTime  0.090 ( 0.091)\tLoss 6.6347e-03 (8.5604e-01)\tAcc@1 100.00 ( 83.63)\tAcc@5 100.00 ( 97.18)\n",
            "Epoch: [141][390/391]\tTime  0.082 ( 0.091)\tLoss 1.2860e-02 (8.7362e-01)\tAcc@1 100.00 ( 82.78)\tAcc@5 100.00 ( 96.90)\n",
            "==> Train Accuracy: Acc@1 82.778 || Acc@5 96.904\n",
            "==> Test Accuracy:  Acc@1 80.130 || Acc@5 95.510\n",
            "==> 38.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 142, lr: 0.0008000000000000003 -----\n",
            "Epoch: [142][  0/391]\tTime  0.239 ( 0.239)\tLoss 1.4094e+00 (1.4094e+00)\tAcc@1  91.41 ( 91.41)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [142][ 30/391]\tTime  0.090 ( 0.095)\tLoss 1.6382e+00 (9.6906e-01)\tAcc@1  72.66 ( 81.93)\tAcc@5  97.66 ( 97.10)\n",
            "Epoch: [142][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.6057e+00 (1.0518e+00)\tAcc@1  41.41 ( 79.89)\tAcc@5  89.06 ( 96.77)\n",
            "Epoch: [142][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.2570e-02 (1.0116e+00)\tAcc@1 100.00 ( 81.27)\tAcc@5 100.00 ( 97.08)\n",
            "Epoch: [142][120/391]\tTime  0.090 ( 0.092)\tLoss 1.7387e-02 (9.0693e-01)\tAcc@1 100.00 ( 83.14)\tAcc@5 100.00 ( 97.24)\n",
            "Epoch: [142][150/391]\tTime  0.090 ( 0.092)\tLoss 1.2899e+00 (9.2733e-01)\tAcc@1  98.44 ( 82.68)\tAcc@5 100.00 ( 97.27)\n",
            "Epoch: [142][180/391]\tTime  0.091 ( 0.091)\tLoss 1.7440e+00 (9.1015e-01)\tAcc@1  29.69 ( 82.47)\tAcc@5  75.78 ( 97.12)\n",
            "Epoch: [142][210/391]\tTime  0.090 ( 0.091)\tLoss 2.6137e-02 (9.0631e-01)\tAcc@1  99.22 ( 82.40)\tAcc@5 100.00 ( 97.04)\n",
            "Epoch: [142][240/391]\tTime  0.090 ( 0.091)\tLoss 3.8822e-02 (9.0181e-01)\tAcc@1  99.22 ( 82.40)\tAcc@5 100.00 ( 96.99)\n",
            "Epoch: [142][270/391]\tTime  0.091 ( 0.091)\tLoss 1.8662e+00 (8.8154e-01)\tAcc@1  60.94 ( 82.85)\tAcc@5  95.31 ( 97.05)\n",
            "Epoch: [142][300/391]\tTime  0.096 ( 0.091)\tLoss 1.2470e+00 (8.7928e-01)\tAcc@1  98.44 ( 83.39)\tAcc@5 100.00 ( 97.17)\n",
            "Epoch: [142][330/391]\tTime  0.090 ( 0.091)\tLoss 1.5640e+00 (8.5499e-01)\tAcc@1  76.56 ( 83.55)\tAcc@5  99.22 ( 97.21)\n",
            "Epoch: [142][360/391]\tTime  0.091 ( 0.091)\tLoss 1.9650e+00 (8.5530e-01)\tAcc@1  67.19 ( 83.93)\tAcc@5  93.75 ( 97.26)\n",
            "Epoch: [142][390/391]\tTime  0.082 ( 0.091)\tLoss 2.6410e-02 (8.6540e-01)\tAcc@1 100.00 ( 83.64)\tAcc@5 100.00 ( 97.18)\n",
            "==> Train Accuracy: Acc@1 83.636 || Acc@5 97.176\n",
            "==> Test Accuracy:  Acc@1 80.070 || Acc@5 95.400\n",
            "==> 38.07 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 143, lr: 0.0008000000000000003 -----\n",
            "Epoch: [143][  0/391]\tTime  0.265 ( 0.265)\tLoss 1.5771e-02 (1.5771e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 30/391]\tTime  0.090 ( 0.096)\tLoss 2.7202e-02 (8.8371e-01)\tAcc@1 100.00 ( 85.89)\tAcc@5 100.00 ( 98.41)\n",
            "Epoch: [143][ 60/391]\tTime  0.090 ( 0.093)\tLoss 2.4767e-02 (8.4657e-01)\tAcc@1 100.00 ( 87.37)\tAcc@5 100.00 ( 98.54)\n",
            "Epoch: [143][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.8366e+00 (8.4341e-01)\tAcc@1  78.12 ( 85.49)\tAcc@5  98.44 ( 98.03)\n",
            "Epoch: [143][120/391]\tTime  0.091 ( 0.092)\tLoss 1.6430e-02 (8.9379e-01)\tAcc@1  99.22 ( 84.39)\tAcc@5 100.00 ( 97.89)\n",
            "Epoch: [143][150/391]\tTime  0.090 ( 0.092)\tLoss 1.4308e-02 (8.7507e-01)\tAcc@1 100.00 ( 85.38)\tAcc@5 100.00 ( 97.96)\n",
            "Epoch: [143][180/391]\tTime  0.090 ( 0.092)\tLoss 1.5960e+00 (8.3489e-01)\tAcc@1  60.16 ( 85.70)\tAcc@5  96.09 ( 97.95)\n",
            "Epoch: [143][210/391]\tTime  0.090 ( 0.091)\tLoss 1.2032e-02 (8.3915e-01)\tAcc@1 100.00 ( 84.87)\tAcc@5 100.00 ( 97.73)\n",
            "Epoch: [143][240/391]\tTime  0.092 ( 0.091)\tLoss 1.6509e+00 (8.2600e-01)\tAcc@1  67.97 ( 85.10)\tAcc@5  91.41 ( 97.70)\n",
            "Epoch: [143][270/391]\tTime  0.090 ( 0.091)\tLoss 7.8848e-03 (8.3014e-01)\tAcc@1 100.00 ( 85.40)\tAcc@5 100.00 ( 97.82)\n",
            "Epoch: [143][300/391]\tTime  0.091 ( 0.091)\tLoss 1.7032e+00 (8.3411e-01)\tAcc@1  51.56 ( 85.09)\tAcc@5  85.16 ( 97.69)\n",
            "Epoch: [143][330/391]\tTime  0.091 ( 0.091)\tLoss 1.6272e+00 (8.6379e-01)\tAcc@1  66.41 ( 84.44)\tAcc@5  94.53 ( 97.54)\n",
            "Epoch: [143][360/391]\tTime  0.092 ( 0.091)\tLoss 1.7644e+00 (8.6790e-01)\tAcc@1  62.50 ( 84.23)\tAcc@5  91.41 ( 97.50)\n",
            "Epoch: [143][390/391]\tTime  0.082 ( 0.091)\tLoss 1.8504e+00 (8.7281e-01)\tAcc@1  61.25 ( 84.12)\tAcc@5  92.50 ( 97.46)\n",
            "==> Train Accuracy: Acc@1 84.116 || Acc@5 97.460\n",
            "==> Test Accuracy:  Acc@1 80.210 || Acc@5 95.470\n",
            "==> 38.10 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 144, lr: 0.0008000000000000003 -----\n",
            "Epoch: [144][  0/391]\tTime  0.245 ( 0.245)\tLoss 4.2809e-02 (4.2809e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.3513e-02 (7.2946e-01)\tAcc@1 100.00 ( 86.24)\tAcc@5 100.00 ( 98.03)\n",
            "Epoch: [144][ 60/391]\tTime  0.091 ( 0.093)\tLoss 1.3367e+00 (8.4411e-01)\tAcc@1  96.88 ( 84.43)\tAcc@5 100.00 ( 97.20)\n",
            "Epoch: [144][ 90/391]\tTime  0.091 ( 0.093)\tLoss 1.7774e+00 (9.4869e-01)\tAcc@1  86.72 ( 81.32)\tAcc@5 100.00 ( 96.75)\n",
            "Epoch: [144][120/391]\tTime  0.090 ( 0.092)\tLoss 1.2270e-02 (8.7944e-01)\tAcc@1 100.00 ( 82.52)\tAcc@5 100.00 ( 96.96)\n",
            "Epoch: [144][150/391]\tTime  0.092 ( 0.092)\tLoss 1.8059e+00 (8.2761e-01)\tAcc@1  53.12 ( 83.85)\tAcc@5  92.19 ( 97.24)\n",
            "Epoch: [144][180/391]\tTime  0.090 ( 0.092)\tLoss 1.0175e-02 (8.8032e-01)\tAcc@1 100.00 ( 82.62)\tAcc@5 100.00 ( 96.90)\n",
            "Epoch: [144][210/391]\tTime  0.092 ( 0.091)\tLoss 1.0779e-02 (8.6478e-01)\tAcc@1 100.00 ( 82.63)\tAcc@5 100.00 ( 96.85)\n",
            "Epoch: [144][240/391]\tTime  0.090 ( 0.091)\tLoss 6.5456e-03 (8.6564e-01)\tAcc@1 100.00 ( 82.55)\tAcc@5 100.00 ( 96.78)\n",
            "Epoch: [144][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6389e+00 (8.6637e-01)\tAcc@1  71.09 ( 82.67)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [144][300/391]\tTime  0.090 ( 0.091)\tLoss 1.8704e-02 (8.8752e-01)\tAcc@1 100.00 ( 82.41)\tAcc@5 100.00 ( 96.81)\n",
            "Epoch: [144][330/391]\tTime  0.092 ( 0.091)\tLoss 1.8325e+00 (8.7049e-01)\tAcc@1  49.22 ( 82.97)\tAcc@5  91.41 ( 96.95)\n",
            "Epoch: [144][360/391]\tTime  0.090 ( 0.091)\tLoss 1.6611e+00 (8.7082e-01)\tAcc@1  83.59 ( 83.02)\tAcc@5  99.22 ( 96.96)\n",
            "Epoch: [144][390/391]\tTime  0.083 ( 0.091)\tLoss 1.7004e+00 (8.8003e-01)\tAcc@1  46.25 ( 83.01)\tAcc@5  87.50 ( 96.97)\n",
            "==> Train Accuracy: Acc@1 83.006 || Acc@5 96.966\n",
            "==> Test Accuracy:  Acc@1 80.270 || Acc@5 95.400\n",
            "==> 38.05 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 145, lr: 0.0008000000000000003 -----\n",
            "Epoch: [145][  0/391]\tTime  0.250 ( 0.250)\tLoss 1.4436e-02 (1.4436e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 30/391]\tTime  0.089 ( 0.096)\tLoss 8.0871e-03 (8.0276e-01)\tAcc@1 100.00 ( 82.81)\tAcc@5 100.00 ( 96.95)\n",
            "Epoch: [145][ 60/391]\tTime  0.089 ( 0.093)\tLoss 1.0995e-02 (8.9022e-01)\tAcc@1 100.00 ( 80.64)\tAcc@5 100.00 ( 96.53)\n",
            "Epoch: [145][ 90/391]\tTime  0.090 ( 0.092)\tLoss 2.0746e-02 (7.8538e-01)\tAcc@1  99.22 ( 83.28)\tAcc@5 100.00 ( 97.01)\n",
            "Epoch: [145][120/391]\tTime  0.091 ( 0.092)\tLoss 1.4101e-02 (8.2376e-01)\tAcc@1 100.00 ( 82.91)\tAcc@5 100.00 ( 96.89)\n",
            "Epoch: [145][150/391]\tTime  0.090 ( 0.092)\tLoss 9.6294e-03 (7.9475e-01)\tAcc@1 100.00 ( 83.72)\tAcc@5 100.00 ( 97.04)\n",
            "Epoch: [145][180/391]\tTime  0.091 ( 0.091)\tLoss 1.3184e-02 (7.9244e-01)\tAcc@1 100.00 ( 83.39)\tAcc@5 100.00 ( 96.98)\n",
            "Epoch: [145][210/391]\tTime  0.090 ( 0.091)\tLoss 9.7897e-03 (7.7943e-01)\tAcc@1 100.00 ( 84.02)\tAcc@5 100.00 ( 97.15)\n",
            "Epoch: [145][240/391]\tTime  0.090 ( 0.091)\tLoss 8.8401e-03 (7.8779e-01)\tAcc@1 100.00 ( 84.53)\tAcc@5 100.00 ( 97.28)\n",
            "Epoch: [145][270/391]\tTime  0.090 ( 0.091)\tLoss 8.0645e-03 (7.8516e-01)\tAcc@1 100.00 ( 84.69)\tAcc@5 100.00 ( 97.33)\n",
            "Epoch: [145][300/391]\tTime  0.090 ( 0.091)\tLoss 1.6086e+00 (7.8382e-01)\tAcc@1  49.22 ( 84.60)\tAcc@5  89.84 ( 97.30)\n",
            "Epoch: [145][330/391]\tTime  0.091 ( 0.091)\tLoss 1.5880e+00 (8.0524e-01)\tAcc@1  53.91 ( 84.52)\tAcc@5  94.53 ( 97.32)\n",
            "Epoch: [145][360/391]\tTime  0.090 ( 0.091)\tLoss 8.8485e-03 (8.0184e-01)\tAcc@1 100.00 ( 84.86)\tAcc@5 100.00 ( 97.41)\n",
            "Epoch: [145][390/391]\tTime  0.081 ( 0.091)\tLoss 1.8622e-02 (7.9643e-01)\tAcc@1 100.00 ( 84.85)\tAcc@5 100.00 ( 97.41)\n",
            "==> Train Accuracy: Acc@1 84.852 || Acc@5 97.406\n",
            "==> Test Accuracy:  Acc@1 80.140 || Acc@5 95.510\n",
            "==> 38.03 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 146, lr: 0.0008000000000000003 -----\n",
            "Epoch: [146][  0/391]\tTime  0.243 ( 0.243)\tLoss 1.3198e+00 (1.3198e+00)\tAcc@1  97.66 ( 97.66)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [146][ 30/391]\tTime  0.090 ( 0.096)\tLoss 1.8580e-02 (8.4363e-01)\tAcc@1  99.22 ( 83.49)\tAcc@5 100.00 ( 97.43)\n",
            "Epoch: [146][ 60/391]\tTime  0.089 ( 0.093)\tLoss 2.1961e-02 (8.5321e-01)\tAcc@1 100.00 ( 85.46)\tAcc@5 100.00 ( 97.85)\n",
            "Epoch: [146][ 90/391]\tTime  0.093 ( 0.093)\tLoss 8.7864e-03 (8.3977e-01)\tAcc@1 100.00 ( 85.05)\tAcc@5 100.00 ( 97.77)\n",
            "Epoch: [146][120/391]\tTime  0.093 ( 0.092)\tLoss 1.5418e+00 (8.2836e-01)\tAcc@1  82.81 ( 85.10)\tAcc@5  96.88 ( 97.82)\n",
            "Epoch: [146][150/391]\tTime  0.091 ( 0.092)\tLoss 1.7793e+00 (8.3100e-01)\tAcc@1  38.28 ( 84.10)\tAcc@5  88.28 ( 97.71)\n",
            "Epoch: [146][180/391]\tTime  0.091 ( 0.092)\tLoss 1.3374e+00 (8.5605e-01)\tAcc@1  98.44 ( 83.77)\tAcc@5 100.00 ( 97.62)\n",
            "Epoch: [146][210/391]\tTime  0.090 ( 0.092)\tLoss 1.6481e+00 (8.6258e-01)\tAcc@1  55.47 ( 83.50)\tAcc@5  96.88 ( 97.53)\n",
            "Epoch: [146][240/391]\tTime  0.090 ( 0.091)\tLoss 1.7467e+00 (8.5809e-01)\tAcc@1  83.59 ( 83.88)\tAcc@5  97.66 ( 97.58)\n",
            "Epoch: [146][270/391]\tTime  0.090 ( 0.091)\tLoss 1.7505e-02 (8.4386e-01)\tAcc@1 100.00 ( 84.09)\tAcc@5 100.00 ( 97.60)\n",
            "Epoch: [146][300/391]\tTime  0.091 ( 0.091)\tLoss 1.5921e+00 (8.4809e-01)\tAcc@1  46.88 ( 84.26)\tAcc@5  92.97 ( 97.62)\n",
            "Epoch: [146][330/391]\tTime  0.091 ( 0.091)\tLoss 1.5391e+00 (8.2581e-01)\tAcc@1  79.69 ( 84.97)\tAcc@5  98.44 ( 97.71)\n",
            "Epoch: [146][360/391]\tTime  0.090 ( 0.091)\tLoss 1.1714e-02 (8.2024e-01)\tAcc@1 100.00 ( 85.23)\tAcc@5 100.00 ( 97.74)\n",
            "Epoch: [146][390/391]\tTime  0.082 ( 0.091)\tLoss 8.0193e-03 (8.1570e-01)\tAcc@1 100.00 ( 85.23)\tAcc@5 100.00 ( 97.72)\n",
            "==> Train Accuracy: Acc@1 85.230 || Acc@5 97.720\n",
            "==> Test Accuracy:  Acc@1 80.880 || Acc@5 95.710\n",
            "==> 38.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 147, lr: 0.0008000000000000003 -----\n",
            "Epoch: [147][  0/391]\tTime  0.258 ( 0.258)\tLoss 1.7197e+00 (1.7197e+00)\tAcc@1  46.09 ( 46.09)\tAcc@5  92.97 ( 92.97)\n",
            "Epoch: [147][ 30/391]\tTime  0.091 ( 0.096)\tLoss 1.6148e+00 (8.9527e-01)\tAcc@1  76.56 ( 84.78)\tAcc@5  98.44 ( 98.21)\n",
            "Epoch: [147][ 60/391]\tTime  0.090 ( 0.094)\tLoss 1.0840e-02 (9.5308e-01)\tAcc@1 100.00 ( 81.07)\tAcc@5 100.00 ( 97.16)\n",
            "Epoch: [147][ 90/391]\tTime  0.090 ( 0.093)\tLoss 1.3650e+00 (8.7393e-01)\tAcc@1  98.44 ( 82.99)\tAcc@5 100.00 ( 97.29)\n",
            "Epoch: [147][120/391]\tTime  0.091 ( 0.092)\tLoss 1.5043e+00 (8.4814e-01)\tAcc@1  53.12 ( 83.01)\tAcc@5  96.88 ( 97.25)\n",
            "Epoch: [147][150/391]\tTime  0.092 ( 0.092)\tLoss 9.6198e-03 (8.6376e-01)\tAcc@1 100.00 ( 82.86)\tAcc@5 100.00 ( 97.15)\n",
            "Epoch: [147][180/391]\tTime  0.090 ( 0.092)\tLoss 1.7490e+00 (8.7834e-01)\tAcc@1  66.41 ( 83.05)\tAcc@5  95.31 ( 97.28)\n",
            "Epoch: [147][210/391]\tTime  0.091 ( 0.091)\tLoss 1.5918e+00 (8.5456e-01)\tAcc@1  72.66 ( 83.75)\tAcc@5  92.19 ( 97.42)\n",
            "Epoch: [147][240/391]\tTime  0.092 ( 0.091)\tLoss 1.7869e+00 (8.3400e-01)\tAcc@1  41.41 ( 83.94)\tAcc@5  93.75 ( 97.44)\n",
            "Epoch: [147][270/391]\tTime  0.092 ( 0.091)\tLoss 1.3013e+00 (8.2745e-01)\tAcc@1  97.66 ( 83.98)\tAcc@5 100.00 ( 97.35)\n",
            "Epoch: [147][300/391]\tTime  0.088 ( 0.091)\tLoss 1.0383e-02 (8.1632e-01)\tAcc@1 100.00 ( 84.52)\tAcc@5 100.00 ( 97.45)\n",
            "Epoch: [147][330/391]\tTime  0.091 ( 0.091)\tLoss 1.5308e+00 (8.1848e-01)\tAcc@1  64.84 ( 84.49)\tAcc@5  96.88 ( 97.49)\n",
            "Epoch: [147][360/391]\tTime  0.091 ( 0.091)\tLoss 1.8126e+00 (8.1362e-01)\tAcc@1  82.81 ( 84.62)\tAcc@5  99.22 ( 97.51)\n",
            "Epoch: [147][390/391]\tTime  0.082 ( 0.091)\tLoss 1.1896e-02 (7.8676e-01)\tAcc@1 100.00 ( 85.18)\tAcc@5 100.00 ( 97.58)\n",
            "==> Train Accuracy: Acc@1 85.180 || Acc@5 97.576\n",
            "==> Test Accuracy:  Acc@1 80.790 || Acc@5 95.590\n",
            "==> 38.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 148, lr: 0.0008000000000000003 -----\n",
            "Epoch: [148][  0/391]\tTime  0.225 ( 0.225)\tLoss 1.2979e-02 (1.2979e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 30/391]\tTime  0.089 ( 0.095)\tLoss 1.5672e+00 (8.8639e-01)\tAcc@1  63.28 ( 81.48)\tAcc@5  95.31 ( 96.77)\n",
            "Epoch: [148][ 60/391]\tTime  0.092 ( 0.093)\tLoss 1.7386e+00 (8.8496e-01)\tAcc@1  71.88 ( 82.03)\tAcc@5  96.09 ( 96.98)\n",
            "Epoch: [148][ 90/391]\tTime  0.090 ( 0.092)\tLoss 1.2910e-02 (8.3823e-01)\tAcc@1 100.00 ( 84.89)\tAcc@5 100.00 ( 97.57)\n",
            "Epoch: [148][120/391]\tTime  0.091 ( 0.092)\tLoss 1.8291e+00 (8.5434e-01)\tAcc@1  50.78 ( 83.82)\tAcc@5  97.66 ( 97.60)\n",
            "Epoch: [148][150/391]\tTime  0.090 ( 0.092)\tLoss 9.7713e-03 (8.8684e-01)\tAcc@1 100.00 ( 82.30)\tAcc@5 100.00 ( 97.30)\n",
            "Epoch: [148][180/391]\tTime  0.090 ( 0.091)\tLoss 1.8335e-02 (8.8709e-01)\tAcc@1 100.00 ( 82.25)\tAcc@5 100.00 ( 97.31)\n",
            "Epoch: [148][210/391]\tTime  0.091 ( 0.091)\tLoss 1.6554e+00 (8.9890e-01)\tAcc@1  92.97 ( 82.04)\tAcc@5 100.00 ( 97.30)\n",
            "Epoch: [148][240/391]\tTime  0.091 ( 0.091)\tLoss 1.5219e-02 (8.7985e-01)\tAcc@1  99.22 ( 82.80)\tAcc@5 100.00 ( 97.37)\n",
            "Epoch: [148][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6256e+00 (8.6387e-01)\tAcc@1  63.28 ( 82.80)\tAcc@5  92.97 ( 97.36)\n",
            "Epoch: [148][300/391]\tTime  0.092 ( 0.091)\tLoss 1.7743e+00 (8.5977e-01)\tAcc@1  39.84 ( 82.92)\tAcc@5  87.50 ( 97.35)\n",
            "Epoch: [148][330/391]\tTime  0.094 ( 0.091)\tLoss 1.8344e+00 (8.5661e-01)\tAcc@1  89.06 ( 83.15)\tAcc@5  99.22 ( 97.34)\n",
            "Epoch: [148][360/391]\tTime  0.086 ( 0.091)\tLoss 1.5042e+00 (8.5043e-01)\tAcc@1  81.25 ( 83.20)\tAcc@5  96.88 ( 97.32)\n",
            "Epoch: [148][390/391]\tTime  0.082 ( 0.091)\tLoss 1.4141e-02 (8.5437e-01)\tAcc@1 100.00 ( 83.32)\tAcc@5 100.00 ( 97.35)\n",
            "==> Train Accuracy: Acc@1 83.324 || Acc@5 97.354\n",
            "==> Test Accuracy:  Acc@1 80.510 || Acc@5 95.670\n",
            "==> 38.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 149, lr: 0.0008000000000000003 -----\n",
            "Epoch: [149][  0/391]\tTime  0.250 ( 0.250)\tLoss 8.5357e-03 (8.5357e-03)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 30/391]\tTime  0.089 ( 0.096)\tLoss 7.5236e-03 (7.0462e-01)\tAcc@1 100.00 ( 87.53)\tAcc@5 100.00 ( 97.98)\n",
            "Epoch: [149][ 60/391]\tTime  0.090 ( 0.093)\tLoss 1.8599e-02 (6.5524e-01)\tAcc@1 100.00 ( 87.53)\tAcc@5 100.00 ( 97.96)\n",
            "Epoch: [149][ 90/391]\tTime  0.088 ( 0.092)\tLoss 2.4654e-02 (7.3856e-01)\tAcc@1  99.22 ( 86.73)\tAcc@5 100.00 ( 97.72)\n",
            "Epoch: [149][120/391]\tTime  0.090 ( 0.092)\tLoss 7.9469e-03 (7.4112e-01)\tAcc@1 100.00 ( 87.56)\tAcc@5 100.00 ( 97.87)\n",
            "Epoch: [149][150/391]\tTime  0.090 ( 0.092)\tLoss 1.3628e-02 (7.8489e-01)\tAcc@1 100.00 ( 85.65)\tAcc@5 100.00 ( 97.56)\n",
            "Epoch: [149][180/391]\tTime  0.090 ( 0.092)\tLoss 6.2239e-03 (8.1106e-01)\tAcc@1 100.00 ( 85.05)\tAcc@5 100.00 ( 97.43)\n",
            "Epoch: [149][210/391]\tTime  0.091 ( 0.091)\tLoss 2.0486e+00 (8.2632e-01)\tAcc@1  71.09 ( 84.71)\tAcc@5  95.31 ( 97.40)\n",
            "Epoch: [149][240/391]\tTime  0.090 ( 0.091)\tLoss 1.5188e-02 (8.2950e-01)\tAcc@1 100.00 ( 85.07)\tAcc@5 100.00 ( 97.48)\n",
            "Epoch: [149][270/391]\tTime  0.091 ( 0.091)\tLoss 1.6706e+00 (8.3797e-01)\tAcc@1  50.00 ( 84.91)\tAcc@5  93.75 ( 97.47)\n",
            "Epoch: [149][300/391]\tTime  0.091 ( 0.091)\tLoss 1.0264e-02 (8.4889e-01)\tAcc@1 100.00 ( 84.51)\tAcc@5 100.00 ( 97.40)\n",
            "Epoch: [149][330/391]\tTime  0.090 ( 0.091)\tLoss 1.4724e-02 (8.5575e-01)\tAcc@1 100.00 ( 84.51)\tAcc@5 100.00 ( 97.40)\n",
            "Epoch: [149][360/391]\tTime  0.091 ( 0.091)\tLoss 1.7469e+00 (8.7086e-01)\tAcc@1  60.94 ( 83.87)\tAcc@5  94.53 ( 97.28)\n",
            "Epoch: [149][390/391]\tTime  0.081 ( 0.091)\tLoss 2.8989e-02 (8.6493e-01)\tAcc@1 100.00 ( 83.75)\tAcc@5 100.00 ( 97.32)\n",
            "==> Train Accuracy: Acc@1 83.754 || Acc@5 97.320\n",
            "==> Test Accuracy:  Acc@1 80.300 || Acc@5 95.400\n",
            "==> 38.08 seconds to train this epoch\n",
            "\n",
            "Best Top-1 Accuracy: 80.88\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-O5vnvmksCcZ"
      },
      "source": [
        "Cutshadow + local_augment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHR6FekI8xkE",
        "outputId": "367674b9-272d-450a-8d53-a82f2b62f9a9"
      },
      "source": [
        "#Cutshadow + local_augment\n",
        "def train(train_loader, epoch, model, optimizer, criterion):\n",
        "    batch_time = AverageMeter('Time', ':6.3f')\n",
        "    losses = AverageMeter('Loss', ':.4e')\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    progress = ProgressMeter(len(train_loader), batch_time, losses,\n",
        "                             top1, top5, prefix=\"Epoch: [{}]\".format(epoch))\n",
        "    # switch to train mode\n",
        "    model.train()\n",
        "\n",
        "    end = time.time()\n",
        "    for i, (input, target) in enumerate(train_loader):\n",
        "\n",
        "        input,target = local_augment(input,target)\n",
        "        # measure data loading time\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "\n",
        "        # compute output\n",
        "        output = model(input)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # measure accuracy and record loss, accuracy \n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        losses.update(loss.item(), input.size(0))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # measure elapsed time\n",
        "        batch_time.update(time.time() - end)\n",
        "        end = time.time()\n",
        "\n",
        "        if i % print_freq == 0:\n",
        "            progress.print(i)\n",
        "\n",
        "    print('==> Train Accuracy: Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "def test(test_loader,epoch, model):\n",
        "    top1 = AverageMeter('Acc@1', ':6.2f')\n",
        "    top5 = AverageMeter('Acc@5', ':6.2f')\n",
        "    model.eval()\n",
        "    for i,(input,target) in enumerate(test_loader):\n",
        "        input = input.cuda()\n",
        "        target = target.cuda()\n",
        "        input,target = local_augment(input,target)\n",
        "        output = model(input)\n",
        "        acc1, acc5 = accuracy(output, target, topk=(1, 5))\n",
        "        top1.update(acc1[0].item(), input.size(0))\n",
        "        top5.update(acc5[0].item(), input.size(0))\n",
        "    print('==> Test Accuracy:  Acc@1 {top1.avg:.3f} || Acc@5 {top5.avg:.3f}'.format(top1=top1, top5=top5))\n",
        "    return top1.avg\n",
        "\n",
        "model = ResNet34(num_classes=num_classes).cuda()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate,momentum=0.9, nesterov=True, weight_decay=5e-4)\n",
        "\n",
        "scheduler = MultiStepLR(optimizer, milestones=[60, 90, 120], gamma=0.2)\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "###########################################################\n",
        "best_acc = 0\n",
        "for epoch in range(epochs):\n",
        "    print(\"\\n----- epoch: {}, lr: {} -----\".format(\n",
        "        epoch, optimizer.param_groups[0][\"lr\"]))\n",
        "\n",
        "    # train for one epoch\n",
        "    start_time = time.time()\n",
        "    train(train_loader, epoch, model, optimizer, criterion)\n",
        "    test_acc = test(test_loader,epoch,model)\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('==> {:.2f} seconds to train this epoch\\n'.format(elapsed_time))\n",
        "    # learning rate scheduling\n",
        "    scheduler.step()\n",
        "    \n",
        "    # Save model for best accuracy\n",
        "    if best_acc < test_acc:\n",
        "        best_acc = test_acc\n",
        "        torch.save(model.state_dict(), 'model_best.pt')\n",
        "\n",
        "torch.save(model.state_dict(),'model_latest.pt')\n",
        "print(f\"Best Top-1 Accuracy: {best_acc}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----- epoch: 0, lr: 0.1 -----\n",
            "Epoch: [0][  0/391]\tTime  0.378 ( 0.378)\tLoss 4.7024e+00 (4.7024e+00)\tAcc@1   0.78 (  0.78)\tAcc@5   7.03 (  7.03)\n",
            "Epoch: [0][ 30/391]\tTime  0.099 ( 0.111)\tLoss 4.9832e+00 (5.4467e+00)\tAcc@1   2.34 (  1.01)\tAcc@5   7.81 (  5.37)\n",
            "Epoch: [0][ 60/391]\tTime  0.101 ( 0.106)\tLoss 4.4685e+00 (5.0371e+00)\tAcc@1   3.12 (  1.36)\tAcc@5  11.72 (  6.53)\n",
            "Epoch: [0][ 90/391]\tTime  0.100 ( 0.104)\tLoss 4.4253e+00 (4.8509e+00)\tAcc@1   1.56 (  1.76)\tAcc@5  10.16 (  8.05)\n",
            "Epoch: [0][120/391]\tTime  0.101 ( 0.103)\tLoss 4.4255e+00 (4.7347e+00)\tAcc@1   3.12 (  2.16)\tAcc@5  12.50 (  9.36)\n",
            "Epoch: [0][150/391]\tTime  0.109 ( 0.102)\tLoss 4.2670e+00 (4.6568e+00)\tAcc@1   7.03 (  2.45)\tAcc@5  22.66 ( 10.33)\n",
            "Epoch: [0][180/391]\tTime  0.099 ( 0.102)\tLoss 4.3208e+00 (4.5939e+00)\tAcc@1   3.91 (  2.78)\tAcc@5  19.53 ( 11.33)\n",
            "Epoch: [0][210/391]\tTime  0.099 ( 0.102)\tLoss 4.1538e+00 (4.5417e+00)\tAcc@1   4.69 (  3.01)\tAcc@5  21.09 ( 12.24)\n",
            "Epoch: [0][240/391]\tTime  0.098 ( 0.101)\tLoss 4.1489e+00 (4.4944e+00)\tAcc@1   7.81 (  3.27)\tAcc@5  21.88 ( 13.19)\n",
            "Epoch: [0][270/391]\tTime  0.109 ( 0.102)\tLoss 4.0847e+00 (4.4536e+00)\tAcc@1   6.25 (  3.50)\tAcc@5  21.09 ( 14.07)\n",
            "Epoch: [0][300/391]\tTime  0.107 ( 0.101)\tLoss 4.1801e+00 (4.4163e+00)\tAcc@1   5.47 (  3.70)\tAcc@5  15.62 ( 14.88)\n",
            "Epoch: [0][330/391]\tTime  0.106 ( 0.101)\tLoss 4.0795e+00 (4.3851e+00)\tAcc@1   7.03 (  3.92)\tAcc@5  24.22 ( 15.61)\n",
            "Epoch: [0][360/391]\tTime  0.103 ( 0.101)\tLoss 3.9832e+00 (4.3556e+00)\tAcc@1   7.81 (  4.21)\tAcc@5  26.56 ( 16.38)\n",
            "Epoch: [0][390/391]\tTime  0.049 ( 0.101)\tLoss 3.8616e+00 (4.3273e+00)\tAcc@1  10.00 (  4.51)\tAcc@5  27.50 ( 17.22)\n",
            "==> Train Accuracy: Acc@1 4.510 || Acc@5 17.220\n",
            "==> Test Accuracy:  Acc@1 4.110 || Acc@5 16.660\n",
            "==> 56.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 1, lr: 0.1 -----\n",
            "Epoch: [1][  0/391]\tTime  0.353 ( 0.353)\tLoss 3.9750e+00 (3.9750e+00)\tAcc@1   6.25 (  6.25)\tAcc@5  25.00 ( 25.00)\n",
            "Epoch: [1][ 30/391]\tTime  0.099 ( 0.111)\tLoss 3.9403e+00 (3.9475e+00)\tAcc@1   7.81 (  7.89)\tAcc@5  25.78 ( 27.34)\n",
            "Epoch: [1][ 60/391]\tTime  0.099 ( 0.106)\tLoss 4.0373e+00 (3.9254e+00)\tAcc@1   7.03 (  8.25)\tAcc@5  24.22 ( 28.10)\n",
            "Epoch: [1][ 90/391]\tTime  0.099 ( 0.104)\tLoss 3.7960e+00 (3.9125e+00)\tAcc@1   9.38 (  8.53)\tAcc@5  36.72 ( 28.68)\n",
            "Epoch: [1][120/391]\tTime  0.096 ( 0.103)\tLoss 3.9131e+00 (3.9015e+00)\tAcc@1  11.72 (  8.72)\tAcc@5  29.69 ( 29.39)\n",
            "Epoch: [1][150/391]\tTime  0.105 ( 0.102)\tLoss 3.7204e+00 (3.8887e+00)\tAcc@1  10.16 (  8.90)\tAcc@5  34.38 ( 29.81)\n",
            "Epoch: [1][180/391]\tTime  0.104 ( 0.102)\tLoss 3.9276e+00 (3.8735e+00)\tAcc@1   5.47 (  9.05)\tAcc@5  29.69 ( 30.26)\n",
            "Epoch: [1][210/391]\tTime  0.100 ( 0.102)\tLoss 3.7671e+00 (3.8598e+00)\tAcc@1  11.72 (  9.32)\tAcc@5  36.72 ( 30.69)\n",
            "Epoch: [1][240/391]\tTime  0.102 ( 0.102)\tLoss 3.8791e+00 (3.8473e+00)\tAcc@1  11.72 (  9.63)\tAcc@5  28.91 ( 31.13)\n",
            "Epoch: [1][270/391]\tTime  0.100 ( 0.101)\tLoss 3.7190e+00 (3.8387e+00)\tAcc@1  12.50 (  9.82)\tAcc@5  34.38 ( 31.40)\n",
            "Epoch: [1][300/391]\tTime  0.099 ( 0.101)\tLoss 3.7841e+00 (3.8281e+00)\tAcc@1  11.72 (  9.98)\tAcc@5  35.94 ( 31.77)\n",
            "Epoch: [1][330/391]\tTime  0.104 ( 0.101)\tLoss 3.5911e+00 (3.8176e+00)\tAcc@1  14.06 ( 10.15)\tAcc@5  37.50 ( 32.05)\n",
            "Epoch: [1][360/391]\tTime  0.102 ( 0.101)\tLoss 3.5861e+00 (3.8077e+00)\tAcc@1  14.06 ( 10.38)\tAcc@5  35.94 ( 32.24)\n",
            "Epoch: [1][390/391]\tTime  0.048 ( 0.101)\tLoss 3.4981e+00 (3.7967e+00)\tAcc@1  12.50 ( 10.54)\tAcc@5  41.25 ( 32.60)\n",
            "==> Train Accuracy: Acc@1 10.542 || Acc@5 32.602\n",
            "==> Test Accuracy:  Acc@1 6.280 || Acc@5 21.590\n",
            "==> 56.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 2, lr: 0.1 -----\n",
            "Epoch: [2][  0/391]\tTime  0.350 ( 0.350)\tLoss 3.6547e+00 (3.6547e+00)\tAcc@1  12.50 ( 12.50)\tAcc@5  35.94 ( 35.94)\n",
            "Epoch: [2][ 30/391]\tTime  0.096 ( 0.110)\tLoss 3.7817e+00 (3.6160e+00)\tAcc@1  10.16 ( 13.03)\tAcc@5  35.16 ( 38.36)\n",
            "Epoch: [2][ 60/391]\tTime  0.098 ( 0.105)\tLoss 3.6690e+00 (3.6150e+00)\tAcc@1  10.94 ( 13.17)\tAcc@5  32.03 ( 37.83)\n",
            "Epoch: [2][ 90/391]\tTime  0.097 ( 0.103)\tLoss 3.5784e+00 (3.6107e+00)\tAcc@1  14.84 ( 13.49)\tAcc@5  41.41 ( 38.10)\n",
            "Epoch: [2][120/391]\tTime  0.098 ( 0.103)\tLoss 3.3459e+00 (3.5962e+00)\tAcc@1  17.97 ( 13.70)\tAcc@5  46.09 ( 38.42)\n",
            "Epoch: [2][150/391]\tTime  0.098 ( 0.102)\tLoss 3.6373e+00 (3.5895e+00)\tAcc@1  14.06 ( 13.66)\tAcc@5  41.41 ( 38.64)\n",
            "Epoch: [2][180/391]\tTime  0.099 ( 0.102)\tLoss 3.3966e+00 (3.5833e+00)\tAcc@1  22.66 ( 13.67)\tAcc@5  42.19 ( 38.94)\n",
            "Epoch: [2][210/391]\tTime  0.098 ( 0.102)\tLoss 3.5984e+00 (3.5731e+00)\tAcc@1  10.16 ( 13.89)\tAcc@5  41.41 ( 39.26)\n",
            "Epoch: [2][240/391]\tTime  0.100 ( 0.102)\tLoss 3.2918e+00 (3.5656e+00)\tAcc@1  17.19 ( 14.16)\tAcc@5  50.78 ( 39.56)\n",
            "Epoch: [2][270/391]\tTime  0.098 ( 0.101)\tLoss 3.4774e+00 (3.5516e+00)\tAcc@1  16.41 ( 14.40)\tAcc@5  40.62 ( 40.08)\n",
            "Epoch: [2][300/391]\tTime  0.099 ( 0.101)\tLoss 3.4874e+00 (3.5414e+00)\tAcc@1  11.72 ( 14.63)\tAcc@5  35.16 ( 40.38)\n",
            "Epoch: [2][330/391]\tTime  0.103 ( 0.101)\tLoss 3.4184e+00 (3.5282e+00)\tAcc@1  19.53 ( 14.90)\tAcc@5  45.31 ( 40.75)\n",
            "Epoch: [2][360/391]\tTime  0.108 ( 0.101)\tLoss 3.2523e+00 (3.5182e+00)\tAcc@1  22.66 ( 15.11)\tAcc@5  47.66 ( 41.07)\n",
            "Epoch: [2][390/391]\tTime  0.048 ( 0.100)\tLoss 3.4858e+00 (3.5077e+00)\tAcc@1  15.00 ( 15.31)\tAcc@5  46.25 ( 41.39)\n",
            "==> Train Accuracy: Acc@1 15.310 || Acc@5 41.394\n",
            "==> Test Accuracy:  Acc@1 8.200 || Acc@5 25.570\n",
            "==> 56.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 3, lr: 0.1 -----\n",
            "Epoch: [3][  0/391]\tTime  0.372 ( 0.372)\tLoss 3.5092e+00 (3.5092e+00)\tAcc@1  16.41 ( 16.41)\tAcc@5  39.84 ( 39.84)\n",
            "Epoch: [3][ 30/391]\tTime  0.096 ( 0.109)\tLoss 3.3856e+00 (3.3729e+00)\tAcc@1  16.41 ( 17.49)\tAcc@5  50.78 ( 46.32)\n",
            "Epoch: [3][ 60/391]\tTime  0.098 ( 0.104)\tLoss 3.1661e+00 (3.3306e+00)\tAcc@1  22.66 ( 18.55)\tAcc@5  53.91 ( 46.77)\n",
            "Epoch: [3][ 90/391]\tTime  0.100 ( 0.103)\tLoss 3.5525e+00 (3.3180e+00)\tAcc@1  14.84 ( 18.61)\tAcc@5  38.28 ( 47.13)\n",
            "Epoch: [3][120/391]\tTime  0.100 ( 0.102)\tLoss 3.4127e+00 (3.3208e+00)\tAcc@1  17.19 ( 18.52)\tAcc@5  41.41 ( 46.73)\n",
            "Epoch: [3][150/391]\tTime  0.099 ( 0.102)\tLoss 3.3025e+00 (3.3144e+00)\tAcc@1  17.19 ( 18.74)\tAcc@5  49.22 ( 47.05)\n",
            "Epoch: [3][180/391]\tTime  0.099 ( 0.101)\tLoss 3.0529e+00 (3.3044e+00)\tAcc@1  19.53 ( 18.84)\tAcc@5  55.47 ( 47.26)\n",
            "Epoch: [3][210/391]\tTime  0.100 ( 0.102)\tLoss 3.1359e+00 (3.2895e+00)\tAcc@1  21.09 ( 19.15)\tAcc@5  53.12 ( 47.62)\n",
            "Epoch: [3][240/391]\tTime  0.099 ( 0.102)\tLoss 3.1661e+00 (3.2751e+00)\tAcc@1  19.53 ( 19.46)\tAcc@5  55.47 ( 48.02)\n",
            "Epoch: [3][270/391]\tTime  0.106 ( 0.102)\tLoss 3.2294e+00 (3.2672e+00)\tAcc@1  17.19 ( 19.58)\tAcc@5  50.78 ( 48.30)\n",
            "Epoch: [3][300/391]\tTime  0.101 ( 0.102)\tLoss 3.0349e+00 (3.2600e+00)\tAcc@1  25.00 ( 19.70)\tAcc@5  52.34 ( 48.51)\n",
            "Epoch: [3][330/391]\tTime  0.104 ( 0.102)\tLoss 3.2468e+00 (3.2527e+00)\tAcc@1  21.09 ( 19.90)\tAcc@5  49.22 ( 48.68)\n",
            "Epoch: [3][360/391]\tTime  0.105 ( 0.102)\tLoss 3.2268e+00 (3.2439e+00)\tAcc@1  14.84 ( 20.08)\tAcc@5  55.47 ( 48.91)\n",
            "Epoch: [3][390/391]\tTime  0.049 ( 0.101)\tLoss 3.1461e+00 (3.2343e+00)\tAcc@1  23.75 ( 20.22)\tAcc@5  46.25 ( 49.19)\n",
            "==> Train Accuracy: Acc@1 20.224 || Acc@5 49.194\n",
            "==> Test Accuracy:  Acc@1 10.520 || Acc@5 29.260\n",
            "==> 57.18 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 4, lr: 0.1 -----\n",
            "Epoch: [4][  0/391]\tTime  0.360 ( 0.360)\tLoss 3.0703e+00 (3.0703e+00)\tAcc@1  18.75 ( 18.75)\tAcc@5  56.25 ( 56.25)\n",
            "Epoch: [4][ 30/391]\tTime  0.099 ( 0.112)\tLoss 3.2255e+00 (3.0488e+00)\tAcc@1  18.75 ( 23.61)\tAcc@5  50.78 ( 54.21)\n",
            "Epoch: [4][ 60/391]\tTime  0.101 ( 0.108)\tLoss 3.0842e+00 (3.0526e+00)\tAcc@1  22.66 ( 23.67)\tAcc@5  50.78 ( 54.03)\n",
            "Epoch: [4][ 90/391]\tTime  0.105 ( 0.107)\tLoss 3.0048e+00 (3.0593e+00)\tAcc@1  27.34 ( 23.15)\tAcc@5  57.81 ( 53.83)\n",
            "Epoch: [4][120/391]\tTime  0.101 ( 0.106)\tLoss 2.9678e+00 (3.0554e+00)\tAcc@1  25.78 ( 23.39)\tAcc@5  55.47 ( 54.03)\n",
            "Epoch: [4][150/391]\tTime  0.098 ( 0.105)\tLoss 3.0726e+00 (3.0466e+00)\tAcc@1  23.44 ( 23.48)\tAcc@5  53.91 ( 54.33)\n",
            "Epoch: [4][180/391]\tTime  0.102 ( 0.104)\tLoss 2.9093e+00 (3.0395e+00)\tAcc@1  25.00 ( 23.68)\tAcc@5  54.69 ( 54.55)\n",
            "Epoch: [4][210/391]\tTime  0.099 ( 0.104)\tLoss 2.8472e+00 (3.0264e+00)\tAcc@1  28.91 ( 23.83)\tAcc@5  57.03 ( 54.95)\n",
            "Epoch: [4][240/391]\tTime  0.105 ( 0.103)\tLoss 3.0291e+00 (3.0182e+00)\tAcc@1  21.88 ( 24.13)\tAcc@5  56.25 ( 55.18)\n",
            "Epoch: [4][270/391]\tTime  0.105 ( 0.103)\tLoss 3.2604e+00 (3.0107e+00)\tAcc@1  25.00 ( 24.31)\tAcc@5  53.91 ( 55.35)\n",
            "Epoch: [4][300/391]\tTime  0.104 ( 0.103)\tLoss 2.8967e+00 (3.0086e+00)\tAcc@1  32.03 ( 24.38)\tAcc@5  60.94 ( 55.40)\n",
            "Epoch: [4][330/391]\tTime  0.100 ( 0.103)\tLoss 2.7760e+00 (3.0039e+00)\tAcc@1  30.47 ( 24.60)\tAcc@5  60.16 ( 55.44)\n",
            "Epoch: [4][360/391]\tTime  0.105 ( 0.103)\tLoss 3.0200e+00 (2.9980e+00)\tAcc@1  19.53 ( 24.71)\tAcc@5  54.69 ( 55.60)\n",
            "Epoch: [4][390/391]\tTime  0.048 ( 0.102)\tLoss 2.7888e+00 (2.9926e+00)\tAcc@1  28.75 ( 24.82)\tAcc@5  61.25 ( 55.76)\n",
            "==> Train Accuracy: Acc@1 24.824 || Acc@5 55.764\n",
            "==> Test Accuracy:  Acc@1 13.010 || Acc@5 36.110\n",
            "==> 57.56 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 5, lr: 0.1 -----\n",
            "Epoch: [5][  0/391]\tTime  0.380 ( 0.380)\tLoss 2.8736e+00 (2.8736e+00)\tAcc@1  27.34 ( 27.34)\tAcc@5  57.81 ( 57.81)\n",
            "Epoch: [5][ 30/391]\tTime  0.103 ( 0.111)\tLoss 2.7912e+00 (2.8686e+00)\tAcc@1  28.12 ( 26.92)\tAcc@5  62.50 ( 58.42)\n",
            "Epoch: [5][ 60/391]\tTime  0.103 ( 0.108)\tLoss 2.8037e+00 (2.8679e+00)\tAcc@1  31.25 ( 26.69)\tAcc@5  60.16 ( 58.35)\n",
            "Epoch: [5][ 90/391]\tTime  0.101 ( 0.106)\tLoss 2.9811e+00 (2.8589e+00)\tAcc@1  22.66 ( 26.75)\tAcc@5  55.47 ( 58.95)\n",
            "Epoch: [5][120/391]\tTime  0.102 ( 0.105)\tLoss 2.9587e+00 (2.8632e+00)\tAcc@1  25.00 ( 26.72)\tAcc@5  59.38 ( 58.82)\n",
            "Epoch: [5][150/391]\tTime  0.101 ( 0.104)\tLoss 2.9883e+00 (2.8584e+00)\tAcc@1  27.34 ( 26.91)\tAcc@5  54.69 ( 58.89)\n",
            "Epoch: [5][180/391]\tTime  0.097 ( 0.104)\tLoss 2.7502e+00 (2.8448e+00)\tAcc@1  28.91 ( 27.26)\tAcc@5  63.28 ( 59.25)\n",
            "Epoch: [5][210/391]\tTime  0.101 ( 0.103)\tLoss 2.6080e+00 (2.8484e+00)\tAcc@1  32.03 ( 27.37)\tAcc@5  66.41 ( 59.24)\n",
            "Epoch: [5][240/391]\tTime  0.098 ( 0.103)\tLoss 2.6399e+00 (2.8508e+00)\tAcc@1  31.25 ( 27.36)\tAcc@5  67.19 ( 59.23)\n",
            "Epoch: [5][270/391]\tTime  0.100 ( 0.103)\tLoss 2.6802e+00 (2.8440e+00)\tAcc@1  25.78 ( 27.53)\tAcc@5  64.06 ( 59.42)\n",
            "Epoch: [5][300/391]\tTime  0.103 ( 0.102)\tLoss 2.6546e+00 (2.8380e+00)\tAcc@1  28.91 ( 27.70)\tAcc@5  66.41 ( 59.59)\n",
            "Epoch: [5][330/391]\tTime  0.104 ( 0.102)\tLoss 2.6642e+00 (2.8324e+00)\tAcc@1  28.91 ( 27.90)\tAcc@5  63.28 ( 59.73)\n",
            "Epoch: [5][360/391]\tTime  0.103 ( 0.102)\tLoss 2.7317e+00 (2.8255e+00)\tAcc@1  32.03 ( 28.00)\tAcc@5  63.28 ( 59.88)\n",
            "Epoch: [5][390/391]\tTime  0.048 ( 0.102)\tLoss 2.7750e+00 (2.8223e+00)\tAcc@1  27.50 ( 28.03)\tAcc@5  61.25 ( 59.97)\n",
            "==> Train Accuracy: Acc@1 28.032 || Acc@5 59.968\n",
            "==> Test Accuracy:  Acc@1 12.630 || Acc@5 34.940\n",
            "==> 57.43 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 6, lr: 0.1 -----\n",
            "Epoch: [6][  0/391]\tTime  0.366 ( 0.366)\tLoss 2.7405e+00 (2.7405e+00)\tAcc@1  29.69 ( 29.69)\tAcc@5  63.28 ( 63.28)\n",
            "Epoch: [6][ 30/391]\tTime  0.100 ( 0.111)\tLoss 2.7118e+00 (2.6456e+00)\tAcc@1  28.12 ( 30.29)\tAcc@5  68.75 ( 63.91)\n",
            "Epoch: [6][ 60/391]\tTime  0.097 ( 0.106)\tLoss 2.8033e+00 (2.6966e+00)\tAcc@1  28.12 ( 30.30)\tAcc@5  57.81 ( 62.79)\n",
            "Epoch: [6][ 90/391]\tTime  0.100 ( 0.104)\tLoss 2.6859e+00 (2.7043e+00)\tAcc@1  32.03 ( 30.52)\tAcc@5  64.84 ( 62.71)\n",
            "Epoch: [6][120/391]\tTime  0.098 ( 0.104)\tLoss 2.7371e+00 (2.6884e+00)\tAcc@1  26.56 ( 30.85)\tAcc@5  60.94 ( 63.19)\n",
            "Epoch: [6][150/391]\tTime  0.099 ( 0.103)\tLoss 2.7288e+00 (2.6984e+00)\tAcc@1  26.56 ( 30.71)\tAcc@5  58.59 ( 62.82)\n",
            "Epoch: [6][180/391]\tTime  0.101 ( 0.103)\tLoss 2.6862e+00 (2.6969e+00)\tAcc@1  25.00 ( 30.71)\tAcc@5  64.06 ( 62.84)\n",
            "Epoch: [6][210/391]\tTime  0.104 ( 0.103)\tLoss 2.4729e+00 (2.6971e+00)\tAcc@1  33.59 ( 30.77)\tAcc@5  71.09 ( 62.97)\n",
            "Epoch: [6][240/391]\tTime  0.104 ( 0.103)\tLoss 2.6249e+00 (2.6919e+00)\tAcc@1  29.69 ( 30.84)\tAcc@5  64.84 ( 63.08)\n",
            "Epoch: [6][270/391]\tTime  0.100 ( 0.103)\tLoss 2.5590e+00 (2.6866e+00)\tAcc@1  33.59 ( 30.94)\tAcc@5  65.62 ( 63.28)\n",
            "Epoch: [6][300/391]\tTime  0.099 ( 0.103)\tLoss 2.7430e+00 (2.6797e+00)\tAcc@1  32.81 ( 31.16)\tAcc@5  56.25 ( 63.38)\n",
            "Epoch: [6][330/391]\tTime  0.101 ( 0.103)\tLoss 3.1816e+00 (2.6765e+00)\tAcc@1  18.75 ( 31.17)\tAcc@5  51.56 ( 63.52)\n",
            "Epoch: [6][360/391]\tTime  0.105 ( 0.103)\tLoss 2.7487e+00 (2.6774e+00)\tAcc@1  29.69 ( 31.09)\tAcc@5  61.72 ( 63.50)\n",
            "Epoch: [6][390/391]\tTime  0.047 ( 0.102)\tLoss 2.5257e+00 (2.6733e+00)\tAcc@1  27.50 ( 31.22)\tAcc@5  66.25 ( 63.56)\n",
            "==> Train Accuracy: Acc@1 31.216 || Acc@5 63.562\n",
            "==> Test Accuracy:  Acc@1 16.080 || Acc@5 39.720\n",
            "==> 57.61 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 7, lr: 0.1 -----\n",
            "Epoch: [7][  0/391]\tTime  0.377 ( 0.377)\tLoss 2.5503e+00 (2.5503e+00)\tAcc@1  37.50 ( 37.50)\tAcc@5  68.75 ( 68.75)\n",
            "Epoch: [7][ 30/391]\tTime  0.101 ( 0.113)\tLoss 2.5060e+00 (2.5099e+00)\tAcc@1  33.59 ( 34.78)\tAcc@5  64.84 ( 67.41)\n",
            "Epoch: [7][ 60/391]\tTime  0.109 ( 0.107)\tLoss 2.4186e+00 (2.5553e+00)\tAcc@1  32.81 ( 33.85)\tAcc@5  69.53 ( 66.24)\n",
            "Epoch: [7][ 90/391]\tTime  0.101 ( 0.105)\tLoss 2.5696e+00 (2.5638e+00)\tAcc@1  30.47 ( 33.46)\tAcc@5  61.72 ( 65.88)\n",
            "Epoch: [7][120/391]\tTime  0.099 ( 0.104)\tLoss 2.4541e+00 (2.5654e+00)\tAcc@1  32.03 ( 33.33)\tAcc@5  72.66 ( 65.93)\n",
            "Epoch: [7][150/391]\tTime  0.098 ( 0.103)\tLoss 2.5813e+00 (2.5589e+00)\tAcc@1  31.25 ( 33.27)\tAcc@5  61.72 ( 66.19)\n",
            "Epoch: [7][180/391]\tTime  0.107 ( 0.103)\tLoss 2.6166e+00 (2.5649e+00)\tAcc@1  33.59 ( 33.22)\tAcc@5  65.62 ( 65.98)\n",
            "Epoch: [7][210/391]\tTime  0.099 ( 0.102)\tLoss 2.5935e+00 (2.5619e+00)\tAcc@1  32.03 ( 33.15)\tAcc@5  64.84 ( 66.02)\n",
            "Epoch: [7][240/391]\tTime  0.097 ( 0.102)\tLoss 2.3910e+00 (2.5569e+00)\tAcc@1  36.72 ( 33.37)\tAcc@5  68.75 ( 66.11)\n",
            "Epoch: [7][270/391]\tTime  0.098 ( 0.102)\tLoss 2.4731e+00 (2.5600e+00)\tAcc@1  43.75 ( 33.33)\tAcc@5  64.84 ( 66.04)\n",
            "Epoch: [7][300/391]\tTime  0.098 ( 0.102)\tLoss 2.2743e+00 (2.5548e+00)\tAcc@1  39.84 ( 33.44)\tAcc@5  73.44 ( 66.21)\n",
            "Epoch: [7][330/391]\tTime  0.096 ( 0.102)\tLoss 2.8041e+00 (2.5506e+00)\tAcc@1  28.12 ( 33.47)\tAcc@5  61.72 ( 66.32)\n",
            "Epoch: [7][360/391]\tTime  0.096 ( 0.101)\tLoss 2.3516e+00 (2.5441e+00)\tAcc@1  35.16 ( 33.56)\tAcc@5  74.22 ( 66.46)\n",
            "Epoch: [7][390/391]\tTime  0.052 ( 0.101)\tLoss 2.3325e+00 (2.5424e+00)\tAcc@1  42.50 ( 33.64)\tAcc@5  68.75 ( 66.49)\n",
            "==> Train Accuracy: Acc@1 33.640 || Acc@5 66.494\n",
            "==> Test Accuracy:  Acc@1 17.040 || Acc@5 41.220\n",
            "==> 56.90 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 8, lr: 0.1 -----\n",
            "Epoch: [8][  0/391]\tTime  0.376 ( 0.376)\tLoss 2.7160e+00 (2.7160e+00)\tAcc@1  31.25 ( 31.25)\tAcc@5  60.16 ( 60.16)\n",
            "Epoch: [8][ 30/391]\tTime  0.099 ( 0.111)\tLoss 2.5038e+00 (2.4221e+00)\tAcc@1  33.59 ( 36.59)\tAcc@5  71.09 ( 69.41)\n",
            "Epoch: [8][ 60/391]\tTime  0.096 ( 0.106)\tLoss 2.3057e+00 (2.4366e+00)\tAcc@1  43.75 ( 36.50)\tAcc@5  75.78 ( 68.81)\n",
            "Epoch: [8][ 90/391]\tTime  0.101 ( 0.104)\tLoss 2.7247e+00 (2.4403e+00)\tAcc@1  29.69 ( 36.14)\tAcc@5  62.50 ( 68.77)\n",
            "Epoch: [8][120/391]\tTime  0.098 ( 0.103)\tLoss 2.4511e+00 (2.4506e+00)\tAcc@1  38.28 ( 36.20)\tAcc@5  68.75 ( 68.64)\n",
            "Epoch: [8][150/391]\tTime  0.099 ( 0.103)\tLoss 2.4900e+00 (2.4518e+00)\tAcc@1  33.59 ( 36.12)\tAcc@5  63.28 ( 68.52)\n",
            "Epoch: [8][180/391]\tTime  0.101 ( 0.102)\tLoss 2.5035e+00 (2.4456e+00)\tAcc@1  34.38 ( 36.38)\tAcc@5  69.53 ( 68.54)\n",
            "Epoch: [8][210/391]\tTime  0.099 ( 0.102)\tLoss 2.6781e+00 (2.4441e+00)\tAcc@1  28.12 ( 36.22)\tAcc@5  61.72 ( 68.65)\n",
            "Epoch: [8][240/391]\tTime  0.096 ( 0.101)\tLoss 2.1029e+00 (2.4462e+00)\tAcc@1  46.09 ( 36.06)\tAcc@5  76.56 ( 68.56)\n",
            "Epoch: [8][270/391]\tTime  0.096 ( 0.101)\tLoss 2.3309e+00 (2.4392e+00)\tAcc@1  40.62 ( 36.18)\tAcc@5  72.66 ( 68.67)\n",
            "Epoch: [8][300/391]\tTime  0.101 ( 0.101)\tLoss 2.7006e+00 (2.4339e+00)\tAcc@1  25.78 ( 36.21)\tAcc@5  57.03 ( 68.77)\n",
            "Epoch: [8][330/391]\tTime  0.103 ( 0.101)\tLoss 2.5292e+00 (2.4336e+00)\tAcc@1  28.91 ( 36.15)\tAcc@5  67.19 ( 68.83)\n",
            "Epoch: [8][360/391]\tTime  0.099 ( 0.101)\tLoss 2.2367e+00 (2.4326e+00)\tAcc@1  43.75 ( 36.10)\tAcc@5  73.44 ( 68.81)\n",
            "Epoch: [8][390/391]\tTime  0.049 ( 0.100)\tLoss 2.4074e+00 (2.4287e+00)\tAcc@1  37.50 ( 36.23)\tAcc@5  70.00 ( 68.87)\n",
            "==> Train Accuracy: Acc@1 36.234 || Acc@5 68.870\n",
            "==> Test Accuracy:  Acc@1 24.390 || Acc@5 52.900\n",
            "==> 56.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 9, lr: 0.1 -----\n",
            "Epoch: [9][  0/391]\tTime  0.334 ( 0.334)\tLoss 2.2511e+00 (2.2511e+00)\tAcc@1  35.94 ( 35.94)\tAcc@5  71.88 ( 71.88)\n",
            "Epoch: [9][ 30/391]\tTime  0.103 ( 0.110)\tLoss 2.7014e+00 (2.3482e+00)\tAcc@1  32.03 ( 37.80)\tAcc@5  60.16 ( 70.29)\n",
            "Epoch: [9][ 60/391]\tTime  0.106 ( 0.107)\tLoss 2.2011e+00 (2.3092e+00)\tAcc@1  39.06 ( 38.70)\tAcc@5  75.00 ( 71.27)\n",
            "Epoch: [9][ 90/391]\tTime  0.101 ( 0.105)\tLoss 2.5275e+00 (2.3233e+00)\tAcc@1  39.84 ( 38.44)\tAcc@5  65.62 ( 71.07)\n",
            "Epoch: [9][120/391]\tTime  0.099 ( 0.105)\tLoss 2.3337e+00 (2.3262e+00)\tAcc@1  36.72 ( 38.40)\tAcc@5  73.44 ( 71.11)\n",
            "Epoch: [9][150/391]\tTime  0.103 ( 0.105)\tLoss 2.3564e+00 (2.3172e+00)\tAcc@1  37.50 ( 38.41)\tAcc@5  68.75 ( 71.35)\n",
            "Epoch: [9][180/391]\tTime  0.110 ( 0.105)\tLoss 2.1774e+00 (2.3192e+00)\tAcc@1  45.31 ( 38.44)\tAcc@5  76.56 ( 71.31)\n",
            "Epoch: [9][210/391]\tTime  0.109 ( 0.105)\tLoss 2.0634e+00 (2.3194e+00)\tAcc@1  47.66 ( 38.44)\tAcc@5  73.44 ( 71.34)\n",
            "Epoch: [9][240/391]\tTime  0.108 ( 0.105)\tLoss 2.2781e+00 (2.3185e+00)\tAcc@1  40.62 ( 38.33)\tAcc@5  75.00 ( 71.40)\n",
            "Epoch: [9][270/391]\tTime  0.105 ( 0.105)\tLoss 2.3635e+00 (2.3302e+00)\tAcc@1  43.75 ( 38.13)\tAcc@5  68.75 ( 71.14)\n",
            "Epoch: [9][300/391]\tTime  0.106 ( 0.106)\tLoss 2.1257e+00 (2.3294e+00)\tAcc@1  49.22 ( 38.17)\tAcc@5  70.31 ( 71.11)\n",
            "Epoch: [9][330/391]\tTime  0.107 ( 0.105)\tLoss 2.3041e+00 (2.3292e+00)\tAcc@1  39.84 ( 38.19)\tAcc@5  69.53 ( 71.07)\n",
            "Epoch: [9][360/391]\tTime  0.105 ( 0.105)\tLoss 2.1336e+00 (2.3236e+00)\tAcc@1  41.41 ( 38.26)\tAcc@5  75.00 ( 71.19)\n",
            "Epoch: [9][390/391]\tTime  0.048 ( 0.105)\tLoss 2.4341e+00 (2.3247e+00)\tAcc@1  30.00 ( 38.20)\tAcc@5  70.00 ( 71.15)\n",
            "==> Train Accuracy: Acc@1 38.202 || Acc@5 71.150\n",
            "==> Test Accuracy:  Acc@1 26.690 || Acc@5 55.730\n",
            "==> 59.01 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 10, lr: 0.1 -----\n",
            "Epoch: [10][  0/391]\tTime  0.375 ( 0.375)\tLoss 2.2205e+00 (2.2205e+00)\tAcc@1  38.28 ( 38.28)\tAcc@5  76.56 ( 76.56)\n",
            "Epoch: [10][ 30/391]\tTime  0.108 ( 0.115)\tLoss 2.0496e+00 (2.2605e+00)\tAcc@1  45.31 ( 40.05)\tAcc@5  80.47 ( 72.05)\n",
            "Epoch: [10][ 60/391]\tTime  0.098 ( 0.109)\tLoss 2.3065e+00 (2.2318e+00)\tAcc@1  34.38 ( 40.47)\tAcc@5  72.66 ( 72.68)\n",
            "Epoch: [10][ 90/391]\tTime  0.099 ( 0.106)\tLoss 2.2017e+00 (2.2321e+00)\tAcc@1  43.75 ( 40.26)\tAcc@5  73.44 ( 72.77)\n",
            "Epoch: [10][120/391]\tTime  0.106 ( 0.104)\tLoss 2.3185e+00 (2.2391e+00)\tAcc@1  36.72 ( 40.17)\tAcc@5  73.44 ( 72.60)\n",
            "Epoch: [10][150/391]\tTime  0.099 ( 0.104)\tLoss 2.1364e+00 (2.2343e+00)\tAcc@1  40.62 ( 40.23)\tAcc@5  79.69 ( 72.78)\n",
            "Epoch: [10][180/391]\tTime  0.097 ( 0.104)\tLoss 2.2442e+00 (2.2302e+00)\tAcc@1  38.28 ( 40.32)\tAcc@5  72.66 ( 72.80)\n",
            "Epoch: [10][210/391]\tTime  0.099 ( 0.103)\tLoss 2.1547e+00 (2.2303e+00)\tAcc@1  39.06 ( 40.31)\tAcc@5  78.12 ( 72.96)\n",
            "Epoch: [10][240/391]\tTime  0.113 ( 0.103)\tLoss 2.3138e+00 (2.2280e+00)\tAcc@1  35.94 ( 40.35)\tAcc@5  70.31 ( 73.02)\n",
            "Epoch: [10][270/391]\tTime  0.099 ( 0.103)\tLoss 2.0540e+00 (2.2281e+00)\tAcc@1  46.88 ( 40.34)\tAcc@5  76.56 ( 73.02)\n",
            "Epoch: [10][300/391]\tTime  0.099 ( 0.103)\tLoss 2.3960e+00 (2.2230e+00)\tAcc@1  32.81 ( 40.46)\tAcc@5  69.53 ( 73.13)\n",
            "Epoch: [10][330/391]\tTime  0.100 ( 0.102)\tLoss 2.2039e+00 (2.2236e+00)\tAcc@1  42.97 ( 40.53)\tAcc@5  75.00 ( 73.14)\n",
            "Epoch: [10][360/391]\tTime  0.101 ( 0.102)\tLoss 2.1934e+00 (2.2242e+00)\tAcc@1  43.75 ( 40.54)\tAcc@5  74.22 ( 73.13)\n",
            "Epoch: [10][390/391]\tTime  0.049 ( 0.102)\tLoss 2.2552e+00 (2.2240e+00)\tAcc@1  47.50 ( 40.57)\tAcc@5  72.50 ( 73.04)\n",
            "==> Train Accuracy: Acc@1 40.574 || Acc@5 73.036\n",
            "==> Test Accuracy:  Acc@1 30.900 || Acc@5 61.650\n",
            "==> 57.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 11, lr: 0.1 -----\n",
            "Epoch: [11][  0/391]\tTime  0.367 ( 0.367)\tLoss 2.2000e+00 (2.2000e+00)\tAcc@1  41.41 ( 41.41)\tAcc@5  73.44 ( 73.44)\n",
            "Epoch: [11][ 30/391]\tTime  0.099 ( 0.112)\tLoss 1.7971e+00 (2.1020e+00)\tAcc@1  50.78 ( 43.22)\tAcc@5  79.69 ( 76.54)\n",
            "Epoch: [11][ 60/391]\tTime  0.101 ( 0.107)\tLoss 2.3137e+00 (2.1132e+00)\tAcc@1  34.38 ( 42.79)\tAcc@5  69.53 ( 76.00)\n",
            "Epoch: [11][ 90/391]\tTime  0.098 ( 0.105)\tLoss 2.1970e+00 (2.1129e+00)\tAcc@1  40.62 ( 43.08)\tAcc@5  68.75 ( 75.60)\n",
            "Epoch: [11][120/391]\tTime  0.099 ( 0.103)\tLoss 2.3915e+00 (2.1305e+00)\tAcc@1  32.03 ( 42.72)\tAcc@5  70.31 ( 75.12)\n",
            "Epoch: [11][150/391]\tTime  0.101 ( 0.103)\tLoss 2.2007e+00 (2.1321e+00)\tAcc@1  39.84 ( 42.74)\tAcc@5  73.44 ( 75.13)\n",
            "Epoch: [11][180/391]\tTime  0.098 ( 0.102)\tLoss 2.2172e+00 (2.1381e+00)\tAcc@1  42.97 ( 42.64)\tAcc@5  71.09 ( 75.06)\n",
            "Epoch: [11][210/391]\tTime  0.115 ( 0.102)\tLoss 2.1682e+00 (2.1363e+00)\tAcc@1  39.84 ( 42.65)\tAcc@5  75.00 ( 75.17)\n",
            "Epoch: [11][240/391]\tTime  0.098 ( 0.102)\tLoss 2.2993e+00 (2.1402e+00)\tAcc@1  42.97 ( 42.47)\tAcc@5  74.22 ( 75.17)\n",
            "Epoch: [11][270/391]\tTime  0.101 ( 0.102)\tLoss 1.9597e+00 (2.1385e+00)\tAcc@1  46.88 ( 42.50)\tAcc@5  80.47 ( 75.11)\n",
            "Epoch: [11][300/391]\tTime  0.101 ( 0.102)\tLoss 2.2715e+00 (2.1412e+00)\tAcc@1  39.84 ( 42.42)\tAcc@5  71.88 ( 75.00)\n",
            "Epoch: [11][330/391]\tTime  0.106 ( 0.102)\tLoss 2.3379e+00 (2.1420e+00)\tAcc@1  38.28 ( 42.36)\tAcc@5  73.44 ( 74.98)\n",
            "Epoch: [11][360/391]\tTime  0.097 ( 0.102)\tLoss 1.9309e+00 (2.1378e+00)\tAcc@1  49.22 ( 42.43)\tAcc@5  78.91 ( 75.03)\n",
            "Epoch: [11][390/391]\tTime  0.051 ( 0.101)\tLoss 2.1823e+00 (2.1346e+00)\tAcc@1  37.50 ( 42.45)\tAcc@5  75.00 ( 75.12)\n",
            "==> Train Accuracy: Acc@1 42.448 || Acc@5 75.122\n",
            "==> Test Accuracy:  Acc@1 32.670 || Acc@5 63.880\n",
            "==> 57.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 12, lr: 0.1 -----\n",
            "Epoch: [12][  0/391]\tTime  0.387 ( 0.387)\tLoss 2.0853e+00 (2.0853e+00)\tAcc@1  42.19 ( 42.19)\tAcc@5  78.12 ( 78.12)\n",
            "Epoch: [12][ 30/391]\tTime  0.107 ( 0.116)\tLoss 1.8702e+00 (2.0694e+00)\tAcc@1  55.47 ( 44.28)\tAcc@5  80.47 ( 76.61)\n",
            "Epoch: [12][ 60/391]\tTime  0.102 ( 0.110)\tLoss 2.1235e+00 (2.0907e+00)\tAcc@1  41.41 ( 43.67)\tAcc@5  73.44 ( 75.85)\n",
            "Epoch: [12][ 90/391]\tTime  0.100 ( 0.108)\tLoss 2.2198e+00 (2.0624e+00)\tAcc@1  41.41 ( 44.38)\tAcc@5  73.44 ( 76.21)\n",
            "Epoch: [12][120/391]\tTime  0.098 ( 0.106)\tLoss 2.0371e+00 (2.0659e+00)\tAcc@1  40.62 ( 44.21)\tAcc@5  75.78 ( 76.14)\n",
            "Epoch: [12][150/391]\tTime  0.099 ( 0.105)\tLoss 1.9538e+00 (2.0586e+00)\tAcc@1  52.34 ( 44.26)\tAcc@5  78.12 ( 76.39)\n",
            "Epoch: [12][180/391]\tTime  0.098 ( 0.104)\tLoss 2.2261e+00 (2.0508e+00)\tAcc@1  43.75 ( 44.46)\tAcc@5  70.31 ( 76.58)\n",
            "Epoch: [12][210/391]\tTime  0.101 ( 0.103)\tLoss 2.0980e+00 (2.0440e+00)\tAcc@1  48.44 ( 44.69)\tAcc@5  71.88 ( 76.73)\n",
            "Epoch: [12][240/391]\tTime  0.105 ( 0.103)\tLoss 1.9055e+00 (2.0478e+00)\tAcc@1  49.22 ( 44.54)\tAcc@5  78.91 ( 76.68)\n",
            "Epoch: [12][270/391]\tTime  0.098 ( 0.103)\tLoss 2.2475e+00 (2.0452e+00)\tAcc@1  37.50 ( 44.51)\tAcc@5  72.66 ( 76.66)\n",
            "Epoch: [12][300/391]\tTime  0.104 ( 0.103)\tLoss 1.8480e+00 (2.0424e+00)\tAcc@1  47.66 ( 44.67)\tAcc@5  78.91 ( 76.70)\n",
            "Epoch: [12][330/391]\tTime  0.103 ( 0.103)\tLoss 2.1214e+00 (2.0442e+00)\tAcc@1  43.75 ( 44.71)\tAcc@5  68.75 ( 76.57)\n",
            "Epoch: [12][360/391]\tTime  0.101 ( 0.103)\tLoss 2.1360e+00 (2.0428e+00)\tAcc@1  41.41 ( 44.59)\tAcc@5  75.00 ( 76.66)\n",
            "Epoch: [12][390/391]\tTime  0.048 ( 0.102)\tLoss 2.2047e+00 (2.0451e+00)\tAcc@1  46.25 ( 44.56)\tAcc@5  76.25 ( 76.57)\n",
            "==> Train Accuracy: Acc@1 44.560 || Acc@5 76.568\n",
            "==> Test Accuracy:  Acc@1 36.930 || Acc@5 68.230\n",
            "==> 57.50 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 13, lr: 0.1 -----\n",
            "Epoch: [13][  0/391]\tTime  0.343 ( 0.343)\tLoss 1.9106e+00 (1.9106e+00)\tAcc@1  47.66 ( 47.66)\tAcc@5  80.47 ( 80.47)\n",
            "Epoch: [13][ 30/391]\tTime  0.103 ( 0.111)\tLoss 1.9570e+00 (1.9583e+00)\tAcc@1  48.44 ( 46.45)\tAcc@5  78.91 ( 78.50)\n",
            "Epoch: [13][ 60/391]\tTime  0.117 ( 0.107)\tLoss 2.0688e+00 (1.9628e+00)\tAcc@1  44.53 ( 46.21)\tAcc@5  75.00 ( 78.07)\n",
            "Epoch: [13][ 90/391]\tTime  0.108 ( 0.106)\tLoss 1.7668e+00 (1.9613e+00)\tAcc@1  53.12 ( 46.07)\tAcc@5  75.78 ( 78.17)\n",
            "Epoch: [13][120/391]\tTime  0.102 ( 0.105)\tLoss 2.1784e+00 (1.9691e+00)\tAcc@1  43.75 ( 45.71)\tAcc@5  73.44 ( 78.09)\n",
            "Epoch: [13][150/391]\tTime  0.111 ( 0.104)\tLoss 1.8221e+00 (1.9700e+00)\tAcc@1  49.22 ( 45.90)\tAcc@5  79.69 ( 78.04)\n",
            "Epoch: [13][180/391]\tTime  0.106 ( 0.103)\tLoss 1.7639e+00 (1.9781e+00)\tAcc@1  58.59 ( 45.83)\tAcc@5  82.81 ( 77.95)\n",
            "Epoch: [13][210/391]\tTime  0.101 ( 0.103)\tLoss 1.9644e+00 (1.9785e+00)\tAcc@1  44.53 ( 45.77)\tAcc@5  82.03 ( 78.04)\n",
            "Epoch: [13][240/391]\tTime  0.099 ( 0.103)\tLoss 1.9446e+00 (1.9770e+00)\tAcc@1  45.31 ( 45.89)\tAcc@5  77.34 ( 78.03)\n",
            "Epoch: [13][270/391]\tTime  0.100 ( 0.102)\tLoss 1.7549e+00 (1.9743e+00)\tAcc@1  54.69 ( 45.93)\tAcc@5  82.03 ( 78.05)\n",
            "Epoch: [13][300/391]\tTime  0.101 ( 0.102)\tLoss 2.0261e+00 (1.9782e+00)\tAcc@1  43.75 ( 45.89)\tAcc@5  73.44 ( 77.91)\n",
            "Epoch: [13][330/391]\tTime  0.096 ( 0.102)\tLoss 2.1590e+00 (1.9804e+00)\tAcc@1  39.06 ( 45.91)\tAcc@5  71.09 ( 77.94)\n",
            "Epoch: [13][360/391]\tTime  0.100 ( 0.101)\tLoss 2.0086e+00 (1.9826e+00)\tAcc@1  40.62 ( 45.82)\tAcc@5  75.78 ( 77.89)\n",
            "Epoch: [13][390/391]\tTime  0.048 ( 0.101)\tLoss 1.9303e+00 (1.9843e+00)\tAcc@1  50.00 ( 45.74)\tAcc@5  77.50 ( 77.84)\n",
            "==> Train Accuracy: Acc@1 45.738 || Acc@5 77.844\n",
            "==> Test Accuracy:  Acc@1 34.950 || Acc@5 65.250\n",
            "==> 57.03 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 14, lr: 0.1 -----\n",
            "Epoch: [14][  0/391]\tTime  0.376 ( 0.376)\tLoss 1.8037e+00 (1.8037e+00)\tAcc@1  48.44 ( 48.44)\tAcc@5  83.59 ( 83.59)\n",
            "Epoch: [14][ 30/391]\tTime  0.097 ( 0.109)\tLoss 1.7817e+00 (1.8793e+00)\tAcc@1  46.88 ( 47.88)\tAcc@5  79.69 ( 80.34)\n",
            "Epoch: [14][ 60/391]\tTime  0.099 ( 0.104)\tLoss 2.2230e+00 (1.8840e+00)\tAcc@1  45.31 ( 48.08)\tAcc@5  71.88 ( 80.08)\n",
            "Epoch: [14][ 90/391]\tTime  0.103 ( 0.104)\tLoss 2.1319e+00 (1.9007e+00)\tAcc@1  43.75 ( 47.68)\tAcc@5  75.00 ( 79.66)\n",
            "Epoch: [14][120/391]\tTime  0.098 ( 0.103)\tLoss 2.1056e+00 (1.8952e+00)\tAcc@1  44.53 ( 47.88)\tAcc@5  77.34 ( 79.87)\n",
            "Epoch: [14][150/391]\tTime  0.102 ( 0.103)\tLoss 1.9458e+00 (1.8981e+00)\tAcc@1  48.44 ( 47.75)\tAcc@5  75.78 ( 79.81)\n",
            "Epoch: [14][180/391]\tTime  0.102 ( 0.103)\tLoss 2.1165e+00 (1.9068e+00)\tAcc@1  45.31 ( 47.53)\tAcc@5  75.78 ( 79.55)\n",
            "Epoch: [14][210/391]\tTime  0.104 ( 0.103)\tLoss 1.8941e+00 (1.9085e+00)\tAcc@1  48.44 ( 47.48)\tAcc@5  77.34 ( 79.50)\n",
            "Epoch: [14][240/391]\tTime  0.105 ( 0.102)\tLoss 1.6925e+00 (1.9103e+00)\tAcc@1  55.47 ( 47.50)\tAcc@5  79.69 ( 79.46)\n",
            "Epoch: [14][270/391]\tTime  0.102 ( 0.102)\tLoss 2.0451e+00 (1.9142e+00)\tAcc@1  46.09 ( 47.38)\tAcc@5  78.91 ( 79.44)\n",
            "Epoch: [14][300/391]\tTime  0.102 ( 0.102)\tLoss 1.7802e+00 (1.9100e+00)\tAcc@1  49.22 ( 47.52)\tAcc@5  82.03 ( 79.50)\n",
            "Epoch: [14][330/391]\tTime  0.107 ( 0.102)\tLoss 1.7463e+00 (1.9126e+00)\tAcc@1  50.78 ( 47.53)\tAcc@5  79.69 ( 79.39)\n",
            "Epoch: [14][360/391]\tTime  0.104 ( 0.102)\tLoss 1.9418e+00 (1.9183e+00)\tAcc@1  46.88 ( 47.45)\tAcc@5  75.78 ( 79.25)\n",
            "Epoch: [14][390/391]\tTime  0.048 ( 0.101)\tLoss 1.9734e+00 (1.9187e+00)\tAcc@1  42.50 ( 47.40)\tAcc@5  77.50 ( 79.22)\n",
            "==> Train Accuracy: Acc@1 47.400 || Acc@5 79.220\n",
            "==> Test Accuracy:  Acc@1 39.560 || Acc@5 69.090\n",
            "==> 57.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 15, lr: 0.1 -----\n",
            "Epoch: [15][  0/391]\tTime  0.344 ( 0.344)\tLoss 1.8961e+00 (1.8961e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  75.78 ( 75.78)\n",
            "Epoch: [15][ 30/391]\tTime  0.100 ( 0.112)\tLoss 1.8029e+00 (1.8297e+00)\tAcc@1  58.59 ( 49.45)\tAcc@5  78.91 ( 80.42)\n",
            "Epoch: [15][ 60/391]\tTime  0.096 ( 0.106)\tLoss 1.6157e+00 (1.8302e+00)\tAcc@1  53.12 ( 49.33)\tAcc@5  85.94 ( 80.51)\n",
            "Epoch: [15][ 90/391]\tTime  0.097 ( 0.104)\tLoss 2.0949e+00 (1.8413e+00)\tAcc@1  44.53 ( 49.18)\tAcc@5  76.56 ( 80.48)\n",
            "Epoch: [15][120/391]\tTime  0.099 ( 0.103)\tLoss 2.2430e+00 (1.8516e+00)\tAcc@1  43.75 ( 48.88)\tAcc@5  74.22 ( 80.42)\n",
            "Epoch: [15][150/391]\tTime  0.099 ( 0.102)\tLoss 1.8926e+00 (1.8674e+00)\tAcc@1  47.66 ( 48.61)\tAcc@5  79.69 ( 79.98)\n",
            "Epoch: [15][180/391]\tTime  0.099 ( 0.102)\tLoss 1.8557e+00 (1.8661e+00)\tAcc@1  48.44 ( 48.73)\tAcc@5  79.69 ( 80.05)\n",
            "Epoch: [15][210/391]\tTime  0.098 ( 0.102)\tLoss 2.0527e+00 (1.8605e+00)\tAcc@1  46.88 ( 48.84)\tAcc@5  72.66 ( 80.24)\n",
            "Epoch: [15][240/391]\tTime  0.103 ( 0.102)\tLoss 1.8194e+00 (1.8598e+00)\tAcc@1  46.88 ( 48.76)\tAcc@5  83.59 ( 80.20)\n",
            "Epoch: [15][270/391]\tTime  0.100 ( 0.102)\tLoss 1.8320e+00 (1.8636e+00)\tAcc@1  48.44 ( 48.66)\tAcc@5  77.34 ( 80.18)\n",
            "Epoch: [15][300/391]\tTime  0.102 ( 0.101)\tLoss 1.9940e+00 (1.8701e+00)\tAcc@1  46.09 ( 48.48)\tAcc@5  80.47 ( 80.13)\n",
            "Epoch: [15][330/391]\tTime  0.098 ( 0.101)\tLoss 1.8341e+00 (1.8694e+00)\tAcc@1  44.53 ( 48.43)\tAcc@5  85.16 ( 80.12)\n",
            "Epoch: [15][360/391]\tTime  0.103 ( 0.101)\tLoss 1.8368e+00 (1.8714e+00)\tAcc@1  45.31 ( 48.41)\tAcc@5  80.47 ( 80.08)\n",
            "Epoch: [15][390/391]\tTime  0.051 ( 0.101)\tLoss 1.7916e+00 (1.8714e+00)\tAcc@1  50.00 ( 48.44)\tAcc@5  81.25 ( 80.06)\n",
            "==> Train Accuracy: Acc@1 48.444 || Acc@5 80.064\n",
            "==> Test Accuracy:  Acc@1 34.890 || Acc@5 66.360\n",
            "==> 56.77 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 16, lr: 0.1 -----\n",
            "Epoch: [16][  0/391]\tTime  0.314 ( 0.314)\tLoss 1.6381e+00 (1.6381e+00)\tAcc@1  50.78 ( 50.78)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [16][ 30/391]\tTime  0.099 ( 0.111)\tLoss 1.8609e+00 (1.7931e+00)\tAcc@1  46.88 ( 50.13)\tAcc@5  77.34 ( 81.58)\n",
            "Epoch: [16][ 60/391]\tTime  0.101 ( 0.106)\tLoss 1.6654e+00 (1.8062e+00)\tAcc@1  50.78 ( 49.69)\tAcc@5  82.03 ( 80.96)\n",
            "Epoch: [16][ 90/391]\tTime  0.102 ( 0.105)\tLoss 1.5477e+00 (1.7947e+00)\tAcc@1  56.25 ( 49.90)\tAcc@5  86.72 ( 81.16)\n",
            "Epoch: [16][120/391]\tTime  0.101 ( 0.104)\tLoss 1.9191e+00 (1.7945e+00)\tAcc@1  41.41 ( 49.88)\tAcc@5  81.25 ( 81.31)\n",
            "Epoch: [16][150/391]\tTime  0.101 ( 0.104)\tLoss 1.7728e+00 (1.7908e+00)\tAcc@1  54.69 ( 50.14)\tAcc@5  81.25 ( 81.23)\n",
            "Epoch: [16][180/391]\tTime  0.101 ( 0.103)\tLoss 1.9637e+00 (1.8019e+00)\tAcc@1  49.22 ( 49.90)\tAcc@5  81.25 ( 81.04)\n",
            "Epoch: [16][210/391]\tTime  0.098 ( 0.103)\tLoss 1.6300e+00 (1.8104e+00)\tAcc@1  53.12 ( 49.74)\tAcc@5  90.62 ( 80.97)\n",
            "Epoch: [16][240/391]\tTime  0.101 ( 0.103)\tLoss 1.9882e+00 (1.8174e+00)\tAcc@1  45.31 ( 49.53)\tAcc@5  78.12 ( 80.95)\n",
            "Epoch: [16][270/391]\tTime  0.100 ( 0.102)\tLoss 1.7638e+00 (1.8205e+00)\tAcc@1  46.09 ( 49.50)\tAcc@5  82.03 ( 80.94)\n",
            "Epoch: [16][300/391]\tTime  0.100 ( 0.102)\tLoss 1.9441e+00 (1.8269e+00)\tAcc@1  45.31 ( 49.42)\tAcc@5  81.25 ( 80.83)\n",
            "Epoch: [16][330/391]\tTime  0.101 ( 0.102)\tLoss 1.8060e+00 (1.8289e+00)\tAcc@1  46.88 ( 49.33)\tAcc@5  84.38 ( 80.79)\n",
            "Epoch: [16][360/391]\tTime  0.100 ( 0.102)\tLoss 1.9680e+00 (1.8262e+00)\tAcc@1  46.09 ( 49.40)\tAcc@5  81.25 ( 80.90)\n",
            "Epoch: [16][390/391]\tTime  0.048 ( 0.102)\tLoss 1.7539e+00 (1.8249e+00)\tAcc@1  55.00 ( 49.43)\tAcc@5  86.25 ( 80.90)\n",
            "==> Train Accuracy: Acc@1 49.434 || Acc@5 80.900\n",
            "==> Test Accuracy:  Acc@1 42.500 || Acc@5 73.210\n",
            "==> 57.42 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 17, lr: 0.1 -----\n",
            "Epoch: [17][  0/391]\tTime  0.406 ( 0.406)\tLoss 1.7081e+00 (1.7081e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [17][ 30/391]\tTime  0.101 ( 0.116)\tLoss 1.6382e+00 (1.7280e+00)\tAcc@1  56.25 ( 52.32)\tAcc@5  86.72 ( 83.17)\n",
            "Epoch: [17][ 60/391]\tTime  0.100 ( 0.109)\tLoss 1.9011e+00 (1.7511e+00)\tAcc@1  48.44 ( 50.99)\tAcc@5  80.47 ( 82.72)\n",
            "Epoch: [17][ 90/391]\tTime  0.105 ( 0.108)\tLoss 1.6833e+00 (1.7543e+00)\tAcc@1  56.25 ( 51.16)\tAcc@5  84.38 ( 82.38)\n",
            "Epoch: [17][120/391]\tTime  0.099 ( 0.106)\tLoss 1.7813e+00 (1.7498e+00)\tAcc@1  49.22 ( 51.25)\tAcc@5  82.03 ( 82.25)\n",
            "Epoch: [17][150/391]\tTime  0.101 ( 0.105)\tLoss 1.9542e+00 (1.7637e+00)\tAcc@1  50.00 ( 51.02)\tAcc@5  81.25 ( 82.13)\n",
            "Epoch: [17][180/391]\tTime  0.105 ( 0.105)\tLoss 1.7689e+00 (1.7694e+00)\tAcc@1  53.12 ( 50.85)\tAcc@5  81.25 ( 82.14)\n",
            "Epoch: [17][210/391]\tTime  0.100 ( 0.104)\tLoss 1.8365e+00 (1.7793e+00)\tAcc@1  54.69 ( 50.51)\tAcc@5  82.03 ( 81.93)\n",
            "Epoch: [17][240/391]\tTime  0.100 ( 0.104)\tLoss 2.0561e+00 (1.7783e+00)\tAcc@1  45.31 ( 50.57)\tAcc@5  73.44 ( 81.92)\n",
            "Epoch: [17][270/391]\tTime  0.099 ( 0.104)\tLoss 1.8875e+00 (1.7844e+00)\tAcc@1  49.22 ( 50.54)\tAcc@5  76.56 ( 81.74)\n",
            "Epoch: [17][300/391]\tTime  0.101 ( 0.103)\tLoss 1.6143e+00 (1.7831e+00)\tAcc@1  52.34 ( 50.63)\tAcc@5  88.28 ( 81.77)\n",
            "Epoch: [17][330/391]\tTime  0.098 ( 0.103)\tLoss 1.7336e+00 (1.7898e+00)\tAcc@1  50.78 ( 50.39)\tAcc@5  83.59 ( 81.70)\n",
            "Epoch: [17][360/391]\tTime  0.099 ( 0.103)\tLoss 1.5681e+00 (1.7926e+00)\tAcc@1  54.69 ( 50.28)\tAcc@5  85.16 ( 81.62)\n",
            "Epoch: [17][390/391]\tTime  0.049 ( 0.102)\tLoss 1.6007e+00 (1.7942e+00)\tAcc@1  53.75 ( 50.24)\tAcc@5  85.00 ( 81.55)\n",
            "==> Train Accuracy: Acc@1 50.238 || Acc@5 81.550\n",
            "==> Test Accuracy:  Acc@1 40.280 || Acc@5 71.480\n",
            "==> 57.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 18, lr: 0.1 -----\n",
            "Epoch: [18][  0/391]\tTime  0.369 ( 0.369)\tLoss 1.8789e+00 (1.8789e+00)\tAcc@1  49.22 ( 49.22)\tAcc@5  79.69 ( 79.69)\n",
            "Epoch: [18][ 30/391]\tTime  0.099 ( 0.113)\tLoss 1.8593e+00 (1.7150e+00)\tAcc@1  48.44 ( 51.61)\tAcc@5  82.03 ( 83.11)\n",
            "Epoch: [18][ 60/391]\tTime  0.098 ( 0.107)\tLoss 1.5072e+00 (1.7204e+00)\tAcc@1  55.47 ( 51.49)\tAcc@5  85.94 ( 82.81)\n",
            "Epoch: [18][ 90/391]\tTime  0.103 ( 0.105)\tLoss 1.7015e+00 (1.7325e+00)\tAcc@1  57.03 ( 51.17)\tAcc@5  85.16 ( 82.90)\n",
            "Epoch: [18][120/391]\tTime  0.098 ( 0.104)\tLoss 1.6077e+00 (1.7221e+00)\tAcc@1  58.59 ( 51.51)\tAcc@5  86.72 ( 83.11)\n",
            "Epoch: [18][150/391]\tTime  0.106 ( 0.103)\tLoss 1.7899e+00 (1.7331e+00)\tAcc@1  53.91 ( 51.52)\tAcc@5  78.91 ( 82.79)\n",
            "Epoch: [18][180/391]\tTime  0.101 ( 0.103)\tLoss 1.8444e+00 (1.7354e+00)\tAcc@1  49.22 ( 51.69)\tAcc@5  82.03 ( 82.71)\n",
            "Epoch: [18][210/391]\tTime  0.104 ( 0.103)\tLoss 1.7558e+00 (1.7416e+00)\tAcc@1  49.22 ( 51.46)\tAcc@5  85.94 ( 82.61)\n",
            "Epoch: [18][240/391]\tTime  0.101 ( 0.103)\tLoss 2.0362e+00 (1.7493e+00)\tAcc@1  41.41 ( 51.23)\tAcc@5  75.78 ( 82.40)\n",
            "Epoch: [18][270/391]\tTime  0.102 ( 0.103)\tLoss 1.6548e+00 (1.7508e+00)\tAcc@1  48.44 ( 51.03)\tAcc@5  85.16 ( 82.36)\n",
            "Epoch: [18][300/391]\tTime  0.097 ( 0.103)\tLoss 1.6704e+00 (1.7529e+00)\tAcc@1  53.91 ( 51.00)\tAcc@5  84.38 ( 82.28)\n",
            "Epoch: [18][330/391]\tTime  0.099 ( 0.103)\tLoss 1.6829e+00 (1.7522e+00)\tAcc@1  50.00 ( 50.98)\tAcc@5  82.81 ( 82.38)\n",
            "Epoch: [18][360/391]\tTime  0.101 ( 0.102)\tLoss 2.1496e+00 (1.7579e+00)\tAcc@1  39.06 ( 50.84)\tAcc@5  71.88 ( 82.26)\n",
            "Epoch: [18][390/391]\tTime  0.054 ( 0.102)\tLoss 1.6904e+00 (1.7631e+00)\tAcc@1  52.50 ( 50.72)\tAcc@5  88.75 ( 82.14)\n",
            "==> Train Accuracy: Acc@1 50.718 || Acc@5 82.140\n",
            "==> Test Accuracy:  Acc@1 40.150 || Acc@5 71.540\n",
            "==> 57.49 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 19, lr: 0.1 -----\n",
            "Epoch: [19][  0/391]\tTime  0.302 ( 0.302)\tLoss 1.8745e+00 (1.8745e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  82.81 ( 82.81)\n",
            "Epoch: [19][ 30/391]\tTime  0.100 ( 0.112)\tLoss 1.3833e+00 (1.6501e+00)\tAcc@1  61.72 ( 53.28)\tAcc@5  89.06 ( 84.15)\n",
            "Epoch: [19][ 60/391]\tTime  0.100 ( 0.107)\tLoss 1.5751e+00 (1.6752e+00)\tAcc@1  56.25 ( 52.86)\tAcc@5  85.16 ( 83.80)\n",
            "Epoch: [19][ 90/391]\tTime  0.097 ( 0.105)\tLoss 1.9464e+00 (1.6916e+00)\tAcc@1  53.91 ( 52.38)\tAcc@5  78.12 ( 83.41)\n",
            "Epoch: [19][120/391]\tTime  0.096 ( 0.104)\tLoss 1.7282e+00 (1.7023e+00)\tAcc@1  53.12 ( 52.17)\tAcc@5  82.81 ( 83.41)\n",
            "Epoch: [19][150/391]\tTime  0.100 ( 0.103)\tLoss 1.9281e+00 (1.7155e+00)\tAcc@1  44.53 ( 51.90)\tAcc@5  78.91 ( 83.15)\n",
            "Epoch: [19][180/391]\tTime  0.100 ( 0.102)\tLoss 1.6677e+00 (1.7229e+00)\tAcc@1  55.47 ( 51.96)\tAcc@5  84.38 ( 82.97)\n",
            "Epoch: [19][210/391]\tTime  0.114 ( 0.102)\tLoss 1.6929e+00 (1.7210e+00)\tAcc@1  55.47 ( 52.09)\tAcc@5  78.91 ( 82.99)\n",
            "Epoch: [19][240/391]\tTime  0.100 ( 0.102)\tLoss 1.5775e+00 (1.7229e+00)\tAcc@1  57.81 ( 52.03)\tAcc@5  85.16 ( 82.92)\n",
            "Epoch: [19][270/391]\tTime  0.100 ( 0.103)\tLoss 1.8332e+00 (1.7257e+00)\tAcc@1  51.56 ( 52.08)\tAcc@5  79.69 ( 82.86)\n",
            "Epoch: [19][300/391]\tTime  0.097 ( 0.102)\tLoss 1.8092e+00 (1.7312e+00)\tAcc@1  48.44 ( 51.90)\tAcc@5  77.34 ( 82.68)\n",
            "Epoch: [19][330/391]\tTime  0.113 ( 0.102)\tLoss 1.9276e+00 (1.7377e+00)\tAcc@1  48.44 ( 51.72)\tAcc@5  78.12 ( 82.62)\n",
            "Epoch: [19][360/391]\tTime  0.101 ( 0.102)\tLoss 1.8960e+00 (1.7404e+00)\tAcc@1  45.31 ( 51.63)\tAcc@5  80.47 ( 82.57)\n",
            "Epoch: [19][390/391]\tTime  0.048 ( 0.102)\tLoss 1.7380e+00 (1.7440e+00)\tAcc@1  55.00 ( 51.56)\tAcc@5  78.75 ( 82.49)\n",
            "==> Train Accuracy: Acc@1 51.560 || Acc@5 82.490\n",
            "==> Test Accuracy:  Acc@1 43.860 || Acc@5 75.630\n",
            "==> 57.37 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 20, lr: 0.1 -----\n",
            "Epoch: [20][  0/391]\tTime  0.382 ( 0.382)\tLoss 1.6105e+00 (1.6105e+00)\tAcc@1  56.25 ( 56.25)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [20][ 30/391]\tTime  0.100 ( 0.112)\tLoss 1.6868e+00 (1.6677e+00)\tAcc@1  52.34 ( 53.53)\tAcc@5  84.38 ( 84.15)\n",
            "Epoch: [20][ 60/391]\tTime  0.102 ( 0.107)\tLoss 1.6689e+00 (1.6719e+00)\tAcc@1  53.12 ( 53.21)\tAcc@5  86.72 ( 83.97)\n",
            "Epoch: [20][ 90/391]\tTime  0.104 ( 0.106)\tLoss 1.6081e+00 (1.6645e+00)\tAcc@1  57.03 ( 53.55)\tAcc@5  85.94 ( 83.93)\n",
            "Epoch: [20][120/391]\tTime  0.098 ( 0.105)\tLoss 1.5779e+00 (1.6733e+00)\tAcc@1  54.69 ( 53.49)\tAcc@5  82.81 ( 83.71)\n",
            "Epoch: [20][150/391]\tTime  0.101 ( 0.104)\tLoss 1.6621e+00 (1.6822e+00)\tAcc@1  53.91 ( 53.17)\tAcc@5  83.59 ( 83.43)\n",
            "Epoch: [20][180/391]\tTime  0.102 ( 0.104)\tLoss 1.7189e+00 (1.6925e+00)\tAcc@1  52.34 ( 53.02)\tAcc@5  82.03 ( 83.32)\n",
            "Epoch: [20][210/391]\tTime  0.102 ( 0.103)\tLoss 1.7531e+00 (1.6923e+00)\tAcc@1  53.91 ( 52.90)\tAcc@5  78.12 ( 83.32)\n",
            "Epoch: [20][240/391]\tTime  0.098 ( 0.103)\tLoss 1.7707e+00 (1.7008e+00)\tAcc@1  50.00 ( 52.57)\tAcc@5  82.03 ( 83.20)\n",
            "Epoch: [20][270/391]\tTime  0.099 ( 0.103)\tLoss 1.5635e+00 (1.7004e+00)\tAcc@1  51.56 ( 52.41)\tAcc@5  86.72 ( 83.22)\n",
            "Epoch: [20][300/391]\tTime  0.102 ( 0.103)\tLoss 1.5207e+00 (1.6998e+00)\tAcc@1  57.81 ( 52.38)\tAcc@5  85.16 ( 83.26)\n",
            "Epoch: [20][330/391]\tTime  0.120 ( 0.103)\tLoss 1.7555e+00 (1.6986e+00)\tAcc@1  55.47 ( 52.48)\tAcc@5  80.47 ( 83.25)\n",
            "Epoch: [20][360/391]\tTime  0.098 ( 0.103)\tLoss 1.7601e+00 (1.7047e+00)\tAcc@1  50.78 ( 52.34)\tAcc@5  81.25 ( 83.10)\n",
            "Epoch: [20][390/391]\tTime  0.048 ( 0.102)\tLoss 2.0196e+00 (1.7071e+00)\tAcc@1  47.50 ( 52.24)\tAcc@5  76.25 ( 83.08)\n",
            "==> Train Accuracy: Acc@1 52.242 || Acc@5 83.076\n",
            "==> Test Accuracy:  Acc@1 42.960 || Acc@5 73.540\n",
            "==> 57.65 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 21, lr: 0.1 -----\n",
            "Epoch: [21][  0/391]\tTime  0.353 ( 0.353)\tLoss 1.6052e+00 (1.6052e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [21][ 30/391]\tTime  0.102 ( 0.110)\tLoss 1.5147e+00 (1.6223e+00)\tAcc@1  56.25 ( 55.49)\tAcc@5  87.50 ( 84.02)\n",
            "Epoch: [21][ 60/391]\tTime  0.097 ( 0.105)\tLoss 1.7071e+00 (1.6114e+00)\tAcc@1  52.34 ( 55.66)\tAcc@5  81.25 ( 84.29)\n",
            "Epoch: [21][ 90/391]\tTime  0.100 ( 0.104)\tLoss 1.8627e+00 (1.6287e+00)\tAcc@1  46.88 ( 54.80)\tAcc@5  79.69 ( 84.22)\n",
            "Epoch: [21][120/391]\tTime  0.102 ( 0.103)\tLoss 1.4237e+00 (1.6462e+00)\tAcc@1  59.38 ( 54.13)\tAcc@5  89.06 ( 84.17)\n",
            "Epoch: [21][150/391]\tTime  0.103 ( 0.103)\tLoss 1.9382e+00 (1.6572e+00)\tAcc@1  49.22 ( 54.03)\tAcc@5  78.12 ( 83.89)\n",
            "Epoch: [21][180/391]\tTime  0.099 ( 0.103)\tLoss 1.5498e+00 (1.6726e+00)\tAcc@1  52.34 ( 53.89)\tAcc@5  88.28 ( 83.57)\n",
            "Epoch: [21][210/391]\tTime  0.100 ( 0.103)\tLoss 1.7547e+00 (1.6762e+00)\tAcc@1  52.34 ( 53.71)\tAcc@5  84.38 ( 83.56)\n",
            "Epoch: [21][240/391]\tTime  0.100 ( 0.103)\tLoss 1.9212e+00 (1.6825e+00)\tAcc@1  46.09 ( 53.55)\tAcc@5  79.69 ( 83.43)\n",
            "Epoch: [21][270/391]\tTime  0.098 ( 0.103)\tLoss 1.7307e+00 (1.6837e+00)\tAcc@1  50.00 ( 53.46)\tAcc@5  83.59 ( 83.41)\n",
            "Epoch: [21][300/391]\tTime  0.098 ( 0.103)\tLoss 1.6110e+00 (1.6806e+00)\tAcc@1  57.03 ( 53.51)\tAcc@5  82.03 ( 83.45)\n",
            "Epoch: [21][330/391]\tTime  0.098 ( 0.102)\tLoss 1.6265e+00 (1.6832e+00)\tAcc@1  54.69 ( 53.43)\tAcc@5  85.16 ( 83.49)\n",
            "Epoch: [21][360/391]\tTime  0.099 ( 0.102)\tLoss 1.6755e+00 (1.6874e+00)\tAcc@1  50.00 ( 53.35)\tAcc@5  84.38 ( 83.41)\n",
            "Epoch: [21][390/391]\tTime  0.046 ( 0.102)\tLoss 1.5706e+00 (1.6900e+00)\tAcc@1  53.75 ( 53.22)\tAcc@5  87.50 ( 83.40)\n",
            "==> Train Accuracy: Acc@1 53.216 || Acc@5 83.396\n",
            "==> Test Accuracy:  Acc@1 44.740 || Acc@5 76.160\n",
            "==> 57.38 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 22, lr: 0.1 -----\n",
            "Epoch: [22][  0/391]\tTime  0.334 ( 0.334)\tLoss 1.5087e+00 (1.5087e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  83.59 ( 83.59)\n",
            "Epoch: [22][ 30/391]\tTime  0.116 ( 0.113)\tLoss 1.6403e+00 (1.6304e+00)\tAcc@1  53.91 ( 54.91)\tAcc@5  83.59 ( 84.07)\n",
            "Epoch: [22][ 60/391]\tTime  0.104 ( 0.107)\tLoss 1.5639e+00 (1.6405e+00)\tAcc@1  50.00 ( 54.50)\tAcc@5  88.28 ( 83.97)\n",
            "Epoch: [22][ 90/391]\tTime  0.101 ( 0.105)\tLoss 1.5682e+00 (1.6264e+00)\tAcc@1  55.47 ( 54.57)\tAcc@5  85.16 ( 84.32)\n",
            "Epoch: [22][120/391]\tTime  0.098 ( 0.104)\tLoss 1.8388e+00 (1.6301e+00)\tAcc@1  43.75 ( 54.24)\tAcc@5  82.81 ( 84.36)\n",
            "Epoch: [22][150/391]\tTime  0.104 ( 0.104)\tLoss 1.6222e+00 (1.6393e+00)\tAcc@1  57.03 ( 53.85)\tAcc@5  82.81 ( 84.31)\n",
            "Epoch: [22][180/391]\tTime  0.101 ( 0.103)\tLoss 1.7841e+00 (1.6470e+00)\tAcc@1  48.44 ( 53.64)\tAcc@5  84.38 ( 84.16)\n",
            "Epoch: [22][210/391]\tTime  0.100 ( 0.103)\tLoss 1.6801e+00 (1.6528e+00)\tAcc@1  53.91 ( 53.55)\tAcc@5  83.59 ( 84.05)\n",
            "Epoch: [22][240/391]\tTime  0.104 ( 0.103)\tLoss 1.5787e+00 (1.6507e+00)\tAcc@1  57.03 ( 53.62)\tAcc@5  85.94 ( 84.08)\n",
            "Epoch: [22][270/391]\tTime  0.102 ( 0.102)\tLoss 1.6831e+00 (1.6549e+00)\tAcc@1  53.91 ( 53.62)\tAcc@5  82.03 ( 83.93)\n",
            "Epoch: [22][300/391]\tTime  0.097 ( 0.103)\tLoss 1.6780e+00 (1.6572e+00)\tAcc@1  53.12 ( 53.66)\tAcc@5  83.59 ( 83.89)\n",
            "Epoch: [22][330/391]\tTime  0.100 ( 0.102)\tLoss 1.6107e+00 (1.6640e+00)\tAcc@1  57.03 ( 53.60)\tAcc@5  86.72 ( 83.76)\n",
            "Epoch: [22][360/391]\tTime  0.098 ( 0.102)\tLoss 1.7658e+00 (1.6643e+00)\tAcc@1  50.00 ( 53.53)\tAcc@5  81.25 ( 83.78)\n",
            "Epoch: [22][390/391]\tTime  0.049 ( 0.102)\tLoss 1.8937e+00 (1.6668e+00)\tAcc@1  45.00 ( 53.47)\tAcc@5  80.00 ( 83.73)\n",
            "==> Train Accuracy: Acc@1 53.468 || Acc@5 83.728\n",
            "==> Test Accuracy:  Acc@1 45.770 || Acc@5 76.010\n",
            "==> 57.48 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 23, lr: 0.1 -----\n",
            "Epoch: [23][  0/391]\tTime  0.377 ( 0.377)\tLoss 1.6446e+00 (1.6446e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [23][ 30/391]\tTime  0.106 ( 0.113)\tLoss 1.6572e+00 (1.6529e+00)\tAcc@1  50.00 ( 53.15)\tAcc@5  84.38 ( 84.00)\n",
            "Epoch: [23][ 60/391]\tTime  0.099 ( 0.108)\tLoss 1.4362e+00 (1.6653e+00)\tAcc@1  59.38 ( 52.93)\tAcc@5  87.50 ( 83.81)\n",
            "Epoch: [23][ 90/391]\tTime  0.100 ( 0.106)\tLoss 1.9701e+00 (1.6628e+00)\tAcc@1  46.09 ( 53.25)\tAcc@5  78.91 ( 83.74)\n",
            "Epoch: [23][120/391]\tTime  0.100 ( 0.104)\tLoss 1.4767e+00 (1.6529e+00)\tAcc@1  61.72 ( 53.74)\tAcc@5  82.03 ( 83.83)\n",
            "Epoch: [23][150/391]\tTime  0.100 ( 0.104)\tLoss 1.5547e+00 (1.6472e+00)\tAcc@1  54.69 ( 53.78)\tAcc@5  82.03 ( 84.02)\n",
            "Epoch: [23][180/391]\tTime  0.100 ( 0.103)\tLoss 1.5991e+00 (1.6546e+00)\tAcc@1  52.34 ( 53.61)\tAcc@5  83.59 ( 83.87)\n",
            "Epoch: [23][210/391]\tTime  0.099 ( 0.103)\tLoss 2.0053e+00 (1.6576e+00)\tAcc@1  45.31 ( 53.54)\tAcc@5  76.56 ( 83.85)\n",
            "Epoch: [23][240/391]\tTime  0.098 ( 0.102)\tLoss 1.7808e+00 (1.6566e+00)\tAcc@1  50.00 ( 53.63)\tAcc@5  85.16 ( 83.88)\n",
            "Epoch: [23][270/391]\tTime  0.111 ( 0.103)\tLoss 1.6343e+00 (1.6541e+00)\tAcc@1  54.69 ( 53.66)\tAcc@5  82.81 ( 83.99)\n",
            "Epoch: [23][300/391]\tTime  0.102 ( 0.102)\tLoss 1.4549e+00 (1.6541e+00)\tAcc@1  58.59 ( 53.73)\tAcc@5  85.16 ( 83.97)\n",
            "Epoch: [23][330/391]\tTime  0.097 ( 0.103)\tLoss 1.7196e+00 (1.6552e+00)\tAcc@1  53.91 ( 53.73)\tAcc@5  85.94 ( 83.95)\n",
            "Epoch: [23][360/391]\tTime  0.109 ( 0.103)\tLoss 1.7500e+00 (1.6551e+00)\tAcc@1  53.91 ( 53.72)\tAcc@5  83.59 ( 83.96)\n",
            "Epoch: [23][390/391]\tTime  0.048 ( 0.102)\tLoss 1.5319e+00 (1.6563e+00)\tAcc@1  60.00 ( 53.63)\tAcc@5  83.75 ( 83.97)\n",
            "==> Train Accuracy: Acc@1 53.632 || Acc@5 83.970\n",
            "==> Test Accuracy:  Acc@1 46.970 || Acc@5 77.410\n",
            "==> 57.46 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 24, lr: 0.1 -----\n",
            "Epoch: [24][  0/391]\tTime  0.351 ( 0.351)\tLoss 1.5284e+00 (1.5284e+00)\tAcc@1  54.69 ( 54.69)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [24][ 30/391]\tTime  0.102 ( 0.113)\tLoss 1.6278e+00 (1.5342e+00)\tAcc@1  47.66 ( 55.70)\tAcc@5  89.84 ( 86.09)\n",
            "Epoch: [24][ 60/391]\tTime  0.101 ( 0.107)\tLoss 1.6823e+00 (1.5589e+00)\tAcc@1  50.00 ( 54.89)\tAcc@5  82.81 ( 85.49)\n",
            "Epoch: [24][ 90/391]\tTime  0.099 ( 0.105)\tLoss 1.5734e+00 (1.5844e+00)\tAcc@1  54.69 ( 54.49)\tAcc@5  86.72 ( 85.04)\n",
            "Epoch: [24][120/391]\tTime  0.104 ( 0.104)\tLoss 1.4988e+00 (1.5872e+00)\tAcc@1  57.81 ( 54.69)\tAcc@5  87.50 ( 84.98)\n",
            "Epoch: [24][150/391]\tTime  0.102 ( 0.103)\tLoss 1.5520e+00 (1.6013e+00)\tAcc@1  60.94 ( 54.53)\tAcc@5  83.59 ( 84.76)\n",
            "Epoch: [24][180/391]\tTime  0.099 ( 0.103)\tLoss 1.8295e+00 (1.5981e+00)\tAcc@1  51.56 ( 54.64)\tAcc@5  82.81 ( 84.78)\n",
            "Epoch: [24][210/391]\tTime  0.100 ( 0.103)\tLoss 1.6705e+00 (1.6035e+00)\tAcc@1  48.44 ( 54.37)\tAcc@5  84.38 ( 84.68)\n",
            "Epoch: [24][240/391]\tTime  0.099 ( 0.102)\tLoss 1.6249e+00 (1.6125e+00)\tAcc@1  59.38 ( 54.17)\tAcc@5  86.72 ( 84.60)\n",
            "Epoch: [24][270/391]\tTime  0.099 ( 0.102)\tLoss 1.5804e+00 (1.6200e+00)\tAcc@1  54.69 ( 54.06)\tAcc@5  87.50 ( 84.49)\n",
            "Epoch: [24][300/391]\tTime  0.100 ( 0.102)\tLoss 1.7681e+00 (1.6280e+00)\tAcc@1  47.66 ( 53.83)\tAcc@5  83.59 ( 84.26)\n",
            "Epoch: [24][330/391]\tTime  0.111 ( 0.102)\tLoss 1.7259e+00 (1.6312e+00)\tAcc@1  52.34 ( 53.76)\tAcc@5  82.81 ( 84.24)\n",
            "Epoch: [24][360/391]\tTime  0.101 ( 0.102)\tLoss 1.5255e+00 (1.6356e+00)\tAcc@1  58.59 ( 53.68)\tAcc@5  87.50 ( 84.20)\n",
            "Epoch: [24][390/391]\tTime  0.048 ( 0.101)\tLoss 2.0072e+00 (1.6387e+00)\tAcc@1  45.00 ( 53.68)\tAcc@5  81.25 ( 84.17)\n",
            "==> Train Accuracy: Acc@1 53.680 || Acc@5 84.170\n",
            "==> Test Accuracy:  Acc@1 49.310 || Acc@5 79.470\n",
            "==> 57.23 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 25, lr: 0.1 -----\n",
            "Epoch: [25][  0/391]\tTime  0.345 ( 0.345)\tLoss 1.7790e+00 (1.7790e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  82.03 ( 82.03)\n",
            "Epoch: [25][ 30/391]\tTime  0.098 ( 0.112)\tLoss 1.5711e+00 (1.5897e+00)\tAcc@1  57.03 ( 55.12)\tAcc@5  87.50 ( 84.40)\n",
            "Epoch: [25][ 60/391]\tTime  0.100 ( 0.106)\tLoss 1.5764e+00 (1.5693e+00)\tAcc@1  53.12 ( 56.11)\tAcc@5  88.28 ( 85.07)\n",
            "Epoch: [25][ 90/391]\tTime  0.107 ( 0.104)\tLoss 1.8424e+00 (1.5921e+00)\tAcc@1  51.56 ( 55.58)\tAcc@5  82.03 ( 84.87)\n",
            "Epoch: [25][120/391]\tTime  0.105 ( 0.104)\tLoss 1.7101e+00 (1.5895e+00)\tAcc@1  50.78 ( 55.57)\tAcc@5  85.16 ( 84.80)\n",
            "Epoch: [25][150/391]\tTime  0.102 ( 0.103)\tLoss 1.7613e+00 (1.5990e+00)\tAcc@1  50.78 ( 55.30)\tAcc@5  81.25 ( 84.75)\n",
            "Epoch: [25][180/391]\tTime  0.103 ( 0.103)\tLoss 1.6993e+00 (1.6009e+00)\tAcc@1  51.56 ( 55.18)\tAcc@5  84.38 ( 84.83)\n",
            "Epoch: [25][210/391]\tTime  0.109 ( 0.103)\tLoss 1.8727e+00 (1.6037e+00)\tAcc@1  50.00 ( 55.16)\tAcc@5  80.47 ( 84.77)\n",
            "Epoch: [25][240/391]\tTime  0.110 ( 0.103)\tLoss 1.6333e+00 (1.6059e+00)\tAcc@1  52.34 ( 54.94)\tAcc@5  82.03 ( 84.76)\n",
            "Epoch: [25][270/391]\tTime  0.110 ( 0.102)\tLoss 1.6580e+00 (1.6071e+00)\tAcc@1  53.91 ( 54.94)\tAcc@5  83.59 ( 84.72)\n",
            "Epoch: [25][300/391]\tTime  0.099 ( 0.102)\tLoss 1.7442e+00 (1.6138e+00)\tAcc@1  46.88 ( 54.70)\tAcc@5  83.59 ( 84.63)\n",
            "Epoch: [25][330/391]\tTime  0.099 ( 0.102)\tLoss 2.0284e+00 (1.6155e+00)\tAcc@1  48.44 ( 54.70)\tAcc@5  75.78 ( 84.61)\n",
            "Epoch: [25][360/391]\tTime  0.106 ( 0.102)\tLoss 1.5592e+00 (1.6177e+00)\tAcc@1  59.38 ( 54.66)\tAcc@5  86.72 ( 84.62)\n",
            "Epoch: [25][390/391]\tTime  0.048 ( 0.102)\tLoss 1.5788e+00 (1.6203e+00)\tAcc@1  53.75 ( 54.55)\tAcc@5  83.75 ( 84.59)\n",
            "==> Train Accuracy: Acc@1 54.546 || Acc@5 84.594\n",
            "==> Test Accuracy:  Acc@1 46.540 || Acc@5 76.550\n",
            "==> 57.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 26, lr: 0.1 -----\n",
            "Epoch: [26][  0/391]\tTime  0.332 ( 0.332)\tLoss 1.5836e+00 (1.5836e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [26][ 30/391]\tTime  0.102 ( 0.110)\tLoss 1.5692e+00 (1.5668e+00)\tAcc@1  50.78 ( 54.89)\tAcc@5  85.94 ( 85.23)\n",
            "Epoch: [26][ 60/391]\tTime  0.102 ( 0.106)\tLoss 1.5839e+00 (1.5494e+00)\tAcc@1  56.25 ( 55.85)\tAcc@5  84.38 ( 85.53)\n",
            "Epoch: [26][ 90/391]\tTime  0.101 ( 0.104)\tLoss 1.6348e+00 (1.5665e+00)\tAcc@1  55.47 ( 55.73)\tAcc@5  83.59 ( 85.35)\n",
            "Epoch: [26][120/391]\tTime  0.100 ( 0.103)\tLoss 1.4553e+00 (1.5673e+00)\tAcc@1  57.03 ( 55.62)\tAcc@5  82.81 ( 85.43)\n",
            "Epoch: [26][150/391]\tTime  0.102 ( 0.102)\tLoss 1.6468e+00 (1.5739e+00)\tAcc@1  55.47 ( 55.39)\tAcc@5  85.94 ( 85.45)\n",
            "Epoch: [26][180/391]\tTime  0.101 ( 0.102)\tLoss 1.4293e+00 (1.5860e+00)\tAcc@1  56.25 ( 55.26)\tAcc@5  87.50 ( 85.22)\n",
            "Epoch: [26][210/391]\tTime  0.100 ( 0.102)\tLoss 1.5339e+00 (1.5989e+00)\tAcc@1  60.16 ( 55.07)\tAcc@5  84.38 ( 84.97)\n",
            "Epoch: [26][240/391]\tTime  0.102 ( 0.102)\tLoss 1.6882e+00 (1.5958e+00)\tAcc@1  48.44 ( 55.14)\tAcc@5  86.72 ( 84.93)\n",
            "Epoch: [26][270/391]\tTime  0.102 ( 0.102)\tLoss 1.7772e+00 (1.6000e+00)\tAcc@1  50.78 ( 54.94)\tAcc@5  78.91 ( 84.94)\n",
            "Epoch: [26][300/391]\tTime  0.105 ( 0.102)\tLoss 1.3887e+00 (1.6005e+00)\tAcc@1  64.06 ( 55.04)\tAcc@5  89.84 ( 84.90)\n",
            "Epoch: [26][330/391]\tTime  0.100 ( 0.102)\tLoss 1.5207e+00 (1.6043e+00)\tAcc@1  57.81 ( 54.96)\tAcc@5  82.81 ( 84.82)\n",
            "Epoch: [26][360/391]\tTime  0.099 ( 0.102)\tLoss 1.6078e+00 (1.6056e+00)\tAcc@1  58.59 ( 54.90)\tAcc@5  82.81 ( 84.68)\n",
            "Epoch: [26][390/391]\tTime  0.051 ( 0.101)\tLoss 1.5300e+00 (1.6045e+00)\tAcc@1  61.25 ( 54.87)\tAcc@5  83.75 ( 84.68)\n",
            "==> Train Accuracy: Acc@1 54.872 || Acc@5 84.684\n",
            "==> Test Accuracy:  Acc@1 46.720 || Acc@5 77.420\n",
            "==> 57.13 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 27, lr: 0.1 -----\n",
            "Epoch: [27][  0/391]\tTime  0.371 ( 0.371)\tLoss 1.5880e+00 (1.5880e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  82.03 ( 82.03)\n",
            "Epoch: [27][ 30/391]\tTime  0.095 ( 0.110)\tLoss 1.3777e+00 (1.4802e+00)\tAcc@1  57.03 ( 57.79)\tAcc@5  87.50 ( 86.77)\n",
            "Epoch: [27][ 60/391]\tTime  0.105 ( 0.106)\tLoss 1.4188e+00 (1.5095e+00)\tAcc@1  59.38 ( 57.59)\tAcc@5  89.06 ( 86.10)\n",
            "Epoch: [27][ 90/391]\tTime  0.098 ( 0.104)\tLoss 1.4641e+00 (1.5218e+00)\tAcc@1  55.47 ( 57.04)\tAcc@5  87.50 ( 86.06)\n",
            "Epoch: [27][120/391]\tTime  0.100 ( 0.104)\tLoss 1.6871e+00 (1.5494e+00)\tAcc@1  52.34 ( 56.33)\tAcc@5  85.16 ( 85.69)\n",
            "Epoch: [27][150/391]\tTime  0.105 ( 0.103)\tLoss 1.5956e+00 (1.5572e+00)\tAcc@1  53.91 ( 56.14)\tAcc@5  87.50 ( 85.59)\n",
            "Epoch: [27][180/391]\tTime  0.104 ( 0.103)\tLoss 1.5576e+00 (1.5724e+00)\tAcc@1  60.16 ( 55.68)\tAcc@5  85.16 ( 85.31)\n",
            "Epoch: [27][210/391]\tTime  0.102 ( 0.102)\tLoss 1.8546e+00 (1.5776e+00)\tAcc@1  49.22 ( 55.65)\tAcc@5  82.03 ( 85.25)\n",
            "Epoch: [27][240/391]\tTime  0.100 ( 0.102)\tLoss 1.6321e+00 (1.5791e+00)\tAcc@1  53.91 ( 55.54)\tAcc@5  85.16 ( 85.23)\n",
            "Epoch: [27][270/391]\tTime  0.098 ( 0.102)\tLoss 1.5293e+00 (1.5784e+00)\tAcc@1  57.03 ( 55.60)\tAcc@5  85.16 ( 85.27)\n",
            "Epoch: [27][300/391]\tTime  0.098 ( 0.102)\tLoss 1.6696e+00 (1.5806e+00)\tAcc@1  51.56 ( 55.53)\tAcc@5  85.94 ( 85.19)\n",
            "Epoch: [27][330/391]\tTime  0.099 ( 0.102)\tLoss 1.7100e+00 (1.5880e+00)\tAcc@1  57.03 ( 55.28)\tAcc@5  78.91 ( 85.08)\n",
            "Epoch: [27][360/391]\tTime  0.097 ( 0.102)\tLoss 1.3923e+00 (1.5911e+00)\tAcc@1  58.59 ( 55.27)\tAcc@5  90.62 ( 85.01)\n",
            "Epoch: [27][390/391]\tTime  0.049 ( 0.101)\tLoss 1.6907e+00 (1.5925e+00)\tAcc@1  53.75 ( 55.23)\tAcc@5  83.75 ( 84.94)\n",
            "==> Train Accuracy: Acc@1 55.226 || Acc@5 84.944\n",
            "==> Test Accuracy:  Acc@1 47.320 || Acc@5 77.560\n",
            "==> 57.25 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 28, lr: 0.1 -----\n",
            "Epoch: [28][  0/391]\tTime  0.372 ( 0.372)\tLoss 1.5294e+00 (1.5294e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [28][ 30/391]\tTime  0.106 ( 0.112)\tLoss 1.6785e+00 (1.5461e+00)\tAcc@1  55.47 ( 56.53)\tAcc@5  81.25 ( 85.51)\n",
            "Epoch: [28][ 60/391]\tTime  0.100 ( 0.107)\tLoss 1.5474e+00 (1.5057e+00)\tAcc@1  55.47 ( 57.57)\tAcc@5  84.38 ( 86.33)\n",
            "Epoch: [28][ 90/391]\tTime  0.099 ( 0.105)\tLoss 1.3920e+00 (1.5239e+00)\tAcc@1  60.94 ( 56.97)\tAcc@5  87.50 ( 86.01)\n",
            "Epoch: [28][120/391]\tTime  0.096 ( 0.103)\tLoss 1.6127e+00 (1.5296e+00)\tAcc@1  51.56 ( 56.89)\tAcc@5  87.50 ( 86.16)\n",
            "Epoch: [28][150/391]\tTime  0.097 ( 0.103)\tLoss 1.5079e+00 (1.5395e+00)\tAcc@1  58.59 ( 56.62)\tAcc@5  87.50 ( 86.01)\n",
            "Epoch: [28][180/391]\tTime  0.101 ( 0.102)\tLoss 1.6232e+00 (1.5509e+00)\tAcc@1  59.38 ( 56.40)\tAcc@5  85.94 ( 85.78)\n",
            "Epoch: [28][210/391]\tTime  0.095 ( 0.101)\tLoss 1.7469e+00 (1.5523e+00)\tAcc@1  55.47 ( 56.39)\tAcc@5  80.47 ( 85.77)\n",
            "Epoch: [28][240/391]\tTime  0.099 ( 0.101)\tLoss 1.6147e+00 (1.5528e+00)\tAcc@1  57.03 ( 56.29)\tAcc@5  85.16 ( 85.68)\n",
            "Epoch: [28][270/391]\tTime  0.096 ( 0.101)\tLoss 1.5015e+00 (1.5563e+00)\tAcc@1  56.25 ( 56.20)\tAcc@5  88.28 ( 85.56)\n",
            "Epoch: [28][300/391]\tTime  0.096 ( 0.100)\tLoss 1.6019e+00 (1.5635e+00)\tAcc@1  53.91 ( 55.99)\tAcc@5  82.81 ( 85.46)\n",
            "Epoch: [28][330/391]\tTime  0.096 ( 0.100)\tLoss 1.7966e+00 (1.5670e+00)\tAcc@1  51.56 ( 55.96)\tAcc@5  84.38 ( 85.42)\n",
            "Epoch: [28][360/391]\tTime  0.105 ( 0.100)\tLoss 1.8413e+00 (1.5728e+00)\tAcc@1  53.12 ( 55.89)\tAcc@5  80.47 ( 85.31)\n",
            "Epoch: [28][390/391]\tTime  0.048 ( 0.100)\tLoss 1.7426e+00 (1.5778e+00)\tAcc@1  53.75 ( 55.72)\tAcc@5  81.25 ( 85.25)\n",
            "==> Train Accuracy: Acc@1 55.718 || Acc@5 85.248\n",
            "==> Test Accuracy:  Acc@1 43.610 || Acc@5 72.780\n",
            "==> 56.55 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 29, lr: 0.1 -----\n",
            "Epoch: [29][  0/391]\tTime  0.331 ( 0.331)\tLoss 1.4286e+00 (1.4286e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  82.81 ( 82.81)\n",
            "Epoch: [29][ 30/391]\tTime  0.097 ( 0.107)\tLoss 1.5422e+00 (1.5122e+00)\tAcc@1  60.16 ( 57.81)\tAcc@5  81.25 ( 86.49)\n",
            "Epoch: [29][ 60/391]\tTime  0.097 ( 0.103)\tLoss 1.7206e+00 (1.5133e+00)\tAcc@1  55.47 ( 57.57)\tAcc@5  84.38 ( 86.87)\n",
            "Epoch: [29][ 90/391]\tTime  0.099 ( 0.102)\tLoss 1.5958e+00 (1.5239e+00)\tAcc@1  52.34 ( 57.48)\tAcc@5  83.59 ( 86.43)\n",
            "Epoch: [29][120/391]\tTime  0.098 ( 0.101)\tLoss 1.7264e+00 (1.5413e+00)\tAcc@1  52.34 ( 56.86)\tAcc@5  85.16 ( 86.21)\n",
            "Epoch: [29][150/391]\tTime  0.096 ( 0.100)\tLoss 1.5888e+00 (1.5476e+00)\tAcc@1  59.38 ( 56.86)\tAcc@5  85.16 ( 85.92)\n",
            "Epoch: [29][180/391]\tTime  0.095 ( 0.100)\tLoss 1.5734e+00 (1.5488e+00)\tAcc@1  55.47 ( 56.71)\tAcc@5  87.50 ( 85.92)\n",
            "Epoch: [29][210/391]\tTime  0.097 ( 0.100)\tLoss 1.5851e+00 (1.5556e+00)\tAcc@1  53.91 ( 56.48)\tAcc@5  88.28 ( 85.79)\n",
            "Epoch: [29][240/391]\tTime  0.112 ( 0.100)\tLoss 1.7559e+00 (1.5579e+00)\tAcc@1  50.78 ( 56.22)\tAcc@5  80.47 ( 85.65)\n",
            "Epoch: [29][270/391]\tTime  0.096 ( 0.100)\tLoss 1.6937e+00 (1.5627e+00)\tAcc@1  50.00 ( 56.09)\tAcc@5  84.38 ( 85.54)\n",
            "Epoch: [29][300/391]\tTime  0.095 ( 0.100)\tLoss 1.5437e+00 (1.5632e+00)\tAcc@1  57.03 ( 56.03)\tAcc@5  85.94 ( 85.53)\n",
            "Epoch: [29][330/391]\tTime  0.099 ( 0.100)\tLoss 1.5148e+00 (1.5660e+00)\tAcc@1  58.59 ( 55.92)\tAcc@5  81.25 ( 85.45)\n",
            "Epoch: [29][360/391]\tTime  0.102 ( 0.100)\tLoss 1.3796e+00 (1.5636e+00)\tAcc@1  57.81 ( 56.01)\tAcc@5  89.06 ( 85.46)\n",
            "Epoch: [29][390/391]\tTime  0.048 ( 0.099)\tLoss 1.5827e+00 (1.5659e+00)\tAcc@1  58.75 ( 55.93)\tAcc@5  87.50 ( 85.45)\n",
            "==> Train Accuracy: Acc@1 55.932 || Acc@5 85.450\n",
            "==> Test Accuracy:  Acc@1 46.630 || Acc@5 77.180\n",
            "==> 56.34 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 30, lr: 0.1 -----\n",
            "Epoch: [30][  0/391]\tTime  0.335 ( 0.335)\tLoss 1.6395e+00 (1.6395e+00)\tAcc@1  50.00 ( 50.00)\tAcc@5  84.38 ( 84.38)\n",
            "Epoch: [30][ 30/391]\tTime  0.099 ( 0.109)\tLoss 1.5173e+00 (1.5020e+00)\tAcc@1  52.34 ( 57.38)\tAcc@5  88.28 ( 86.29)\n",
            "Epoch: [30][ 60/391]\tTime  0.097 ( 0.103)\tLoss 1.5272e+00 (1.4952e+00)\tAcc@1  60.94 ( 57.81)\tAcc@5  85.94 ( 86.07)\n",
            "Epoch: [30][ 90/391]\tTime  0.099 ( 0.101)\tLoss 1.7857e+00 (1.5265e+00)\tAcc@1  48.44 ( 56.99)\tAcc@5  82.03 ( 85.60)\n",
            "Epoch: [30][120/391]\tTime  0.105 ( 0.101)\tLoss 1.5805e+00 (1.5323e+00)\tAcc@1  54.69 ( 56.69)\tAcc@5  88.28 ( 85.68)\n",
            "Epoch: [30][150/391]\tTime  0.102 ( 0.100)\tLoss 1.7920e+00 (1.5356e+00)\tAcc@1  52.34 ( 56.56)\tAcc@5  79.69 ( 85.80)\n",
            "Epoch: [30][180/391]\tTime  0.099 ( 0.100)\tLoss 1.6686e+00 (1.5417e+00)\tAcc@1  51.56 ( 56.48)\tAcc@5  85.94 ( 85.81)\n",
            "Epoch: [30][210/391]\tTime  0.102 ( 0.100)\tLoss 1.6215e+00 (1.5398e+00)\tAcc@1  56.25 ( 56.57)\tAcc@5  83.59 ( 85.84)\n",
            "Epoch: [30][240/391]\tTime  0.096 ( 0.100)\tLoss 1.5137e+00 (1.5424e+00)\tAcc@1  56.25 ( 56.64)\tAcc@5  83.59 ( 85.72)\n",
            "Epoch: [30][270/391]\tTime  0.098 ( 0.100)\tLoss 1.5961e+00 (1.5445e+00)\tAcc@1  52.34 ( 56.46)\tAcc@5  85.16 ( 85.70)\n",
            "Epoch: [30][300/391]\tTime  0.097 ( 0.100)\tLoss 1.6787e+00 (1.5502e+00)\tAcc@1  53.91 ( 56.28)\tAcc@5  83.59 ( 85.62)\n",
            "Epoch: [30][330/391]\tTime  0.099 ( 0.099)\tLoss 1.5449e+00 (1.5549e+00)\tAcc@1  57.81 ( 56.17)\tAcc@5  88.28 ( 85.52)\n",
            "Epoch: [30][360/391]\tTime  0.095 ( 0.100)\tLoss 1.6379e+00 (1.5581e+00)\tAcc@1  53.12 ( 56.06)\tAcc@5  86.72 ( 85.48)\n",
            "Epoch: [30][390/391]\tTime  0.048 ( 0.099)\tLoss 1.5580e+00 (1.5596e+00)\tAcc@1  47.50 ( 56.05)\tAcc@5  90.00 ( 85.46)\n",
            "==> Train Accuracy: Acc@1 56.050 || Acc@5 85.462\n",
            "==> Test Accuracy:  Acc@1 47.700 || Acc@5 78.540\n",
            "==> 56.39 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 31, lr: 0.1 -----\n",
            "Epoch: [31][  0/391]\tTime  0.319 ( 0.319)\tLoss 1.3689e+00 (1.3689e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  86.72 ( 86.72)\n",
            "Epoch: [31][ 30/391]\tTime  0.098 ( 0.110)\tLoss 1.4807e+00 (1.4415e+00)\tAcc@1  61.72 ( 59.17)\tAcc@5  85.94 ( 87.12)\n",
            "Epoch: [31][ 60/391]\tTime  0.097 ( 0.105)\tLoss 1.5627e+00 (1.4395e+00)\tAcc@1  57.03 ( 59.52)\tAcc@5  86.72 ( 87.28)\n",
            "Epoch: [31][ 90/391]\tTime  0.095 ( 0.103)\tLoss 1.4699e+00 (1.4624e+00)\tAcc@1  57.03 ( 58.77)\tAcc@5  85.94 ( 86.98)\n",
            "Epoch: [31][120/391]\tTime  0.100 ( 0.103)\tLoss 1.7282e+00 (1.4943e+00)\tAcc@1  51.56 ( 57.88)\tAcc@5  82.81 ( 86.60)\n",
            "Epoch: [31][150/391]\tTime  0.096 ( 0.102)\tLoss 1.4334e+00 (1.5037e+00)\tAcc@1  57.81 ( 57.46)\tAcc@5  85.16 ( 86.47)\n",
            "Epoch: [31][180/391]\tTime  0.097 ( 0.101)\tLoss 1.3590e+00 (1.5113e+00)\tAcc@1  59.38 ( 57.29)\tAcc@5  85.16 ( 86.43)\n",
            "Epoch: [31][210/391]\tTime  0.099 ( 0.101)\tLoss 1.4503e+00 (1.5200e+00)\tAcc@1  57.03 ( 57.28)\tAcc@5  85.16 ( 86.18)\n",
            "Epoch: [31][240/391]\tTime  0.098 ( 0.101)\tLoss 1.6238e+00 (1.5340e+00)\tAcc@1  54.69 ( 56.88)\tAcc@5  83.59 ( 85.94)\n",
            "Epoch: [31][270/391]\tTime  0.098 ( 0.101)\tLoss 1.5167e+00 (1.5346e+00)\tAcc@1  53.91 ( 56.90)\tAcc@5  87.50 ( 85.96)\n",
            "Epoch: [31][300/391]\tTime  0.097 ( 0.100)\tLoss 1.3668e+00 (1.5392e+00)\tAcc@1  57.81 ( 56.76)\tAcc@5  88.28 ( 85.87)\n",
            "Epoch: [31][330/391]\tTime  0.107 ( 0.100)\tLoss 1.6567e+00 (1.5423e+00)\tAcc@1  54.69 ( 56.68)\tAcc@5  84.38 ( 85.79)\n",
            "Epoch: [31][360/391]\tTime  0.102 ( 0.100)\tLoss 1.4350e+00 (1.5456e+00)\tAcc@1  58.59 ( 56.48)\tAcc@5  85.16 ( 85.74)\n",
            "Epoch: [31][390/391]\tTime  0.049 ( 0.100)\tLoss 1.6759e+00 (1.5476e+00)\tAcc@1  57.50 ( 56.46)\tAcc@5  83.75 ( 85.72)\n",
            "==> Train Accuracy: Acc@1 56.460 || Acc@5 85.718\n",
            "==> Test Accuracy:  Acc@1 43.510 || Acc@5 74.090\n",
            "==> 56.56 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 32, lr: 0.1 -----\n",
            "Epoch: [32][  0/391]\tTime  0.392 ( 0.392)\tLoss 1.5265e+00 (1.5265e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [32][ 30/391]\tTime  0.100 ( 0.110)\tLoss 1.4765e+00 (1.4559e+00)\tAcc@1  57.03 ( 58.19)\tAcc@5  86.72 ( 87.07)\n",
            "Epoch: [32][ 60/391]\tTime  0.097 ( 0.105)\tLoss 1.4558e+00 (1.4790e+00)\tAcc@1  62.50 ( 57.80)\tAcc@5  81.25 ( 86.59)\n",
            "Epoch: [32][ 90/391]\tTime  0.101 ( 0.104)\tLoss 1.4699e+00 (1.4973e+00)\tAcc@1  54.69 ( 57.49)\tAcc@5  82.03 ( 86.22)\n",
            "Epoch: [32][120/391]\tTime  0.102 ( 0.103)\tLoss 1.3786e+00 (1.4994e+00)\tAcc@1  56.25 ( 57.41)\tAcc@5  88.28 ( 86.42)\n",
            "Epoch: [32][150/391]\tTime  0.103 ( 0.102)\tLoss 1.4338e+00 (1.4972e+00)\tAcc@1  63.28 ( 57.43)\tAcc@5  87.50 ( 86.57)\n",
            "Epoch: [32][180/391]\tTime  0.098 ( 0.102)\tLoss 1.5898e+00 (1.5053e+00)\tAcc@1  57.81 ( 57.39)\tAcc@5  87.50 ( 86.35)\n",
            "Epoch: [32][210/391]\tTime  0.097 ( 0.102)\tLoss 1.7875e+00 (1.5125e+00)\tAcc@1  53.12 ( 57.26)\tAcc@5  80.47 ( 86.27)\n",
            "Epoch: [32][240/391]\tTime  0.096 ( 0.101)\tLoss 1.3316e+00 (1.5224e+00)\tAcc@1  58.59 ( 57.08)\tAcc@5  89.06 ( 86.10)\n",
            "Epoch: [32][270/391]\tTime  0.096 ( 0.101)\tLoss 1.9042e+00 (1.5263e+00)\tAcc@1  45.31 ( 56.93)\tAcc@5  81.25 ( 86.06)\n",
            "Epoch: [32][300/391]\tTime  0.097 ( 0.101)\tLoss 1.5432e+00 (1.5300e+00)\tAcc@1  53.12 ( 56.79)\tAcc@5  85.16 ( 85.96)\n",
            "Epoch: [32][330/391]\tTime  0.103 ( 0.100)\tLoss 1.9130e+00 (1.5359e+00)\tAcc@1  48.44 ( 56.61)\tAcc@5  83.59 ( 85.88)\n",
            "Epoch: [32][360/391]\tTime  0.097 ( 0.100)\tLoss 1.4136e+00 (1.5412e+00)\tAcc@1  59.38 ( 56.51)\tAcc@5  85.94 ( 85.82)\n",
            "Epoch: [32][390/391]\tTime  0.048 ( 0.100)\tLoss 1.4553e+00 (1.5439e+00)\tAcc@1  58.75 ( 56.52)\tAcc@5  90.00 ( 85.79)\n",
            "==> Train Accuracy: Acc@1 56.524 || Acc@5 85.788\n",
            "==> Test Accuracy:  Acc@1 46.400 || Acc@5 77.310\n",
            "==> 56.21 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 33, lr: 0.1 -----\n",
            "Epoch: [33][  0/391]\tTime  0.314 ( 0.314)\tLoss 1.5109e+00 (1.5109e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  86.72 ( 86.72)\n",
            "Epoch: [33][ 30/391]\tTime  0.121 ( 0.109)\tLoss 1.3768e+00 (1.4516e+00)\tAcc@1  56.25 ( 58.74)\tAcc@5  89.06 ( 87.20)\n",
            "Epoch: [33][ 60/391]\tTime  0.104 ( 0.106)\tLoss 1.4158e+00 (1.4555e+00)\tAcc@1  62.50 ( 58.85)\tAcc@5  88.28 ( 86.97)\n",
            "Epoch: [33][ 90/391]\tTime  0.106 ( 0.104)\tLoss 1.6044e+00 (1.4618e+00)\tAcc@1  54.69 ( 58.56)\tAcc@5  86.72 ( 87.24)\n",
            "Epoch: [33][120/391]\tTime  0.100 ( 0.103)\tLoss 1.6210e+00 (1.4769e+00)\tAcc@1  56.25 ( 58.00)\tAcc@5  84.38 ( 86.91)\n",
            "Epoch: [33][150/391]\tTime  0.098 ( 0.102)\tLoss 1.8191e+00 (1.4913e+00)\tAcc@1  52.34 ( 57.59)\tAcc@5  82.03 ( 86.58)\n",
            "Epoch: [33][180/391]\tTime  0.116 ( 0.102)\tLoss 1.4644e+00 (1.4948e+00)\tAcc@1  56.25 ( 57.64)\tAcc@5  87.50 ( 86.62)\n",
            "Epoch: [33][210/391]\tTime  0.098 ( 0.102)\tLoss 1.5056e+00 (1.5020e+00)\tAcc@1  54.69 ( 57.49)\tAcc@5  88.28 ( 86.49)\n",
            "Epoch: [33][240/391]\tTime  0.097 ( 0.102)\tLoss 1.8766e+00 (1.5098e+00)\tAcc@1  50.00 ( 57.28)\tAcc@5  75.78 ( 86.32)\n",
            "Epoch: [33][270/391]\tTime  0.095 ( 0.101)\tLoss 1.4827e+00 (1.5147e+00)\tAcc@1  60.16 ( 57.20)\tAcc@5  86.72 ( 86.21)\n",
            "Epoch: [33][300/391]\tTime  0.105 ( 0.101)\tLoss 1.4751e+00 (1.5175e+00)\tAcc@1  50.78 ( 57.12)\tAcc@5  89.06 ( 86.18)\n",
            "Epoch: [33][330/391]\tTime  0.096 ( 0.101)\tLoss 1.5963e+00 (1.5209e+00)\tAcc@1  55.47 ( 56.93)\tAcc@5  83.59 ( 86.13)\n",
            "Epoch: [33][360/391]\tTime  0.095 ( 0.101)\tLoss 1.6052e+00 (1.5234e+00)\tAcc@1  57.03 ( 56.88)\tAcc@5  85.94 ( 86.13)\n",
            "Epoch: [33][390/391]\tTime  0.047 ( 0.100)\tLoss 1.5234e+00 (1.5257e+00)\tAcc@1  62.50 ( 56.81)\tAcc@5  85.00 ( 86.11)\n",
            "==> Train Accuracy: Acc@1 56.810 || Acc@5 86.112\n",
            "==> Test Accuracy:  Acc@1 47.650 || Acc@5 77.920\n",
            "==> 56.62 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 34, lr: 0.1 -----\n",
            "Epoch: [34][  0/391]\tTime  0.330 ( 0.330)\tLoss 1.6430e+00 (1.6430e+00)\tAcc@1  51.56 ( 51.56)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [34][ 30/391]\tTime  0.097 ( 0.108)\tLoss 1.3606e+00 (1.4356e+00)\tAcc@1  61.72 ( 58.29)\tAcc@5  89.06 ( 87.70)\n",
            "Epoch: [34][ 60/391]\tTime  0.104 ( 0.105)\tLoss 1.4656e+00 (1.4881e+00)\tAcc@1  60.16 ( 57.31)\tAcc@5  85.16 ( 86.83)\n",
            "Epoch: [34][ 90/391]\tTime  0.097 ( 0.105)\tLoss 1.5081e+00 (1.4752e+00)\tAcc@1  57.81 ( 57.68)\tAcc@5  86.72 ( 87.14)\n",
            "Epoch: [34][120/391]\tTime  0.097 ( 0.103)\tLoss 1.5417e+00 (1.4777e+00)\tAcc@1  53.91 ( 57.81)\tAcc@5  87.50 ( 87.16)\n",
            "Epoch: [34][150/391]\tTime  0.096 ( 0.102)\tLoss 1.3203e+00 (1.4798e+00)\tAcc@1  60.94 ( 57.90)\tAcc@5  89.06 ( 87.00)\n",
            "Epoch: [34][180/391]\tTime  0.097 ( 0.102)\tLoss 1.6567e+00 (1.4929e+00)\tAcc@1  49.22 ( 57.49)\tAcc@5  85.16 ( 86.78)\n",
            "Epoch: [34][210/391]\tTime  0.100 ( 0.101)\tLoss 1.4295e+00 (1.4938e+00)\tAcc@1  58.59 ( 57.52)\tAcc@5  89.84 ( 86.70)\n",
            "Epoch: [34][240/391]\tTime  0.098 ( 0.101)\tLoss 1.3460e+00 (1.5000e+00)\tAcc@1  61.72 ( 57.43)\tAcc@5  89.84 ( 86.53)\n",
            "Epoch: [34][270/391]\tTime  0.102 ( 0.101)\tLoss 1.5602e+00 (1.5085e+00)\tAcc@1  55.47 ( 57.22)\tAcc@5  85.16 ( 86.40)\n",
            "Epoch: [34][300/391]\tTime  0.100 ( 0.101)\tLoss 1.5206e+00 (1.5142e+00)\tAcc@1  61.72 ( 57.04)\tAcc@5  82.81 ( 86.29)\n",
            "Epoch: [34][330/391]\tTime  0.099 ( 0.101)\tLoss 1.6428e+00 (1.5163e+00)\tAcc@1  49.22 ( 56.97)\tAcc@5  83.59 ( 86.22)\n",
            "Epoch: [34][360/391]\tTime  0.097 ( 0.101)\tLoss 1.6419e+00 (1.5159e+00)\tAcc@1  50.00 ( 57.03)\tAcc@5  82.03 ( 86.26)\n",
            "Epoch: [34][390/391]\tTime  0.048 ( 0.101)\tLoss 1.8657e+00 (1.5217e+00)\tAcc@1  45.00 ( 56.88)\tAcc@5  78.75 ( 86.20)\n",
            "==> Train Accuracy: Acc@1 56.880 || Acc@5 86.204\n",
            "==> Test Accuracy:  Acc@1 47.810 || Acc@5 78.120\n",
            "==> 56.86 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 35, lr: 0.1 -----\n",
            "Epoch: [35][  0/391]\tTime  0.327 ( 0.327)\tLoss 1.3895e+00 (1.3895e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [35][ 30/391]\tTime  0.097 ( 0.107)\tLoss 1.3492e+00 (1.4195e+00)\tAcc@1  64.84 ( 59.80)\tAcc@5  89.06 ( 87.35)\n",
            "Epoch: [35][ 60/391]\tTime  0.098 ( 0.106)\tLoss 1.5268e+00 (1.4390e+00)\tAcc@1  51.56 ( 58.57)\tAcc@5  86.72 ( 87.51)\n",
            "Epoch: [35][ 90/391]\tTime  0.098 ( 0.104)\tLoss 1.1702e+00 (1.4632e+00)\tAcc@1  62.50 ( 58.23)\tAcc@5  92.97 ( 87.18)\n",
            "Epoch: [35][120/391]\tTime  0.095 ( 0.103)\tLoss 1.7571e+00 (1.4755e+00)\tAcc@1  50.78 ( 58.04)\tAcc@5  84.38 ( 86.94)\n",
            "Epoch: [35][150/391]\tTime  0.107 ( 0.103)\tLoss 1.5397e+00 (1.4856e+00)\tAcc@1  55.47 ( 57.78)\tAcc@5  86.72 ( 86.85)\n",
            "Epoch: [35][180/391]\tTime  0.096 ( 0.103)\tLoss 1.6198e+00 (1.4936e+00)\tAcc@1  53.12 ( 57.61)\tAcc@5  85.94 ( 86.77)\n",
            "Epoch: [35][210/391]\tTime  0.095 ( 0.102)\tLoss 1.5492e+00 (1.4931e+00)\tAcc@1  54.69 ( 57.52)\tAcc@5  85.94 ( 86.75)\n",
            "Epoch: [35][240/391]\tTime  0.097 ( 0.102)\tLoss 1.4562e+00 (1.4924e+00)\tAcc@1  59.38 ( 57.60)\tAcc@5  89.84 ( 86.69)\n",
            "Epoch: [35][270/391]\tTime  0.098 ( 0.101)\tLoss 1.4611e+00 (1.4976e+00)\tAcc@1  57.81 ( 57.48)\tAcc@5  88.28 ( 86.53)\n",
            "Epoch: [35][300/391]\tTime  0.101 ( 0.101)\tLoss 1.7466e+00 (1.5007e+00)\tAcc@1  50.00 ( 57.39)\tAcc@5  89.06 ( 86.55)\n",
            "Epoch: [35][330/391]\tTime  0.101 ( 0.101)\tLoss 1.5744e+00 (1.5035e+00)\tAcc@1  57.03 ( 57.33)\tAcc@5  86.72 ( 86.51)\n",
            "Epoch: [35][360/391]\tTime  0.097 ( 0.101)\tLoss 1.4348e+00 (1.5064e+00)\tAcc@1  60.94 ( 57.24)\tAcc@5  84.38 ( 86.43)\n",
            "Epoch: [35][390/391]\tTime  0.053 ( 0.100)\tLoss 1.6899e+00 (1.5095e+00)\tAcc@1  47.50 ( 57.22)\tAcc@5  77.50 ( 86.30)\n",
            "==> Train Accuracy: Acc@1 57.218 || Acc@5 86.304\n",
            "==> Test Accuracy:  Acc@1 48.330 || Acc@5 79.410\n",
            "==> 56.72 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 36, lr: 0.1 -----\n",
            "Epoch: [36][  0/391]\tTime  0.315 ( 0.315)\tLoss 1.3298e+00 (1.3298e+00)\tAcc@1  64.84 ( 64.84)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [36][ 30/391]\tTime  0.098 ( 0.108)\tLoss 1.3734e+00 (1.4695e+00)\tAcc@1  57.81 ( 58.67)\tAcc@5  88.28 ( 87.00)\n",
            "Epoch: [36][ 60/391]\tTime  0.098 ( 0.104)\tLoss 1.3854e+00 (1.4501e+00)\tAcc@1  59.38 ( 59.14)\tAcc@5  86.72 ( 87.50)\n",
            "Epoch: [36][ 90/391]\tTime  0.097 ( 0.102)\tLoss 1.5665e+00 (1.4696e+00)\tAcc@1  55.47 ( 58.56)\tAcc@5  84.38 ( 86.96)\n",
            "Epoch: [36][120/391]\tTime  0.096 ( 0.102)\tLoss 1.7598e+00 (1.4690e+00)\tAcc@1  52.34 ( 58.26)\tAcc@5  82.03 ( 86.85)\n",
            "Epoch: [36][150/391]\tTime  0.098 ( 0.102)\tLoss 1.6064e+00 (1.4767e+00)\tAcc@1  53.91 ( 58.11)\tAcc@5  88.28 ( 86.77)\n",
            "Epoch: [36][180/391]\tTime  0.106 ( 0.102)\tLoss 1.7231e+00 (1.4765e+00)\tAcc@1  50.00 ( 58.01)\tAcc@5  83.59 ( 86.93)\n",
            "Epoch: [36][210/391]\tTime  0.098 ( 0.101)\tLoss 1.3950e+00 (1.4799e+00)\tAcc@1  58.59 ( 57.91)\tAcc@5  90.62 ( 86.87)\n",
            "Epoch: [36][240/391]\tTime  0.110 ( 0.101)\tLoss 1.3492e+00 (1.4843e+00)\tAcc@1  60.94 ( 57.76)\tAcc@5  86.72 ( 86.79)\n",
            "Epoch: [36][270/391]\tTime  0.096 ( 0.101)\tLoss 1.7302e+00 (1.4899e+00)\tAcc@1  50.00 ( 57.75)\tAcc@5  80.47 ( 86.71)\n",
            "Epoch: [36][300/391]\tTime  0.099 ( 0.101)\tLoss 1.5226e+00 (1.4956e+00)\tAcc@1  54.69 ( 57.67)\tAcc@5  87.50 ( 86.58)\n",
            "Epoch: [36][330/391]\tTime  0.099 ( 0.101)\tLoss 1.7038e+00 (1.4998e+00)\tAcc@1  55.47 ( 57.55)\tAcc@5  84.38 ( 86.52)\n",
            "Epoch: [36][360/391]\tTime  0.098 ( 0.101)\tLoss 1.4982e+00 (1.5027e+00)\tAcc@1  59.38 ( 57.48)\tAcc@5  86.72 ( 86.52)\n",
            "Epoch: [36][390/391]\tTime  0.048 ( 0.100)\tLoss 1.4984e+00 (1.5053e+00)\tAcc@1  56.25 ( 57.37)\tAcc@5  88.75 ( 86.53)\n",
            "==> Train Accuracy: Acc@1 57.374 || Acc@5 86.528\n",
            "==> Test Accuracy:  Acc@1 46.600 || Acc@5 77.030\n",
            "==> 56.77 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 37, lr: 0.1 -----\n",
            "Epoch: [37][  0/391]\tTime  0.364 ( 0.364)\tLoss 1.3737e+00 (1.3737e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [37][ 30/391]\tTime  0.097 ( 0.111)\tLoss 1.3121e+00 (1.4265e+00)\tAcc@1  62.50 ( 59.78)\tAcc@5  91.41 ( 87.98)\n",
            "Epoch: [37][ 60/391]\tTime  0.096 ( 0.105)\tLoss 1.6097e+00 (1.4502e+00)\tAcc@1  57.81 ( 59.27)\tAcc@5  79.69 ( 87.50)\n",
            "Epoch: [37][ 90/391]\tTime  0.098 ( 0.103)\tLoss 1.4051e+00 (1.4605e+00)\tAcc@1  58.59 ( 58.99)\tAcc@5  85.94 ( 87.07)\n",
            "Epoch: [37][120/391]\tTime  0.098 ( 0.102)\tLoss 1.5156e+00 (1.4628e+00)\tAcc@1  58.59 ( 58.79)\tAcc@5  86.72 ( 87.00)\n",
            "Epoch: [37][150/391]\tTime  0.101 ( 0.101)\tLoss 1.4413e+00 (1.4634e+00)\tAcc@1  59.38 ( 58.61)\tAcc@5  84.38 ( 87.03)\n",
            "Epoch: [37][180/391]\tTime  0.097 ( 0.102)\tLoss 1.3776e+00 (1.4726e+00)\tAcc@1  64.06 ( 58.52)\tAcc@5  85.94 ( 86.88)\n",
            "Epoch: [37][210/391]\tTime  0.096 ( 0.102)\tLoss 1.6144e+00 (1.4834e+00)\tAcc@1  57.81 ( 58.23)\tAcc@5  85.16 ( 86.72)\n",
            "Epoch: [37][240/391]\tTime  0.098 ( 0.102)\tLoss 1.4245e+00 (1.4856e+00)\tAcc@1  57.03 ( 58.21)\tAcc@5  89.84 ( 86.68)\n",
            "Epoch: [37][270/391]\tTime  0.096 ( 0.101)\tLoss 1.4566e+00 (1.4840e+00)\tAcc@1  57.03 ( 58.23)\tAcc@5  87.50 ( 86.79)\n",
            "Epoch: [37][300/391]\tTime  0.095 ( 0.101)\tLoss 1.3039e+00 (1.4914e+00)\tAcc@1  60.94 ( 58.05)\tAcc@5  92.19 ( 86.66)\n",
            "Epoch: [37][330/391]\tTime  0.113 ( 0.101)\tLoss 1.4871e+00 (1.4969e+00)\tAcc@1  57.03 ( 57.83)\tAcc@5  84.38 ( 86.50)\n",
            "Epoch: [37][360/391]\tTime  0.099 ( 0.101)\tLoss 1.3654e+00 (1.5009e+00)\tAcc@1  57.03 ( 57.74)\tAcc@5  88.28 ( 86.41)\n",
            "Epoch: [37][390/391]\tTime  0.049 ( 0.101)\tLoss 1.2331e+00 (1.5045e+00)\tAcc@1  71.25 ( 57.60)\tAcc@5  87.50 ( 86.36)\n",
            "==> Train Accuracy: Acc@1 57.596 || Acc@5 86.360\n",
            "==> Test Accuracy:  Acc@1 46.630 || Acc@5 76.460\n",
            "==> 56.79 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 38, lr: 0.1 -----\n",
            "Epoch: [38][  0/391]\tTime  0.346 ( 0.346)\tLoss 1.6463e+00 (1.6463e+00)\tAcc@1  53.91 ( 53.91)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [38][ 30/391]\tTime  0.097 ( 0.110)\tLoss 1.3796e+00 (1.4024e+00)\tAcc@1  60.16 ( 59.93)\tAcc@5  88.28 ( 88.63)\n",
            "Epoch: [38][ 60/391]\tTime  0.098 ( 0.108)\tLoss 1.4997e+00 (1.4061e+00)\tAcc@1  60.94 ( 60.31)\tAcc@5  85.94 ( 88.18)\n",
            "Epoch: [38][ 90/391]\tTime  0.097 ( 0.105)\tLoss 1.4954e+00 (1.4225e+00)\tAcc@1  56.25 ( 59.73)\tAcc@5  85.16 ( 87.81)\n",
            "Epoch: [38][120/391]\tTime  0.096 ( 0.104)\tLoss 1.5923e+00 (1.4331e+00)\tAcc@1  53.91 ( 59.35)\tAcc@5  84.38 ( 87.68)\n",
            "Epoch: [38][150/391]\tTime  0.096 ( 0.103)\tLoss 1.4881e+00 (1.4523e+00)\tAcc@1  56.25 ( 58.81)\tAcc@5  89.06 ( 87.23)\n",
            "Epoch: [38][180/391]\tTime  0.100 ( 0.102)\tLoss 1.3013e+00 (1.4576e+00)\tAcc@1  61.72 ( 58.55)\tAcc@5  92.97 ( 87.09)\n",
            "Epoch: [38][210/391]\tTime  0.095 ( 0.103)\tLoss 1.5138e+00 (1.4707e+00)\tAcc@1  58.59 ( 58.28)\tAcc@5  87.50 ( 86.87)\n",
            "Epoch: [38][240/391]\tTime  0.098 ( 0.102)\tLoss 1.5421e+00 (1.4821e+00)\tAcc@1  52.34 ( 57.95)\tAcc@5  86.72 ( 86.70)\n",
            "Epoch: [38][270/391]\tTime  0.098 ( 0.102)\tLoss 1.5047e+00 (1.4819e+00)\tAcc@1  54.69 ( 58.01)\tAcc@5  86.72 ( 86.74)\n",
            "Epoch: [38][300/391]\tTime  0.098 ( 0.102)\tLoss 1.5731e+00 (1.4870e+00)\tAcc@1  54.69 ( 57.86)\tAcc@5  82.81 ( 86.77)\n",
            "Epoch: [38][330/391]\tTime  0.100 ( 0.102)\tLoss 1.4768e+00 (1.4946e+00)\tAcc@1  58.59 ( 57.69)\tAcc@5  91.41 ( 86.65)\n",
            "Epoch: [38][360/391]\tTime  0.097 ( 0.101)\tLoss 1.5041e+00 (1.4955e+00)\tAcc@1  53.12 ( 57.65)\tAcc@5  85.16 ( 86.62)\n",
            "Epoch: [38][390/391]\tTime  0.049 ( 0.101)\tLoss 1.2684e+00 (1.4951e+00)\tAcc@1  61.25 ( 57.70)\tAcc@5  92.50 ( 86.58)\n",
            "==> Train Accuracy: Acc@1 57.698 || Acc@5 86.582\n",
            "==> Test Accuracy:  Acc@1 47.920 || Acc@5 76.940\n",
            "==> 57.33 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 39, lr: 0.1 -----\n",
            "Epoch: [39][  0/391]\tTime  0.333 ( 0.333)\tLoss 1.3800e+00 (1.3800e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  92.19 ( 92.19)\n",
            "Epoch: [39][ 30/391]\tTime  0.103 ( 0.110)\tLoss 1.4867e+00 (1.4241e+00)\tAcc@1  60.94 ( 60.23)\tAcc@5  85.16 ( 88.16)\n",
            "Epoch: [39][ 60/391]\tTime  0.099 ( 0.105)\tLoss 1.4401e+00 (1.4256e+00)\tAcc@1  59.38 ( 59.61)\tAcc@5  89.06 ( 88.14)\n",
            "Epoch: [39][ 90/391]\tTime  0.099 ( 0.104)\tLoss 1.2433e+00 (1.4380e+00)\tAcc@1  65.62 ( 58.89)\tAcc@5  92.97 ( 88.07)\n",
            "Epoch: [39][120/391]\tTime  0.101 ( 0.103)\tLoss 1.3330e+00 (1.4455e+00)\tAcc@1  60.94 ( 58.71)\tAcc@5  91.41 ( 87.76)\n",
            "Epoch: [39][150/391]\tTime  0.101 ( 0.103)\tLoss 1.4209e+00 (1.4503e+00)\tAcc@1  62.50 ( 58.67)\tAcc@5  89.84 ( 87.56)\n",
            "Epoch: [39][180/391]\tTime  0.099 ( 0.102)\tLoss 1.5003e+00 (1.4542e+00)\tAcc@1  53.12 ( 58.67)\tAcc@5  86.72 ( 87.44)\n",
            "Epoch: [39][210/391]\tTime  0.099 ( 0.102)\tLoss 1.6046e+00 (1.4655e+00)\tAcc@1  60.94 ( 58.38)\tAcc@5  81.25 ( 87.30)\n",
            "Epoch: [39][240/391]\tTime  0.100 ( 0.102)\tLoss 1.5091e+00 (1.4723e+00)\tAcc@1  54.69 ( 58.22)\tAcc@5  85.94 ( 87.08)\n",
            "Epoch: [39][270/391]\tTime  0.098 ( 0.102)\tLoss 1.6026e+00 (1.4735e+00)\tAcc@1  50.78 ( 58.16)\tAcc@5  83.59 ( 87.05)\n",
            "Epoch: [39][300/391]\tTime  0.098 ( 0.102)\tLoss 1.1997e+00 (1.4818e+00)\tAcc@1  64.06 ( 57.92)\tAcc@5  91.41 ( 86.91)\n",
            "Epoch: [39][330/391]\tTime  0.096 ( 0.102)\tLoss 1.5349e+00 (1.4852e+00)\tAcc@1  57.03 ( 57.86)\tAcc@5  83.59 ( 86.86)\n",
            "Epoch: [39][360/391]\tTime  0.101 ( 0.102)\tLoss 1.5959e+00 (1.4846e+00)\tAcc@1  58.59 ( 57.87)\tAcc@5  81.25 ( 86.85)\n",
            "Epoch: [39][390/391]\tTime  0.049 ( 0.102)\tLoss 1.4706e+00 (1.4887e+00)\tAcc@1  52.50 ( 57.69)\tAcc@5  86.25 ( 86.81)\n",
            "==> Train Accuracy: Acc@1 57.688 || Acc@5 86.808\n",
            "==> Test Accuracy:  Acc@1 44.980 || Acc@5 76.410\n",
            "==> 57.62 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 40, lr: 0.1 -----\n",
            "Epoch: [40][  0/391]\tTime  0.356 ( 0.356)\tLoss 1.2236e+00 (1.2236e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [40][ 30/391]\tTime  0.099 ( 0.109)\tLoss 1.4835e+00 (1.4084e+00)\tAcc@1  58.59 ( 60.31)\tAcc@5  85.94 ( 87.68)\n",
            "Epoch: [40][ 60/391]\tTime  0.099 ( 0.104)\tLoss 1.3923e+00 (1.4078e+00)\tAcc@1  61.72 ( 60.21)\tAcc@5  90.62 ( 87.88)\n",
            "Epoch: [40][ 90/391]\tTime  0.106 ( 0.103)\tLoss 1.4586e+00 (1.4242e+00)\tAcc@1  64.06 ( 59.74)\tAcc@5  85.94 ( 87.66)\n",
            "Epoch: [40][120/391]\tTime  0.103 ( 0.102)\tLoss 1.3294e+00 (1.4405e+00)\tAcc@1  58.59 ( 59.14)\tAcc@5  89.84 ( 87.46)\n",
            "Epoch: [40][150/391]\tTime  0.101 ( 0.102)\tLoss 1.6472e+00 (1.4470e+00)\tAcc@1  51.56 ( 58.89)\tAcc@5  84.38 ( 87.28)\n",
            "Epoch: [40][180/391]\tTime  0.100 ( 0.102)\tLoss 1.4326e+00 (1.4509e+00)\tAcc@1  57.03 ( 58.62)\tAcc@5  87.50 ( 87.23)\n",
            "Epoch: [40][210/391]\tTime  0.101 ( 0.101)\tLoss 1.6644e+00 (1.4604e+00)\tAcc@1  53.91 ( 58.36)\tAcc@5  85.94 ( 87.07)\n",
            "Epoch: [40][240/391]\tTime  0.099 ( 0.101)\tLoss 1.3850e+00 (1.4611e+00)\tAcc@1  56.25 ( 58.29)\tAcc@5  89.84 ( 87.06)\n",
            "Epoch: [40][270/391]\tTime  0.100 ( 0.102)\tLoss 1.7969e+00 (1.4725e+00)\tAcc@1  51.56 ( 58.11)\tAcc@5  82.81 ( 86.89)\n",
            "Epoch: [40][300/391]\tTime  0.096 ( 0.102)\tLoss 1.4841e+00 (1.4720e+00)\tAcc@1  59.38 ( 58.14)\tAcc@5  85.94 ( 86.82)\n",
            "Epoch: [40][330/391]\tTime  0.099 ( 0.102)\tLoss 1.6239e+00 (1.4667e+00)\tAcc@1  51.56 ( 58.26)\tAcc@5  86.72 ( 86.89)\n",
            "Epoch: [40][360/391]\tTime  0.097 ( 0.101)\tLoss 1.5868e+00 (1.4748e+00)\tAcc@1  53.12 ( 58.10)\tAcc@5  89.06 ( 86.77)\n",
            "Epoch: [40][390/391]\tTime  0.048 ( 0.101)\tLoss 1.3977e+00 (1.4800e+00)\tAcc@1  55.00 ( 57.96)\tAcc@5  86.25 ( 86.70)\n",
            "==> Train Accuracy: Acc@1 57.956 || Acc@5 86.702\n",
            "==> Test Accuracy:  Acc@1 47.150 || Acc@5 77.680\n",
            "==> 56.89 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 41, lr: 0.1 -----\n",
            "Epoch: [41][  0/391]\tTime  0.341 ( 0.341)\tLoss 1.1164e+00 (1.1164e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [41][ 30/391]\tTime  0.107 ( 0.112)\tLoss 1.3911e+00 (1.3674e+00)\tAcc@1  56.25 ( 61.11)\tAcc@5  89.84 ( 88.73)\n",
            "Epoch: [41][ 60/391]\tTime  0.102 ( 0.107)\tLoss 1.4475e+00 (1.4069e+00)\tAcc@1  57.81 ( 60.09)\tAcc@5  85.16 ( 88.24)\n",
            "Epoch: [41][ 90/391]\tTime  0.100 ( 0.104)\tLoss 1.5540e+00 (1.4231e+00)\tAcc@1  52.34 ( 59.38)\tAcc@5  82.81 ( 87.79)\n",
            "Epoch: [41][120/391]\tTime  0.100 ( 0.103)\tLoss 1.5185e+00 (1.4293e+00)\tAcc@1  56.25 ( 59.22)\tAcc@5  83.59 ( 87.63)\n",
            "Epoch: [41][150/391]\tTime  0.099 ( 0.102)\tLoss 1.2555e+00 (1.4385e+00)\tAcc@1  61.72 ( 59.05)\tAcc@5  92.19 ( 87.54)\n",
            "Epoch: [41][180/391]\tTime  0.100 ( 0.102)\tLoss 1.5703e+00 (1.4425e+00)\tAcc@1  53.91 ( 58.90)\tAcc@5  83.59 ( 87.49)\n",
            "Epoch: [41][210/391]\tTime  0.103 ( 0.101)\tLoss 1.6878e+00 (1.4440e+00)\tAcc@1  60.16 ( 58.86)\tAcc@5  84.38 ( 87.41)\n",
            "Epoch: [41][240/391]\tTime  0.118 ( 0.101)\tLoss 1.5314e+00 (1.4526e+00)\tAcc@1  57.03 ( 58.62)\tAcc@5  86.72 ( 87.25)\n",
            "Epoch: [41][270/391]\tTime  0.100 ( 0.101)\tLoss 1.7476e+00 (1.4603e+00)\tAcc@1  53.12 ( 58.42)\tAcc@5  85.16 ( 87.17)\n",
            "Epoch: [41][300/391]\tTime  0.104 ( 0.102)\tLoss 1.4024e+00 (1.4646e+00)\tAcc@1  60.16 ( 58.31)\tAcc@5  89.06 ( 87.10)\n",
            "Epoch: [41][330/391]\tTime  0.101 ( 0.102)\tLoss 1.8149e+00 (1.4717e+00)\tAcc@1  52.34 ( 58.13)\tAcc@5  82.81 ( 86.99)\n",
            "Epoch: [41][360/391]\tTime  0.099 ( 0.102)\tLoss 1.6452e+00 (1.4815e+00)\tAcc@1  56.25 ( 57.92)\tAcc@5  83.59 ( 86.74)\n",
            "Epoch: [41][390/391]\tTime  0.048 ( 0.101)\tLoss 1.7264e+00 (1.4863e+00)\tAcc@1  50.00 ( 57.84)\tAcc@5  83.75 ( 86.65)\n",
            "==> Train Accuracy: Acc@1 57.840 || Acc@5 86.646\n",
            "==> Test Accuracy:  Acc@1 47.310 || Acc@5 78.150\n",
            "==> 57.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 42, lr: 0.1 -----\n",
            "Epoch: [42][  0/391]\tTime  0.355 ( 0.355)\tLoss 1.5273e+00 (1.5273e+00)\tAcc@1  52.34 ( 52.34)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [42][ 30/391]\tTime  0.099 ( 0.109)\tLoss 1.1448e+00 (1.3700e+00)\tAcc@1  64.06 ( 60.69)\tAcc@5  93.75 ( 88.41)\n",
            "Epoch: [42][ 60/391]\tTime  0.099 ( 0.104)\tLoss 1.3684e+00 (1.3930e+00)\tAcc@1  62.50 ( 60.22)\tAcc@5  86.72 ( 88.17)\n",
            "Epoch: [42][ 90/391]\tTime  0.098 ( 0.103)\tLoss 1.4201e+00 (1.4103e+00)\tAcc@1  55.47 ( 59.74)\tAcc@5  91.41 ( 87.98)\n",
            "Epoch: [42][120/391]\tTime  0.105 ( 0.103)\tLoss 1.4851e+00 (1.4171e+00)\tAcc@1  53.91 ( 59.43)\tAcc@5  83.59 ( 87.80)\n",
            "Epoch: [42][150/391]\tTime  0.098 ( 0.102)\tLoss 1.7547e+00 (1.4283e+00)\tAcc@1  54.69 ( 59.22)\tAcc@5  78.12 ( 87.57)\n",
            "Epoch: [42][180/391]\tTime  0.098 ( 0.102)\tLoss 1.2930e+00 (1.4299e+00)\tAcc@1  67.19 ( 59.06)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [42][210/391]\tTime  0.096 ( 0.101)\tLoss 1.4808e+00 (1.4416e+00)\tAcc@1  56.25 ( 58.69)\tAcc@5  89.84 ( 87.37)\n",
            "Epoch: [42][240/391]\tTime  0.097 ( 0.101)\tLoss 1.7002e+00 (1.4473e+00)\tAcc@1  57.03 ( 58.52)\tAcc@5  84.38 ( 87.29)\n",
            "Epoch: [42][270/391]\tTime  0.097 ( 0.101)\tLoss 1.3081e+00 (1.4505e+00)\tAcc@1  57.03 ( 58.42)\tAcc@5  91.41 ( 87.28)\n",
            "Epoch: [42][300/391]\tTime  0.099 ( 0.101)\tLoss 1.4546e+00 (1.4520e+00)\tAcc@1  60.16 ( 58.35)\tAcc@5  85.16 ( 87.25)\n",
            "Epoch: [42][330/391]\tTime  0.115 ( 0.101)\tLoss 1.4257e+00 (1.4591e+00)\tAcc@1  57.81 ( 58.20)\tAcc@5  89.84 ( 87.20)\n",
            "Epoch: [42][360/391]\tTime  0.102 ( 0.101)\tLoss 1.5417e+00 (1.4650e+00)\tAcc@1  58.59 ( 58.12)\tAcc@5  85.16 ( 87.10)\n",
            "Epoch: [42][390/391]\tTime  0.051 ( 0.101)\tLoss 1.6506e+00 (1.4690e+00)\tAcc@1  53.75 ( 58.06)\tAcc@5  83.75 ( 87.04)\n",
            "==> Train Accuracy: Acc@1 58.064 || Acc@5 87.040\n",
            "==> Test Accuracy:  Acc@1 51.380 || Acc@5 81.570\n",
            "==> 57.17 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 43, lr: 0.1 -----\n",
            "Epoch: [43][  0/391]\tTime  0.345 ( 0.345)\tLoss 1.3557e+00 (1.3557e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [43][ 30/391]\tTime  0.098 ( 0.111)\tLoss 1.5436e+00 (1.3586e+00)\tAcc@1  55.47 ( 60.94)\tAcc@5  84.38 ( 88.84)\n",
            "Epoch: [43][ 60/391]\tTime  0.098 ( 0.106)\tLoss 1.2881e+00 (1.3775e+00)\tAcc@1  62.50 ( 60.78)\tAcc@5  91.41 ( 88.51)\n",
            "Epoch: [43][ 90/391]\tTime  0.104 ( 0.104)\tLoss 1.5048e+00 (1.3866e+00)\tAcc@1  56.25 ( 60.35)\tAcc@5  84.38 ( 88.38)\n",
            "Epoch: [43][120/391]\tTime  0.097 ( 0.104)\tLoss 1.4850e+00 (1.4059e+00)\tAcc@1  57.03 ( 59.85)\tAcc@5  86.72 ( 88.02)\n",
            "Epoch: [43][150/391]\tTime  0.098 ( 0.103)\tLoss 1.3104e+00 (1.4074e+00)\tAcc@1  65.62 ( 59.81)\tAcc@5  87.50 ( 87.95)\n",
            "Epoch: [43][180/391]\tTime  0.097 ( 0.102)\tLoss 1.6875e+00 (1.4202e+00)\tAcc@1  54.69 ( 59.44)\tAcc@5  83.59 ( 87.81)\n",
            "Epoch: [43][210/391]\tTime  0.099 ( 0.102)\tLoss 1.5703e+00 (1.4333e+00)\tAcc@1  60.16 ( 59.13)\tAcc@5  83.59 ( 87.59)\n",
            "Epoch: [43][240/391]\tTime  0.098 ( 0.102)\tLoss 1.6129e+00 (1.4424e+00)\tAcc@1  50.00 ( 58.91)\tAcc@5  87.50 ( 87.46)\n",
            "Epoch: [43][270/391]\tTime  0.096 ( 0.101)\tLoss 1.5045e+00 (1.4498e+00)\tAcc@1  58.59 ( 58.79)\tAcc@5  88.28 ( 87.36)\n",
            "Epoch: [43][300/391]\tTime  0.102 ( 0.101)\tLoss 1.3858e+00 (1.4545e+00)\tAcc@1  60.94 ( 58.67)\tAcc@5  88.28 ( 87.27)\n",
            "Epoch: [43][330/391]\tTime  0.097 ( 0.101)\tLoss 1.4795e+00 (1.4589e+00)\tAcc@1  57.81 ( 58.64)\tAcc@5  86.72 ( 87.20)\n",
            "Epoch: [43][360/391]\tTime  0.097 ( 0.101)\tLoss 1.5645e+00 (1.4611e+00)\tAcc@1  55.47 ( 58.61)\tAcc@5  84.38 ( 87.14)\n",
            "Epoch: [43][390/391]\tTime  0.048 ( 0.100)\tLoss 1.2563e+00 (1.4617e+00)\tAcc@1  62.50 ( 58.56)\tAcc@5  85.00 ( 87.15)\n",
            "==> Train Accuracy: Acc@1 58.564 || Acc@5 87.150\n",
            "==> Test Accuracy:  Acc@1 47.940 || Acc@5 78.210\n",
            "==> 56.69 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 44, lr: 0.1 -----\n",
            "Epoch: [44][  0/391]\tTime  0.344 ( 0.344)\tLoss 1.3493e+00 (1.3493e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [44][ 30/391]\tTime  0.097 ( 0.108)\tLoss 1.2604e+00 (1.3689e+00)\tAcc@1  64.84 ( 61.62)\tAcc@5  91.41 ( 88.28)\n",
            "Epoch: [44][ 60/391]\tTime  0.097 ( 0.104)\tLoss 1.1543e+00 (1.3929e+00)\tAcc@1  67.19 ( 60.95)\tAcc@5  87.50 ( 87.77)\n",
            "Epoch: [44][ 90/391]\tTime  0.106 ( 0.102)\tLoss 1.5117e+00 (1.4109e+00)\tAcc@1  53.12 ( 60.13)\tAcc@5  89.84 ( 87.70)\n",
            "Epoch: [44][120/391]\tTime  0.098 ( 0.101)\tLoss 1.4434e+00 (1.4138e+00)\tAcc@1  55.47 ( 59.92)\tAcc@5  86.72 ( 87.75)\n",
            "Epoch: [44][150/391]\tTime  0.099 ( 0.100)\tLoss 1.3992e+00 (1.4283e+00)\tAcc@1  60.16 ( 59.59)\tAcc@5  89.84 ( 87.53)\n",
            "Epoch: [44][180/391]\tTime  0.098 ( 0.100)\tLoss 1.4301e+00 (1.4278e+00)\tAcc@1  63.28 ( 59.43)\tAcc@5  87.50 ( 87.65)\n",
            "Epoch: [44][210/391]\tTime  0.099 ( 0.100)\tLoss 1.6194e+00 (1.4320e+00)\tAcc@1  57.81 ( 59.22)\tAcc@5  84.38 ( 87.64)\n",
            "Epoch: [44][240/391]\tTime  0.101 ( 0.100)\tLoss 1.3099e+00 (1.4399e+00)\tAcc@1  60.94 ( 58.97)\tAcc@5  89.84 ( 87.53)\n",
            "Epoch: [44][270/391]\tTime  0.096 ( 0.100)\tLoss 1.4107e+00 (1.4435e+00)\tAcc@1  65.62 ( 58.93)\tAcc@5  87.50 ( 87.37)\n",
            "Epoch: [44][300/391]\tTime  0.095 ( 0.100)\tLoss 1.6615e+00 (1.4474e+00)\tAcc@1  50.00 ( 58.85)\tAcc@5  85.94 ( 87.33)\n",
            "Epoch: [44][330/391]\tTime  0.096 ( 0.100)\tLoss 1.5848e+00 (1.4550e+00)\tAcc@1  55.47 ( 58.65)\tAcc@5  82.03 ( 87.15)\n",
            "Epoch: [44][360/391]\tTime  0.097 ( 0.100)\tLoss 1.3345e+00 (1.4579e+00)\tAcc@1  64.06 ( 58.62)\tAcc@5  89.84 ( 87.12)\n",
            "Epoch: [44][390/391]\tTime  0.049 ( 0.100)\tLoss 1.7743e+00 (1.4612e+00)\tAcc@1  50.00 ( 58.49)\tAcc@5  87.50 ( 87.09)\n",
            "==> Train Accuracy: Acc@1 58.490 || Acc@5 87.090\n",
            "==> Test Accuracy:  Acc@1 50.400 || Acc@5 80.510\n",
            "==> 56.40 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 45, lr: 0.1 -----\n",
            "Epoch: [45][  0/391]\tTime  0.353 ( 0.353)\tLoss 1.2519e+00 (1.2519e+00)\tAcc@1  66.41 ( 66.41)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [45][ 30/391]\tTime  0.097 ( 0.109)\tLoss 1.2357e+00 (1.3635e+00)\tAcc@1  60.94 ( 61.19)\tAcc@5  91.41 ( 88.43)\n",
            "Epoch: [45][ 60/391]\tTime  0.103 ( 0.106)\tLoss 1.4053e+00 (1.3812e+00)\tAcc@1  60.94 ( 60.59)\tAcc@5  84.38 ( 87.87)\n",
            "Epoch: [45][ 90/391]\tTime  0.100 ( 0.105)\tLoss 1.3429e+00 (1.3804e+00)\tAcc@1  58.59 ( 60.39)\tAcc@5  89.84 ( 88.12)\n",
            "Epoch: [45][120/391]\tTime  0.097 ( 0.105)\tLoss 1.4919e+00 (1.3948e+00)\tAcc@1  60.16 ( 59.95)\tAcc@5  82.81 ( 88.05)\n",
            "Epoch: [45][150/391]\tTime  0.102 ( 0.104)\tLoss 1.3919e+00 (1.4149e+00)\tAcc@1  67.97 ( 59.57)\tAcc@5  89.06 ( 87.78)\n",
            "Epoch: [45][180/391]\tTime  0.100 ( 0.103)\tLoss 1.1946e+00 (1.4179e+00)\tAcc@1  61.72 ( 59.59)\tAcc@5  92.97 ( 87.73)\n",
            "Epoch: [45][210/391]\tTime  0.099 ( 0.103)\tLoss 1.1498e+00 (1.4269e+00)\tAcc@1  67.19 ( 59.34)\tAcc@5  89.84 ( 87.59)\n",
            "Epoch: [45][240/391]\tTime  0.098 ( 0.103)\tLoss 1.6210e+00 (1.4288e+00)\tAcc@1  53.91 ( 59.26)\tAcc@5  85.16 ( 87.55)\n",
            "Epoch: [45][270/391]\tTime  0.098 ( 0.102)\tLoss 1.7642e+00 (1.4415e+00)\tAcc@1  50.00 ( 58.98)\tAcc@5  82.03 ( 87.31)\n",
            "Epoch: [45][300/391]\tTime  0.096 ( 0.103)\tLoss 1.5550e+00 (1.4472e+00)\tAcc@1  55.47 ( 58.72)\tAcc@5  85.94 ( 87.28)\n",
            "Epoch: [45][330/391]\tTime  0.102 ( 0.103)\tLoss 1.5625e+00 (1.4494e+00)\tAcc@1  57.03 ( 58.73)\tAcc@5  85.16 ( 87.17)\n",
            "Epoch: [45][360/391]\tTime  0.097 ( 0.103)\tLoss 1.4931e+00 (1.4517e+00)\tAcc@1  52.34 ( 58.68)\tAcc@5  87.50 ( 87.19)\n",
            "Epoch: [45][390/391]\tTime  0.048 ( 0.103)\tLoss 1.6633e+00 (1.4589e+00)\tAcc@1  56.25 ( 58.50)\tAcc@5  81.25 ( 87.04)\n",
            "==> Train Accuracy: Acc@1 58.502 || Acc@5 87.042\n",
            "==> Test Accuracy:  Acc@1 50.560 || Acc@5 80.800\n",
            "==> 57.78 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 46, lr: 0.1 -----\n",
            "Epoch: [46][  0/391]\tTime  0.370 ( 0.370)\tLoss 1.3564e+00 (1.3564e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [46][ 30/391]\tTime  0.104 ( 0.113)\tLoss 1.4185e+00 (1.3424e+00)\tAcc@1  58.59 ( 61.19)\tAcc@5  88.28 ( 89.57)\n",
            "Epoch: [46][ 60/391]\tTime  0.098 ( 0.107)\tLoss 1.3143e+00 (1.3740e+00)\tAcc@1  60.94 ( 60.30)\tAcc@5  88.28 ( 88.79)\n",
            "Epoch: [46][ 90/391]\tTime  0.096 ( 0.105)\tLoss 1.3578e+00 (1.3906e+00)\tAcc@1  60.16 ( 59.84)\tAcc@5  86.72 ( 88.45)\n",
            "Epoch: [46][120/391]\tTime  0.097 ( 0.104)\tLoss 1.4433e+00 (1.3907e+00)\tAcc@1  55.47 ( 59.99)\tAcc@5  89.06 ( 88.36)\n",
            "Epoch: [46][150/391]\tTime  0.098 ( 0.104)\tLoss 1.3057e+00 (1.4004e+00)\tAcc@1  59.38 ( 59.70)\tAcc@5  89.06 ( 88.15)\n",
            "Epoch: [46][180/391]\tTime  0.102 ( 0.104)\tLoss 1.4273e+00 (1.4142e+00)\tAcc@1  60.16 ( 59.49)\tAcc@5  86.72 ( 87.94)\n",
            "Epoch: [46][210/391]\tTime  0.099 ( 0.103)\tLoss 1.3805e+00 (1.4172e+00)\tAcc@1  64.84 ( 59.40)\tAcc@5  86.72 ( 87.86)\n",
            "Epoch: [46][240/391]\tTime  0.097 ( 0.103)\tLoss 1.4836e+00 (1.4225e+00)\tAcc@1  53.91 ( 59.28)\tAcc@5  90.62 ( 87.75)\n",
            "Epoch: [46][270/391]\tTime  0.100 ( 0.102)\tLoss 1.8058e+00 (1.4319e+00)\tAcc@1  54.69 ( 59.08)\tAcc@5  77.34 ( 87.59)\n",
            "Epoch: [46][300/391]\tTime  0.095 ( 0.102)\tLoss 1.5404e+00 (1.4384e+00)\tAcc@1  57.03 ( 58.87)\tAcc@5  84.38 ( 87.45)\n",
            "Epoch: [46][330/391]\tTime  0.106 ( 0.102)\tLoss 1.6382e+00 (1.4423e+00)\tAcc@1  53.12 ( 58.80)\tAcc@5  86.72 ( 87.35)\n",
            "Epoch: [46][360/391]\tTime  0.108 ( 0.102)\tLoss 1.6867e+00 (1.4489e+00)\tAcc@1  47.66 ( 58.61)\tAcc@5  83.59 ( 87.28)\n",
            "Epoch: [46][390/391]\tTime  0.049 ( 0.101)\tLoss 1.6739e+00 (1.4525e+00)\tAcc@1  52.50 ( 58.51)\tAcc@5  83.75 ( 87.25)\n",
            "==> Train Accuracy: Acc@1 58.512 || Acc@5 87.252\n",
            "==> Test Accuracy:  Acc@1 50.920 || Acc@5 80.650\n",
            "==> 57.43 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 47, lr: 0.1 -----\n",
            "Epoch: [47][  0/391]\tTime  0.361 ( 0.361)\tLoss 1.5083e+00 (1.5083e+00)\tAcc@1  55.47 ( 55.47)\tAcc@5  85.16 ( 85.16)\n",
            "Epoch: [47][ 30/391]\tTime  0.100 ( 0.108)\tLoss 1.2906e+00 (1.3675e+00)\tAcc@1  64.84 ( 61.39)\tAcc@5  86.72 ( 88.81)\n",
            "Epoch: [47][ 60/391]\tTime  0.097 ( 0.103)\tLoss 1.7330e+00 (1.4006e+00)\tAcc@1  49.22 ( 60.14)\tAcc@5  83.59 ( 88.42)\n",
            "Epoch: [47][ 90/391]\tTime  0.101 ( 0.102)\tLoss 1.3636e+00 (1.3962e+00)\tAcc@1  60.94 ( 59.96)\tAcc@5  87.50 ( 88.56)\n",
            "Epoch: [47][120/391]\tTime  0.101 ( 0.101)\tLoss 1.5800e+00 (1.4061e+00)\tAcc@1  58.59 ( 59.59)\tAcc@5  82.03 ( 88.44)\n",
            "Epoch: [47][150/391]\tTime  0.102 ( 0.101)\tLoss 1.3880e+00 (1.4137e+00)\tAcc@1  57.81 ( 59.35)\tAcc@5  90.62 ( 88.29)\n",
            "Epoch: [47][180/391]\tTime  0.102 ( 0.101)\tLoss 1.3561e+00 (1.4256e+00)\tAcc@1  60.94 ( 59.15)\tAcc@5  90.62 ( 88.00)\n",
            "Epoch: [47][210/391]\tTime  0.100 ( 0.101)\tLoss 1.4769e+00 (1.4298e+00)\tAcc@1  54.69 ( 59.06)\tAcc@5  86.72 ( 87.84)\n",
            "Epoch: [47][240/391]\tTime  0.102 ( 0.102)\tLoss 1.7240e+00 (1.4316e+00)\tAcc@1  49.22 ( 58.90)\tAcc@5  84.38 ( 87.82)\n",
            "Epoch: [47][270/391]\tTime  0.107 ( 0.101)\tLoss 1.5298e+00 (1.4313e+00)\tAcc@1  57.03 ( 58.98)\tAcc@5  89.06 ( 87.87)\n",
            "Epoch: [47][300/391]\tTime  0.099 ( 0.101)\tLoss 1.5556e+00 (1.4367e+00)\tAcc@1  55.47 ( 58.81)\tAcc@5  84.38 ( 87.79)\n",
            "Epoch: [47][330/391]\tTime  0.101 ( 0.101)\tLoss 1.3680e+00 (1.4411e+00)\tAcc@1  61.72 ( 58.71)\tAcc@5  85.16 ( 87.67)\n",
            "Epoch: [47][360/391]\tTime  0.099 ( 0.101)\tLoss 1.4609e+00 (1.4465e+00)\tAcc@1  56.25 ( 58.64)\tAcc@5  87.50 ( 87.51)\n",
            "Epoch: [47][390/391]\tTime  0.049 ( 0.100)\tLoss 1.7181e+00 (1.4551e+00)\tAcc@1  50.00 ( 58.46)\tAcc@5  83.75 ( 87.35)\n",
            "==> Train Accuracy: Acc@1 58.460 || Acc@5 87.352\n",
            "==> Test Accuracy:  Acc@1 49.260 || Acc@5 79.390\n",
            "==> 56.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 48, lr: 0.1 -----\n",
            "Epoch: [48][  0/391]\tTime  0.336 ( 0.336)\tLoss 1.4011e+00 (1.4011e+00)\tAcc@1  61.72 ( 61.72)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [48][ 30/391]\tTime  0.099 ( 0.107)\tLoss 1.2607e+00 (1.3847e+00)\tAcc@1  65.62 ( 60.84)\tAcc@5  87.50 ( 88.41)\n",
            "Epoch: [48][ 60/391]\tTime  0.098 ( 0.103)\tLoss 1.5302e+00 (1.3993e+00)\tAcc@1  52.34 ( 59.81)\tAcc@5  91.41 ( 87.83)\n",
            "Epoch: [48][ 90/391]\tTime  0.095 ( 0.102)\tLoss 1.4635e+00 (1.4000e+00)\tAcc@1  57.03 ( 59.83)\tAcc@5  88.28 ( 87.96)\n",
            "Epoch: [48][120/391]\tTime  0.101 ( 0.101)\tLoss 1.3765e+00 (1.4104e+00)\tAcc@1  60.94 ( 59.67)\tAcc@5  89.06 ( 87.65)\n",
            "Epoch: [48][150/391]\tTime  0.099 ( 0.101)\tLoss 1.5629e+00 (1.4153e+00)\tAcc@1  55.47 ( 59.62)\tAcc@5  83.59 ( 87.59)\n",
            "Epoch: [48][180/391]\tTime  0.100 ( 0.100)\tLoss 1.3125e+00 (1.4237e+00)\tAcc@1  66.41 ( 59.39)\tAcc@5  89.06 ( 87.46)\n",
            "Epoch: [48][210/391]\tTime  0.100 ( 0.100)\tLoss 1.5557e+00 (1.4312e+00)\tAcc@1  57.81 ( 59.20)\tAcc@5  82.81 ( 87.33)\n",
            "Epoch: [48][240/391]\tTime  0.101 ( 0.100)\tLoss 1.4944e+00 (1.4363e+00)\tAcc@1  54.69 ( 59.08)\tAcc@5  87.50 ( 87.34)\n",
            "Epoch: [48][270/391]\tTime  0.096 ( 0.100)\tLoss 1.3961e+00 (1.4369e+00)\tAcc@1  57.03 ( 59.00)\tAcc@5  87.50 ( 87.38)\n",
            "Epoch: [48][300/391]\tTime  0.098 ( 0.100)\tLoss 1.5494e+00 (1.4359e+00)\tAcc@1  57.81 ( 59.02)\tAcc@5  85.16 ( 87.38)\n",
            "Epoch: [48][330/391]\tTime  0.098 ( 0.100)\tLoss 1.5871e+00 (1.4410e+00)\tAcc@1  55.47 ( 58.90)\tAcc@5  84.38 ( 87.31)\n",
            "Epoch: [48][360/391]\tTime  0.109 ( 0.100)\tLoss 1.1328e+00 (1.4452e+00)\tAcc@1  68.75 ( 58.88)\tAcc@5  89.84 ( 87.24)\n",
            "Epoch: [48][390/391]\tTime  0.049 ( 0.100)\tLoss 1.3621e+00 (1.4485e+00)\tAcc@1  55.00 ( 58.79)\tAcc@5  91.25 ( 87.21)\n",
            "==> Train Accuracy: Acc@1 58.794 || Acc@5 87.210\n",
            "==> Test Accuracy:  Acc@1 48.660 || Acc@5 77.860\n",
            "==> 56.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 49, lr: 0.1 -----\n",
            "Epoch: [49][  0/391]\tTime  0.356 ( 0.356)\tLoss 1.4084e+00 (1.4084e+00)\tAcc@1  57.81 ( 57.81)\tAcc@5  89.06 ( 89.06)\n",
            "Epoch: [49][ 30/391]\tTime  0.098 ( 0.109)\tLoss 1.3245e+00 (1.3883e+00)\tAcc@1  56.25 ( 60.89)\tAcc@5  90.62 ( 87.85)\n",
            "Epoch: [49][ 60/391]\tTime  0.096 ( 0.104)\tLoss 1.4243e+00 (1.3966e+00)\tAcc@1  59.38 ( 60.13)\tAcc@5  85.16 ( 87.94)\n",
            "Epoch: [49][ 90/391]\tTime  0.097 ( 0.104)\tLoss 1.4436e+00 (1.4127e+00)\tAcc@1  67.97 ( 59.82)\tAcc@5  84.38 ( 87.71)\n",
            "Epoch: [49][120/391]\tTime  0.100 ( 0.103)\tLoss 1.3766e+00 (1.4214e+00)\tAcc@1  58.59 ( 59.58)\tAcc@5  92.19 ( 87.56)\n",
            "Epoch: [49][150/391]\tTime  0.098 ( 0.102)\tLoss 1.3266e+00 (1.4254e+00)\tAcc@1  62.50 ( 59.45)\tAcc@5  90.62 ( 87.59)\n",
            "Epoch: [49][180/391]\tTime  0.095 ( 0.102)\tLoss 1.4105e+00 (1.4289e+00)\tAcc@1  62.50 ( 59.21)\tAcc@5  84.38 ( 87.60)\n",
            "Epoch: [49][210/391]\tTime  0.097 ( 0.101)\tLoss 1.4176e+00 (1.4377e+00)\tAcc@1  56.25 ( 58.85)\tAcc@5  89.06 ( 87.45)\n",
            "Epoch: [49][240/391]\tTime  0.098 ( 0.101)\tLoss 1.3911e+00 (1.4385e+00)\tAcc@1  61.72 ( 58.89)\tAcc@5  85.94 ( 87.37)\n",
            "Epoch: [49][270/391]\tTime  0.106 ( 0.101)\tLoss 1.6220e+00 (1.4409e+00)\tAcc@1  57.03 ( 58.94)\tAcc@5  85.94 ( 87.34)\n",
            "Epoch: [49][300/391]\tTime  0.104 ( 0.101)\tLoss 1.3458e+00 (1.4409e+00)\tAcc@1  60.16 ( 58.95)\tAcc@5  89.84 ( 87.37)\n",
            "Epoch: [49][330/391]\tTime  0.096 ( 0.101)\tLoss 1.6092e+00 (1.4422e+00)\tAcc@1  53.12 ( 58.93)\tAcc@5  82.81 ( 87.35)\n",
            "Epoch: [49][360/391]\tTime  0.098 ( 0.101)\tLoss 1.1769e+00 (1.4469e+00)\tAcc@1  65.62 ( 58.76)\tAcc@5  92.97 ( 87.30)\n",
            "Epoch: [49][390/391]\tTime  0.049 ( 0.100)\tLoss 1.8045e+00 (1.4469e+00)\tAcc@1  45.00 ( 58.74)\tAcc@5  87.50 ( 87.32)\n",
            "==> Train Accuracy: Acc@1 58.742 || Acc@5 87.318\n",
            "==> Test Accuracy:  Acc@1 46.790 || Acc@5 77.380\n",
            "==> 56.87 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 50, lr: 0.1 -----\n",
            "Epoch: [50][  0/391]\tTime  0.316 ( 0.316)\tLoss 1.0980e+00 (1.0980e+00)\tAcc@1  65.62 ( 65.62)\tAcc@5  91.41 ( 91.41)\n",
            "Epoch: [50][ 30/391]\tTime  0.100 ( 0.109)\tLoss 1.4481e+00 (1.3054e+00)\tAcc@1  56.25 ( 61.95)\tAcc@5  89.06 ( 89.69)\n",
            "Epoch: [50][ 60/391]\tTime  0.098 ( 0.105)\tLoss 1.4500e+00 (1.3488e+00)\tAcc@1  57.81 ( 60.85)\tAcc@5  85.16 ( 88.84)\n",
            "Epoch: [50][ 90/391]\tTime  0.102 ( 0.103)\tLoss 1.4388e+00 (1.3725e+00)\tAcc@1  53.12 ( 60.31)\tAcc@5  89.06 ( 88.41)\n",
            "Epoch: [50][120/391]\tTime  0.098 ( 0.103)\tLoss 1.2969e+00 (1.3768e+00)\tAcc@1  64.06 ( 60.25)\tAcc@5  92.19 ( 88.40)\n",
            "Epoch: [50][150/391]\tTime  0.101 ( 0.103)\tLoss 1.3707e+00 (1.3891e+00)\tAcc@1  60.16 ( 60.03)\tAcc@5  87.50 ( 88.27)\n",
            "Epoch: [50][180/391]\tTime  0.107 ( 0.104)\tLoss 1.4190e+00 (1.3956e+00)\tAcc@1  61.72 ( 59.86)\tAcc@5  89.06 ( 88.26)\n",
            "Epoch: [50][210/391]\tTime  0.100 ( 0.103)\tLoss 1.5892e+00 (1.4120e+00)\tAcc@1  49.22 ( 59.42)\tAcc@5  85.94 ( 88.01)\n",
            "Epoch: [50][240/391]\tTime  0.100 ( 0.103)\tLoss 1.4699e+00 (1.4187e+00)\tAcc@1  62.50 ( 59.26)\tAcc@5  85.16 ( 87.94)\n",
            "Epoch: [50][270/391]\tTime  0.107 ( 0.103)\tLoss 1.6061e+00 (1.4214e+00)\tAcc@1  53.91 ( 59.31)\tAcc@5  84.38 ( 87.90)\n",
            "Epoch: [50][300/391]\tTime  0.101 ( 0.103)\tLoss 1.2594e+00 (1.4224e+00)\tAcc@1  60.94 ( 59.33)\tAcc@5  88.28 ( 87.86)\n",
            "Epoch: [50][330/391]\tTime  0.096 ( 0.103)\tLoss 1.5544e+00 (1.4281e+00)\tAcc@1  53.12 ( 59.26)\tAcc@5  83.59 ( 87.70)\n",
            "Epoch: [50][360/391]\tTime  0.097 ( 0.102)\tLoss 1.4085e+00 (1.4319e+00)\tAcc@1  60.94 ( 59.16)\tAcc@5  90.62 ( 87.64)\n",
            "Epoch: [50][390/391]\tTime  0.049 ( 0.102)\tLoss 1.3557e+00 (1.4336e+00)\tAcc@1  61.25 ( 59.13)\tAcc@5  86.25 ( 87.61)\n",
            "==> Train Accuracy: Acc@1 59.130 || Acc@5 87.608\n",
            "==> Test Accuracy:  Acc@1 48.210 || Acc@5 78.350\n",
            "==> 57.55 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 51, lr: 0.1 -----\n",
            "Epoch: [51][  0/391]\tTime  0.360 ( 0.360)\tLoss 1.3558e+00 (1.3558e+00)\tAcc@1  60.94 ( 60.94)\tAcc@5  87.50 ( 87.50)\n",
            "Epoch: [51][ 30/391]\tTime  0.105 ( 0.109)\tLoss 1.3323e+00 (1.3591e+00)\tAcc@1  56.25 ( 61.57)\tAcc@5  92.19 ( 88.63)\n",
            "Epoch: [51][ 60/391]\tTime  0.097 ( 0.104)\tLoss 1.2677e+00 (1.3500e+00)\tAcc@1  61.72 ( 61.31)\tAcc@5  90.62 ( 89.11)\n",
            "Epoch: [51][ 90/391]\tTime  0.096 ( 0.102)\tLoss 1.5415e+00 (1.3649e+00)\tAcc@1  60.16 ( 60.83)\tAcc@5  82.03 ( 88.89)\n",
            "Epoch: [51][120/391]\tTime  0.099 ( 0.101)\tLoss 1.4260e+00 (1.3821e+00)\tAcc@1  58.59 ( 60.43)\tAcc@5  90.62 ( 88.69)\n",
            "Epoch: [51][150/391]\tTime  0.107 ( 0.102)\tLoss 1.4560e+00 (1.3892e+00)\tAcc@1  56.25 ( 60.29)\tAcc@5  86.72 ( 88.51)\n",
            "Epoch: [51][180/391]\tTime  0.099 ( 0.102)\tLoss 1.5635e+00 (1.3961e+00)\tAcc@1  53.12 ( 60.00)\tAcc@5  88.28 ( 88.36)\n",
            "Epoch: [51][210/391]\tTime  0.099 ( 0.101)\tLoss 1.7857e+00 (1.4068e+00)\tAcc@1  52.34 ( 59.80)\tAcc@5  85.16 ( 88.23)\n",
            "Epoch: [51][240/391]\tTime  0.099 ( 0.101)\tLoss 1.4801e+00 (1.4132e+00)\tAcc@1  60.16 ( 59.67)\tAcc@5  89.06 ( 88.14)\n",
            "Epoch: [51][270/391]\tTime  0.097 ( 0.101)\tLoss 1.3445e+00 (1.4189e+00)\tAcc@1  57.81 ( 59.58)\tAcc@5  92.19 ( 88.14)\n",
            "Epoch: [51][300/391]\tTime  0.098 ( 0.101)\tLoss 1.5337e+00 (1.4247e+00)\tAcc@1  51.56 ( 59.39)\tAcc@5  88.28 ( 88.13)\n",
            "Epoch: [51][330/391]\tTime  0.098 ( 0.101)\tLoss 1.4087e+00 (1.4291e+00)\tAcc@1  55.47 ( 59.23)\tAcc@5  89.06 ( 87.93)\n",
            "Epoch: [51][360/391]\tTime  0.099 ( 0.101)\tLoss 1.4532e+00 (1.4316e+00)\tAcc@1  54.69 ( 59.23)\tAcc@5  89.06 ( 87.86)\n",
            "Epoch: [51][390/391]\tTime  0.048 ( 0.101)\tLoss 1.7751e+00 (1.4336e+00)\tAcc@1  50.00 ( 59.14)\tAcc@5  77.50 ( 87.85)\n",
            "==> Train Accuracy: Acc@1 59.136 || Acc@5 87.848\n",
            "==> Test Accuracy:  Acc@1 51.780 || Acc@5 81.140\n",
            "==> 56.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 52, lr: 0.1 -----\n",
            "Epoch: [52][  0/391]\tTime  0.356 ( 0.356)\tLoss 1.4226e+00 (1.4226e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [52][ 30/391]\tTime  0.097 ( 0.119)\tLoss 1.3258e+00 (1.3651e+00)\tAcc@1  61.72 ( 61.11)\tAcc@5  85.94 ( 88.46)\n",
            "Epoch: [52][ 60/391]\tTime  0.097 ( 0.109)\tLoss 1.4484e+00 (1.3752e+00)\tAcc@1  54.69 ( 60.81)\tAcc@5  88.28 ( 88.11)\n",
            "Epoch: [52][ 90/391]\tTime  0.097 ( 0.106)\tLoss 1.7009e+00 (1.3688e+00)\tAcc@1  55.47 ( 60.78)\tAcc@5  82.03 ( 88.35)\n",
            "Epoch: [52][120/391]\tTime  0.096 ( 0.104)\tLoss 1.6469e+00 (1.3868e+00)\tAcc@1  55.47 ( 60.38)\tAcc@5  82.03 ( 88.07)\n",
            "Epoch: [52][150/391]\tTime  0.097 ( 0.103)\tLoss 1.3845e+00 (1.3917e+00)\tAcc@1  60.94 ( 60.14)\tAcc@5  86.72 ( 87.96)\n",
            "Epoch: [52][180/391]\tTime  0.095 ( 0.103)\tLoss 1.6596e+00 (1.3997e+00)\tAcc@1  56.25 ( 59.88)\tAcc@5  83.59 ( 87.91)\n",
            "Epoch: [52][210/391]\tTime  0.098 ( 0.102)\tLoss 1.4342e+00 (1.4062e+00)\tAcc@1  55.47 ( 59.73)\tAcc@5  85.94 ( 87.86)\n",
            "Epoch: [52][240/391]\tTime  0.098 ( 0.102)\tLoss 1.5252e+00 (1.4126e+00)\tAcc@1  57.81 ( 59.66)\tAcc@5  85.16 ( 87.80)\n",
            "Epoch: [52][270/391]\tTime  0.105 ( 0.102)\tLoss 1.5530e+00 (1.4166e+00)\tAcc@1  53.91 ( 59.50)\tAcc@5  84.38 ( 87.80)\n",
            "Epoch: [52][300/391]\tTime  0.114 ( 0.101)\tLoss 1.4910e+00 (1.4210e+00)\tAcc@1  57.03 ( 59.34)\tAcc@5  83.59 ( 87.74)\n",
            "Epoch: [52][330/391]\tTime  0.097 ( 0.101)\tLoss 1.2588e+00 (1.4235e+00)\tAcc@1  63.28 ( 59.28)\tAcc@5  90.62 ( 87.64)\n",
            "Epoch: [52][360/391]\tTime  0.097 ( 0.101)\tLoss 1.1836e+00 (1.4334e+00)\tAcc@1  66.41 ( 59.10)\tAcc@5  90.62 ( 87.48)\n",
            "Epoch: [52][390/391]\tTime  0.046 ( 0.101)\tLoss 1.5257e+00 (1.4374e+00)\tAcc@1  56.25 ( 59.00)\tAcc@5  87.50 ( 87.39)\n",
            "==> Train Accuracy: Acc@1 58.998 || Acc@5 87.392\n",
            "==> Test Accuracy:  Acc@1 46.020 || Acc@5 75.200\n",
            "==> 56.84 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 53, lr: 0.1 -----\n",
            "Epoch: [53][  0/391]\tTime  0.370 ( 0.370)\tLoss 1.5093e+00 (1.5093e+00)\tAcc@1  62.50 ( 62.50)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [53][ 30/391]\tTime  0.100 ( 0.111)\tLoss 1.0545e+00 (1.3496e+00)\tAcc@1  68.75 ( 61.49)\tAcc@5  93.75 ( 88.86)\n",
            "Epoch: [53][ 60/391]\tTime  0.103 ( 0.106)\tLoss 1.4186e+00 (1.3601e+00)\tAcc@1  59.38 ( 60.60)\tAcc@5  87.50 ( 88.63)\n",
            "Epoch: [53][ 90/391]\tTime  0.097 ( 0.104)\tLoss 1.4120e+00 (1.3712e+00)\tAcc@1  60.94 ( 60.45)\tAcc@5  83.59 ( 88.43)\n",
            "Epoch: [53][120/391]\tTime  0.099 ( 0.105)\tLoss 1.3489e+00 (1.3812e+00)\tAcc@1  59.38 ( 60.36)\tAcc@5  86.72 ( 88.19)\n",
            "Epoch: [53][150/391]\tTime  0.099 ( 0.104)\tLoss 1.5497e+00 (1.3827e+00)\tAcc@1  54.69 ( 60.29)\tAcc@5  86.72 ( 88.18)\n",
            "Epoch: [53][180/391]\tTime  0.099 ( 0.103)\tLoss 1.4815e+00 (1.3926e+00)\tAcc@1  58.59 ( 60.15)\tAcc@5  89.06 ( 88.01)\n",
            "Epoch: [53][210/391]\tTime  0.100 ( 0.103)\tLoss 1.3459e+00 (1.4013e+00)\tAcc@1  59.38 ( 59.86)\tAcc@5  89.84 ( 87.96)\n",
            "Epoch: [53][240/391]\tTime  0.097 ( 0.102)\tLoss 1.4574e+00 (1.4107e+00)\tAcc@1  56.25 ( 59.65)\tAcc@5  89.06 ( 87.84)\n",
            "Epoch: [53][270/391]\tTime  0.099 ( 0.102)\tLoss 1.5241e+00 (1.4136e+00)\tAcc@1  55.47 ( 59.44)\tAcc@5  89.06 ( 87.83)\n",
            "Epoch: [53][300/391]\tTime  0.105 ( 0.102)\tLoss 1.5689e+00 (1.4173e+00)\tAcc@1  55.47 ( 59.32)\tAcc@5  85.16 ( 87.74)\n",
            "Epoch: [53][330/391]\tTime  0.106 ( 0.101)\tLoss 1.4032e+00 (1.4188e+00)\tAcc@1  64.06 ( 59.37)\tAcc@5  85.94 ( 87.79)\n",
            "Epoch: [53][360/391]\tTime  0.100 ( 0.101)\tLoss 1.4527e+00 (1.4245e+00)\tAcc@1  56.25 ( 59.26)\tAcc@5  84.38 ( 87.66)\n",
            "Epoch: [53][390/391]\tTime  0.049 ( 0.101)\tLoss 1.2921e+00 (1.4271e+00)\tAcc@1  63.75 ( 59.21)\tAcc@5  91.25 ( 87.61)\n",
            "==> Train Accuracy: Acc@1 59.208 || Acc@5 87.610\n",
            "==> Test Accuracy:  Acc@1 46.630 || Acc@5 79.040\n",
            "==> 57.03 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 54, lr: 0.1 -----\n",
            "Epoch: [54][  0/391]\tTime  0.318 ( 0.318)\tLoss 1.2936e+00 (1.2936e+00)\tAcc@1  60.16 ( 60.16)\tAcc@5  90.62 ( 90.62)\n",
            "Epoch: [54][ 30/391]\tTime  0.097 ( 0.108)\tLoss 1.2750e+00 (1.3493e+00)\tAcc@1  64.06 ( 61.29)\tAcc@5  90.62 ( 88.63)\n",
            "Epoch: [54][ 60/391]\tTime  0.098 ( 0.104)\tLoss 1.2878e+00 (1.3489e+00)\tAcc@1  62.50 ( 61.16)\tAcc@5  90.62 ( 88.97)\n",
            "Epoch: [54][ 90/391]\tTime  0.103 ( 0.104)\tLoss 1.2370e+00 (1.3589e+00)\tAcc@1  61.72 ( 60.97)\tAcc@5  92.19 ( 88.63)\n",
            "Epoch: [54][120/391]\tTime  0.098 ( 0.103)\tLoss 1.4992e+00 (1.3586e+00)\tAcc@1  57.81 ( 60.95)\tAcc@5  88.28 ( 88.62)\n",
            "Epoch: [54][150/391]\tTime  0.097 ( 0.102)\tLoss 1.4188e+00 (1.3711e+00)\tAcc@1  57.81 ( 60.56)\tAcc@5  86.72 ( 88.45)\n",
            "Epoch: [54][180/391]\tTime  0.097 ( 0.101)\tLoss 1.5717e+00 (1.3898e+00)\tAcc@1  57.03 ( 60.25)\tAcc@5  82.81 ( 88.09)\n",
            "Epoch: [54][210/391]\tTime  0.099 ( 0.101)\tLoss 1.4516e+00 (1.4016e+00)\tAcc@1  57.03 ( 60.02)\tAcc@5  87.50 ( 87.94)\n",
            "Epoch: [54][240/391]\tTime  0.103 ( 0.101)\tLoss 1.6640e+00 (1.4097e+00)\tAcc@1  55.47 ( 59.70)\tAcc@5  84.38 ( 87.82)\n",
            "Epoch: [54][270/391]\tTime  0.098 ( 0.101)\tLoss 1.2941e+00 (1.4172e+00)\tAcc@1  63.28 ( 59.45)\tAcc@5  91.41 ( 87.79)\n",
            "Epoch: [54][300/391]\tTime  0.096 ( 0.101)\tLoss 1.5552e+00 (1.4267e+00)\tAcc@1  57.81 ( 59.22)\tAcc@5  87.50 ( 87.67)\n",
            "Epoch: [54][330/391]\tTime  0.102 ( 0.100)\tLoss 1.5135e+00 (1.4299e+00)\tAcc@1  53.91 ( 59.21)\tAcc@5  83.59 ( 87.60)\n",
            "Epoch: [54][360/391]\tTime  0.100 ( 0.100)\tLoss 1.4582e+00 (1.4306e+00)\tAcc@1  54.69 ( 59.22)\tAcc@5  89.06 ( 87.54)\n",
            "Epoch: [54][390/391]\tTime  0.048 ( 0.100)\tLoss 1.1191e+00 (1.4366e+00)\tAcc@1  70.00 ( 59.08)\tAcc@5  93.75 ( 87.40)\n",
            "==> Train Accuracy: Acc@1 59.084 || Acc@5 87.402\n",
            "==> Test Accuracy:  Acc@1 49.290 || Acc@5 78.910\n",
            "==> 56.45 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 55, lr: 0.1 -----\n",
            "Epoch: [55][  0/391]\tTime  0.345 ( 0.345)\tLoss 1.3373e+00 (1.3373e+00)\tAcc@1  63.28 ( 63.28)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [55][ 30/391]\tTime  0.102 ( 0.108)\tLoss 1.2847e+00 (1.3502e+00)\tAcc@1  61.72 ( 61.42)\tAcc@5  89.06 ( 88.58)\n",
            "Epoch: [55][ 60/391]\tTime  0.097 ( 0.103)\tLoss 1.4349e+00 (1.3300e+00)\tAcc@1  59.38 ( 61.73)\tAcc@5  83.59 ( 88.74)\n",
            "Epoch: [55][ 90/391]\tTime  0.098 ( 0.102)\tLoss 1.3694e+00 (1.3495e+00)\tAcc@1  64.84 ( 61.41)\tAcc@5  89.06 ( 88.62)\n",
            "Epoch: [55][120/391]\tTime  0.099 ( 0.102)\tLoss 1.4932e+00 (1.3670e+00)\tAcc@1  57.81 ( 60.72)\tAcc@5  85.94 ( 88.44)\n",
            "Epoch: [55][150/391]\tTime  0.097 ( 0.102)\tLoss 1.1573e+00 (1.3692e+00)\tAcc@1  66.41 ( 60.73)\tAcc@5  92.97 ( 88.44)\n",
            "Epoch: [55][180/391]\tTime  0.113 ( 0.102)\tLoss 1.3667e+00 (1.3774e+00)\tAcc@1  64.06 ( 60.54)\tAcc@5  88.28 ( 88.29)\n",
            "Epoch: [55][210/391]\tTime  0.097 ( 0.102)\tLoss 1.4688e+00 (1.3838e+00)\tAcc@1  58.59 ( 60.47)\tAcc@5  86.72 ( 88.20)\n",
            "Epoch: [55][240/391]\tTime  0.097 ( 0.102)\tLoss 1.5835e+00 (1.3931e+00)\tAcc@1  56.25 ( 60.31)\tAcc@5  80.47 ( 87.95)\n",
            "Epoch: [55][270/391]\tTime  0.097 ( 0.102)\tLoss 1.5089e+00 (1.4009e+00)\tAcc@1  56.25 ( 60.12)\tAcc@5  87.50 ( 87.86)\n",
            "Epoch: [55][300/391]\tTime  0.110 ( 0.101)\tLoss 1.5348e+00 (1.4016e+00)\tAcc@1  53.91 ( 59.97)\tAcc@5  89.06 ( 87.89)\n",
            "Epoch: [55][330/391]\tTime  0.099 ( 0.102)\tLoss 1.3924e+00 (1.4044e+00)\tAcc@1  61.72 ( 59.90)\tAcc@5  89.06 ( 87.87)\n",
            "Epoch: [55][360/391]\tTime  0.098 ( 0.101)\tLoss 1.3196e+00 (1.4125e+00)\tAcc@1  64.06 ( 59.74)\tAcc@5  87.50 ( 87.77)\n",
            "Epoch: [55][390/391]\tTime  0.049 ( 0.101)\tLoss 1.4249e+00 (1.4202e+00)\tAcc@1  60.00 ( 59.56)\tAcc@5  86.25 ( 87.68)\n",
            "==> Train Accuracy: Acc@1 59.558 || Acc@5 87.680\n",
            "==> Test Accuracy:  Acc@1 48.630 || Acc@5 79.260\n",
            "==> 56.91 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 56, lr: 0.1 -----\n",
            "Epoch: [56][  0/391]\tTime  0.375 ( 0.375)\tLoss 1.0049e+00 (1.0049e+00)\tAcc@1  71.09 ( 71.09)\tAcc@5  94.53 ( 94.53)\n",
            "Epoch: [56][ 30/391]\tTime  0.104 ( 0.108)\tLoss 1.2995e+00 (1.3284e+00)\tAcc@1  64.84 ( 61.39)\tAcc@5  89.84 ( 89.31)\n",
            "Epoch: [56][ 60/391]\tTime  0.105 ( 0.107)\tLoss 1.2378e+00 (1.3391e+00)\tAcc@1  67.19 ( 61.42)\tAcc@5  88.28 ( 88.86)\n",
            "Epoch: [56][ 90/391]\tTime  0.105 ( 0.104)\tLoss 1.3066e+00 (1.3603e+00)\tAcc@1  60.16 ( 60.93)\tAcc@5  92.97 ( 88.80)\n",
            "Epoch: [56][120/391]\tTime  0.096 ( 0.103)\tLoss 1.5504e+00 (1.3682e+00)\tAcc@1  58.59 ( 60.74)\tAcc@5  85.94 ( 88.65)\n",
            "Epoch: [56][150/391]\tTime  0.104 ( 0.103)\tLoss 1.7001e+00 (1.3823e+00)\tAcc@1  53.12 ( 60.50)\tAcc@5  84.38 ( 88.46)\n",
            "Epoch: [56][180/391]\tTime  0.097 ( 0.102)\tLoss 1.2013e+00 (1.3918e+00)\tAcc@1  66.41 ( 60.41)\tAcc@5  89.06 ( 88.17)\n",
            "Epoch: [56][210/391]\tTime  0.101 ( 0.102)\tLoss 1.1730e+00 (1.3991e+00)\tAcc@1  64.84 ( 59.96)\tAcc@5  92.97 ( 88.14)\n",
            "Epoch: [56][240/391]\tTime  0.101 ( 0.102)\tLoss 1.5344e+00 (1.4104e+00)\tAcc@1  57.03 ( 59.72)\tAcc@5  87.50 ( 87.94)\n",
            "Epoch: [56][270/391]\tTime  0.113 ( 0.102)\tLoss 1.3987e+00 (1.4134e+00)\tAcc@1  60.16 ( 59.65)\tAcc@5  88.28 ( 87.89)\n",
            "Epoch: [56][300/391]\tTime  0.100 ( 0.102)\tLoss 1.3783e+00 (1.4167e+00)\tAcc@1  61.72 ( 59.60)\tAcc@5  89.06 ( 87.88)\n",
            "Epoch: [56][330/391]\tTime  0.104 ( 0.102)\tLoss 1.5513e+00 (1.4214e+00)\tAcc@1  57.03 ( 59.61)\tAcc@5  84.38 ( 87.76)\n",
            "Epoch: [56][360/391]\tTime  0.097 ( 0.102)\tLoss 1.6061e+00 (1.4274e+00)\tAcc@1  54.69 ( 59.43)\tAcc@5  86.72 ( 87.67)\n",
            "Epoch: [56][390/391]\tTime  0.049 ( 0.102)\tLoss 1.7103e+00 (1.4307e+00)\tAcc@1  48.75 ( 59.32)\tAcc@5  81.25 ( 87.67)\n",
            "==> Train Accuracy: Acc@1 59.322 || Acc@5 87.670\n",
            "==> Test Accuracy:  Acc@1 47.920 || Acc@5 78.490\n",
            "==> 57.21 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 57, lr: 0.1 -----\n",
            "Epoch: [57][  0/391]\tTime  0.314 ( 0.314)\tLoss 1.4363e+00 (1.4363e+00)\tAcc@1  59.38 ( 59.38)\tAcc@5  85.94 ( 85.94)\n",
            "Epoch: [57][ 30/391]\tTime  0.103 ( 0.112)\tLoss 1.2934e+00 (1.3539e+00)\tAcc@1  64.06 ( 60.69)\tAcc@5  90.62 ( 88.91)\n",
            "Epoch: [57][ 60/391]\tTime  0.101 ( 0.107)\tLoss 1.4310e+00 (1.3631e+00)\tAcc@1  56.25 ( 60.85)\tAcc@5  88.28 ( 88.65)\n",
            "Epoch: [57][ 90/391]\tTime  0.099 ( 0.105)\tLoss 1.2254e+00 (1.3644e+00)\tAcc@1  61.72 ( 60.61)\tAcc@5  90.62 ( 88.75)\n",
            "Epoch: [57][120/391]\tTime  0.102 ( 0.105)\tLoss 1.3801e+00 (1.3783e+00)\tAcc@1  61.72 ( 60.31)\tAcc@5  89.06 ( 88.52)\n",
            "Epoch: [57][150/391]\tTime  0.100 ( 0.104)\tLoss 1.2178e+00 (1.3789e+00)\tAcc@1  60.16 ( 60.34)\tAcc@5  91.41 ( 88.48)\n",
            "Epoch: [57][180/391]\tTime  0.102 ( 0.104)\tLoss 1.4636e+00 (1.3913e+00)\tAcc@1  63.28 ( 60.02)\tAcc@5  85.94 ( 88.28)\n",
            "Epoch: [57][210/391]\tTime  0.100 ( 0.104)\tLoss 1.5768e+00 (1.3955e+00)\tAcc@1  55.47 ( 59.86)\tAcc@5  89.84 ( 88.23)\n",
            "Epoch: [57][240/391]\tTime  0.099 ( 0.103)\tLoss 1.4140e+00 (1.4012e+00)\tAcc@1  57.03 ( 59.68)\tAcc@5  88.28 ( 88.18)\n",
            "Epoch: [57][270/391]\tTime  0.103 ( 0.103)\tLoss 1.3887e+00 (1.4010e+00)\tAcc@1  56.25 ( 59.70)\tAcc@5  89.06 ( 88.23)\n",
            "Epoch: [57][300/391]\tTime  0.102 ( 0.103)\tLoss 1.5017e+00 (1.4095e+00)\tAcc@1  60.16 ( 59.48)\tAcc@5  85.94 ( 88.15)\n",
            "Epoch: [57][330/391]\tTime  0.099 ( 0.103)\tLoss 1.3953e+00 (1.4138e+00)\tAcc@1  60.16 ( 59.37)\tAcc@5  89.84 ( 88.08)\n",
            "Epoch: [57][360/391]\tTime  0.106 ( 0.103)\tLoss 1.3994e+00 (1.4148e+00)\tAcc@1  57.81 ( 59.37)\tAcc@5  88.28 ( 88.03)\n",
            "Epoch: [57][390/391]\tTime  0.049 ( 0.103)\tLoss 1.6496e+00 (1.4157e+00)\tAcc@1  57.50 ( 59.44)\tAcc@5  81.25 ( 87.96)\n",
            "==> Train Accuracy: Acc@1 59.438 || Acc@5 87.956\n",
            "==> Test Accuracy:  Acc@1 53.280 || Acc@5 83.210\n",
            "==> 57.76 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 58, lr: 0.1 -----\n",
            "Epoch: [58][  0/391]\tTime  0.360 ( 0.360)\tLoss 1.3248e+00 (1.3248e+00)\tAcc@1  64.06 ( 64.06)\tAcc@5  89.84 ( 89.84)\n",
            "Epoch: [58][ 30/391]\tTime  0.100 ( 0.112)\tLoss 1.2127e+00 (1.3739e+00)\tAcc@1  66.41 ( 60.96)\tAcc@5  90.62 ( 88.21)\n",
            "Epoch: [58][ 60/391]\tTime  0.103 ( 0.108)\tLoss 1.2852e+00 (1.3555e+00)\tAcc@1  61.72 ( 61.27)\tAcc@5  89.06 ( 88.73)\n",
            "Epoch: [58][ 90/391]\tTime  0.101 ( 0.106)\tLoss 1.2844e+00 (1.3568e+00)\tAcc@1  62.50 ( 61.44)\tAcc@5  89.84 ( 88.74)\n",
            "Epoch: [58][120/391]\tTime  0.107 ( 0.106)\tLoss 1.4693e+00 (1.3779e+00)\tAcc@1  62.50 ( 60.85)\tAcc@5  85.16 ( 88.51)\n",
            "Epoch: [58][150/391]\tTime  0.101 ( 0.106)\tLoss 1.5137e+00 (1.3855e+00)\tAcc@1  53.91 ( 60.52)\tAcc@5  85.16 ( 88.31)\n",
            "Epoch: [58][180/391]\tTime  0.115 ( 0.105)\tLoss 1.7654e+00 (1.3950e+00)\tAcc@1  49.22 ( 60.26)\tAcc@5  80.47 ( 88.16)\n",
            "Epoch: [58][210/391]\tTime  0.110 ( 0.105)\tLoss 1.6776e+00 (1.4005e+00)\tAcc@1  52.34 ( 60.04)\tAcc@5  89.84 ( 87.98)\n",
            "Epoch: [58][240/391]\tTime  0.099 ( 0.105)\tLoss 1.3199e+00 (1.4057e+00)\tAcc@1  63.28 ( 59.83)\tAcc@5  90.62 ( 87.95)\n",
            "Epoch: [58][270/391]\tTime  0.098 ( 0.104)\tLoss 1.3250e+00 (1.4095e+00)\tAcc@1  58.59 ( 59.72)\tAcc@5  88.28 ( 87.91)\n",
            "Epoch: [58][300/391]\tTime  0.100 ( 0.104)\tLoss 1.5289e+00 (1.4113e+00)\tAcc@1  60.16 ( 59.65)\tAcc@5  83.59 ( 87.86)\n",
            "Epoch: [58][330/391]\tTime  0.101 ( 0.104)\tLoss 1.6279e+00 (1.4168e+00)\tAcc@1  55.47 ( 59.51)\tAcc@5  86.72 ( 87.76)\n",
            "Epoch: [58][360/391]\tTime  0.099 ( 0.104)\tLoss 1.5983e+00 (1.4220e+00)\tAcc@1  57.03 ( 59.35)\tAcc@5  87.50 ( 87.67)\n",
            "Epoch: [58][390/391]\tTime  0.048 ( 0.103)\tLoss 1.1817e+00 (1.4245e+00)\tAcc@1  67.50 ( 59.30)\tAcc@5  91.25 ( 87.63)\n",
            "==> Train Accuracy: Acc@1 59.296 || Acc@5 87.626\n",
            "==> Test Accuracy:  Acc@1 49.680 || Acc@5 79.170\n",
            "==> 58.06 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 59, lr: 0.1 -----\n",
            "Epoch: [59][  0/391]\tTime  0.333 ( 0.333)\tLoss 1.4904e+00 (1.4904e+00)\tAcc@1  57.03 ( 57.03)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [59][ 30/391]\tTime  0.103 ( 0.115)\tLoss 1.2337e+00 (1.3331e+00)\tAcc@1  63.28 ( 60.81)\tAcc@5  90.62 ( 89.09)\n",
            "Epoch: [59][ 60/391]\tTime  0.115 ( 0.109)\tLoss 1.4706e+00 (1.3453e+00)\tAcc@1  51.56 ( 61.36)\tAcc@5  85.94 ( 88.96)\n",
            "Epoch: [59][ 90/391]\tTime  0.102 ( 0.106)\tLoss 1.4949e+00 (1.3629e+00)\tAcc@1  59.38 ( 60.94)\tAcc@5  85.94 ( 88.60)\n",
            "Epoch: [59][120/391]\tTime  0.098 ( 0.105)\tLoss 1.4241e+00 (1.3649e+00)\tAcc@1  57.03 ( 60.88)\tAcc@5  87.50 ( 88.53)\n",
            "Epoch: [59][150/391]\tTime  0.098 ( 0.104)\tLoss 1.1670e+00 (1.3697e+00)\tAcc@1  69.53 ( 60.77)\tAcc@5  90.62 ( 88.44)\n",
            "Epoch: [59][180/391]\tTime  0.100 ( 0.104)\tLoss 1.5049e+00 (1.3857e+00)\tAcc@1  60.16 ( 60.39)\tAcc@5  85.94 ( 88.32)\n",
            "Epoch: [59][210/391]\tTime  0.100 ( 0.104)\tLoss 1.7011e+00 (1.4048e+00)\tAcc@1  50.00 ( 60.02)\tAcc@5  83.59 ( 87.96)\n",
            "Epoch: [59][240/391]\tTime  0.100 ( 0.104)\tLoss 1.3999e+00 (1.4079e+00)\tAcc@1  64.06 ( 59.96)\tAcc@5  89.06 ( 87.89)\n",
            "Epoch: [59][270/391]\tTime  0.097 ( 0.104)\tLoss 1.2945e+00 (1.4079e+00)\tAcc@1  64.06 ( 59.98)\tAcc@5  88.28 ( 87.87)\n",
            "Epoch: [59][300/391]\tTime  0.109 ( 0.104)\tLoss 1.4937e+00 (1.4102e+00)\tAcc@1  57.03 ( 59.84)\tAcc@5  85.16 ( 87.84)\n",
            "Epoch: [59][330/391]\tTime  0.099 ( 0.104)\tLoss 1.4490e+00 (1.4126e+00)\tAcc@1  56.25 ( 59.71)\tAcc@5  85.94 ( 87.82)\n",
            "Epoch: [59][360/391]\tTime  0.099 ( 0.103)\tLoss 1.2109e+00 (1.4138e+00)\tAcc@1  65.62 ( 59.69)\tAcc@5  95.31 ( 87.81)\n",
            "Epoch: [59][390/391]\tTime  0.049 ( 0.103)\tLoss 1.8036e+00 (1.4182e+00)\tAcc@1  51.25 ( 59.54)\tAcc@5  81.25 ( 87.71)\n",
            "==> Train Accuracy: Acc@1 59.536 || Acc@5 87.714\n",
            "==> Test Accuracy:  Acc@1 49.610 || Acc@5 80.150\n",
            "==> 57.67 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 60, lr: 0.020000000000000004 -----\n",
            "Epoch: [60][  0/391]\tTime  0.361 ( 0.361)\tLoss 1.4053e+00 (1.4053e+00)\tAcc@1  58.59 ( 58.59)\tAcc@5  88.28 ( 88.28)\n",
            "Epoch: [60][ 30/391]\tTime  0.100 ( 0.112)\tLoss 9.1750e-01 (1.2211e+00)\tAcc@1  72.66 ( 64.44)\tAcc@5  97.66 ( 90.50)\n",
            "Epoch: [60][ 60/391]\tTime  0.099 ( 0.107)\tLoss 9.9958e-01 (1.1370e+00)\tAcc@1  71.09 ( 67.51)\tAcc@5  93.75 ( 91.33)\n",
            "Epoch: [60][ 90/391]\tTime  0.097 ( 0.105)\tLoss 1.0014e+00 (1.0924e+00)\tAcc@1  71.09 ( 68.71)\tAcc@5  93.75 ( 91.92)\n",
            "Epoch: [60][120/391]\tTime  0.098 ( 0.104)\tLoss 9.9257e-01 (1.0692e+00)\tAcc@1  71.09 ( 69.31)\tAcc@5  94.53 ( 92.21)\n",
            "Epoch: [60][150/391]\tTime  0.099 ( 0.103)\tLoss 9.4665e-01 (1.0457e+00)\tAcc@1  75.00 ( 69.90)\tAcc@5  94.53 ( 92.55)\n",
            "Epoch: [60][180/391]\tTime  0.098 ( 0.103)\tLoss 8.8439e-01 (1.0265e+00)\tAcc@1  73.44 ( 70.43)\tAcc@5  93.75 ( 92.74)\n",
            "Epoch: [60][210/391]\tTime  0.097 ( 0.103)\tLoss 7.5111e-01 (1.0181e+00)\tAcc@1  72.66 ( 70.61)\tAcc@5  97.66 ( 92.84)\n",
            "Epoch: [60][240/391]\tTime  0.097 ( 0.103)\tLoss 8.7030e-01 (1.0091e+00)\tAcc@1  74.22 ( 70.76)\tAcc@5  94.53 ( 93.04)\n",
            "Epoch: [60][270/391]\tTime  0.122 ( 0.103)\tLoss 1.0334e+00 (9.9847e-01)\tAcc@1  68.75 ( 71.06)\tAcc@5  92.19 ( 93.17)\n",
            "Epoch: [60][300/391]\tTime  0.101 ( 0.103)\tLoss 1.0735e+00 (9.9478e-01)\tAcc@1  67.97 ( 71.07)\tAcc@5  88.28 ( 93.18)\n",
            "Epoch: [60][330/391]\tTime  0.104 ( 0.102)\tLoss 7.4762e-01 (9.8348e-01)\tAcc@1  77.34 ( 71.36)\tAcc@5  96.88 ( 93.29)\n",
            "Epoch: [60][360/391]\tTime  0.099 ( 0.102)\tLoss 9.1526e-01 (9.7333e-01)\tAcc@1  72.66 ( 71.63)\tAcc@5  92.19 ( 93.41)\n",
            "Epoch: [60][390/391]\tTime  0.047 ( 0.102)\tLoss 1.0449e+00 (9.6624e-01)\tAcc@1  72.50 ( 71.82)\tAcc@5  91.25 ( 93.48)\n",
            "==> Train Accuracy: Acc@1 71.820 || Acc@5 93.482\n",
            "==> Test Accuracy:  Acc@1 64.600 || Acc@5 89.270\n",
            "==> 57.06 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 61, lr: 0.020000000000000004 -----\n",
            "Epoch: [61][  0/391]\tTime  0.363 ( 0.363)\tLoss 7.9649e-01 (7.9649e-01)\tAcc@1  75.78 ( 75.78)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [61][ 30/391]\tTime  0.098 ( 0.109)\tLoss 8.6011e-01 (8.2243e-01)\tAcc@1  75.00 ( 75.83)\tAcc@5  92.97 ( 94.93)\n",
            "Epoch: [61][ 60/391]\tTime  0.096 ( 0.105)\tLoss 8.3822e-01 (8.1498e-01)\tAcc@1  75.78 ( 76.22)\tAcc@5  94.53 ( 95.12)\n",
            "Epoch: [61][ 90/391]\tTime  0.099 ( 0.103)\tLoss 8.0121e-01 (8.0888e-01)\tAcc@1  73.44 ( 76.43)\tAcc@5  94.53 ( 95.18)\n",
            "Epoch: [61][120/391]\tTime  0.095 ( 0.102)\tLoss 7.0815e-01 (8.1381e-01)\tAcc@1  80.47 ( 76.28)\tAcc@5  96.09 ( 95.23)\n",
            "Epoch: [61][150/391]\tTime  0.096 ( 0.102)\tLoss 7.8936e-01 (8.1739e-01)\tAcc@1  74.22 ( 76.00)\tAcc@5  97.66 ( 95.17)\n",
            "Epoch: [61][180/391]\tTime  0.095 ( 0.102)\tLoss 5.5115e-01 (8.1272e-01)\tAcc@1  82.81 ( 75.99)\tAcc@5  96.88 ( 95.30)\n",
            "Epoch: [61][210/391]\tTime  0.098 ( 0.101)\tLoss 7.3200e-01 (8.1373e-01)\tAcc@1  75.00 ( 75.96)\tAcc@5  96.88 ( 95.29)\n",
            "Epoch: [61][240/391]\tTime  0.098 ( 0.101)\tLoss 6.5678e-01 (8.1168e-01)\tAcc@1  80.47 ( 76.05)\tAcc@5  97.66 ( 95.34)\n",
            "Epoch: [61][270/391]\tTime  0.097 ( 0.101)\tLoss 7.6046e-01 (8.1240e-01)\tAcc@1  78.91 ( 76.06)\tAcc@5  96.88 ( 95.30)\n",
            "Epoch: [61][300/391]\tTime  0.096 ( 0.101)\tLoss 6.6300e-01 (8.0923e-01)\tAcc@1  80.47 ( 76.11)\tAcc@5  96.09 ( 95.36)\n",
            "Epoch: [61][330/391]\tTime  0.101 ( 0.101)\tLoss 7.5809e-01 (8.0985e-01)\tAcc@1  79.69 ( 76.01)\tAcc@5  94.53 ( 95.33)\n",
            "Epoch: [61][360/391]\tTime  0.117 ( 0.101)\tLoss 7.8289e-01 (8.0931e-01)\tAcc@1  74.22 ( 76.02)\tAcc@5  96.09 ( 95.35)\n",
            "Epoch: [61][390/391]\tTime  0.049 ( 0.100)\tLoss 8.5090e-01 (8.0962e-01)\tAcc@1  75.00 ( 76.00)\tAcc@5  93.75 ( 95.33)\n",
            "==> Train Accuracy: Acc@1 76.002 || Acc@5 95.332\n",
            "==> Test Accuracy:  Acc@1 65.050 || Acc@5 89.830\n",
            "==> 56.76 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 62, lr: 0.020000000000000004 -----\n",
            "Epoch: [62][  0/391]\tTime  0.343 ( 0.343)\tLoss 7.9334e-01 (7.9334e-01)\tAcc@1  77.34 ( 77.34)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [62][ 30/391]\tTime  0.097 ( 0.109)\tLoss 8.2134e-01 (7.3459e-01)\tAcc@1  78.12 ( 78.00)\tAcc@5  94.53 ( 96.27)\n",
            "Epoch: [62][ 60/391]\tTime  0.096 ( 0.105)\tLoss 7.8800e-01 (7.2750e-01)\tAcc@1  75.78 ( 78.29)\tAcc@5  97.66 ( 96.30)\n",
            "Epoch: [62][ 90/391]\tTime  0.098 ( 0.103)\tLoss 7.7884e-01 (7.2012e-01)\tAcc@1  77.34 ( 78.40)\tAcc@5  98.44 ( 96.42)\n",
            "Epoch: [62][120/391]\tTime  0.095 ( 0.102)\tLoss 8.0745e-01 (7.3166e-01)\tAcc@1  74.22 ( 78.00)\tAcc@5  96.09 ( 96.35)\n",
            "Epoch: [62][150/391]\tTime  0.098 ( 0.101)\tLoss 5.7664e-01 (7.2157e-01)\tAcc@1  82.81 ( 78.35)\tAcc@5  98.44 ( 96.36)\n",
            "Epoch: [62][180/391]\tTime  0.099 ( 0.101)\tLoss 7.0814e-01 (7.3055e-01)\tAcc@1  78.91 ( 78.13)\tAcc@5  96.09 ( 96.28)\n",
            "Epoch: [62][210/391]\tTime  0.095 ( 0.100)\tLoss 8.0081e-01 (7.3795e-01)\tAcc@1  74.22 ( 77.87)\tAcc@5  96.09 ( 96.20)\n",
            "Epoch: [62][240/391]\tTime  0.102 ( 0.101)\tLoss 5.6414e-01 (7.4109e-01)\tAcc@1  79.69 ( 77.84)\tAcc@5  99.22 ( 96.15)\n",
            "Epoch: [62][270/391]\tTime  0.096 ( 0.101)\tLoss 7.5890e-01 (7.4343e-01)\tAcc@1  73.44 ( 77.76)\tAcc@5  94.53 ( 96.11)\n",
            "Epoch: [62][300/391]\tTime  0.107 ( 0.101)\tLoss 8.9841e-01 (7.4315e-01)\tAcc@1  80.47 ( 77.83)\tAcc@5  92.97 ( 96.08)\n",
            "Epoch: [62][330/391]\tTime  0.098 ( 0.101)\tLoss 8.1432e-01 (7.4483e-01)\tAcc@1  76.56 ( 77.76)\tAcc@5  96.88 ( 96.04)\n",
            "Epoch: [62][360/391]\tTime  0.098 ( 0.101)\tLoss 9.2345e-01 (7.4693e-01)\tAcc@1  73.44 ( 77.74)\tAcc@5  95.31 ( 96.03)\n",
            "Epoch: [62][390/391]\tTime  0.048 ( 0.100)\tLoss 1.2869e+00 (7.4829e-01)\tAcc@1  70.00 ( 77.69)\tAcc@5  87.50 ( 96.02)\n",
            "==> Train Accuracy: Acc@1 77.692 || Acc@5 96.016\n",
            "==> Test Accuracy:  Acc@1 65.580 || Acc@5 89.440\n",
            "==> 56.64 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 63, lr: 0.020000000000000004 -----\n",
            "Epoch: [63][  0/391]\tTime  0.375 ( 0.375)\tLoss 7.2150e-01 (7.2150e-01)\tAcc@1  78.12 ( 78.12)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [63][ 30/391]\tTime  0.096 ( 0.116)\tLoss 6.7665e-01 (7.0390e-01)\tAcc@1  79.69 ( 78.70)\tAcc@5  93.75 ( 96.45)\n",
            "Epoch: [63][ 60/391]\tTime  0.097 ( 0.108)\tLoss 8.6028e-01 (6.9409e-01)\tAcc@1  69.53 ( 78.94)\tAcc@5  96.09 ( 96.55)\n",
            "Epoch: [63][ 90/391]\tTime  0.096 ( 0.105)\tLoss 8.4132e-01 (6.9260e-01)\tAcc@1  71.88 ( 79.09)\tAcc@5  98.44 ( 96.52)\n",
            "Epoch: [63][120/391]\tTime  0.096 ( 0.104)\tLoss 7.1940e-01 (6.9707e-01)\tAcc@1  77.34 ( 78.93)\tAcc@5  96.09 ( 96.58)\n",
            "Epoch: [63][150/391]\tTime  0.096 ( 0.103)\tLoss 6.3313e-01 (6.9377e-01)\tAcc@1  78.91 ( 78.94)\tAcc@5  99.22 ( 96.66)\n",
            "Epoch: [63][180/391]\tTime  0.098 ( 0.102)\tLoss 8.5897e-01 (6.9587e-01)\tAcc@1  74.22 ( 79.00)\tAcc@5  96.09 ( 96.59)\n",
            "Epoch: [63][210/391]\tTime  0.098 ( 0.101)\tLoss 7.8428e-01 (6.9966e-01)\tAcc@1  75.00 ( 78.89)\tAcc@5  96.88 ( 96.52)\n",
            "Epoch: [63][240/391]\tTime  0.097 ( 0.102)\tLoss 7.3372e-01 (7.0170e-01)\tAcc@1  78.12 ( 78.84)\tAcc@5  96.09 ( 96.50)\n",
            "Epoch: [63][270/391]\tTime  0.098 ( 0.101)\tLoss 6.3599e-01 (7.0503e-01)\tAcc@1  78.12 ( 78.70)\tAcc@5  97.66 ( 96.48)\n",
            "Epoch: [63][300/391]\tTime  0.097 ( 0.101)\tLoss 6.9657e-01 (7.0858e-01)\tAcc@1  78.91 ( 78.54)\tAcc@5  95.31 ( 96.41)\n",
            "Epoch: [63][330/391]\tTime  0.097 ( 0.102)\tLoss 6.0157e-01 (7.0893e-01)\tAcc@1  80.47 ( 78.53)\tAcc@5  96.88 ( 96.38)\n",
            "Epoch: [63][360/391]\tTime  0.099 ( 0.101)\tLoss 6.4371e-01 (7.1103e-01)\tAcc@1  83.59 ( 78.51)\tAcc@5  96.88 ( 96.32)\n",
            "Epoch: [63][390/391]\tTime  0.048 ( 0.101)\tLoss 4.7850e-01 (7.1182e-01)\tAcc@1  85.00 ( 78.47)\tAcc@5 100.00 ( 96.30)\n",
            "==> Train Accuracy: Acc@1 78.466 || Acc@5 96.304\n",
            "==> Test Accuracy:  Acc@1 65.740 || Acc@5 89.570\n",
            "==> 56.85 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 64, lr: 0.020000000000000004 -----\n",
            "Epoch: [64][  0/391]\tTime  0.357 ( 0.357)\tLoss 5.2836e-01 (5.2836e-01)\tAcc@1  87.50 ( 87.50)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [64][ 30/391]\tTime  0.101 ( 0.110)\tLoss 6.5800e-01 (6.4866e-01)\tAcc@1  76.56 ( 80.82)\tAcc@5  97.66 ( 96.75)\n",
            "Epoch: [64][ 60/391]\tTime  0.098 ( 0.106)\tLoss 7.2753e-01 (6.5507e-01)\tAcc@1  80.47 ( 80.62)\tAcc@5  93.75 ( 96.55)\n",
            "Epoch: [64][ 90/391]\tTime  0.101 ( 0.104)\tLoss 5.4107e-01 (6.5835e-01)\tAcc@1  87.50 ( 80.45)\tAcc@5  97.66 ( 96.54)\n",
            "Epoch: [64][120/391]\tTime  0.100 ( 0.104)\tLoss 7.0355e-01 (6.6732e-01)\tAcc@1  80.47 ( 80.11)\tAcc@5  96.09 ( 96.62)\n",
            "Epoch: [64][150/391]\tTime  0.098 ( 0.104)\tLoss 6.6906e-01 (6.6865e-01)\tAcc@1  78.91 ( 80.04)\tAcc@5  97.66 ( 96.62)\n",
            "Epoch: [64][180/391]\tTime  0.097 ( 0.103)\tLoss 8.1667e-01 (6.6434e-01)\tAcc@1  75.00 ( 80.12)\tAcc@5  96.09 ( 96.72)\n",
            "Epoch: [64][210/391]\tTime  0.098 ( 0.102)\tLoss 8.9573e-01 (6.6449e-01)\tAcc@1  76.56 ( 80.21)\tAcc@5  94.53 ( 96.75)\n",
            "Epoch: [64][240/391]\tTime  0.096 ( 0.102)\tLoss 6.8214e-01 (6.6618e-01)\tAcc@1  78.12 ( 80.14)\tAcc@5  98.44 ( 96.76)\n",
            "Epoch: [64][270/391]\tTime  0.095 ( 0.101)\tLoss 5.7986e-01 (6.6908e-01)\tAcc@1  78.91 ( 80.01)\tAcc@5  97.66 ( 96.72)\n",
            "Epoch: [64][300/391]\tTime  0.100 ( 0.101)\tLoss 7.1768e-01 (6.7040e-01)\tAcc@1  78.91 ( 79.97)\tAcc@5  95.31 ( 96.71)\n",
            "Epoch: [64][330/391]\tTime  0.098 ( 0.101)\tLoss 5.7874e-01 (6.7123e-01)\tAcc@1  81.25 ( 79.87)\tAcc@5  96.88 ( 96.69)\n",
            "Epoch: [64][360/391]\tTime  0.106 ( 0.102)\tLoss 8.1638e-01 (6.7535e-01)\tAcc@1  71.09 ( 79.72)\tAcc@5  95.31 ( 96.67)\n",
            "Epoch: [64][390/391]\tTime  0.049 ( 0.101)\tLoss 7.8786e-01 (6.7794e-01)\tAcc@1  73.75 ( 79.62)\tAcc@5  93.75 ( 96.63)\n",
            "==> Train Accuracy: Acc@1 79.622 || Acc@5 96.626\n",
            "==> Test Accuracy:  Acc@1 66.220 || Acc@5 90.160\n",
            "==> 56.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 65, lr: 0.020000000000000004 -----\n",
            "Epoch: [65][  0/391]\tTime  0.363 ( 0.363)\tLoss 4.7100e-01 (4.7100e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [65][ 30/391]\tTime  0.102 ( 0.110)\tLoss 5.8672e-01 (5.9197e-01)\tAcc@1  82.03 ( 82.48)\tAcc@5  99.22 ( 97.58)\n",
            "Epoch: [65][ 60/391]\tTime  0.098 ( 0.104)\tLoss 7.1210e-01 (5.9586e-01)\tAcc@1  82.03 ( 82.07)\tAcc@5  96.88 ( 97.55)\n",
            "Epoch: [65][ 90/391]\tTime  0.097 ( 0.103)\tLoss 7.7635e-01 (6.1395e-01)\tAcc@1  75.00 ( 81.34)\tAcc@5  92.97 ( 97.33)\n",
            "Epoch: [65][120/391]\tTime  0.099 ( 0.102)\tLoss 5.4752e-01 (6.1755e-01)\tAcc@1  81.25 ( 81.21)\tAcc@5  96.09 ( 97.28)\n",
            "Epoch: [65][150/391]\tTime  0.099 ( 0.102)\tLoss 7.3884e-01 (6.1793e-01)\tAcc@1  76.56 ( 81.23)\tAcc@5  96.88 ( 97.28)\n",
            "Epoch: [65][180/391]\tTime  0.100 ( 0.101)\tLoss 6.5991e-01 (6.2292e-01)\tAcc@1  81.25 ( 81.17)\tAcc@5  96.09 ( 97.24)\n",
            "Epoch: [65][210/391]\tTime  0.096 ( 0.102)\tLoss 5.6124e-01 (6.2468e-01)\tAcc@1  80.47 ( 81.07)\tAcc@5  98.44 ( 97.20)\n",
            "Epoch: [65][240/391]\tTime  0.096 ( 0.101)\tLoss 6.7584e-01 (6.2939e-01)\tAcc@1  82.81 ( 81.01)\tAcc@5  98.44 ( 97.11)\n",
            "Epoch: [65][270/391]\tTime  0.098 ( 0.101)\tLoss 5.4368e-01 (6.2999e-01)\tAcc@1  85.94 ( 80.98)\tAcc@5  99.22 ( 97.13)\n",
            "Epoch: [65][300/391]\tTime  0.097 ( 0.101)\tLoss 6.0600e-01 (6.3161e-01)\tAcc@1  82.81 ( 80.91)\tAcc@5  97.66 ( 97.14)\n",
            "Epoch: [65][330/391]\tTime  0.098 ( 0.101)\tLoss 5.6951e-01 (6.3501e-01)\tAcc@1  82.03 ( 80.80)\tAcc@5  96.88 ( 97.10)\n",
            "Epoch: [65][360/391]\tTime  0.102 ( 0.101)\tLoss 7.7168e-01 (6.3827e-01)\tAcc@1  81.25 ( 80.71)\tAcc@5  94.53 ( 97.04)\n",
            "Epoch: [65][390/391]\tTime  0.046 ( 0.100)\tLoss 6.8318e-01 (6.4349e-01)\tAcc@1  82.50 ( 80.57)\tAcc@5  96.25 ( 97.03)\n",
            "==> Train Accuracy: Acc@1 80.574 || Acc@5 97.026\n",
            "==> Test Accuracy:  Acc@1 65.500 || Acc@5 89.300\n",
            "==> 56.74 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 66, lr: 0.020000000000000004 -----\n",
            "Epoch: [66][  0/391]\tTime  0.345 ( 0.345)\tLoss 6.2194e-01 (6.2194e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  96.88 ( 96.88)\n",
            "Epoch: [66][ 30/391]\tTime  0.097 ( 0.108)\tLoss 6.8816e-01 (5.9957e-01)\tAcc@1  80.47 ( 82.16)\tAcc@5  96.09 ( 97.03)\n",
            "Epoch: [66][ 60/391]\tTime  0.097 ( 0.103)\tLoss 6.5626e-01 (6.0201e-01)\tAcc@1  76.56 ( 81.88)\tAcc@5  96.09 ( 97.27)\n",
            "Epoch: [66][ 90/391]\tTime  0.098 ( 0.102)\tLoss 7.3817e-01 (5.9581e-01)\tAcc@1  77.34 ( 82.13)\tAcc@5  96.09 ( 97.41)\n",
            "Epoch: [66][120/391]\tTime  0.097 ( 0.101)\tLoss 6.0456e-01 (5.9792e-01)\tAcc@1  82.03 ( 82.06)\tAcc@5  98.44 ( 97.47)\n",
            "Epoch: [66][150/391]\tTime  0.101 ( 0.100)\tLoss 7.2842e-01 (5.9945e-01)\tAcc@1  78.12 ( 82.11)\tAcc@5  96.09 ( 97.41)\n",
            "Epoch: [66][180/391]\tTime  0.104 ( 0.100)\tLoss 6.5024e-01 (6.0334e-01)\tAcc@1  79.69 ( 81.86)\tAcc@5  99.22 ( 97.45)\n",
            "Epoch: [66][210/391]\tTime  0.101 ( 0.100)\tLoss 7.1768e-01 (6.1075e-01)\tAcc@1  82.81 ( 81.66)\tAcc@5  97.66 ( 97.36)\n",
            "Epoch: [66][240/391]\tTime  0.098 ( 0.100)\tLoss 5.8926e-01 (6.1695e-01)\tAcc@1  82.03 ( 81.47)\tAcc@5  99.22 ( 97.34)\n",
            "Epoch: [66][270/391]\tTime  0.096 ( 0.100)\tLoss 6.2741e-01 (6.2252e-01)\tAcc@1  75.78 ( 81.25)\tAcc@5  98.44 ( 97.31)\n",
            "Epoch: [66][300/391]\tTime  0.098 ( 0.101)\tLoss 5.7313e-01 (6.2364e-01)\tAcc@1  85.94 ( 81.23)\tAcc@5  96.88 ( 97.25)\n",
            "Epoch: [66][330/391]\tTime  0.098 ( 0.100)\tLoss 9.0664e-01 (6.2987e-01)\tAcc@1  75.78 ( 80.98)\tAcc@5  92.19 ( 97.18)\n",
            "Epoch: [66][360/391]\tTime  0.096 ( 0.100)\tLoss 6.9392e-01 (6.3241e-01)\tAcc@1  78.91 ( 80.90)\tAcc@5  98.44 ( 97.18)\n",
            "Epoch: [66][390/391]\tTime  0.049 ( 0.100)\tLoss 6.8239e-01 (6.3513e-01)\tAcc@1  78.75 ( 80.79)\tAcc@5  95.00 ( 97.17)\n",
            "==> Train Accuracy: Acc@1 80.788 || Acc@5 97.174\n",
            "==> Test Accuracy:  Acc@1 64.400 || Acc@5 89.050\n",
            "==> 56.61 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 67, lr: 0.020000000000000004 -----\n",
            "Epoch: [67][  0/391]\tTime  0.375 ( 0.375)\tLoss 6.4868e-01 (6.4868e-01)\tAcc@1  78.91 ( 78.91)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [67][ 30/391]\tTime  0.095 ( 0.108)\tLoss 4.8596e-01 (5.7166e-01)\tAcc@1  85.94 ( 82.99)\tAcc@5  99.22 ( 97.45)\n",
            "Epoch: [67][ 60/391]\tTime  0.100 ( 0.104)\tLoss 6.1408e-01 (5.7618e-01)\tAcc@1  82.03 ( 82.74)\tAcc@5  98.44 ( 97.43)\n",
            "Epoch: [67][ 90/391]\tTime  0.098 ( 0.103)\tLoss 5.7780e-01 (5.8744e-01)\tAcc@1  82.03 ( 82.35)\tAcc@5  98.44 ( 97.45)\n",
            "Epoch: [67][120/391]\tTime  0.096 ( 0.102)\tLoss 4.4286e-01 (5.8502e-01)\tAcc@1  85.94 ( 82.27)\tAcc@5  99.22 ( 97.49)\n",
            "Epoch: [67][150/391]\tTime  0.097 ( 0.101)\tLoss 6.9396e-01 (5.8407e-01)\tAcc@1  75.78 ( 82.23)\tAcc@5 100.00 ( 97.60)\n",
            "Epoch: [67][180/391]\tTime  0.094 ( 0.101)\tLoss 5.9648e-01 (5.8741e-01)\tAcc@1  77.34 ( 82.18)\tAcc@5  96.88 ( 97.53)\n",
            "Epoch: [67][210/391]\tTime  0.099 ( 0.101)\tLoss 6.3601e-01 (5.9236e-01)\tAcc@1  82.81 ( 82.03)\tAcc@5  97.66 ( 97.52)\n",
            "Epoch: [67][240/391]\tTime  0.098 ( 0.100)\tLoss 6.4489e-01 (5.9775e-01)\tAcc@1  81.25 ( 81.87)\tAcc@5  97.66 ( 97.48)\n",
            "Epoch: [67][270/391]\tTime  0.104 ( 0.100)\tLoss 5.6666e-01 (5.9858e-01)\tAcc@1  84.38 ( 81.84)\tAcc@5  98.44 ( 97.49)\n",
            "Epoch: [67][300/391]\tTime  0.101 ( 0.100)\tLoss 7.9068e-01 (6.0228e-01)\tAcc@1  75.00 ( 81.70)\tAcc@5  95.31 ( 97.45)\n",
            "Epoch: [67][330/391]\tTime  0.097 ( 0.100)\tLoss 6.0330e-01 (6.0534e-01)\tAcc@1  84.38 ( 81.62)\tAcc@5  93.75 ( 97.39)\n",
            "Epoch: [67][360/391]\tTime  0.097 ( 0.100)\tLoss 5.2986e-01 (6.0818e-01)\tAcc@1  84.38 ( 81.51)\tAcc@5  98.44 ( 97.41)\n",
            "Epoch: [67][390/391]\tTime  0.048 ( 0.100)\tLoss 7.9259e-01 (6.1179e-01)\tAcc@1  75.00 ( 81.38)\tAcc@5  95.00 ( 97.39)\n",
            "==> Train Accuracy: Acc@1 81.378 || Acc@5 97.386\n",
            "==> Test Accuracy:  Acc@1 65.000 || Acc@5 88.810\n",
            "==> 56.49 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 68, lr: 0.020000000000000004 -----\n",
            "Epoch: [68][  0/391]\tTime  0.347 ( 0.347)\tLoss 4.5219e-01 (4.5219e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [68][ 30/391]\tTime  0.097 ( 0.112)\tLoss 4.9575e-01 (5.6272e-01)\tAcc@1  82.03 ( 83.06)\tAcc@5  98.44 ( 97.71)\n",
            "Epoch: [68][ 60/391]\tTime  0.095 ( 0.106)\tLoss 5.4182e-01 (5.6032e-01)\tAcc@1  82.03 ( 82.86)\tAcc@5  96.09 ( 97.77)\n",
            "Epoch: [68][ 90/391]\tTime  0.096 ( 0.104)\tLoss 6.2278e-01 (5.6535e-01)\tAcc@1  82.03 ( 82.78)\tAcc@5  97.66 ( 97.80)\n",
            "Epoch: [68][120/391]\tTime  0.102 ( 0.103)\tLoss 5.9860e-01 (5.6624e-01)\tAcc@1  83.59 ( 82.80)\tAcc@5  96.88 ( 97.77)\n",
            "Epoch: [68][150/391]\tTime  0.098 ( 0.103)\tLoss 5.2058e-01 (5.6713e-01)\tAcc@1  83.59 ( 82.79)\tAcc@5  96.09 ( 97.73)\n",
            "Epoch: [68][180/391]\tTime  0.099 ( 0.102)\tLoss 7.2800e-01 (5.7889e-01)\tAcc@1  78.91 ( 82.47)\tAcc@5  96.09 ( 97.61)\n",
            "Epoch: [68][210/391]\tTime  0.096 ( 0.101)\tLoss 4.6766e-01 (5.8263e-01)\tAcc@1  89.06 ( 82.33)\tAcc@5  97.66 ( 97.57)\n",
            "Epoch: [68][240/391]\tTime  0.095 ( 0.101)\tLoss 5.3407e-01 (5.8404e-01)\tAcc@1  82.81 ( 82.21)\tAcc@5  97.66 ( 97.54)\n",
            "Epoch: [68][270/391]\tTime  0.096 ( 0.101)\tLoss 7.1117e-01 (5.8956e-01)\tAcc@1  80.47 ( 81.99)\tAcc@5  97.66 ( 97.54)\n",
            "Epoch: [68][300/391]\tTime  0.104 ( 0.101)\tLoss 5.6697e-01 (5.9364e-01)\tAcc@1  82.03 ( 81.83)\tAcc@5  98.44 ( 97.55)\n",
            "Epoch: [68][330/391]\tTime  0.099 ( 0.101)\tLoss 6.1299e-01 (5.9837e-01)\tAcc@1  81.25 ( 81.66)\tAcc@5  99.22 ( 97.53)\n",
            "Epoch: [68][360/391]\tTime  0.100 ( 0.101)\tLoss 8.4737e-01 (6.0328e-01)\tAcc@1  75.00 ( 81.48)\tAcc@5  94.53 ( 97.49)\n",
            "Epoch: [68][390/391]\tTime  0.049 ( 0.100)\tLoss 6.7730e-01 (6.0772e-01)\tAcc@1  81.25 ( 81.35)\tAcc@5  98.75 ( 97.47)\n",
            "==> Train Accuracy: Acc@1 81.348 || Acc@5 97.474\n",
            "==> Test Accuracy:  Acc@1 65.010 || Acc@5 89.220\n",
            "==> 56.77 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 69, lr: 0.020000000000000004 -----\n",
            "Epoch: [69][  0/391]\tTime  0.350 ( 0.350)\tLoss 5.7848e-01 (5.7848e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [69][ 30/391]\tTime  0.099 ( 0.109)\tLoss 4.4103e-01 (5.4001e-01)\tAcc@1  88.28 ( 83.34)\tAcc@5  97.66 ( 98.36)\n",
            "Epoch: [69][ 60/391]\tTime  0.105 ( 0.104)\tLoss 4.5502e-01 (5.5004e-01)\tAcc@1  80.47 ( 82.77)\tAcc@5  98.44 ( 98.21)\n",
            "Epoch: [69][ 90/391]\tTime  0.105 ( 0.103)\tLoss 5.3753e-01 (5.6215e-01)\tAcc@1  79.69 ( 82.75)\tAcc@5  99.22 ( 97.94)\n",
            "Epoch: [69][120/391]\tTime  0.108 ( 0.103)\tLoss 5.0246e-01 (5.6141e-01)\tAcc@1  82.03 ( 82.64)\tAcc@5  99.22 ( 97.99)\n",
            "Epoch: [69][150/391]\tTime  0.100 ( 0.102)\tLoss 6.0101e-01 (5.6904e-01)\tAcc@1  82.03 ( 82.38)\tAcc@5 100.00 ( 97.94)\n",
            "Epoch: [69][180/391]\tTime  0.099 ( 0.102)\tLoss 6.2117e-01 (5.7382e-01)\tAcc@1  82.03 ( 82.29)\tAcc@5  96.09 ( 97.82)\n",
            "Epoch: [69][210/391]\tTime  0.101 ( 0.102)\tLoss 6.7301e-01 (5.7952e-01)\tAcc@1  81.25 ( 82.09)\tAcc@5  96.88 ( 97.79)\n",
            "Epoch: [69][240/391]\tTime  0.099 ( 0.102)\tLoss 5.9787e-01 (5.8021e-01)\tAcc@1  79.69 ( 82.11)\tAcc@5  99.22 ( 97.80)\n",
            "Epoch: [69][270/391]\tTime  0.097 ( 0.102)\tLoss 7.7953e-01 (5.8786e-01)\tAcc@1  75.78 ( 81.78)\tAcc@5  95.31 ( 97.72)\n",
            "Epoch: [69][300/391]\tTime  0.102 ( 0.101)\tLoss 7.4476e-01 (5.9349e-01)\tAcc@1  76.56 ( 81.66)\tAcc@5  96.88 ( 97.66)\n",
            "Epoch: [69][330/391]\tTime  0.094 ( 0.102)\tLoss 5.1386e-01 (5.9643e-01)\tAcc@1  85.16 ( 81.55)\tAcc@5  98.44 ( 97.64)\n",
            "Epoch: [69][360/391]\tTime  0.096 ( 0.101)\tLoss 8.0038e-01 (6.0344e-01)\tAcc@1  74.22 ( 81.35)\tAcc@5  96.09 ( 97.54)\n",
            "Epoch: [69][390/391]\tTime  0.048 ( 0.101)\tLoss 6.5120e-01 (6.0624e-01)\tAcc@1  77.50 ( 81.23)\tAcc@5  97.50 ( 97.48)\n",
            "==> Train Accuracy: Acc@1 81.226 || Acc@5 97.482\n",
            "==> Test Accuracy:  Acc@1 63.930 || Acc@5 88.910\n",
            "==> 56.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 70, lr: 0.020000000000000004 -----\n",
            "Epoch: [70][  0/391]\tTime  0.334 ( 0.334)\tLoss 5.1626e-01 (5.1626e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [70][ 30/391]\tTime  0.098 ( 0.109)\tLoss 5.5182e-01 (5.2685e-01)\tAcc@1  82.03 ( 84.07)\tAcc@5  99.22 ( 98.21)\n",
            "Epoch: [70][ 60/391]\tTime  0.097 ( 0.105)\tLoss 5.6776e-01 (5.3934e-01)\tAcc@1  79.69 ( 83.41)\tAcc@5  98.44 ( 98.00)\n",
            "Epoch: [70][ 90/391]\tTime  0.102 ( 0.103)\tLoss 8.0149e-01 (5.4879e-01)\tAcc@1  73.44 ( 83.11)\tAcc@5  96.88 ( 97.98)\n",
            "Epoch: [70][120/391]\tTime  0.100 ( 0.102)\tLoss 5.2259e-01 (5.6026e-01)\tAcc@1  78.91 ( 82.67)\tAcc@5  98.44 ( 97.86)\n",
            "Epoch: [70][150/391]\tTime  0.096 ( 0.101)\tLoss 5.9110e-01 (5.6216e-01)\tAcc@1  78.91 ( 82.57)\tAcc@5  99.22 ( 97.83)\n",
            "Epoch: [70][180/391]\tTime  0.097 ( 0.100)\tLoss 6.6225e-01 (5.6627e-01)\tAcc@1  81.25 ( 82.50)\tAcc@5  97.66 ( 97.76)\n",
            "Epoch: [70][210/391]\tTime  0.099 ( 0.100)\tLoss 6.8004e-01 (5.6515e-01)\tAcc@1  82.03 ( 82.60)\tAcc@5  96.88 ( 97.78)\n",
            "Epoch: [70][240/391]\tTime  0.097 ( 0.100)\tLoss 6.0721e-01 (5.7226e-01)\tAcc@1  81.25 ( 82.28)\tAcc@5  96.88 ( 97.72)\n",
            "Epoch: [70][270/391]\tTime  0.097 ( 0.100)\tLoss 8.3002e-01 (5.7919e-01)\tAcc@1  74.22 ( 82.03)\tAcc@5  95.31 ( 97.67)\n",
            "Epoch: [70][300/391]\tTime  0.097 ( 0.100)\tLoss 8.3807e-01 (5.8618e-01)\tAcc@1  74.22 ( 81.83)\tAcc@5  94.53 ( 97.62)\n",
            "Epoch: [70][330/391]\tTime  0.098 ( 0.101)\tLoss 6.0342e-01 (5.8899e-01)\tAcc@1  82.03 ( 81.75)\tAcc@5  96.09 ( 97.62)\n",
            "Epoch: [70][360/391]\tTime  0.097 ( 0.100)\tLoss 8.7379e-01 (5.9701e-01)\tAcc@1  74.22 ( 81.48)\tAcc@5  95.31 ( 97.55)\n",
            "Epoch: [70][390/391]\tTime  0.049 ( 0.100)\tLoss 7.8861e-01 (5.9945e-01)\tAcc@1  77.50 ( 81.44)\tAcc@5  95.00 ( 97.55)\n",
            "==> Train Accuracy: Acc@1 81.440 || Acc@5 97.548\n",
            "==> Test Accuracy:  Acc@1 64.210 || Acc@5 88.690\n",
            "==> 56.60 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 71, lr: 0.020000000000000004 -----\n",
            "Epoch: [71][  0/391]\tTime  0.335 ( 0.335)\tLoss 4.3869e-01 (4.3869e-01)\tAcc@1  84.38 ( 84.38)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [71][ 30/391]\tTime  0.096 ( 0.109)\tLoss 5.7953e-01 (5.4486e-01)\tAcc@1  85.16 ( 83.69)\tAcc@5  96.88 ( 97.93)\n",
            "Epoch: [71][ 60/391]\tTime  0.095 ( 0.104)\tLoss 5.9660e-01 (5.4517e-01)\tAcc@1  81.25 ( 83.49)\tAcc@5  97.66 ( 97.94)\n",
            "Epoch: [71][ 90/391]\tTime  0.096 ( 0.104)\tLoss 5.9167e-01 (5.4812e-01)\tAcc@1  84.38 ( 83.39)\tAcc@5  99.22 ( 97.94)\n",
            "Epoch: [71][120/391]\tTime  0.096 ( 0.103)\tLoss 4.5606e-01 (5.5025e-01)\tAcc@1  89.06 ( 83.30)\tAcc@5  99.22 ( 98.03)\n",
            "Epoch: [71][150/391]\tTime  0.094 ( 0.102)\tLoss 6.9078e-01 (5.5100e-01)\tAcc@1  82.03 ( 83.23)\tAcc@5  96.09 ( 97.98)\n",
            "Epoch: [71][180/391]\tTime  0.096 ( 0.101)\tLoss 5.1545e-01 (5.4994e-01)\tAcc@1  82.03 ( 83.08)\tAcc@5  99.22 ( 98.02)\n",
            "Epoch: [71][210/391]\tTime  0.098 ( 0.101)\tLoss 5.6619e-01 (5.5589e-01)\tAcc@1  84.38 ( 82.86)\tAcc@5  97.66 ( 97.97)\n",
            "Epoch: [71][240/391]\tTime  0.099 ( 0.101)\tLoss 6.8277e-01 (5.5990e-01)\tAcc@1  78.91 ( 82.74)\tAcc@5  96.09 ( 97.96)\n",
            "Epoch: [71][270/391]\tTime  0.097 ( 0.101)\tLoss 6.0599e-01 (5.6771e-01)\tAcc@1  82.03 ( 82.46)\tAcc@5  95.31 ( 97.92)\n",
            "Epoch: [71][300/391]\tTime  0.099 ( 0.100)\tLoss 7.6976e-01 (5.7305e-01)\tAcc@1  80.47 ( 82.35)\tAcc@5  94.53 ( 97.87)\n",
            "Epoch: [71][330/391]\tTime  0.096 ( 0.100)\tLoss 7.0360e-01 (5.7616e-01)\tAcc@1  77.34 ( 82.21)\tAcc@5  97.66 ( 97.83)\n",
            "Epoch: [71][360/391]\tTime  0.101 ( 0.100)\tLoss 5.8340e-01 (5.8056e-01)\tAcc@1  80.47 ( 82.03)\tAcc@5  97.66 ( 97.82)\n",
            "Epoch: [71][390/391]\tTime  0.049 ( 0.100)\tLoss 5.6437e-01 (5.8648e-01)\tAcc@1  83.75 ( 81.85)\tAcc@5 100.00 ( 97.78)\n",
            "==> Train Accuracy: Acc@1 81.848 || Acc@5 97.780\n",
            "==> Test Accuracy:  Acc@1 64.520 || Acc@5 88.250\n",
            "==> 56.42 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 72, lr: 0.020000000000000004 -----\n",
            "Epoch: [72][  0/391]\tTime  0.361 ( 0.361)\tLoss 4.4666e-01 (4.4666e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [72][ 30/391]\tTime  0.102 ( 0.114)\tLoss 5.0054e-01 (5.1657e-01)\tAcc@1  83.59 ( 84.17)\tAcc@5  99.22 ( 98.41)\n",
            "Epoch: [72][ 60/391]\tTime  0.110 ( 0.108)\tLoss 3.8882e-01 (5.2150e-01)\tAcc@1  88.28 ( 83.94)\tAcc@5  98.44 ( 98.41)\n",
            "Epoch: [72][ 90/391]\tTime  0.097 ( 0.106)\tLoss 6.1440e-01 (5.2969e-01)\tAcc@1  82.03 ( 83.64)\tAcc@5  98.44 ( 98.33)\n",
            "Epoch: [72][120/391]\tTime  0.096 ( 0.104)\tLoss 4.4240e-01 (5.3545e-01)\tAcc@1  85.16 ( 83.37)\tAcc@5  97.66 ( 98.25)\n",
            "Epoch: [72][150/391]\tTime  0.099 ( 0.103)\tLoss 6.7704e-01 (5.4459e-01)\tAcc@1  75.00 ( 83.04)\tAcc@5  98.44 ( 98.16)\n",
            "Epoch: [72][180/391]\tTime  0.097 ( 0.103)\tLoss 6.3665e-01 (5.5190e-01)\tAcc@1  79.69 ( 82.94)\tAcc@5  99.22 ( 98.05)\n",
            "Epoch: [72][210/391]\tTime  0.097 ( 0.102)\tLoss 6.0753e-01 (5.5913e-01)\tAcc@1  80.47 ( 82.65)\tAcc@5  98.44 ( 98.04)\n",
            "Epoch: [72][240/391]\tTime  0.098 ( 0.102)\tLoss 5.4338e-01 (5.6185e-01)\tAcc@1  85.16 ( 82.56)\tAcc@5  99.22 ( 98.04)\n",
            "Epoch: [72][270/391]\tTime  0.099 ( 0.102)\tLoss 8.3124e-01 (5.6724e-01)\tAcc@1  72.66 ( 82.30)\tAcc@5  96.88 ( 98.05)\n",
            "Epoch: [72][300/391]\tTime  0.105 ( 0.101)\tLoss 4.5082e-01 (5.7194e-01)\tAcc@1  82.81 ( 82.19)\tAcc@5  99.22 ( 98.00)\n",
            "Epoch: [72][330/391]\tTime  0.098 ( 0.101)\tLoss 5.6723e-01 (5.7533e-01)\tAcc@1  80.47 ( 82.09)\tAcc@5  96.88 ( 97.93)\n",
            "Epoch: [72][360/391]\tTime  0.097 ( 0.101)\tLoss 4.8142e-01 (5.7979e-01)\tAcc@1  85.16 ( 81.92)\tAcc@5  98.44 ( 97.88)\n",
            "Epoch: [72][390/391]\tTime  0.049 ( 0.100)\tLoss 4.4971e-01 (5.8370e-01)\tAcc@1  83.75 ( 81.83)\tAcc@5 100.00 ( 97.85)\n",
            "==> Train Accuracy: Acc@1 81.834 || Acc@5 97.848\n",
            "==> Test Accuracy:  Acc@1 63.640 || Acc@5 88.290\n",
            "==> 56.72 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 73, lr: 0.020000000000000004 -----\n",
            "Epoch: [73][  0/391]\tTime  0.365 ( 0.365)\tLoss 3.9970e-01 (3.9970e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [73][ 30/391]\tTime  0.094 ( 0.109)\tLoss 5.8387e-01 (5.2692e-01)\tAcc@1  81.25 ( 84.35)\tAcc@5  96.88 ( 98.26)\n",
            "Epoch: [73][ 60/391]\tTime  0.110 ( 0.108)\tLoss 3.9466e-01 (5.3593e-01)\tAcc@1  87.50 ( 83.98)\tAcc@5 100.00 ( 98.32)\n",
            "Epoch: [73][ 90/391]\tTime  0.101 ( 0.105)\tLoss 6.2394e-01 (5.4325e-01)\tAcc@1  84.38 ( 83.73)\tAcc@5  99.22 ( 98.15)\n",
            "Epoch: [73][120/391]\tTime  0.096 ( 0.103)\tLoss 5.3976e-01 (5.5042e-01)\tAcc@1  81.25 ( 83.32)\tAcc@5  99.22 ( 98.14)\n",
            "Epoch: [73][150/391]\tTime  0.104 ( 0.103)\tLoss 4.6212e-01 (5.4974e-01)\tAcc@1  84.38 ( 83.24)\tAcc@5  99.22 ( 98.16)\n",
            "Epoch: [73][180/391]\tTime  0.101 ( 0.103)\tLoss 5.4701e-01 (5.5300e-01)\tAcc@1  85.16 ( 83.14)\tAcc@5  95.31 ( 98.06)\n",
            "Epoch: [73][210/391]\tTime  0.103 ( 0.102)\tLoss 7.5639e-01 (5.5620e-01)\tAcc@1  75.00 ( 82.96)\tAcc@5  94.53 ( 98.07)\n",
            "Epoch: [73][240/391]\tTime  0.107 ( 0.102)\tLoss 5.7797e-01 (5.5768e-01)\tAcc@1  85.16 ( 83.01)\tAcc@5  96.09 ( 97.98)\n",
            "Epoch: [73][270/391]\tTime  0.104 ( 0.102)\tLoss 5.5583e-01 (5.6349e-01)\tAcc@1  81.25 ( 82.75)\tAcc@5  98.44 ( 97.87)\n",
            "Epoch: [73][300/391]\tTime  0.106 ( 0.102)\tLoss 6.4205e-01 (5.7025e-01)\tAcc@1  75.00 ( 82.47)\tAcc@5  95.31 ( 97.82)\n",
            "Epoch: [73][330/391]\tTime  0.097 ( 0.101)\tLoss 6.2757e-01 (5.7550e-01)\tAcc@1  80.47 ( 82.36)\tAcc@5  97.66 ( 97.76)\n",
            "Epoch: [73][360/391]\tTime  0.100 ( 0.101)\tLoss 7.4464e-01 (5.7963e-01)\tAcc@1  79.69 ( 82.24)\tAcc@5  96.88 ( 97.73)\n",
            "Epoch: [73][390/391]\tTime  0.048 ( 0.101)\tLoss 6.3204e-01 (5.8180e-01)\tAcc@1  75.00 ( 82.07)\tAcc@5  97.50 ( 97.72)\n",
            "==> Train Accuracy: Acc@1 82.074 || Acc@5 97.718\n",
            "==> Test Accuracy:  Acc@1 63.420 || Acc@5 88.330\n",
            "==> 56.74 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 74, lr: 0.020000000000000004 -----\n",
            "Epoch: [74][  0/391]\tTime  0.346 ( 0.346)\tLoss 5.3624e-01 (5.3624e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [74][ 30/391]\tTime  0.109 ( 0.112)\tLoss 5.2785e-01 (5.3734e-01)\tAcc@1  86.72 ( 84.38)\tAcc@5  99.22 ( 98.26)\n",
            "Epoch: [74][ 60/391]\tTime  0.100 ( 0.107)\tLoss 5.4068e-01 (5.3452e-01)\tAcc@1  85.16 ( 83.93)\tAcc@5  98.44 ( 98.16)\n",
            "Epoch: [74][ 90/391]\tTime  0.108 ( 0.106)\tLoss 5.4739e-01 (5.3511e-01)\tAcc@1  83.59 ( 83.78)\tAcc@5  99.22 ( 98.21)\n",
            "Epoch: [74][120/391]\tTime  0.099 ( 0.104)\tLoss 5.7737e-01 (5.3925e-01)\tAcc@1  85.16 ( 83.71)\tAcc@5  96.09 ( 98.21)\n",
            "Epoch: [74][150/391]\tTime  0.099 ( 0.104)\tLoss 6.2818e-01 (5.4331e-01)\tAcc@1  79.69 ( 83.46)\tAcc@5  96.88 ( 98.15)\n",
            "Epoch: [74][180/391]\tTime  0.097 ( 0.103)\tLoss 6.0829e-01 (5.4471e-01)\tAcc@1  81.25 ( 83.36)\tAcc@5  96.88 ( 98.17)\n",
            "Epoch: [74][210/391]\tTime  0.114 ( 0.103)\tLoss 6.2118e-01 (5.4876e-01)\tAcc@1  80.47 ( 83.28)\tAcc@5  98.44 ( 98.10)\n",
            "Epoch: [74][240/391]\tTime  0.114 ( 0.102)\tLoss 6.9361e-01 (5.5373e-01)\tAcc@1  82.03 ( 83.16)\tAcc@5  96.88 ( 98.05)\n",
            "Epoch: [74][270/391]\tTime  0.107 ( 0.102)\tLoss 4.5233e-01 (5.5823e-01)\tAcc@1  85.16 ( 83.08)\tAcc@5  97.66 ( 98.00)\n",
            "Epoch: [74][300/391]\tTime  0.110 ( 0.102)\tLoss 6.9032e-01 (5.6191e-01)\tAcc@1  78.91 ( 82.94)\tAcc@5  97.66 ( 97.96)\n",
            "Epoch: [74][330/391]\tTime  0.103 ( 0.102)\tLoss 7.6535e-01 (5.6753e-01)\tAcc@1  78.12 ( 82.73)\tAcc@5  94.53 ( 97.89)\n",
            "Epoch: [74][360/391]\tTime  0.104 ( 0.102)\tLoss 6.2905e-01 (5.7168e-01)\tAcc@1  77.34 ( 82.55)\tAcc@5  97.66 ( 97.86)\n",
            "Epoch: [74][390/391]\tTime  0.049 ( 0.102)\tLoss 5.5133e-01 (5.7584e-01)\tAcc@1  81.25 ( 82.45)\tAcc@5  98.75 ( 97.81)\n",
            "==> Train Accuracy: Acc@1 82.446 || Acc@5 97.808\n",
            "==> Test Accuracy:  Acc@1 64.270 || Acc@5 88.790\n",
            "==> 57.30 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 75, lr: 0.020000000000000004 -----\n",
            "Epoch: [75][  0/391]\tTime  0.341 ( 0.341)\tLoss 4.5181e-01 (4.5181e-01)\tAcc@1  82.81 ( 82.81)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [75][ 30/391]\tTime  0.099 ( 0.113)\tLoss 5.3830e-01 (5.4237e-01)\tAcc@1  79.69 ( 83.44)\tAcc@5  98.44 ( 97.76)\n",
            "Epoch: [75][ 60/391]\tTime  0.098 ( 0.107)\tLoss 5.0073e-01 (5.2981e-01)\tAcc@1  85.94 ( 83.61)\tAcc@5  99.22 ( 98.05)\n",
            "Epoch: [75][ 90/391]\tTime  0.096 ( 0.104)\tLoss 6.3062e-01 (5.3002e-01)\tAcc@1  78.91 ( 83.62)\tAcc@5  96.88 ( 98.16)\n",
            "Epoch: [75][120/391]\tTime  0.114 ( 0.104)\tLoss 4.1671e-01 (5.2443e-01)\tAcc@1  84.38 ( 83.76)\tAcc@5 100.00 ( 98.21)\n",
            "Epoch: [75][150/391]\tTime  0.103 ( 0.105)\tLoss 3.6346e-01 (5.3022e-01)\tAcc@1  92.97 ( 83.58)\tAcc@5 100.00 ( 98.16)\n",
            "Epoch: [75][180/391]\tTime  0.095 ( 0.104)\tLoss 7.6634e-01 (5.4093e-01)\tAcc@1  75.00 ( 83.23)\tAcc@5  95.31 ( 98.11)\n",
            "Epoch: [75][210/391]\tTime  0.096 ( 0.103)\tLoss 5.1557e-01 (5.4921e-01)\tAcc@1  86.72 ( 82.98)\tAcc@5  95.31 ( 98.09)\n",
            "Epoch: [75][240/391]\tTime  0.101 ( 0.102)\tLoss 5.4167e-01 (5.5542e-01)\tAcc@1  83.59 ( 82.76)\tAcc@5  97.66 ( 98.05)\n",
            "Epoch: [75][270/391]\tTime  0.097 ( 0.102)\tLoss 5.8265e-01 (5.5677e-01)\tAcc@1  78.91 ( 82.72)\tAcc@5  99.22 ( 98.05)\n",
            "Epoch: [75][300/391]\tTime  0.097 ( 0.102)\tLoss 8.0452e-01 (5.6191e-01)\tAcc@1  78.91 ( 82.57)\tAcc@5  96.09 ( 98.03)\n",
            "Epoch: [75][330/391]\tTime  0.098 ( 0.101)\tLoss 7.0109e-01 (5.6767e-01)\tAcc@1  74.22 ( 82.40)\tAcc@5  98.44 ( 97.97)\n",
            "Epoch: [75][360/391]\tTime  0.099 ( 0.101)\tLoss 4.8831e-01 (5.7066e-01)\tAcc@1  86.72 ( 82.35)\tAcc@5  99.22 ( 97.94)\n",
            "Epoch: [75][390/391]\tTime  0.049 ( 0.101)\tLoss 4.8297e-01 (5.7432e-01)\tAcc@1  83.75 ( 82.23)\tAcc@5  97.50 ( 97.92)\n",
            "==> Train Accuracy: Acc@1 82.234 || Acc@5 97.918\n",
            "==> Test Accuracy:  Acc@1 62.760 || Acc@5 87.660\n",
            "==> 56.76 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 76, lr: 0.020000000000000004 -----\n",
            "Epoch: [76][  0/391]\tTime  0.372 ( 0.372)\tLoss 7.0760e-01 (7.0760e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5  96.09 ( 96.09)\n",
            "Epoch: [76][ 30/391]\tTime  0.095 ( 0.107)\tLoss 4.0321e-01 (5.3480e-01)\tAcc@1  89.06 ( 83.74)\tAcc@5  99.22 ( 98.01)\n",
            "Epoch: [76][ 60/391]\tTime  0.093 ( 0.102)\tLoss 5.1399e-01 (5.2936e-01)\tAcc@1  82.81 ( 84.03)\tAcc@5  97.66 ( 98.17)\n",
            "Epoch: [76][ 90/391]\tTime  0.099 ( 0.101)\tLoss 6.5508e-01 (5.3060e-01)\tAcc@1  76.56 ( 83.83)\tAcc@5  97.66 ( 98.20)\n",
            "Epoch: [76][120/391]\tTime  0.101 ( 0.101)\tLoss 5.5266e-01 (5.2517e-01)\tAcc@1  83.59 ( 83.90)\tAcc@5  97.66 ( 98.23)\n",
            "Epoch: [76][150/391]\tTime  0.112 ( 0.101)\tLoss 6.2310e-01 (5.3194e-01)\tAcc@1  83.59 ( 83.74)\tAcc@5  97.66 ( 98.16)\n",
            "Epoch: [76][180/391]\tTime  0.102 ( 0.101)\tLoss 6.7093e-01 (5.3714e-01)\tAcc@1  80.47 ( 83.55)\tAcc@5  96.09 ( 98.11)\n",
            "Epoch: [76][210/391]\tTime  0.101 ( 0.101)\tLoss 5.8480e-01 (5.3823e-01)\tAcc@1  81.25 ( 83.55)\tAcc@5  97.66 ( 98.13)\n",
            "Epoch: [76][240/391]\tTime  0.101 ( 0.101)\tLoss 5.8755e-01 (5.4463e-01)\tAcc@1  83.59 ( 83.29)\tAcc@5  99.22 ( 98.10)\n",
            "Epoch: [76][270/391]\tTime  0.097 ( 0.101)\tLoss 5.1557e-01 (5.4719e-01)\tAcc@1  81.25 ( 83.22)\tAcc@5  98.44 ( 98.07)\n",
            "Epoch: [76][300/391]\tTime  0.103 ( 0.101)\tLoss 6.2170e-01 (5.5085e-01)\tAcc@1  80.47 ( 83.15)\tAcc@5  96.09 ( 98.01)\n",
            "Epoch: [76][330/391]\tTime  0.098 ( 0.100)\tLoss 6.0020e-01 (5.5570e-01)\tAcc@1  80.47 ( 82.99)\tAcc@5  98.44 ( 97.97)\n",
            "Epoch: [76][360/391]\tTime  0.101 ( 0.101)\tLoss 5.3091e-01 (5.6292e-01)\tAcc@1  83.59 ( 82.78)\tAcc@5  98.44 ( 97.90)\n",
            "Epoch: [76][390/391]\tTime  0.048 ( 0.100)\tLoss 5.6652e-01 (5.6450e-01)\tAcc@1  83.75 ( 82.75)\tAcc@5  98.75 ( 97.90)\n",
            "==> Train Accuracy: Acc@1 82.752 || Acc@5 97.902\n",
            "==> Test Accuracy:  Acc@1 63.270 || Acc@5 87.420\n",
            "==> 56.66 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 77, lr: 0.020000000000000004 -----\n",
            "Epoch: [77][  0/391]\tTime  0.347 ( 0.347)\tLoss 4.3884e-01 (4.3884e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [77][ 30/391]\tTime  0.099 ( 0.108)\tLoss 4.1410e-01 (5.0131e-01)\tAcc@1  87.50 ( 84.45)\tAcc@5 100.00 ( 98.54)\n",
            "Epoch: [77][ 60/391]\tTime  0.101 ( 0.103)\tLoss 4.9780e-01 (5.0160e-01)\tAcc@1  84.38 ( 84.76)\tAcc@5  99.22 ( 98.41)\n",
            "Epoch: [77][ 90/391]\tTime  0.099 ( 0.102)\tLoss 5.6679e-01 (5.0480e-01)\tAcc@1  82.81 ( 84.54)\tAcc@5  97.66 ( 98.45)\n",
            "Epoch: [77][120/391]\tTime  0.101 ( 0.101)\tLoss 5.6104e-01 (5.1372e-01)\tAcc@1  84.38 ( 84.19)\tAcc@5  99.22 ( 98.41)\n",
            "Epoch: [77][150/391]\tTime  0.096 ( 0.101)\tLoss 4.2347e-01 (5.2220e-01)\tAcc@1  88.28 ( 83.84)\tAcc@5  97.66 ( 98.37)\n",
            "Epoch: [77][180/391]\tTime  0.095 ( 0.100)\tLoss 5.5703e-01 (5.3097e-01)\tAcc@1  83.59 ( 83.59)\tAcc@5  96.88 ( 98.29)\n",
            "Epoch: [77][210/391]\tTime  0.096 ( 0.101)\tLoss 3.9810e-01 (5.3086e-01)\tAcc@1  85.94 ( 83.63)\tAcc@5  99.22 ( 98.29)\n",
            "Epoch: [77][240/391]\tTime  0.097 ( 0.101)\tLoss 6.1644e-01 (5.3704e-01)\tAcc@1  80.47 ( 83.36)\tAcc@5  96.09 ( 98.22)\n",
            "Epoch: [77][270/391]\tTime  0.096 ( 0.101)\tLoss 6.0706e-01 (5.4128e-01)\tAcc@1  79.69 ( 83.24)\tAcc@5  98.44 ( 98.19)\n",
            "Epoch: [77][300/391]\tTime  0.096 ( 0.100)\tLoss 5.9273e-01 (5.4673e-01)\tAcc@1  82.81 ( 83.07)\tAcc@5 100.00 ( 98.19)\n",
            "Epoch: [77][330/391]\tTime  0.096 ( 0.101)\tLoss 7.2183e-01 (5.5350e-01)\tAcc@1  73.44 ( 82.82)\tAcc@5  96.09 ( 98.11)\n",
            "Epoch: [77][360/391]\tTime  0.095 ( 0.100)\tLoss 6.9243e-01 (5.5779e-01)\tAcc@1  80.47 ( 82.68)\tAcc@5  96.09 ( 98.09)\n",
            "Epoch: [77][390/391]\tTime  0.048 ( 0.100)\tLoss 6.1550e-01 (5.6434e-01)\tAcc@1  83.75 ( 82.50)\tAcc@5  95.00 ( 98.01)\n",
            "==> Train Accuracy: Acc@1 82.498 || Acc@5 98.006\n",
            "==> Test Accuracy:  Acc@1 60.410 || Acc@5 86.790\n",
            "==> 56.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 78, lr: 0.020000000000000004 -----\n",
            "Epoch: [78][  0/391]\tTime  0.357 ( 0.357)\tLoss 4.8579e-01 (4.8579e-01)\tAcc@1  90.62 ( 90.62)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [78][ 30/391]\tTime  0.097 ( 0.108)\tLoss 5.1358e-01 (5.1824e-01)\tAcc@1  85.94 ( 84.25)\tAcc@5  96.88 ( 98.39)\n",
            "Epoch: [78][ 60/391]\tTime  0.095 ( 0.103)\tLoss 6.1129e-01 (5.1259e-01)\tAcc@1  79.69 ( 84.25)\tAcc@5  97.66 ( 98.44)\n",
            "Epoch: [78][ 90/391]\tTime  0.096 ( 0.103)\tLoss 4.2477e-01 (5.1085e-01)\tAcc@1  87.50 ( 84.28)\tAcc@5  99.22 ( 98.44)\n",
            "Epoch: [78][120/391]\tTime  0.098 ( 0.102)\tLoss 3.9416e-01 (5.0600e-01)\tAcc@1  91.41 ( 84.52)\tAcc@5 100.00 ( 98.35)\n",
            "Epoch: [78][150/391]\tTime  0.096 ( 0.101)\tLoss 4.7979e-01 (5.1368e-01)\tAcc@1  85.94 ( 84.16)\tAcc@5  99.22 ( 98.34)\n",
            "Epoch: [78][180/391]\tTime  0.097 ( 0.100)\tLoss 6.9441e-01 (5.1920e-01)\tAcc@1  78.91 ( 84.03)\tAcc@5  98.44 ( 98.30)\n",
            "Epoch: [78][210/391]\tTime  0.102 ( 0.100)\tLoss 6.4557e-01 (5.2756e-01)\tAcc@1  82.03 ( 83.76)\tAcc@5  96.88 ( 98.24)\n",
            "Epoch: [78][240/391]\tTime  0.104 ( 0.101)\tLoss 4.5694e-01 (5.2880e-01)\tAcc@1  82.03 ( 83.78)\tAcc@5  98.44 ( 98.24)\n",
            "Epoch: [78][270/391]\tTime  0.102 ( 0.101)\tLoss 6.6510e-01 (5.3649e-01)\tAcc@1  81.25 ( 83.53)\tAcc@5  96.09 ( 98.17)\n",
            "Epoch: [78][300/391]\tTime  0.102 ( 0.100)\tLoss 6.3280e-01 (5.4219e-01)\tAcc@1  82.81 ( 83.30)\tAcc@5  96.88 ( 98.13)\n",
            "Epoch: [78][330/391]\tTime  0.097 ( 0.100)\tLoss 4.5164e-01 (5.4749e-01)\tAcc@1  88.28 ( 83.13)\tAcc@5  96.88 ( 98.08)\n",
            "Epoch: [78][360/391]\tTime  0.098 ( 0.100)\tLoss 5.9189e-01 (5.5221e-01)\tAcc@1  82.81 ( 82.90)\tAcc@5  98.44 ( 98.05)\n",
            "Epoch: [78][390/391]\tTime  0.056 ( 0.100)\tLoss 5.5629e-01 (5.5253e-01)\tAcc@1  83.75 ( 82.85)\tAcc@5  97.50 ( 98.06)\n",
            "==> Train Accuracy: Acc@1 82.848 || Acc@5 98.064\n",
            "==> Test Accuracy:  Acc@1 62.260 || Acc@5 87.220\n",
            "==> 56.52 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 79, lr: 0.020000000000000004 -----\n",
            "Epoch: [79][  0/391]\tTime  0.358 ( 0.358)\tLoss 4.7111e-01 (4.7111e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [79][ 30/391]\tTime  0.097 ( 0.109)\tLoss 3.8281e-01 (4.8097e-01)\tAcc@1  87.50 ( 84.53)\tAcc@5  99.22 ( 98.54)\n",
            "Epoch: [79][ 60/391]\tTime  0.101 ( 0.104)\tLoss 3.9415e-01 (4.9624e-01)\tAcc@1  89.06 ( 84.57)\tAcc@5 100.00 ( 98.49)\n",
            "Epoch: [79][ 90/391]\tTime  0.105 ( 0.102)\tLoss 4.2398e-01 (5.0263e-01)\tAcc@1  88.28 ( 84.38)\tAcc@5  99.22 ( 98.39)\n",
            "Epoch: [79][120/391]\tTime  0.100 ( 0.101)\tLoss 5.1819e-01 (5.1378e-01)\tAcc@1  82.03 ( 83.92)\tAcc@5  99.22 ( 98.33)\n",
            "Epoch: [79][150/391]\tTime  0.097 ( 0.101)\tLoss 5.5607e-01 (5.1339e-01)\tAcc@1  81.25 ( 83.89)\tAcc@5  97.66 ( 98.36)\n",
            "Epoch: [79][180/391]\tTime  0.097 ( 0.101)\tLoss 5.0410e-01 (5.2007e-01)\tAcc@1  83.59 ( 83.71)\tAcc@5  98.44 ( 98.29)\n",
            "Epoch: [79][210/391]\tTime  0.097 ( 0.101)\tLoss 5.7060e-01 (5.2842e-01)\tAcc@1  82.03 ( 83.54)\tAcc@5  96.09 ( 98.17)\n",
            "Epoch: [79][240/391]\tTime  0.097 ( 0.100)\tLoss 5.7731e-01 (5.3320e-01)\tAcc@1  79.69 ( 83.40)\tAcc@5  98.44 ( 98.15)\n",
            "Epoch: [79][270/391]\tTime  0.103 ( 0.101)\tLoss 6.9238e-01 (5.3659e-01)\tAcc@1  77.34 ( 83.30)\tAcc@5  96.88 ( 98.13)\n",
            "Epoch: [79][300/391]\tTime  0.097 ( 0.101)\tLoss 6.8193e-01 (5.4301e-01)\tAcc@1  78.91 ( 83.05)\tAcc@5  97.66 ( 98.08)\n",
            "Epoch: [79][330/391]\tTime  0.097 ( 0.100)\tLoss 4.8678e-01 (5.4734e-01)\tAcc@1  83.59 ( 82.87)\tAcc@5  99.22 ( 98.04)\n",
            "Epoch: [79][360/391]\tTime  0.103 ( 0.100)\tLoss 7.1614e-01 (5.5392e-01)\tAcc@1  76.56 ( 82.70)\tAcc@5  98.44 ( 98.01)\n",
            "Epoch: [79][390/391]\tTime  0.049 ( 0.100)\tLoss 6.3693e-01 (5.6046e-01)\tAcc@1  78.75 ( 82.51)\tAcc@5  97.50 ( 97.96)\n",
            "==> Train Accuracy: Acc@1 82.510 || Acc@5 97.958\n",
            "==> Test Accuracy:  Acc@1 62.180 || Acc@5 87.390\n",
            "==> 56.60 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 80, lr: 0.020000000000000004 -----\n",
            "Epoch: [80][  0/391]\tTime  0.368 ( 0.368)\tLoss 5.5881e-01 (5.5881e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [80][ 30/391]\tTime  0.100 ( 0.109)\tLoss 4.7506e-01 (5.1103e-01)\tAcc@1  85.16 ( 84.98)\tAcc@5 100.00 ( 98.44)\n",
            "Epoch: [80][ 60/391]\tTime  0.114 ( 0.107)\tLoss 4.5176e-01 (5.0761e-01)\tAcc@1  85.16 ( 85.04)\tAcc@5  98.44 ( 98.45)\n",
            "Epoch: [80][ 90/391]\tTime  0.103 ( 0.105)\tLoss 5.0605e-01 (5.1469e-01)\tAcc@1  87.50 ( 84.70)\tAcc@5  98.44 ( 98.36)\n",
            "Epoch: [80][120/391]\tTime  0.100 ( 0.104)\tLoss 5.3960e-01 (5.1478e-01)\tAcc@1  87.50 ( 84.61)\tAcc@5  98.44 ( 98.33)\n",
            "Epoch: [80][150/391]\tTime  0.101 ( 0.103)\tLoss 4.1922e-01 (5.1383e-01)\tAcc@1  89.84 ( 84.56)\tAcc@5  97.66 ( 98.33)\n",
            "Epoch: [80][180/391]\tTime  0.097 ( 0.102)\tLoss 5.5288e-01 (5.2023e-01)\tAcc@1  80.47 ( 84.27)\tAcc@5  96.88 ( 98.33)\n",
            "Epoch: [80][210/391]\tTime  0.099 ( 0.102)\tLoss 4.7661e-01 (5.2202e-01)\tAcc@1  83.59 ( 84.17)\tAcc@5  99.22 ( 98.31)\n",
            "Epoch: [80][240/391]\tTime  0.098 ( 0.101)\tLoss 5.6254e-01 (5.2709e-01)\tAcc@1  82.03 ( 83.92)\tAcc@5  97.66 ( 98.26)\n",
            "Epoch: [80][270/391]\tTime  0.096 ( 0.101)\tLoss 4.9190e-01 (5.3488e-01)\tAcc@1  82.03 ( 83.67)\tAcc@5  99.22 ( 98.17)\n",
            "Epoch: [80][300/391]\tTime  0.105 ( 0.102)\tLoss 5.8456e-01 (5.3999e-01)\tAcc@1  83.59 ( 83.57)\tAcc@5  98.44 ( 98.12)\n",
            "Epoch: [80][330/391]\tTime  0.099 ( 0.101)\tLoss 6.4830e-01 (5.4447e-01)\tAcc@1  73.44 ( 83.42)\tAcc@5  96.88 ( 98.10)\n",
            "Epoch: [80][360/391]\tTime  0.098 ( 0.101)\tLoss 6.8427e-01 (5.4819e-01)\tAcc@1  78.91 ( 83.29)\tAcc@5  96.09 ( 98.06)\n",
            "Epoch: [80][390/391]\tTime  0.049 ( 0.101)\tLoss 4.3596e-01 (5.5098e-01)\tAcc@1  87.50 ( 83.18)\tAcc@5  98.75 ( 98.03)\n",
            "==> Train Accuracy: Acc@1 83.178 || Acc@5 98.034\n",
            "==> Test Accuracy:  Acc@1 63.710 || Acc@5 87.840\n",
            "==> 56.84 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 81, lr: 0.020000000000000004 -----\n",
            "Epoch: [81][  0/391]\tTime  0.359 ( 0.359)\tLoss 4.2591e-01 (4.2591e-01)\tAcc@1  86.72 ( 86.72)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [81][ 30/391]\tTime  0.094 ( 0.111)\tLoss 4.9087e-01 (4.7262e-01)\tAcc@1  80.47 ( 85.69)\tAcc@5  99.22 ( 98.61)\n",
            "Epoch: [81][ 60/391]\tTime  0.098 ( 0.105)\tLoss 4.4846e-01 (4.8663e-01)\tAcc@1  86.72 ( 85.12)\tAcc@5  98.44 ( 98.64)\n",
            "Epoch: [81][ 90/391]\tTime  0.097 ( 0.103)\tLoss 5.7727e-01 (4.9329e-01)\tAcc@1  85.94 ( 84.90)\tAcc@5  96.09 ( 98.69)\n",
            "Epoch: [81][120/391]\tTime  0.095 ( 0.102)\tLoss 5.1079e-01 (4.9998e-01)\tAcc@1  85.16 ( 84.63)\tAcc@5  99.22 ( 98.67)\n",
            "Epoch: [81][150/391]\tTime  0.094 ( 0.101)\tLoss 4.1931e-01 (5.0657e-01)\tAcc@1  87.50 ( 84.36)\tAcc@5  97.66 ( 98.55)\n",
            "Epoch: [81][180/391]\tTime  0.095 ( 0.101)\tLoss 4.5027e-01 (5.1482e-01)\tAcc@1  87.50 ( 84.10)\tAcc@5  97.66 ( 98.49)\n",
            "Epoch: [81][210/391]\tTime  0.098 ( 0.100)\tLoss 4.8813e-01 (5.1454e-01)\tAcc@1  85.94 ( 84.08)\tAcc@5  99.22 ( 98.52)\n",
            "Epoch: [81][240/391]\tTime  0.107 ( 0.100)\tLoss 4.9956e-01 (5.1750e-01)\tAcc@1  87.50 ( 83.95)\tAcc@5  98.44 ( 98.46)\n",
            "Epoch: [81][270/391]\tTime  0.099 ( 0.100)\tLoss 4.9470e-01 (5.2285e-01)\tAcc@1  83.59 ( 83.78)\tAcc@5  97.66 ( 98.39)\n",
            "Epoch: [81][300/391]\tTime  0.098 ( 0.100)\tLoss 7.8531e-01 (5.2805e-01)\tAcc@1  78.12 ( 83.59)\tAcc@5 100.00 ( 98.33)\n",
            "Epoch: [81][330/391]\tTime  0.105 ( 0.100)\tLoss 5.6885e-01 (5.3296e-01)\tAcc@1  84.38 ( 83.43)\tAcc@5  99.22 ( 98.26)\n",
            "Epoch: [81][360/391]\tTime  0.095 ( 0.100)\tLoss 7.0963e-01 (5.3617e-01)\tAcc@1  76.56 ( 83.28)\tAcc@5  98.44 ( 98.26)\n",
            "Epoch: [81][390/391]\tTime  0.050 ( 0.100)\tLoss 7.7485e-01 (5.4104e-01)\tAcc@1  78.75 ( 83.13)\tAcc@5  96.25 ( 98.23)\n",
            "==> Train Accuracy: Acc@1 83.132 || Acc@5 98.230\n",
            "==> Test Accuracy:  Acc@1 63.090 || Acc@5 87.570\n",
            "==> 56.55 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 82, lr: 0.020000000000000004 -----\n",
            "Epoch: [82][  0/391]\tTime  0.372 ( 0.372)\tLoss 4.2222e-01 (4.2222e-01)\tAcc@1  85.16 ( 85.16)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [82][ 30/391]\tTime  0.107 ( 0.114)\tLoss 4.4809e-01 (4.7743e-01)\tAcc@1  86.72 ( 85.08)\tAcc@5  98.44 ( 98.61)\n",
            "Epoch: [82][ 60/391]\tTime  0.100 ( 0.109)\tLoss 4.5695e-01 (4.7624e-01)\tAcc@1  87.50 ( 85.21)\tAcc@5  98.44 ( 98.68)\n",
            "Epoch: [82][ 90/391]\tTime  0.115 ( 0.106)\tLoss 4.2566e-01 (4.8463e-01)\tAcc@1  86.72 ( 85.14)\tAcc@5 100.00 ( 98.58)\n",
            "Epoch: [82][120/391]\tTime  0.107 ( 0.106)\tLoss 3.9454e-01 (4.8842e-01)\tAcc@1  90.62 ( 85.12)\tAcc@5  98.44 ( 98.57)\n",
            "Epoch: [82][150/391]\tTime  0.112 ( 0.106)\tLoss 5.6726e-01 (4.9454e-01)\tAcc@1  82.81 ( 84.86)\tAcc@5  95.31 ( 98.43)\n",
            "Epoch: [82][180/391]\tTime  0.102 ( 0.106)\tLoss 4.6750e-01 (4.9516e-01)\tAcc@1  86.72 ( 84.83)\tAcc@5  99.22 ( 98.47)\n",
            "Epoch: [82][210/391]\tTime  0.113 ( 0.107)\tLoss 5.3453e-01 (4.9687e-01)\tAcc@1  82.03 ( 84.69)\tAcc@5  96.88 ( 98.40)\n",
            "Epoch: [82][240/391]\tTime  0.099 ( 0.107)\tLoss 5.7131e-01 (5.0020e-01)\tAcc@1  84.38 ( 84.51)\tAcc@5  95.31 ( 98.39)\n",
            "Epoch: [82][270/391]\tTime  0.100 ( 0.106)\tLoss 5.7983e-01 (5.0757e-01)\tAcc@1  79.69 ( 84.31)\tAcc@5 100.00 ( 98.35)\n",
            "Epoch: [82][300/391]\tTime  0.100 ( 0.106)\tLoss 5.1856e-01 (5.1767e-01)\tAcc@1  84.38 ( 83.91)\tAcc@5  99.22 ( 98.31)\n",
            "Epoch: [82][330/391]\tTime  0.115 ( 0.106)\tLoss 6.2989e-01 (5.2533e-01)\tAcc@1  82.03 ( 83.73)\tAcc@5  98.44 ( 98.27)\n",
            "Epoch: [82][360/391]\tTime  0.108 ( 0.107)\tLoss 6.3284e-01 (5.3074e-01)\tAcc@1  80.47 ( 83.59)\tAcc@5  97.66 ( 98.26)\n",
            "Epoch: [82][390/391]\tTime  0.053 ( 0.106)\tLoss 4.9988e-01 (5.3526e-01)\tAcc@1  86.25 ( 83.42)\tAcc@5  98.75 ( 98.24)\n",
            "==> Train Accuracy: Acc@1 83.422 || Acc@5 98.238\n",
            "==> Test Accuracy:  Acc@1 63.150 || Acc@5 87.560\n",
            "==> 59.61 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 83, lr: 0.020000000000000004 -----\n",
            "Epoch: [83][  0/391]\tTime  0.358 ( 0.358)\tLoss 5.7331e-01 (5.7331e-01)\tAcc@1  81.25 ( 81.25)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [83][ 30/391]\tTime  0.098 ( 0.110)\tLoss 5.0265e-01 (4.9553e-01)\tAcc@1  85.94 ( 85.11)\tAcc@5  97.66 ( 98.59)\n",
            "Epoch: [83][ 60/391]\tTime  0.098 ( 0.105)\tLoss 4.3912e-01 (5.0263e-01)\tAcc@1  87.50 ( 84.81)\tAcc@5  99.22 ( 98.50)\n",
            "Epoch: [83][ 90/391]\tTime  0.100 ( 0.104)\tLoss 4.5947e-01 (4.8883e-01)\tAcc@1  82.81 ( 85.18)\tAcc@5 100.00 ( 98.59)\n",
            "Epoch: [83][120/391]\tTime  0.098 ( 0.103)\tLoss 5.6165e-01 (4.8893e-01)\tAcc@1  83.59 ( 85.13)\tAcc@5  98.44 ( 98.55)\n",
            "Epoch: [83][150/391]\tTime  0.102 ( 0.102)\tLoss 3.9983e-01 (4.8951e-01)\tAcc@1  85.94 ( 85.01)\tAcc@5  99.22 ( 98.55)\n",
            "Epoch: [83][180/391]\tTime  0.108 ( 0.102)\tLoss 4.1660e-01 (4.9784e-01)\tAcc@1  86.72 ( 84.73)\tAcc@5 100.00 ( 98.51)\n",
            "Epoch: [83][210/391]\tTime  0.104 ( 0.102)\tLoss 5.4874e-01 (5.0216e-01)\tAcc@1  83.59 ( 84.52)\tAcc@5  98.44 ( 98.50)\n",
            "Epoch: [83][240/391]\tTime  0.100 ( 0.102)\tLoss 5.2404e-01 (5.0870e-01)\tAcc@1  85.94 ( 84.36)\tAcc@5  98.44 ( 98.48)\n",
            "Epoch: [83][270/391]\tTime  0.100 ( 0.102)\tLoss 5.0097e-01 (5.1390e-01)\tAcc@1  86.72 ( 84.19)\tAcc@5  97.66 ( 98.44)\n",
            "Epoch: [83][300/391]\tTime  0.098 ( 0.102)\tLoss 5.3475e-01 (5.2268e-01)\tAcc@1  86.72 ( 83.91)\tAcc@5  95.31 ( 98.36)\n",
            "Epoch: [83][330/391]\tTime  0.098 ( 0.101)\tLoss 6.5377e-01 (5.2881e-01)\tAcc@1  79.69 ( 83.70)\tAcc@5  98.44 ( 98.33)\n",
            "Epoch: [83][360/391]\tTime  0.105 ( 0.102)\tLoss 7.1439e-01 (5.3349e-01)\tAcc@1  78.91 ( 83.54)\tAcc@5  96.09 ( 98.29)\n",
            "Epoch: [83][390/391]\tTime  0.048 ( 0.101)\tLoss 5.6396e-01 (5.3734e-01)\tAcc@1  83.75 ( 83.40)\tAcc@5  96.25 ( 98.28)\n",
            "==> Train Accuracy: Acc@1 83.398 || Acc@5 98.276\n",
            "==> Test Accuracy:  Acc@1 62.780 || Acc@5 87.500\n",
            "==> 57.20 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 84, lr: 0.020000000000000004 -----\n",
            "Epoch: [84][  0/391]\tTime  0.358 ( 0.358)\tLoss 5.3995e-01 (5.3995e-01)\tAcc@1  80.47 ( 80.47)\tAcc@5  98.44 ( 98.44)\n",
            "Epoch: [84][ 30/391]\tTime  0.098 ( 0.110)\tLoss 4.5749e-01 (4.6380e-01)\tAcc@1  86.72 ( 85.58)\tAcc@5  99.22 ( 98.66)\n",
            "Epoch: [84][ 60/391]\tTime  0.098 ( 0.105)\tLoss 4.8812e-01 (4.5789e-01)\tAcc@1  81.25 ( 85.90)\tAcc@5  99.22 ( 98.76)\n",
            "Epoch: [84][ 90/391]\tTime  0.098 ( 0.104)\tLoss 4.3115e-01 (4.5547e-01)\tAcc@1  86.72 ( 85.87)\tAcc@5  99.22 ( 98.76)\n",
            "Epoch: [84][120/391]\tTime  0.101 ( 0.103)\tLoss 4.7876e-01 (4.6444e-01)\tAcc@1  85.94 ( 85.54)\tAcc@5  97.66 ( 98.73)\n",
            "Epoch: [84][150/391]\tTime  0.101 ( 0.103)\tLoss 4.5883e-01 (4.7019e-01)\tAcc@1  87.50 ( 85.45)\tAcc@5  98.44 ( 98.71)\n",
            "Epoch: [84][180/391]\tTime  0.110 ( 0.103)\tLoss 4.1464e-01 (4.8008e-01)\tAcc@1  85.94 ( 85.05)\tAcc@5 100.00 ( 98.62)\n",
            "Epoch: [84][210/391]\tTime  0.105 ( 0.103)\tLoss 3.8327e-01 (4.8482e-01)\tAcc@1  87.50 ( 84.90)\tAcc@5 100.00 ( 98.63)\n",
            "Epoch: [84][240/391]\tTime  0.101 ( 0.104)\tLoss 4.9400e-01 (4.9040e-01)\tAcc@1  89.06 ( 84.76)\tAcc@5  97.66 ( 98.60)\n",
            "Epoch: [84][270/391]\tTime  0.099 ( 0.104)\tLoss 5.0011e-01 (4.9671e-01)\tAcc@1  85.16 ( 84.55)\tAcc@5  99.22 ( 98.58)\n",
            "Epoch: [84][300/391]\tTime  0.097 ( 0.103)\tLoss 4.7611e-01 (5.0184e-01)\tAcc@1  86.72 ( 84.39)\tAcc@5  99.22 ( 98.54)\n",
            "Epoch: [84][330/391]\tTime  0.097 ( 0.103)\tLoss 6.0851e-01 (5.0867e-01)\tAcc@1  82.03 ( 84.22)\tAcc@5  99.22 ( 98.50)\n",
            "Epoch: [84][360/391]\tTime  0.098 ( 0.103)\tLoss 6.5006e-01 (5.1365e-01)\tAcc@1  82.03 ( 84.06)\tAcc@5  96.88 ( 98.49)\n",
            "Epoch: [84][390/391]\tTime  0.049 ( 0.102)\tLoss 6.2304e-01 (5.2020e-01)\tAcc@1  80.00 ( 83.84)\tAcc@5  96.25 ( 98.43)\n",
            "==> Train Accuracy: Acc@1 83.842 || Acc@5 98.426\n",
            "==> Test Accuracy:  Acc@1 62.250 || Acc@5 86.930\n",
            "==> 57.50 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 85, lr: 0.020000000000000004 -----\n",
            "Epoch: [85][  0/391]\tTime  0.352 ( 0.352)\tLoss 3.9006e-01 (3.9006e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [85][ 30/391]\tTime  0.102 ( 0.113)\tLoss 5.0981e-01 (4.7424e-01)\tAcc@1  85.16 ( 85.56)\tAcc@5  96.88 ( 98.36)\n",
            "Epoch: [85][ 60/391]\tTime  0.102 ( 0.107)\tLoss 4.3760e-01 (4.7279e-01)\tAcc@1  83.59 ( 85.37)\tAcc@5 100.00 ( 98.49)\n",
            "Epoch: [85][ 90/391]\tTime  0.101 ( 0.105)\tLoss 3.6947e-01 (4.6695e-01)\tAcc@1  89.84 ( 85.50)\tAcc@5  99.22 ( 98.62)\n",
            "Epoch: [85][120/391]\tTime  0.103 ( 0.104)\tLoss 6.9838e-01 (4.7323e-01)\tAcc@1  80.47 ( 85.29)\tAcc@5  96.88 ( 98.59)\n",
            "Epoch: [85][150/391]\tTime  0.103 ( 0.103)\tLoss 4.2103e-01 (4.7789e-01)\tAcc@1  89.84 ( 85.15)\tAcc@5  99.22 ( 98.62)\n",
            "Epoch: [85][180/391]\tTime  0.101 ( 0.102)\tLoss 7.4246e-01 (4.7922e-01)\tAcc@1  78.12 ( 85.09)\tAcc@5  96.09 ( 98.61)\n",
            "Epoch: [85][210/391]\tTime  0.099 ( 0.102)\tLoss 4.8652e-01 (4.8951e-01)\tAcc@1  84.38 ( 84.78)\tAcc@5  97.66 ( 98.53)\n",
            "Epoch: [85][240/391]\tTime  0.096 ( 0.102)\tLoss 5.7362e-01 (4.9476e-01)\tAcc@1  84.38 ( 84.66)\tAcc@5  99.22 ( 98.48)\n",
            "Epoch: [85][270/391]\tTime  0.099 ( 0.102)\tLoss 4.9004e-01 (4.9700e-01)\tAcc@1  80.47 ( 84.59)\tAcc@5 100.00 ( 98.45)\n",
            "Epoch: [85][300/391]\tTime  0.099 ( 0.102)\tLoss 4.6633e-01 (5.0213e-01)\tAcc@1  86.72 ( 84.42)\tAcc@5  98.44 ( 98.43)\n",
            "Epoch: [85][330/391]\tTime  0.097 ( 0.102)\tLoss 6.2957e-01 (5.0523e-01)\tAcc@1  78.12 ( 84.36)\tAcc@5  98.44 ( 98.41)\n",
            "Epoch: [85][360/391]\tTime  0.095 ( 0.102)\tLoss 6.0825e-01 (5.1011e-01)\tAcc@1  84.38 ( 84.20)\tAcc@5  97.66 ( 98.40)\n",
            "Epoch: [85][390/391]\tTime  0.048 ( 0.101)\tLoss 5.9416e-01 (5.1735e-01)\tAcc@1  83.75 ( 83.94)\tAcc@5  98.75 ( 98.35)\n",
            "==> Train Accuracy: Acc@1 83.940 || Acc@5 98.346\n",
            "==> Test Accuracy:  Acc@1 61.270 || Acc@5 86.450\n",
            "==> 57.06 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 86, lr: 0.020000000000000004 -----\n",
            "Epoch: [86][  0/391]\tTime  0.381 ( 0.381)\tLoss 4.8597e-01 (4.8597e-01)\tAcc@1  85.94 ( 85.94)\tAcc@5  97.66 ( 97.66)\n",
            "Epoch: [86][ 30/391]\tTime  0.099 ( 0.112)\tLoss 6.3483e-01 (4.5297e-01)\tAcc@1  78.12 ( 86.11)\tAcc@5  96.88 ( 98.84)\n",
            "Epoch: [86][ 60/391]\tTime  0.100 ( 0.106)\tLoss 4.8722e-01 (4.4857e-01)\tAcc@1  83.59 ( 86.27)\tAcc@5  99.22 ( 98.91)\n",
            "Epoch: [86][ 90/391]\tTime  0.100 ( 0.105)\tLoss 4.2891e-01 (4.6201e-01)\tAcc@1  88.28 ( 85.72)\tAcc@5 100.00 ( 98.82)\n",
            "Epoch: [86][120/391]\tTime  0.100 ( 0.103)\tLoss 5.4413e-01 (4.6407e-01)\tAcc@1  86.72 ( 85.69)\tAcc@5  97.66 ( 98.74)\n",
            "Epoch: [86][150/391]\tTime  0.097 ( 0.103)\tLoss 6.2513e-01 (4.6950e-01)\tAcc@1  79.69 ( 85.46)\tAcc@5  99.22 ( 98.72)\n",
            "Epoch: [86][180/391]\tTime  0.097 ( 0.103)\tLoss 5.1179e-01 (4.7587e-01)\tAcc@1  83.59 ( 85.17)\tAcc@5  98.44 ( 98.72)\n",
            "Epoch: [86][210/391]\tTime  0.096 ( 0.102)\tLoss 4.2392e-01 (4.8097e-01)\tAcc@1  85.94 ( 85.04)\tAcc@5  98.44 ( 98.68)\n",
            "Epoch: [86][240/391]\tTime  0.099 ( 0.102)\tLoss 5.0147e-01 (4.8761e-01)\tAcc@1  82.81 ( 84.83)\tAcc@5  99.22 ( 98.63)\n",
            "Epoch: [86][270/391]\tTime  0.104 ( 0.102)\tLoss 4.8864e-01 (4.9425e-01)\tAcc@1  84.38 ( 84.61)\tAcc@5  99.22 ( 98.56)\n",
            "Epoch: [86][300/391]\tTime  0.104 ( 0.102)\tLoss 5.0601e-01 (4.9955e-01)\tAcc@1  87.50 ( 84.45)\tAcc@5  98.44 ( 98.53)\n",
            "Epoch: [86][330/391]\tTime  0.118 ( 0.102)\tLoss 4.7604e-01 (5.0543e-01)\tAcc@1  84.38 ( 84.26)\tAcc@5  99.22 ( 98.48)\n",
            "Epoch: [86][360/391]\tTime  0.110 ( 0.102)\tLoss 4.8460e-01 (5.0840e-01)\tAcc@1  86.72 ( 84.20)\tAcc@5  99.22 ( 98.44)\n",
            "Epoch: [86][390/391]\tTime  0.048 ( 0.101)\tLoss 7.3908e-01 (5.1268e-01)\tAcc@1  80.00 ( 84.08)\tAcc@5  92.50 ( 98.40)\n",
            "==> Train Accuracy: Acc@1 84.084 || Acc@5 98.402\n",
            "==> Test Accuracy:  Acc@1 61.960 || Acc@5 87.070\n",
            "==> 57.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 87, lr: 0.020000000000000004 -----\n",
            "Epoch: [87][  0/391]\tTime  0.379 ( 0.379)\tLoss 5.7029e-01 (5.7029e-01)\tAcc@1  79.69 ( 79.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [87][ 30/391]\tTime  0.100 ( 0.110)\tLoss 4.8457e-01 (4.6736e-01)\tAcc@1  85.16 ( 85.41)\tAcc@5  99.22 ( 99.04)\n",
            "Epoch: [87][ 60/391]\tTime  0.098 ( 0.105)\tLoss 3.9903e-01 (4.5457e-01)\tAcc@1  85.94 ( 86.09)\tAcc@5  99.22 ( 99.00)\n",
            "Epoch: [87][ 90/391]\tTime  0.099 ( 0.104)\tLoss 5.4574e-01 (4.6733e-01)\tAcc@1  85.94 ( 85.57)\tAcc@5  97.66 ( 98.88)\n",
            "Epoch: [87][120/391]\tTime  0.104 ( 0.103)\tLoss 4.7789e-01 (4.6770e-01)\tAcc@1  84.38 ( 85.58)\tAcc@5  98.44 ( 98.85)\n",
            "Epoch: [87][150/391]\tTime  0.099 ( 0.103)\tLoss 5.8439e-01 (4.7635e-01)\tAcc@1  79.69 ( 85.29)\tAcc@5  96.88 ( 98.70)\n",
            "Epoch: [87][180/391]\tTime  0.106 ( 0.102)\tLoss 4.2845e-01 (4.7736e-01)\tAcc@1  86.72 ( 85.34)\tAcc@5  99.22 ( 98.69)\n",
            "Epoch: [87][210/391]\tTime  0.102 ( 0.102)\tLoss 4.8109e-01 (4.7937e-01)\tAcc@1  83.59 ( 85.30)\tAcc@5  97.66 ( 98.63)\n",
            "Epoch: [87][240/391]\tTime  0.098 ( 0.102)\tLoss 5.6543e-01 (4.8392e-01)\tAcc@1  81.25 ( 85.13)\tAcc@5  98.44 ( 98.61)\n",
            "Epoch: [87][270/391]\tTime  0.096 ( 0.102)\tLoss 5.1834e-01 (4.9006e-01)\tAcc@1  82.03 ( 84.82)\tAcc@5  99.22 ( 98.63)\n",
            "Epoch: [87][300/391]\tTime  0.104 ( 0.102)\tLoss 4.0582e-01 (4.9420e-01)\tAcc@1  85.94 ( 84.67)\tAcc@5  99.22 ( 98.63)\n",
            "Epoch: [87][330/391]\tTime  0.096 ( 0.102)\tLoss 4.0846e-01 (4.9920e-01)\tAcc@1  89.06 ( 84.52)\tAcc@5  99.22 ( 98.60)\n",
            "Epoch: [87][360/391]\tTime  0.096 ( 0.101)\tLoss 4.8337e-01 (5.0356e-01)\tAcc@1  83.59 ( 84.43)\tAcc@5  98.44 ( 98.55)\n",
            "Epoch: [87][390/391]\tTime  0.049 ( 0.101)\tLoss 7.8485e-01 (5.0745e-01)\tAcc@1  71.25 ( 84.33)\tAcc@5  98.75 ( 98.53)\n",
            "==> Train Accuracy: Acc@1 84.334 || Acc@5 98.526\n",
            "==> Test Accuracy:  Acc@1 62.280 || Acc@5 87.490\n",
            "==> 56.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 88, lr: 0.020000000000000004 -----\n",
            "Epoch: [88][  0/391]\tTime  0.364 ( 0.364)\tLoss 4.1932e-01 (4.1932e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [88][ 30/391]\tTime  0.097 ( 0.108)\tLoss 3.9708e-01 (4.6372e-01)\tAcc@1  87.50 ( 85.74)\tAcc@5  98.44 ( 98.64)\n",
            "Epoch: [88][ 60/391]\tTime  0.097 ( 0.104)\tLoss 5.2089e-01 (4.6194e-01)\tAcc@1  84.38 ( 85.46)\tAcc@5  97.66 ( 98.82)\n",
            "Epoch: [88][ 90/391]\tTime  0.097 ( 0.103)\tLoss 5.6238e-01 (4.5931e-01)\tAcc@1  82.81 ( 85.59)\tAcc@5  96.88 ( 98.90)\n",
            "Epoch: [88][120/391]\tTime  0.096 ( 0.102)\tLoss 3.9262e-01 (4.5841e-01)\tAcc@1  85.16 ( 85.79)\tAcc@5  99.22 ( 98.86)\n",
            "Epoch: [88][150/391]\tTime  0.100 ( 0.101)\tLoss 5.7790e-01 (4.6789e-01)\tAcc@1  80.47 ( 85.50)\tAcc@5  99.22 ( 98.74)\n",
            "Epoch: [88][180/391]\tTime  0.113 ( 0.101)\tLoss 5.3158e-01 (4.7278e-01)\tAcc@1  82.03 ( 85.37)\tAcc@5  97.66 ( 98.70)\n",
            "Epoch: [88][210/391]\tTime  0.100 ( 0.101)\tLoss 4.2801e-01 (4.7941e-01)\tAcc@1  84.38 ( 85.17)\tAcc@5 100.00 ( 98.70)\n",
            "Epoch: [88][240/391]\tTime  0.099 ( 0.101)\tLoss 6.6825e-01 (4.8574e-01)\tAcc@1  80.47 ( 84.98)\tAcc@5  98.44 ( 98.66)\n",
            "Epoch: [88][270/391]\tTime  0.101 ( 0.101)\tLoss 4.9407e-01 (4.9205e-01)\tAcc@1  84.38 ( 84.78)\tAcc@5  98.44 ( 98.65)\n",
            "Epoch: [88][300/391]\tTime  0.102 ( 0.101)\tLoss 4.9876e-01 (4.9357e-01)\tAcc@1  85.16 ( 84.76)\tAcc@5  99.22 ( 98.61)\n",
            "Epoch: [88][330/391]\tTime  0.106 ( 0.101)\tLoss 5.8629e-01 (4.9983e-01)\tAcc@1  85.16 ( 84.54)\tAcc@5  95.31 ( 98.56)\n",
            "Epoch: [88][360/391]\tTime  0.096 ( 0.101)\tLoss 5.9609e-01 (5.0345e-01)\tAcc@1  80.47 ( 84.37)\tAcc@5  97.66 ( 98.55)\n",
            "Epoch: [88][390/391]\tTime  0.048 ( 0.100)\tLoss 4.6505e-01 (5.0671e-01)\tAcc@1  85.00 ( 84.24)\tAcc@5  97.50 ( 98.53)\n",
            "==> Train Accuracy: Acc@1 84.240 || Acc@5 98.530\n",
            "==> Test Accuracy:  Acc@1 63.190 || Acc@5 87.750\n",
            "==> 56.59 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 89, lr: 0.020000000000000004 -----\n",
            "Epoch: [89][  0/391]\tTime  0.344 ( 0.344)\tLoss 4.2937e-01 (4.2937e-01)\tAcc@1  88.28 ( 88.28)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [89][ 30/391]\tTime  0.098 ( 0.109)\tLoss 5.0308e-01 (4.3962e-01)\tAcc@1  86.72 ( 87.50)\tAcc@5  96.88 ( 98.79)\n",
            "Epoch: [89][ 60/391]\tTime  0.106 ( 0.106)\tLoss 4.5111e-01 (4.4326e-01)\tAcc@1  85.94 ( 86.86)\tAcc@5  99.22 ( 98.86)\n",
            "Epoch: [89][ 90/391]\tTime  0.102 ( 0.104)\tLoss 4.3688e-01 (4.3924e-01)\tAcc@1  86.72 ( 86.86)\tAcc@5  98.44 ( 98.86)\n",
            "Epoch: [89][120/391]\tTime  0.101 ( 0.103)\tLoss 4.0825e-01 (4.4176e-01)\tAcc@1  89.06 ( 86.68)\tAcc@5 100.00 ( 98.80)\n",
            "Epoch: [89][150/391]\tTime  0.105 ( 0.102)\tLoss 4.2374e-01 (4.4461e-01)\tAcc@1  86.72 ( 86.52)\tAcc@5  99.22 ( 98.80)\n",
            "Epoch: [89][180/391]\tTime  0.098 ( 0.101)\tLoss 5.5517e-01 (4.5437e-01)\tAcc@1  80.47 ( 86.11)\tAcc@5  98.44 ( 98.74)\n",
            "Epoch: [89][210/391]\tTime  0.097 ( 0.101)\tLoss 5.3192e-01 (4.6229e-01)\tAcc@1  83.59 ( 85.83)\tAcc@5 100.00 ( 98.74)\n",
            "Epoch: [89][240/391]\tTime  0.105 ( 0.101)\tLoss 5.2606e-01 (4.6582e-01)\tAcc@1  82.81 ( 85.68)\tAcc@5  99.22 ( 98.74)\n",
            "Epoch: [89][270/391]\tTime  0.101 ( 0.101)\tLoss 5.0799e-01 (4.6634e-01)\tAcc@1  82.03 ( 85.66)\tAcc@5  99.22 ( 98.76)\n",
            "Epoch: [89][300/391]\tTime  0.105 ( 0.101)\tLoss 7.0083e-01 (4.7691e-01)\tAcc@1  78.91 ( 85.36)\tAcc@5  99.22 ( 98.68)\n",
            "Epoch: [89][330/391]\tTime  0.101 ( 0.101)\tLoss 5.0416e-01 (4.8386e-01)\tAcc@1  82.03 ( 85.14)\tAcc@5  99.22 ( 98.64)\n",
            "Epoch: [89][360/391]\tTime  0.104 ( 0.101)\tLoss 6.7431e-01 (4.8841e-01)\tAcc@1  78.12 ( 84.95)\tAcc@5  96.88 ( 98.61)\n",
            "Epoch: [89][390/391]\tTime  0.048 ( 0.101)\tLoss 8.1187e-01 (4.9379e-01)\tAcc@1  77.50 ( 84.78)\tAcc@5  95.00 ( 98.57)\n",
            "==> Train Accuracy: Acc@1 84.782 || Acc@5 98.574\n",
            "==> Test Accuracy:  Acc@1 63.290 || Acc@5 87.600\n",
            "==> 56.85 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 90, lr: 0.004000000000000001 -----\n",
            "Epoch: [90][  0/391]\tTime  0.339 ( 0.339)\tLoss 4.4303e-01 (4.4303e-01)\tAcc@1  89.06 ( 89.06)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [90][ 30/391]\tTime  0.102 ( 0.108)\tLoss 3.5386e-01 (4.0716e-01)\tAcc@1  89.06 ( 87.58)\tAcc@5 100.00 ( 99.02)\n",
            "Epoch: [90][ 60/391]\tTime  0.101 ( 0.106)\tLoss 3.4000e-01 (3.6986e-01)\tAcc@1  90.62 ( 88.86)\tAcc@5  99.22 ( 99.23)\n",
            "Epoch: [90][ 90/391]\tTime  0.098 ( 0.104)\tLoss 2.8311e-01 (3.4429e-01)\tAcc@1  92.97 ( 89.80)\tAcc@5  99.22 ( 99.34)\n",
            "Epoch: [90][120/391]\tTime  0.098 ( 0.103)\tLoss 3.0102e-01 (3.3186e-01)\tAcc@1  93.75 ( 90.19)\tAcc@5  98.44 ( 99.38)\n",
            "Epoch: [90][150/391]\tTime  0.116 ( 0.103)\tLoss 3.9034e-01 (3.2377e-01)\tAcc@1  86.72 ( 90.54)\tAcc@5 100.00 ( 99.40)\n",
            "Epoch: [90][180/391]\tTime  0.100 ( 0.102)\tLoss 2.4648e-01 (3.1229e-01)\tAcc@1  93.75 ( 90.91)\tAcc@5 100.00 ( 99.46)\n",
            "Epoch: [90][210/391]\tTime  0.110 ( 0.102)\tLoss 3.0210e-01 (3.0443e-01)\tAcc@1  92.19 ( 91.06)\tAcc@5 100.00 ( 99.49)\n",
            "Epoch: [90][240/391]\tTime  0.097 ( 0.102)\tLoss 4.1486e-01 (3.0292e-01)\tAcc@1  89.06 ( 91.13)\tAcc@5  99.22 ( 99.50)\n",
            "Epoch: [90][270/391]\tTime  0.100 ( 0.101)\tLoss 2.6309e-01 (2.9773e-01)\tAcc@1  92.19 ( 91.27)\tAcc@5 100.00 ( 99.53)\n",
            "Epoch: [90][300/391]\tTime  0.096 ( 0.101)\tLoss 2.6246e-01 (2.9206e-01)\tAcc@1  91.41 ( 91.47)\tAcc@5 100.00 ( 99.54)\n",
            "Epoch: [90][330/391]\tTime  0.096 ( 0.101)\tLoss 2.5576e-01 (2.8761e-01)\tAcc@1  93.75 ( 91.66)\tAcc@5 100.00 ( 99.54)\n",
            "Epoch: [90][360/391]\tTime  0.102 ( 0.101)\tLoss 2.0854e-01 (2.8380e-01)\tAcc@1  94.53 ( 91.76)\tAcc@5 100.00 ( 99.57)\n",
            "Epoch: [90][390/391]\tTime  0.049 ( 0.101)\tLoss 2.7869e-01 (2.8085e-01)\tAcc@1  92.50 ( 91.87)\tAcc@5  98.75 ( 99.58)\n",
            "==> Train Accuracy: Acc@1 91.868 || Acc@5 99.580\n",
            "==> Test Accuracy:  Acc@1 69.410 || Acc@5 90.790\n",
            "==> 56.89 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 91, lr: 0.004000000000000001 -----\n",
            "Epoch: [91][  0/391]\tTime  0.410 ( 0.410)\tLoss 2.3420e-01 (2.3420e-01)\tAcc@1  92.97 ( 92.97)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [91][ 30/391]\tTime  0.098 ( 0.112)\tLoss 1.9344e-01 (2.2004e-01)\tAcc@1  92.19 ( 93.80)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [91][ 60/391]\tTime  0.099 ( 0.106)\tLoss 1.8382e-01 (2.1348e-01)\tAcc@1  96.09 ( 94.08)\tAcc@5 100.00 ( 99.78)\n",
            "Epoch: [91][ 90/391]\tTime  0.099 ( 0.104)\tLoss 1.6612e-01 (2.1174e-01)\tAcc@1  97.66 ( 94.14)\tAcc@5  99.22 ( 99.79)\n",
            "Epoch: [91][120/391]\tTime  0.101 ( 0.103)\tLoss 2.0805e-01 (2.0686e-01)\tAcc@1  95.31 ( 94.37)\tAcc@5  99.22 ( 99.78)\n",
            "Epoch: [91][150/391]\tTime  0.101 ( 0.103)\tLoss 1.3653e-01 (2.0450e-01)\tAcc@1  96.88 ( 94.43)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [91][180/391]\tTime  0.102 ( 0.102)\tLoss 2.3219e-01 (2.0442e-01)\tAcc@1  94.53 ( 94.42)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [91][210/391]\tTime  0.098 ( 0.102)\tLoss 2.0061e-01 (2.0410e-01)\tAcc@1  93.75 ( 94.47)\tAcc@5 100.00 ( 99.75)\n",
            "Epoch: [91][240/391]\tTime  0.109 ( 0.102)\tLoss 2.1779e-01 (2.0381e-01)\tAcc@1  92.19 ( 94.45)\tAcc@5  99.22 ( 99.76)\n",
            "Epoch: [91][270/391]\tTime  0.096 ( 0.102)\tLoss 1.7706e-01 (2.0277e-01)\tAcc@1  96.88 ( 94.50)\tAcc@5 100.00 ( 99.76)\n",
            "Epoch: [91][300/391]\tTime  0.099 ( 0.102)\tLoss 2.2183e-01 (2.0090e-01)\tAcc@1  94.53 ( 94.61)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [91][330/391]\tTime  0.096 ( 0.101)\tLoss 1.8345e-01 (1.9984e-01)\tAcc@1  95.31 ( 94.62)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [91][360/391]\tTime  0.105 ( 0.101)\tLoss 2.0893e-01 (1.9937e-01)\tAcc@1  96.09 ( 94.60)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [91][390/391]\tTime  0.048 ( 0.101)\tLoss 2.1550e-01 (1.9838e-01)\tAcc@1  91.25 ( 94.63)\tAcc@5 100.00 ( 99.77)\n",
            "==> Train Accuracy: Acc@1 94.628 || Acc@5 99.774\n",
            "==> Test Accuracy:  Acc@1 69.940 || Acc@5 91.120\n",
            "==> 56.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 92, lr: 0.004000000000000001 -----\n",
            "Epoch: [92][  0/391]\tTime  0.426 ( 0.426)\tLoss 1.5944e-01 (1.5944e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5  99.22 ( 99.22)\n",
            "Epoch: [92][ 30/391]\tTime  0.107 ( 0.116)\tLoss 1.6690e-01 (1.6896e-01)\tAcc@1  92.97 ( 95.54)\tAcc@5 100.00 ( 99.77)\n",
            "Epoch: [92][ 60/391]\tTime  0.098 ( 0.111)\tLoss 1.9487e-01 (1.7482e-01)\tAcc@1  96.09 ( 95.53)\tAcc@5 100.00 ( 99.80)\n",
            "Epoch: [92][ 90/391]\tTime  0.099 ( 0.108)\tLoss 1.6059e-01 (1.7154e-01)\tAcc@1  95.31 ( 95.56)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [92][120/391]\tTime  0.102 ( 0.106)\tLoss 2.1230e-01 (1.7359e-01)\tAcc@1  92.97 ( 95.41)\tAcc@5 100.00 ( 99.79)\n",
            "Epoch: [92][150/391]\tTime  0.104 ( 0.105)\tLoss 2.1151e-01 (1.7163e-01)\tAcc@1  95.31 ( 95.48)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [92][180/391]\tTime  0.109 ( 0.105)\tLoss 1.6544e-01 (1.7320e-01)\tAcc@1  96.88 ( 95.48)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [92][210/391]\tTime  0.102 ( 0.105)\tLoss 1.5331e-01 (1.7408e-01)\tAcc@1  97.66 ( 95.46)\tAcc@5 100.00 ( 99.81)\n",
            "Epoch: [92][240/391]\tTime  0.104 ( 0.104)\tLoss 1.3981e-01 (1.7403e-01)\tAcc@1  96.88 ( 95.41)\tAcc@5  99.22 ( 99.81)\n",
            "Epoch: [92][270/391]\tTime  0.098 ( 0.104)\tLoss 2.1154e-01 (1.7355e-01)\tAcc@1  94.53 ( 95.47)\tAcc@5  99.22 ( 99.82)\n",
            "Epoch: [92][300/391]\tTime  0.098 ( 0.103)\tLoss 2.1185e-01 (1.7285e-01)\tAcc@1  95.31 ( 95.51)\tAcc@5  99.22 ( 99.83)\n",
            "Epoch: [92][330/391]\tTime  0.095 ( 0.103)\tLoss 2.7711e-01 (1.7401e-01)\tAcc@1  92.19 ( 95.48)\tAcc@5  98.44 ( 99.83)\n",
            "Epoch: [92][360/391]\tTime  0.099 ( 0.103)\tLoss 2.0497e-01 (1.7304e-01)\tAcc@1  92.97 ( 95.52)\tAcc@5 100.00 ( 99.83)\n",
            "Epoch: [92][390/391]\tTime  0.048 ( 0.102)\tLoss 1.6385e-01 (1.7271e-01)\tAcc@1  96.25 ( 95.56)\tAcc@5 100.00 ( 99.83)\n",
            "==> Train Accuracy: Acc@1 95.560 || Acc@5 99.828\n",
            "==> Test Accuracy:  Acc@1 69.970 || Acc@5 90.920\n",
            "==> 57.43 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 93, lr: 0.004000000000000001 -----\n",
            "Epoch: [93][  0/391]\tTime  0.380 ( 0.380)\tLoss 1.8024e-01 (1.8024e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [93][ 30/391]\tTime  0.102 ( 0.110)\tLoss 1.8381e-01 (1.5796e-01)\tAcc@1  96.88 ( 96.04)\tAcc@5  99.22 ( 99.82)\n",
            "Epoch: [93][ 60/391]\tTime  0.101 ( 0.107)\tLoss 2.0635e-01 (1.5733e-01)\tAcc@1  95.31 ( 96.09)\tAcc@5  99.22 ( 99.88)\n",
            "Epoch: [93][ 90/391]\tTime  0.097 ( 0.105)\tLoss 1.2330e-01 (1.5696e-01)\tAcc@1  96.09 ( 96.18)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [93][120/391]\tTime  0.096 ( 0.104)\tLoss 1.9504e-01 (1.5609e-01)\tAcc@1  92.97 ( 96.17)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [93][150/391]\tTime  0.098 ( 0.103)\tLoss 1.5835e-01 (1.5460e-01)\tAcc@1  94.53 ( 96.15)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [93][180/391]\tTime  0.098 ( 0.102)\tLoss 1.1983e-01 (1.5402e-01)\tAcc@1  98.44 ( 96.19)\tAcc@5 100.00 ( 99.88)\n",
            "Epoch: [93][210/391]\tTime  0.100 ( 0.102)\tLoss 1.4877e-01 (1.5370e-01)\tAcc@1  97.66 ( 96.21)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [93][240/391]\tTime  0.104 ( 0.101)\tLoss 1.9586e-01 (1.5399e-01)\tAcc@1  93.75 ( 96.16)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [93][270/391]\tTime  0.106 ( 0.101)\tLoss 1.0894e-01 (1.5388e-01)\tAcc@1  98.44 ( 96.15)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [93][300/391]\tTime  0.098 ( 0.101)\tLoss 1.4277e-01 (1.5436e-01)\tAcc@1  96.09 ( 96.13)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [93][330/391]\tTime  0.097 ( 0.101)\tLoss 1.4392e-01 (1.5451e-01)\tAcc@1  94.53 ( 96.11)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [93][360/391]\tTime  0.099 ( 0.101)\tLoss 1.4258e-01 (1.5491e-01)\tAcc@1  96.88 ( 96.12)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [93][390/391]\tTime  0.048 ( 0.100)\tLoss 1.4976e-01 (1.5464e-01)\tAcc@1  97.50 ( 96.14)\tAcc@5 100.00 ( 99.89)\n",
            "==> Train Accuracy: Acc@1 96.140 || Acc@5 99.890\n",
            "==> Test Accuracy:  Acc@1 70.320 || Acc@5 91.320\n",
            "==> 56.75 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 94, lr: 0.004000000000000001 -----\n",
            "Epoch: [94][  0/391]\tTime  0.354 ( 0.354)\tLoss 7.1135e-02 (7.1135e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [94][ 30/391]\tTime  0.098 ( 0.110)\tLoss 1.6884e-01 (1.3529e-01)\tAcc@1  95.31 ( 96.70)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [94][ 60/391]\tTime  0.107 ( 0.106)\tLoss 1.1867e-01 (1.3167e-01)\tAcc@1  97.66 ( 97.09)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [94][ 90/391]\tTime  0.096 ( 0.104)\tLoss 9.8392e-02 (1.2987e-01)\tAcc@1  99.22 ( 97.14)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [94][120/391]\tTime  0.096 ( 0.103)\tLoss 1.3164e-01 (1.3450e-01)\tAcc@1  96.88 ( 96.93)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [94][150/391]\tTime  0.097 ( 0.102)\tLoss 1.6962e-01 (1.3683e-01)\tAcc@1  96.88 ( 96.83)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [94][180/391]\tTime  0.099 ( 0.102)\tLoss 1.1591e-01 (1.3814e-01)\tAcc@1  97.66 ( 96.69)\tAcc@5  99.22 ( 99.89)\n",
            "Epoch: [94][210/391]\tTime  0.094 ( 0.102)\tLoss 1.9458e-01 (1.3770e-01)\tAcc@1  95.31 ( 96.67)\tAcc@5 100.00 ( 99.89)\n",
            "Epoch: [94][240/391]\tTime  0.104 ( 0.101)\tLoss 1.2324e-01 (1.3564e-01)\tAcc@1  96.88 ( 96.70)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [94][270/391]\tTime  0.095 ( 0.101)\tLoss 1.1269e-01 (1.3519e-01)\tAcc@1  96.09 ( 96.71)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [94][300/391]\tTime  0.093 ( 0.100)\tLoss 1.3342e-01 (1.3555e-01)\tAcc@1  96.88 ( 96.65)\tAcc@5 100.00 ( 99.90)\n",
            "Epoch: [94][330/391]\tTime  0.094 ( 0.100)\tLoss 1.0717e-01 (1.3495e-01)\tAcc@1  98.44 ( 96.67)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [94][360/391]\tTime  0.095 ( 0.100)\tLoss 1.0977e-01 (1.3468e-01)\tAcc@1  96.88 ( 96.69)\tAcc@5 100.00 ( 99.91)\n",
            "Epoch: [94][390/391]\tTime  0.048 ( 0.099)\tLoss 1.2411e-01 (1.3543e-01)\tAcc@1 100.00 ( 96.67)\tAcc@5 100.00 ( 99.91)\n",
            "==> Train Accuracy: Acc@1 96.674 || Acc@5 99.908\n",
            "==> Test Accuracy:  Acc@1 70.350 || Acc@5 90.830\n",
            "==> 56.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 95, lr: 0.004000000000000001 -----\n",
            "Epoch: [95][  0/391]\tTime  0.337 ( 0.337)\tLoss 1.0863e-01 (1.0863e-01)\tAcc@1  96.09 ( 96.09)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][ 30/391]\tTime  0.099 ( 0.108)\tLoss 6.8964e-02 (1.1245e-01)\tAcc@1  98.44 ( 97.48)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [95][ 60/391]\tTime  0.100 ( 0.104)\tLoss 1.3412e-01 (1.1986e-01)\tAcc@1  96.88 ( 97.20)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [95][ 90/391]\tTime  0.096 ( 0.102)\tLoss 1.3832e-01 (1.2225e-01)\tAcc@1  95.31 ( 97.12)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [95][120/391]\tTime  0.097 ( 0.101)\tLoss 1.2186e-01 (1.2239e-01)\tAcc@1  95.31 ( 97.14)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [95][150/391]\tTime  0.097 ( 0.102)\tLoss 1.0150e-01 (1.2336e-01)\tAcc@1  97.66 ( 97.08)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [95][180/391]\tTime  0.097 ( 0.101)\tLoss 1.4377e-01 (1.2366e-01)\tAcc@1  96.88 ( 97.10)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [95][210/391]\tTime  0.096 ( 0.101)\tLoss 1.2764e-01 (1.2283e-01)\tAcc@1  95.31 ( 97.10)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [95][240/391]\tTime  0.095 ( 0.101)\tLoss 1.3313e-01 (1.2307e-01)\tAcc@1  95.31 ( 97.10)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [95][270/391]\tTime  0.096 ( 0.101)\tLoss 1.3220e-01 (1.2307e-01)\tAcc@1  96.88 ( 97.11)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [95][300/391]\tTime  0.099 ( 0.100)\tLoss 1.2112e-01 (1.2310e-01)\tAcc@1  97.66 ( 97.14)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [95][330/391]\tTime  0.097 ( 0.100)\tLoss 1.2279e-01 (1.2319e-01)\tAcc@1  97.66 ( 97.12)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [95][360/391]\tTime  0.104 ( 0.100)\tLoss 9.5309e-02 (1.2360e-01)\tAcc@1  96.88 ( 97.10)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [95][390/391]\tTime  0.048 ( 0.100)\tLoss 1.4777e-01 (1.2395e-01)\tAcc@1  97.50 ( 97.08)\tAcc@5 100.00 ( 99.95)\n",
            "==> Train Accuracy: Acc@1 97.076 || Acc@5 99.952\n",
            "==> Test Accuracy:  Acc@1 70.570 || Acc@5 91.040\n",
            "==> 56.37 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 96, lr: 0.004000000000000001 -----\n",
            "Epoch: [96][  0/391]\tTime  0.337 ( 0.337)\tLoss 1.3011e-01 (1.3011e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [96][ 30/391]\tTime  0.095 ( 0.108)\tLoss 1.7521e-01 (1.1562e-01)\tAcc@1  96.09 ( 97.35)\tAcc@5 100.00 ( 99.87)\n",
            "Epoch: [96][ 60/391]\tTime  0.097 ( 0.105)\tLoss 9.6864e-02 (1.1171e-01)\tAcc@1  97.66 ( 97.44)\tAcc@5 100.00 ( 99.92)\n",
            "Epoch: [96][ 90/391]\tTime  0.096 ( 0.103)\tLoss 1.2326e-01 (1.1115e-01)\tAcc@1  96.88 ( 97.38)\tAcc@5 100.00 ( 99.93)\n",
            "Epoch: [96][120/391]\tTime  0.097 ( 0.102)\tLoss 1.4586e-01 (1.1558e-01)\tAcc@1  96.09 ( 97.18)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [96][150/391]\tTime  0.095 ( 0.101)\tLoss 1.3453e-01 (1.1332e-01)\tAcc@1  94.53 ( 97.27)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [96][180/391]\tTime  0.096 ( 0.101)\tLoss 1.1966e-01 (1.1339e-01)\tAcc@1  96.88 ( 97.27)\tAcc@5  99.22 ( 99.94)\n",
            "Epoch: [96][210/391]\tTime  0.101 ( 0.101)\tLoss 1.1663e-01 (1.1386e-01)\tAcc@1  97.66 ( 97.27)\tAcc@5  99.22 ( 99.92)\n",
            "Epoch: [96][240/391]\tTime  0.104 ( 0.101)\tLoss 1.0260e-01 (1.1324e-01)\tAcc@1  97.66 ( 97.32)\tAcc@5 100.00 ( 99.93)\n",
            "Epoch: [96][270/391]\tTime  0.101 ( 0.101)\tLoss 7.9917e-02 (1.1361e-01)\tAcc@1  97.66 ( 97.30)\tAcc@5 100.00 ( 99.93)\n",
            "Epoch: [96][300/391]\tTime  0.100 ( 0.101)\tLoss 1.4474e-01 (1.1339e-01)\tAcc@1  96.09 ( 97.35)\tAcc@5 100.00 ( 99.93)\n",
            "Epoch: [96][330/391]\tTime  0.098 ( 0.100)\tLoss 1.0115e-01 (1.1402e-01)\tAcc@1  98.44 ( 97.34)\tAcc@5 100.00 ( 99.93)\n",
            "Epoch: [96][360/391]\tTime  0.094 ( 0.100)\tLoss 1.0813e-01 (1.1464e-01)\tAcc@1  96.88 ( 97.29)\tAcc@5 100.00 ( 99.94)\n",
            "Epoch: [96][390/391]\tTime  0.048 ( 0.100)\tLoss 2.1370e-01 (1.1495e-01)\tAcc@1  93.75 ( 97.27)\tAcc@5 100.00 ( 99.94)\n",
            "==> Train Accuracy: Acc@1 97.266 || Acc@5 99.936\n",
            "==> Test Accuracy:  Acc@1 70.200 || Acc@5 90.930\n",
            "==> 56.46 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 97, lr: 0.004000000000000001 -----\n",
            "Epoch: [97][  0/391]\tTime  0.355 ( 0.355)\tLoss 1.1277e-01 (1.1277e-01)\tAcc@1  95.31 ( 95.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [97][ 30/391]\tTime  0.103 ( 0.110)\tLoss 1.2524e-01 (1.0148e-01)\tAcc@1  96.88 ( 97.96)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [97][ 60/391]\tTime  0.095 ( 0.104)\tLoss 1.1335e-01 (1.0609e-01)\tAcc@1  97.66 ( 97.48)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [97][ 90/391]\tTime  0.096 ( 0.102)\tLoss 1.1941e-01 (1.0688e-01)\tAcc@1  96.88 ( 97.51)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [97][120/391]\tTime  0.098 ( 0.101)\tLoss 5.3133e-02 (1.0658e-01)\tAcc@1 100.00 ( 97.54)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [97][150/391]\tTime  0.096 ( 0.101)\tLoss 6.5555e-02 (1.0586e-01)\tAcc@1 100.00 ( 97.58)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [97][180/391]\tTime  0.098 ( 0.101)\tLoss 8.0015e-02 (1.0595e-01)\tAcc@1  99.22 ( 97.57)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [97][210/391]\tTime  0.102 ( 0.101)\tLoss 8.6741e-02 (1.0519e-01)\tAcc@1  98.44 ( 97.59)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [97][240/391]\tTime  0.097 ( 0.101)\tLoss 1.2557e-01 (1.0480e-01)\tAcc@1  96.88 ( 97.58)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [97][270/391]\tTime  0.097 ( 0.100)\tLoss 1.0210e-01 (1.0480e-01)\tAcc@1  97.66 ( 97.59)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [97][300/391]\tTime  0.098 ( 0.100)\tLoss 1.0151e-01 (1.0619e-01)\tAcc@1  98.44 ( 97.57)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [97][330/391]\tTime  0.095 ( 0.100)\tLoss 1.0125e-01 (1.0577e-01)\tAcc@1  98.44 ( 97.60)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [97][360/391]\tTime  0.097 ( 0.100)\tLoss 1.5664e-01 (1.0604e-01)\tAcc@1  96.09 ( 97.58)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [97][390/391]\tTime  0.049 ( 0.099)\tLoss 1.2976e-01 (1.0613e-01)\tAcc@1  97.50 ( 97.58)\tAcc@5 100.00 ( 99.96)\n",
            "==> Train Accuracy: Acc@1 97.576 || Acc@5 99.960\n",
            "==> Test Accuracy:  Acc@1 70.380 || Acc@5 91.000\n",
            "==> 56.35 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 98, lr: 0.004000000000000001 -----\n",
            "Epoch: [98][  0/391]\tTime  0.333 ( 0.333)\tLoss 1.0769e-01 (1.0769e-01)\tAcc@1  96.88 ( 96.88)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [98][ 30/391]\tTime  0.097 ( 0.108)\tLoss 1.1768e-01 (9.8916e-02)\tAcc@1  96.09 ( 97.71)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [98][ 60/391]\tTime  0.095 ( 0.103)\tLoss 1.4787e-01 (9.7346e-02)\tAcc@1  94.53 ( 97.84)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [98][ 90/391]\tTime  0.103 ( 0.102)\tLoss 7.9920e-02 (9.8992e-02)\tAcc@1  99.22 ( 97.85)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [98][120/391]\tTime  0.108 ( 0.102)\tLoss 9.8612e-02 (9.8283e-02)\tAcc@1  98.44 ( 97.94)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [98][150/391]\tTime  0.097 ( 0.101)\tLoss 9.5826e-02 (9.8783e-02)\tAcc@1  97.66 ( 97.85)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [98][180/391]\tTime  0.095 ( 0.101)\tLoss 1.5654e-01 (9.9067e-02)\tAcc@1  96.09 ( 97.87)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [98][210/391]\tTime  0.102 ( 0.101)\tLoss 1.1079e-01 (9.9835e-02)\tAcc@1  96.88 ( 97.83)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [98][240/391]\tTime  0.100 ( 0.101)\tLoss 7.8268e-02 (1.0086e-01)\tAcc@1  99.22 ( 97.74)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [98][270/391]\tTime  0.100 ( 0.100)\tLoss 1.3292e-01 (1.0038e-01)\tAcc@1  95.31 ( 97.74)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [98][300/391]\tTime  0.097 ( 0.100)\tLoss 8.6764e-02 (1.0076e-01)\tAcc@1  98.44 ( 97.75)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [98][330/391]\tTime  0.099 ( 0.100)\tLoss 7.4313e-02 (1.0066e-01)\tAcc@1  98.44 ( 97.76)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [98][360/391]\tTime  0.095 ( 0.100)\tLoss 9.3036e-02 (1.0108e-01)\tAcc@1  97.66 ( 97.74)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [98][390/391]\tTime  0.048 ( 0.099)\tLoss 7.3830e-02 (1.0156e-01)\tAcc@1  98.75 ( 97.73)\tAcc@5 100.00 ( 99.96)\n",
            "==> Train Accuracy: Acc@1 97.726 || Acc@5 99.956\n",
            "==> Test Accuracy:  Acc@1 70.760 || Acc@5 90.990\n",
            "==> 55.88 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 99, lr: 0.004000000000000001 -----\n",
            "Epoch: [99][  0/391]\tTime  0.382 ( 0.382)\tLoss 6.0080e-02 (6.0080e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [99][ 30/391]\tTime  0.094 ( 0.112)\tLoss 1.0614e-01 (8.2841e-02)\tAcc@1  97.66 ( 98.44)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [99][ 60/391]\tTime  0.092 ( 0.105)\tLoss 5.3725e-02 (8.8576e-02)\tAcc@1 100.00 ( 98.13)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [99][ 90/391]\tTime  0.095 ( 0.102)\tLoss 1.4679e-01 (9.0843e-02)\tAcc@1  96.09 ( 98.03)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [99][120/391]\tTime  0.096 ( 0.101)\tLoss 7.1570e-02 (9.1824e-02)\tAcc@1  98.44 ( 98.02)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [99][150/391]\tTime  0.101 ( 0.100)\tLoss 9.7449e-02 (9.3064e-02)\tAcc@1  98.44 ( 98.01)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [99][180/391]\tTime  0.101 ( 0.099)\tLoss 9.2479e-02 (9.3563e-02)\tAcc@1  97.66 ( 97.93)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [99][210/391]\tTime  0.095 ( 0.099)\tLoss 1.2609e-01 (9.2952e-02)\tAcc@1  96.88 ( 97.93)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [99][240/391]\tTime  0.095 ( 0.099)\tLoss 1.1129e-01 (9.2274e-02)\tAcc@1  96.88 ( 97.97)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [99][270/391]\tTime  0.101 ( 0.099)\tLoss 1.4052e-01 (9.3293e-02)\tAcc@1  94.53 ( 97.94)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [99][300/391]\tTime  0.096 ( 0.099)\tLoss 1.1671e-01 (9.4232e-02)\tAcc@1  96.88 ( 97.93)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [99][330/391]\tTime  0.094 ( 0.099)\tLoss 4.1509e-02 (9.4360e-02)\tAcc@1 100.00 ( 97.94)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [99][360/391]\tTime  0.094 ( 0.099)\tLoss 5.8716e-02 (9.4653e-02)\tAcc@1  98.44 ( 97.93)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [99][390/391]\tTime  0.049 ( 0.098)\tLoss 1.5675e-01 (9.5049e-02)\tAcc@1  96.25 ( 97.93)\tAcc@5  98.75 ( 99.96)\n",
            "==> Train Accuracy: Acc@1 97.930 || Acc@5 99.960\n",
            "==> Test Accuracy:  Acc@1 70.480 || Acc@5 91.120\n",
            "==> 55.46 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 100, lr: 0.004000000000000001 -----\n",
            "Epoch: [100][  0/391]\tTime  0.342 ( 0.342)\tLoss 5.5443e-02 (5.5443e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][ 30/391]\tTime  0.097 ( 0.106)\tLoss 1.0102e-01 (8.2135e-02)\tAcc@1  98.44 ( 98.41)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [100][ 60/391]\tTime  0.102 ( 0.101)\tLoss 8.9043e-02 (8.7145e-02)\tAcc@1  98.44 ( 98.17)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [100][ 90/391]\tTime  0.094 ( 0.100)\tLoss 9.2523e-02 (8.7506e-02)\tAcc@1  98.44 ( 98.14)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [100][120/391]\tTime  0.094 ( 0.100)\tLoss 8.6622e-02 (8.8122e-02)\tAcc@1  99.22 ( 98.15)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [100][150/391]\tTime  0.094 ( 0.099)\tLoss 7.7835e-02 (8.8127e-02)\tAcc@1  99.22 ( 98.17)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [100][180/391]\tTime  0.096 ( 0.098)\tLoss 7.0138e-02 (8.7669e-02)\tAcc@1  99.22 ( 98.19)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [100][210/391]\tTime  0.094 ( 0.098)\tLoss 8.6426e-02 (8.8972e-02)\tAcc@1  98.44 ( 98.14)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [100][240/391]\tTime  0.095 ( 0.098)\tLoss 8.9198e-02 (8.9283e-02)\tAcc@1  97.66 ( 98.09)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [100][270/391]\tTime  0.094 ( 0.098)\tLoss 4.5915e-02 (8.8198e-02)\tAcc@1 100.00 ( 98.13)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [100][300/391]\tTime  0.094 ( 0.097)\tLoss 1.2654e-01 (8.8527e-02)\tAcc@1  96.09 ( 98.15)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [100][330/391]\tTime  0.113 ( 0.097)\tLoss 6.6542e-02 (8.8464e-02)\tAcc@1  97.66 ( 98.15)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [100][360/391]\tTime  0.093 ( 0.097)\tLoss 1.0870e-01 (8.8549e-02)\tAcc@1  99.22 ( 98.16)\tAcc@5  99.22 ( 99.97)\n",
            "Epoch: [100][390/391]\tTime  0.048 ( 0.097)\tLoss 1.4971e-01 (8.8834e-02)\tAcc@1  95.00 ( 98.14)\tAcc@5 100.00 ( 99.97)\n",
            "==> Train Accuracy: Acc@1 98.138 || Acc@5 99.972\n",
            "==> Test Accuracy:  Acc@1 70.660 || Acc@5 91.110\n",
            "==> 54.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 101, lr: 0.004000000000000001 -----\n",
            "Epoch: [101][  0/391]\tTime  0.334 ( 0.334)\tLoss 5.7912e-02 (5.7912e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [101][ 30/391]\tTime  0.097 ( 0.105)\tLoss 8.3038e-02 (8.3950e-02)\tAcc@1  97.66 ( 98.19)\tAcc@5  99.22 ( 99.97)\n",
            "Epoch: [101][ 60/391]\tTime  0.096 ( 0.101)\tLoss 1.0222e-01 (8.0409e-02)\tAcc@1  98.44 ( 98.31)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [101][ 90/391]\tTime  0.095 ( 0.100)\tLoss 7.5445e-02 (8.3708e-02)\tAcc@1  99.22 ( 98.16)\tAcc@5 100.00 ( 99.95)\n",
            "Epoch: [101][120/391]\tTime  0.096 ( 0.099)\tLoss 9.5940e-02 (8.3355e-02)\tAcc@1  97.66 ( 98.22)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [101][150/391]\tTime  0.098 ( 0.098)\tLoss 6.9522e-02 (8.3343e-02)\tAcc@1  99.22 ( 98.22)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [101][180/391]\tTime  0.096 ( 0.099)\tLoss 6.7809e-02 (8.2479e-02)\tAcc@1  97.66 ( 98.24)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [101][210/391]\tTime  0.095 ( 0.098)\tLoss 7.6338e-02 (8.3562e-02)\tAcc@1  99.22 ( 98.22)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [101][240/391]\tTime  0.099 ( 0.098)\tLoss 7.2204e-02 (8.4067e-02)\tAcc@1  98.44 ( 98.21)\tAcc@5 100.00 ( 99.96)\n",
            "Epoch: [101][270/391]\tTime  0.095 ( 0.098)\tLoss 6.0971e-02 (8.3684e-02)\tAcc@1 100.00 ( 98.24)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [101][300/391]\tTime  0.109 ( 0.098)\tLoss 7.8456e-02 (8.3609e-02)\tAcc@1  98.44 ( 98.24)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [101][330/391]\tTime  0.096 ( 0.098)\tLoss 7.6527e-02 (8.3689e-02)\tAcc@1  99.22 ( 98.24)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [101][360/391]\tTime  0.094 ( 0.098)\tLoss 1.0201e-01 (8.3852e-02)\tAcc@1  97.66 ( 98.22)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [101][390/391]\tTime  0.048 ( 0.097)\tLoss 1.0985e-01 (8.4230e-02)\tAcc@1  97.50 ( 98.20)\tAcc@5 100.00 ( 99.97)\n",
            "==> Train Accuracy: Acc@1 98.204 || Acc@5 99.974\n",
            "==> Test Accuracy:  Acc@1 70.660 || Acc@5 90.760\n",
            "==> 55.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 102, lr: 0.004000000000000001 -----\n",
            "Epoch: [102][  0/391]\tTime  0.375 ( 0.375)\tLoss 5.6553e-02 (5.6553e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 30/391]\tTime  0.095 ( 0.107)\tLoss 9.4454e-02 (7.4003e-02)\tAcc@1  96.88 ( 98.61)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 60/391]\tTime  0.096 ( 0.102)\tLoss 6.7268e-02 (7.3118e-02)\tAcc@1  99.22 ( 98.64)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][ 90/391]\tTime  0.094 ( 0.100)\tLoss 6.9684e-02 (7.4574e-02)\tAcc@1  98.44 ( 98.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][120/391]\tTime  0.100 ( 0.099)\tLoss 9.0871e-02 (7.5710e-02)\tAcc@1  97.66 ( 98.50)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][150/391]\tTime  0.096 ( 0.098)\tLoss 5.7539e-02 (7.6747e-02)\tAcc@1  97.66 ( 98.45)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [102][180/391]\tTime  0.094 ( 0.098)\tLoss 1.1273e-01 (7.7045e-02)\tAcc@1  96.88 ( 98.46)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][210/391]\tTime  0.094 ( 0.098)\tLoss 1.0180e-01 (7.7148e-02)\tAcc@1  97.66 ( 98.46)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [102][240/391]\tTime  0.102 ( 0.097)\tLoss 5.6307e-02 (7.7132e-02)\tAcc@1  99.22 ( 98.45)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [102][270/391]\tTime  0.093 ( 0.097)\tLoss 7.9452e-02 (7.7301e-02)\tAcc@1  96.88 ( 98.45)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [102][300/391]\tTime  0.096 ( 0.097)\tLoss 9.3691e-02 (7.8207e-02)\tAcc@1  96.88 ( 98.42)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [102][330/391]\tTime  0.111 ( 0.097)\tLoss 7.0452e-02 (7.7995e-02)\tAcc@1  98.44 ( 98.43)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [102][360/391]\tTime  0.095 ( 0.097)\tLoss 9.0654e-02 (7.8042e-02)\tAcc@1  99.22 ( 98.43)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [102][390/391]\tTime  0.048 ( 0.097)\tLoss 8.7567e-02 (7.8197e-02)\tAcc@1 100.00 ( 98.40)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 98.402 || Acc@5 99.982\n",
            "==> Test Accuracy:  Acc@1 70.420 || Acc@5 90.880\n",
            "==> 54.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 103, lr: 0.004000000000000001 -----\n",
            "Epoch: [103][  0/391]\tTime  0.353 ( 0.353)\tLoss 9.1054e-02 (9.1054e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 30/391]\tTime  0.095 ( 0.106)\tLoss 6.4124e-02 (7.1925e-02)\tAcc@1  99.22 ( 98.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 60/391]\tTime  0.093 ( 0.101)\tLoss 7.3638e-02 (7.4428e-02)\tAcc@1  97.66 ( 98.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][ 90/391]\tTime  0.094 ( 0.100)\tLoss 8.3669e-02 (7.4869e-02)\tAcc@1  99.22 ( 98.51)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][120/391]\tTime  0.104 ( 0.099)\tLoss 8.1682e-02 (7.2805e-02)\tAcc@1  97.66 ( 98.59)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [103][150/391]\tTime  0.093 ( 0.099)\tLoss 7.8861e-02 (7.3850e-02)\tAcc@1  97.66 ( 98.53)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [103][180/391]\tTime  0.093 ( 0.098)\tLoss 6.9145e-02 (7.3639e-02)\tAcc@1  98.44 ( 98.55)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [103][210/391]\tTime  0.094 ( 0.098)\tLoss 1.0954e-01 (7.4058e-02)\tAcc@1  98.44 ( 98.50)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [103][240/391]\tTime  0.099 ( 0.098)\tLoss 7.9190e-02 (7.3849e-02)\tAcc@1  97.66 ( 98.53)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [103][270/391]\tTime  0.097 ( 0.098)\tLoss 7.6084e-02 (7.4834e-02)\tAcc@1  98.44 ( 98.53)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [103][300/391]\tTime  0.095 ( 0.098)\tLoss 8.3303e-02 (7.4882e-02)\tAcc@1  98.44 ( 98.55)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [103][330/391]\tTime  0.097 ( 0.097)\tLoss 8.7808e-02 (7.5266e-02)\tAcc@1  97.66 ( 98.53)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [103][360/391]\tTime  0.094 ( 0.098)\tLoss 1.5527e-01 (7.5888e-02)\tAcc@1  93.75 ( 98.50)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [103][390/391]\tTime  0.049 ( 0.097)\tLoss 1.0505e-01 (7.5378e-02)\tAcc@1  96.25 ( 98.52)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 98.516 || Acc@5 99.988\n",
            "==> Test Accuracy:  Acc@1 70.780 || Acc@5 90.940\n",
            "==> 55.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 104, lr: 0.004000000000000001 -----\n",
            "Epoch: [104][  0/391]\tTime  0.363 ( 0.363)\tLoss 6.0459e-02 (6.0459e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][ 30/391]\tTime  0.095 ( 0.106)\tLoss 6.9657e-02 (6.9777e-02)\tAcc@1  98.44 ( 98.64)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][ 60/391]\tTime  0.099 ( 0.102)\tLoss 5.4468e-02 (6.9834e-02)\tAcc@1  99.22 ( 98.60)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][ 90/391]\tTime  0.094 ( 0.100)\tLoss 6.7104e-02 (7.1650e-02)\tAcc@1  98.44 ( 98.57)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [104][120/391]\tTime  0.097 ( 0.099)\tLoss 3.8735e-02 (7.0530e-02)\tAcc@1 100.00 ( 98.69)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [104][150/391]\tTime  0.094 ( 0.099)\tLoss 5.1488e-02 (7.1029e-02)\tAcc@1  99.22 ( 98.69)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [104][180/391]\tTime  0.095 ( 0.099)\tLoss 8.0262e-02 (7.0334e-02)\tAcc@1  98.44 ( 98.71)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [104][210/391]\tTime  0.093 ( 0.099)\tLoss 5.5034e-02 (7.1096e-02)\tAcc@1  99.22 ( 98.69)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [104][240/391]\tTime  0.095 ( 0.099)\tLoss 6.4297e-02 (7.2619e-02)\tAcc@1  98.44 ( 98.63)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [104][270/391]\tTime  0.092 ( 0.098)\tLoss 1.1806e-01 (7.2356e-02)\tAcc@1  96.88 ( 98.63)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [104][300/391]\tTime  0.093 ( 0.098)\tLoss 7.3239e-02 (7.2004e-02)\tAcc@1  97.66 ( 98.65)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [104][330/391]\tTime  0.094 ( 0.098)\tLoss 1.3532e-01 (7.2206e-02)\tAcc@1  96.09 ( 98.64)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [104][360/391]\tTime  0.093 ( 0.098)\tLoss 8.5323e-02 (7.3003e-02)\tAcc@1  98.44 ( 98.58)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [104][390/391]\tTime  0.048 ( 0.097)\tLoss 8.8982e-02 (7.3081e-02)\tAcc@1  97.50 ( 98.59)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 98.592 || Acc@5 99.982\n",
            "==> Test Accuracy:  Acc@1 70.540 || Acc@5 90.660\n",
            "==> 55.43 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 105, lr: 0.004000000000000001 -----\n",
            "Epoch: [105][  0/391]\tTime  0.382 ( 0.382)\tLoss 7.4910e-02 (7.4910e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [105][ 30/391]\tTime  0.094 ( 0.109)\tLoss 6.6517e-02 (7.1773e-02)\tAcc@1  99.22 ( 98.71)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [105][ 60/391]\tTime  0.093 ( 0.102)\tLoss 5.4168e-02 (7.0130e-02)\tAcc@1 100.00 ( 98.63)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [105][ 90/391]\tTime  0.094 ( 0.100)\tLoss 8.6737e-02 (6.7777e-02)\tAcc@1  98.44 ( 98.76)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [105][120/391]\tTime  0.094 ( 0.099)\tLoss 6.0063e-02 (6.7104e-02)\tAcc@1  98.44 ( 98.77)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [105][150/391]\tTime  0.114 ( 0.099)\tLoss 8.6066e-02 (6.8300e-02)\tAcc@1  99.22 ( 98.72)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [105][180/391]\tTime  0.099 ( 0.099)\tLoss 9.5145e-02 (6.9676e-02)\tAcc@1  96.88 ( 98.66)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [105][210/391]\tTime  0.093 ( 0.098)\tLoss 1.3342e-01 (6.9821e-02)\tAcc@1  94.53 ( 98.63)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [105][240/391]\tTime  0.095 ( 0.098)\tLoss 1.1758e-01 (6.9932e-02)\tAcc@1  96.88 ( 98.63)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [105][270/391]\tTime  0.103 ( 0.098)\tLoss 8.6101e-02 (6.9602e-02)\tAcc@1  98.44 ( 98.66)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [105][300/391]\tTime  0.093 ( 0.097)\tLoss 7.7059e-02 (6.9459e-02)\tAcc@1  98.44 ( 98.65)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [105][330/391]\tTime  0.096 ( 0.098)\tLoss 8.1732e-02 (7.0151e-02)\tAcc@1  97.66 ( 98.62)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [105][360/391]\tTime  0.092 ( 0.097)\tLoss 5.4714e-02 (7.0664e-02)\tAcc@1 100.00 ( 98.62)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [105][390/391]\tTime  0.048 ( 0.097)\tLoss 3.9126e-02 (7.1242e-02)\tAcc@1 100.00 ( 98.59)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 98.594 || Acc@5 99.980\n",
            "==> Test Accuracy:  Acc@1 70.260 || Acc@5 90.780\n",
            "==> 55.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 106, lr: 0.004000000000000001 -----\n",
            "Epoch: [106][  0/391]\tTime  0.344 ( 0.344)\tLoss 5.7536e-02 (5.7536e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][ 30/391]\tTime  0.102 ( 0.111)\tLoss 5.3410e-02 (6.1143e-02)\tAcc@1  99.22 ( 98.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [106][ 60/391]\tTime  0.096 ( 0.106)\tLoss 5.9796e-02 (6.3674e-02)\tAcc@1  99.22 ( 98.72)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [106][ 90/391]\tTime  0.095 ( 0.102)\tLoss 9.3734e-02 (6.5386e-02)\tAcc@1  96.09 ( 98.65)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [106][120/391]\tTime  0.097 ( 0.103)\tLoss 6.4561e-02 (6.5554e-02)\tAcc@1  98.44 ( 98.68)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [106][150/391]\tTime  0.108 ( 0.102)\tLoss 3.4636e-02 (6.3968e-02)\tAcc@1 100.00 ( 98.76)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [106][180/391]\tTime  0.099 ( 0.102)\tLoss 5.1417e-02 (6.5378e-02)\tAcc@1  99.22 ( 98.70)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [106][210/391]\tTime  0.100 ( 0.101)\tLoss 4.4701e-02 (6.5715e-02)\tAcc@1  99.22 ( 98.73)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [106][240/391]\tTime  0.098 ( 0.101)\tLoss 1.8296e-01 (6.6229e-02)\tAcc@1  94.53 ( 98.72)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [106][270/391]\tTime  0.098 ( 0.101)\tLoss 7.2932e-02 (6.5683e-02)\tAcc@1  99.22 ( 98.77)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [106][300/391]\tTime  0.098 ( 0.100)\tLoss 9.4841e-02 (6.6180e-02)\tAcc@1  98.44 ( 98.76)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [106][330/391]\tTime  0.097 ( 0.100)\tLoss 5.0511e-02 (6.7018e-02)\tAcc@1 100.00 ( 98.74)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [106][360/391]\tTime  0.098 ( 0.100)\tLoss 8.2964e-02 (6.7446e-02)\tAcc@1  99.22 ( 98.71)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [106][390/391]\tTime  0.048 ( 0.100)\tLoss 5.3127e-02 (6.7304e-02)\tAcc@1 100.00 ( 98.70)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 98.702 || Acc@5 99.984\n",
            "==> Test Accuracy:  Acc@1 70.120 || Acc@5 90.990\n",
            "==> 56.11 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 107, lr: 0.004000000000000001 -----\n",
            "Epoch: [107][  0/391]\tTime  0.328 ( 0.328)\tLoss 6.6221e-02 (6.6221e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [107][ 30/391]\tTime  0.098 ( 0.106)\tLoss 7.3456e-02 (6.6394e-02)\tAcc@1  98.44 ( 98.61)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [107][ 60/391]\tTime  0.098 ( 0.102)\tLoss 6.5361e-02 (6.2615e-02)\tAcc@1  99.22 ( 98.78)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][ 90/391]\tTime  0.096 ( 0.101)\tLoss 9.6756e-02 (6.6428e-02)\tAcc@1  96.88 ( 98.61)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [107][120/391]\tTime  0.096 ( 0.100)\tLoss 7.9452e-02 (6.5866e-02)\tAcc@1  98.44 ( 98.63)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][150/391]\tTime  0.096 ( 0.100)\tLoss 8.8087e-02 (6.5702e-02)\tAcc@1  97.66 ( 98.62)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][180/391]\tTime  0.095 ( 0.099)\tLoss 5.4040e-02 (6.4836e-02)\tAcc@1  99.22 ( 98.69)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][210/391]\tTime  0.095 ( 0.099)\tLoss 5.6485e-02 (6.4620e-02)\tAcc@1  99.22 ( 98.72)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][240/391]\tTime  0.094 ( 0.099)\tLoss 4.1672e-02 (6.4788e-02)\tAcc@1 100.00 ( 98.71)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][270/391]\tTime  0.094 ( 0.099)\tLoss 7.3019e-02 (6.4078e-02)\tAcc@1  97.66 ( 98.75)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][300/391]\tTime  0.096 ( 0.098)\tLoss 7.1939e-02 (6.5382e-02)\tAcc@1  97.66 ( 98.70)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][330/391]\tTime  0.095 ( 0.098)\tLoss 4.4462e-02 (6.5423e-02)\tAcc@1  99.22 ( 98.72)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][360/391]\tTime  0.098 ( 0.098)\tLoss 3.7106e-02 (6.5636e-02)\tAcc@1 100.00 ( 98.73)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [107][390/391]\tTime  0.048 ( 0.098)\tLoss 1.0505e-01 (6.5796e-02)\tAcc@1  97.50 ( 98.72)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 98.718 || Acc@5 99.992\n",
            "==> Test Accuracy:  Acc@1 70.030 || Acc@5 90.550\n",
            "==> 55.26 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 108, lr: 0.004000000000000001 -----\n",
            "Epoch: [108][  0/391]\tTime  0.357 ( 0.357)\tLoss 2.6209e-02 (2.6209e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][ 30/391]\tTime  0.093 ( 0.105)\tLoss 4.6838e-02 (5.5884e-02)\tAcc@1  99.22 ( 98.89)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [108][ 60/391]\tTime  0.097 ( 0.101)\tLoss 5.6625e-02 (5.7015e-02)\tAcc@1  98.44 ( 98.96)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [108][ 90/391]\tTime  0.095 ( 0.099)\tLoss 8.3830e-02 (5.9486e-02)\tAcc@1  99.22 ( 98.96)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [108][120/391]\tTime  0.107 ( 0.099)\tLoss 4.8598e-02 (6.0980e-02)\tAcc@1 100.00 ( 98.93)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [108][150/391]\tTime  0.094 ( 0.099)\tLoss 8.0434e-02 (6.1242e-02)\tAcc@1  98.44 ( 98.91)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [108][180/391]\tTime  0.092 ( 0.098)\tLoss 1.3606e-01 (6.2918e-02)\tAcc@1  96.09 ( 98.84)\tAcc@5  99.22 ( 99.98)\n",
            "Epoch: [108][210/391]\tTime  0.095 ( 0.098)\tLoss 1.3808e-01 (6.2805e-02)\tAcc@1  96.09 ( 98.82)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [108][240/391]\tTime  0.100 ( 0.098)\tLoss 9.4597e-02 (6.3305e-02)\tAcc@1  97.66 ( 98.82)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [108][270/391]\tTime  0.095 ( 0.098)\tLoss 9.9996e-02 (6.3424e-02)\tAcc@1  96.88 ( 98.81)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [108][300/391]\tTime  0.093 ( 0.098)\tLoss 6.9600e-02 (6.3505e-02)\tAcc@1  98.44 ( 98.82)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [108][330/391]\tTime  0.103 ( 0.098)\tLoss 8.1450e-02 (6.3295e-02)\tAcc@1  98.44 ( 98.82)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [108][360/391]\tTime  0.101 ( 0.098)\tLoss 8.8978e-02 (6.3988e-02)\tAcc@1  97.66 ( 98.81)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [108][390/391]\tTime  0.048 ( 0.097)\tLoss 3.1622e-02 (6.4042e-02)\tAcc@1 100.00 ( 98.82)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 98.816 || Acc@5 99.986\n",
            "==> Test Accuracy:  Acc@1 70.600 || Acc@5 90.760\n",
            "==> 55.03 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 109, lr: 0.004000000000000001 -----\n",
            "Epoch: [109][  0/391]\tTime  0.360 ( 0.360)\tLoss 5.3751e-02 (5.3751e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][ 30/391]\tTime  0.100 ( 0.105)\tLoss 4.9884e-02 (4.8249e-02)\tAcc@1  99.22 ( 99.32)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [109][ 60/391]\tTime  0.094 ( 0.101)\tLoss 5.6553e-02 (5.2674e-02)\tAcc@1  99.22 ( 99.17)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [109][ 90/391]\tTime  0.096 ( 0.100)\tLoss 7.3881e-02 (5.5476e-02)\tAcc@1  98.44 ( 99.10)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [109][120/391]\tTime  0.094 ( 0.099)\tLoss 4.1458e-02 (5.7729e-02)\tAcc@1  99.22 ( 99.04)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [109][150/391]\tTime  0.100 ( 0.098)\tLoss 3.6891e-02 (5.8208e-02)\tAcc@1 100.00 ( 98.99)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [109][180/391]\tTime  0.095 ( 0.098)\tLoss 3.6151e-02 (5.7459e-02)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [109][210/391]\tTime  0.095 ( 0.098)\tLoss 3.6742e-02 (5.8166e-02)\tAcc@1 100.00 ( 98.96)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [109][240/391]\tTime  0.094 ( 0.098)\tLoss 4.9376e-02 (5.8851e-02)\tAcc@1  98.44 ( 98.94)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [109][270/391]\tTime  0.094 ( 0.098)\tLoss 6.1024e-02 (5.8715e-02)\tAcc@1  99.22 ( 98.95)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [109][300/391]\tTime  0.097 ( 0.097)\tLoss 2.9383e-02 (5.8988e-02)\tAcc@1 100.00 ( 98.94)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [109][330/391]\tTime  0.100 ( 0.098)\tLoss 4.0866e-02 (5.8483e-02)\tAcc@1  99.22 ( 98.97)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [109][360/391]\tTime  0.100 ( 0.098)\tLoss 5.7570e-02 (5.9131e-02)\tAcc@1  99.22 ( 98.94)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [109][390/391]\tTime  0.048 ( 0.097)\tLoss 4.8074e-02 (5.9750e-02)\tAcc@1 100.00 ( 98.90)\tAcc@5 100.00 ( 99.98)\n",
            "==> Train Accuracy: Acc@1 98.902 || Acc@5 99.982\n",
            "==> Test Accuracy:  Acc@1 70.230 || Acc@5 90.850\n",
            "==> 54.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 110, lr: 0.004000000000000001 -----\n",
            "Epoch: [110][  0/391]\tTime  0.347 ( 0.347)\tLoss 5.9415e-02 (5.9415e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [110][ 30/391]\tTime  0.094 ( 0.105)\tLoss 3.1870e-02 (4.9919e-02)\tAcc@1 100.00 ( 99.24)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [110][ 60/391]\tTime  0.096 ( 0.101)\tLoss 7.8046e-02 (5.2105e-02)\tAcc@1  97.66 ( 99.21)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][ 90/391]\tTime  0.100 ( 0.100)\tLoss 5.4280e-02 (5.2990e-02)\tAcc@1  99.22 ( 99.12)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][120/391]\tTime  0.095 ( 0.100)\tLoss 5.3672e-02 (5.2890e-02)\tAcc@1  98.44 ( 99.12)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][150/391]\tTime  0.095 ( 0.099)\tLoss 6.9400e-02 (5.3605e-02)\tAcc@1  97.66 ( 99.06)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][180/391]\tTime  0.102 ( 0.098)\tLoss 4.0875e-02 (5.4095e-02)\tAcc@1  99.22 ( 99.07)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][210/391]\tTime  0.107 ( 0.099)\tLoss 4.6590e-02 (5.4872e-02)\tAcc@1 100.00 ( 99.05)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][240/391]\tTime  0.096 ( 0.098)\tLoss 4.5102e-02 (5.5208e-02)\tAcc@1  99.22 ( 99.03)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][270/391]\tTime  0.093 ( 0.098)\tLoss 2.9602e-02 (5.5655e-02)\tAcc@1 100.00 ( 99.02)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][300/391]\tTime  0.094 ( 0.098)\tLoss 3.3037e-02 (5.6135e-02)\tAcc@1  99.22 ( 98.99)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][330/391]\tTime  0.099 ( 0.098)\tLoss 4.4564e-02 (5.6116e-02)\tAcc@1  99.22 ( 99.00)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][360/391]\tTime  0.095 ( 0.097)\tLoss 8.4608e-02 (5.6823e-02)\tAcc@1  97.66 ( 98.96)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [110][390/391]\tTime  0.049 ( 0.097)\tLoss 1.1035e-01 (5.7443e-02)\tAcc@1  95.00 ( 98.94)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 98.940 || Acc@5 99.988\n",
            "==> Test Accuracy:  Acc@1 71.140 || Acc@5 90.860\n",
            "==> 54.99 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 111, lr: 0.004000000000000001 -----\n",
            "Epoch: [111][  0/391]\tTime  0.335 ( 0.335)\tLoss 5.6838e-02 (5.6838e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [111][ 30/391]\tTime  0.098 ( 0.106)\tLoss 2.9918e-02 (5.7740e-02)\tAcc@1  99.22 ( 98.77)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [111][ 60/391]\tTime  0.096 ( 0.101)\tLoss 6.1187e-02 (5.4971e-02)\tAcc@1  98.44 ( 98.87)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][ 90/391]\tTime  0.095 ( 0.099)\tLoss 5.5196e-02 (5.4056e-02)\tAcc@1  99.22 ( 98.97)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][120/391]\tTime  0.092 ( 0.098)\tLoss 4.8551e-02 (5.4523e-02)\tAcc@1 100.00 ( 98.92)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][150/391]\tTime  0.093 ( 0.098)\tLoss 5.8577e-02 (5.4003e-02)\tAcc@1  99.22 ( 98.97)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][180/391]\tTime  0.096 ( 0.098)\tLoss 5.1226e-02 (5.3586e-02)\tAcc@1  99.22 ( 99.00)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][210/391]\tTime  0.096 ( 0.098)\tLoss 8.4227e-02 (5.4341e-02)\tAcc@1  96.88 ( 98.99)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][240/391]\tTime  0.102 ( 0.098)\tLoss 7.8304e-02 (5.4547e-02)\tAcc@1  98.44 ( 99.00)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][270/391]\tTime  0.097 ( 0.098)\tLoss 2.6644e-02 (5.4634e-02)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][300/391]\tTime  0.098 ( 0.098)\tLoss 7.7877e-02 (5.4714e-02)\tAcc@1  96.88 ( 99.02)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][330/391]\tTime  0.098 ( 0.098)\tLoss 5.3145e-02 (5.5494e-02)\tAcc@1 100.00 ( 99.02)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][360/391]\tTime  0.094 ( 0.098)\tLoss 7.7708e-02 (5.5757e-02)\tAcc@1  98.44 ( 98.98)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [111][390/391]\tTime  0.049 ( 0.097)\tLoss 9.0784e-02 (5.5761e-02)\tAcc@1  98.75 ( 98.99)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 98.986 || Acc@5 99.988\n",
            "==> Test Accuracy:  Acc@1 70.590 || Acc@5 90.330\n",
            "==> 55.13 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 112, lr: 0.004000000000000001 -----\n",
            "Epoch: [112][  0/391]\tTime  0.328 ( 0.328)\tLoss 2.9174e-02 (2.9174e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][ 30/391]\tTime  0.094 ( 0.105)\tLoss 6.2438e-02 (4.8757e-02)\tAcc@1  97.66 ( 98.99)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][ 60/391]\tTime  0.102 ( 0.101)\tLoss 4.4464e-02 (4.7333e-02)\tAcc@1  99.22 ( 99.12)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][ 90/391]\tTime  0.101 ( 0.100)\tLoss 6.5258e-02 (4.8420e-02)\tAcc@1  98.44 ( 99.11)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][120/391]\tTime  0.097 ( 0.099)\tLoss 4.3930e-02 (4.7854e-02)\tAcc@1  99.22 ( 99.14)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][150/391]\tTime  0.100 ( 0.099)\tLoss 6.4758e-02 (4.8295e-02)\tAcc@1  97.66 ( 99.16)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][180/391]\tTime  0.101 ( 0.099)\tLoss 2.1193e-02 (4.8859e-02)\tAcc@1 100.00 ( 99.13)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [112][210/391]\tTime  0.094 ( 0.099)\tLoss 3.5814e-02 (4.9466e-02)\tAcc@1 100.00 ( 99.14)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][240/391]\tTime  0.094 ( 0.099)\tLoss 3.8874e-02 (4.8937e-02)\tAcc@1  99.22 ( 99.18)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][270/391]\tTime  0.097 ( 0.098)\tLoss 4.4728e-02 (4.9175e-02)\tAcc@1 100.00 ( 99.18)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][300/391]\tTime  0.098 ( 0.098)\tLoss 7.9480e-02 (4.9143e-02)\tAcc@1  96.09 ( 99.18)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][330/391]\tTime  0.097 ( 0.099)\tLoss 3.4641e-02 (4.9557e-02)\tAcc@1 100.00 ( 99.17)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][360/391]\tTime  0.094 ( 0.099)\tLoss 4.3752e-02 (4.9974e-02)\tAcc@1  99.22 ( 99.16)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [112][390/391]\tTime  0.048 ( 0.098)\tLoss 2.3898e-02 (5.0318e-02)\tAcc@1 100.00 ( 99.15)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 99.146 || Acc@5 99.992\n",
            "==> Test Accuracy:  Acc@1 70.850 || Acc@5 90.800\n",
            "==> 55.51 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 113, lr: 0.004000000000000001 -----\n",
            "Epoch: [113][  0/391]\tTime  0.348 ( 0.348)\tLoss 5.8448e-02 (5.8448e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [113][ 30/391]\tTime  0.100 ( 0.107)\tLoss 3.7945e-02 (5.2022e-02)\tAcc@1 100.00 ( 99.22)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [113][ 60/391]\tTime  0.097 ( 0.103)\tLoss 4.7704e-02 (4.9710e-02)\tAcc@1  99.22 ( 99.18)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][ 90/391]\tTime  0.095 ( 0.102)\tLoss 2.4881e-02 (5.1233e-02)\tAcc@1 100.00 ( 99.16)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [113][120/391]\tTime  0.098 ( 0.101)\tLoss 5.9482e-02 (5.0859e-02)\tAcc@1  98.44 ( 99.15)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][150/391]\tTime  0.096 ( 0.101)\tLoss 3.2811e-02 (5.1008e-02)\tAcc@1  99.22 ( 99.15)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][180/391]\tTime  0.098 ( 0.100)\tLoss 3.2358e-02 (5.0492e-02)\tAcc@1  99.22 ( 99.16)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][210/391]\tTime  0.099 ( 0.100)\tLoss 7.4002e-02 (5.1528e-02)\tAcc@1  97.66 ( 99.12)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][240/391]\tTime  0.095 ( 0.100)\tLoss 4.9336e-02 (5.1090e-02)\tAcc@1 100.00 ( 99.12)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][270/391]\tTime  0.094 ( 0.099)\tLoss 2.8706e-02 (5.1265e-02)\tAcc@1 100.00 ( 99.12)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][300/391]\tTime  0.100 ( 0.099)\tLoss 1.0601e-01 (5.1969e-02)\tAcc@1  96.88 ( 99.11)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][330/391]\tTime  0.096 ( 0.099)\tLoss 3.9259e-02 (5.1853e-02)\tAcc@1 100.00 ( 99.11)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][360/391]\tTime  0.104 ( 0.099)\tLoss 5.2919e-02 (5.2248e-02)\tAcc@1 100.00 ( 99.12)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [113][390/391]\tTime  0.048 ( 0.099)\tLoss 8.7575e-02 (5.2555e-02)\tAcc@1  97.50 ( 99.11)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 99.110 || Acc@5 99.990\n",
            "==> Test Accuracy:  Acc@1 70.930 || Acc@5 90.850\n",
            "==> 56.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 114, lr: 0.004000000000000001 -----\n",
            "Epoch: [114][  0/391]\tTime  0.386 ( 0.386)\tLoss 3.9715e-02 (3.9715e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 30/391]\tTime  0.097 ( 0.108)\tLoss 1.9146e-02 (4.8686e-02)\tAcc@1 100.00 ( 99.17)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 60/391]\tTime  0.095 ( 0.104)\tLoss 5.5922e-02 (5.0316e-02)\tAcc@1  97.66 ( 99.14)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][ 90/391]\tTime  0.105 ( 0.102)\tLoss 3.8658e-02 (4.8827e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [114][120/391]\tTime  0.100 ( 0.101)\tLoss 4.0584e-02 (4.8865e-02)\tAcc@1  99.22 ( 99.21)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [114][150/391]\tTime  0.097 ( 0.101)\tLoss 5.2468e-02 (4.8740e-02)\tAcc@1  99.22 ( 99.20)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [114][180/391]\tTime  0.095 ( 0.100)\tLoss 2.7725e-02 (4.9146e-02)\tAcc@1 100.00 ( 99.20)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [114][210/391]\tTime  0.098 ( 0.100)\tLoss 5.2881e-02 (4.9614e-02)\tAcc@1  98.44 ( 99.20)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [114][240/391]\tTime  0.103 ( 0.100)\tLoss 8.6545e-02 (4.9947e-02)\tAcc@1  98.44 ( 99.17)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [114][270/391]\tTime  0.096 ( 0.100)\tLoss 4.7686e-02 (4.9838e-02)\tAcc@1  99.22 ( 99.19)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [114][300/391]\tTime  0.099 ( 0.100)\tLoss 7.5074e-02 (5.0316e-02)\tAcc@1  98.44 ( 99.16)\tAcc@5  99.22 ( 99.99)\n",
            "Epoch: [114][330/391]\tTime  0.102 ( 0.100)\tLoss 1.0193e-01 (5.0832e-02)\tAcc@1  97.66 ( 99.15)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [114][360/391]\tTime  0.096 ( 0.100)\tLoss 4.2534e-02 (5.1837e-02)\tAcc@1 100.00 ( 99.10)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [114][390/391]\tTime  0.053 ( 0.099)\tLoss 4.1537e-02 (5.1775e-02)\tAcc@1 100.00 ( 99.11)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 99.110 || Acc@5 99.986\n",
            "==> Test Accuracy:  Acc@1 71.130 || Acc@5 90.760\n",
            "==> 56.12 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 115, lr: 0.004000000000000001 -----\n",
            "Epoch: [115][  0/391]\tTime  0.354 ( 0.354)\tLoss 5.6151e-02 (5.6151e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 30/391]\tTime  0.104 ( 0.108)\tLoss 3.8958e-02 (4.5696e-02)\tAcc@1 100.00 ( 99.40)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 60/391]\tTime  0.104 ( 0.105)\tLoss 5.2852e-02 (4.4466e-02)\tAcc@1  98.44 ( 99.33)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][ 90/391]\tTime  0.097 ( 0.103)\tLoss 4.8058e-02 (4.5893e-02)\tAcc@1  99.22 ( 99.32)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][120/391]\tTime  0.102 ( 0.102)\tLoss 4.7552e-02 (4.6342e-02)\tAcc@1  98.44 ( 99.29)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][150/391]\tTime  0.095 ( 0.101)\tLoss 4.1891e-02 (4.6760e-02)\tAcc@1  99.22 ( 99.30)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [115][180/391]\tTime  0.103 ( 0.100)\tLoss 3.2007e-02 (4.7310e-02)\tAcc@1 100.00 ( 99.28)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][210/391]\tTime  0.095 ( 0.100)\tLoss 3.9152e-02 (4.7865e-02)\tAcc@1  99.22 ( 99.24)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][240/391]\tTime  0.096 ( 0.100)\tLoss 3.3003e-02 (4.8496e-02)\tAcc@1 100.00 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][270/391]\tTime  0.097 ( 0.100)\tLoss 9.5214e-02 (4.8867e-02)\tAcc@1  98.44 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][300/391]\tTime  0.097 ( 0.100)\tLoss 3.2405e-02 (4.8952e-02)\tAcc@1 100.00 ( 99.21)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][330/391]\tTime  0.099 ( 0.100)\tLoss 5.3009e-02 (4.8941e-02)\tAcc@1  99.22 ( 99.21)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][360/391]\tTime  0.097 ( 0.100)\tLoss 3.0126e-02 (4.9285e-02)\tAcc@1 100.00 ( 99.21)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [115][390/391]\tTime  0.048 ( 0.099)\tLoss 7.1375e-02 (4.9102e-02)\tAcc@1  98.75 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.220 || Acc@5 99.996\n",
            "==> Test Accuracy:  Acc@1 70.790 || Acc@5 90.950\n",
            "==> 56.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 116, lr: 0.004000000000000001 -----\n",
            "Epoch: [116][  0/391]\tTime  0.335 ( 0.335)\tLoss 4.9129e-02 (4.9129e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][ 30/391]\tTime  0.092 ( 0.106)\tLoss 4.8814e-02 (4.8848e-02)\tAcc@1 100.00 ( 99.02)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][ 60/391]\tTime  0.095 ( 0.102)\tLoss 2.6821e-02 (4.9660e-02)\tAcc@1 100.00 ( 99.01)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [116][ 90/391]\tTime  0.096 ( 0.100)\tLoss 4.3429e-02 (4.9183e-02)\tAcc@1  99.22 ( 99.07)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [116][120/391]\tTime  0.095 ( 0.099)\tLoss 3.3419e-02 (4.9742e-02)\tAcc@1 100.00 ( 99.08)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [116][150/391]\tTime  0.117 ( 0.099)\tLoss 4.0279e-02 (4.9079e-02)\tAcc@1 100.00 ( 99.12)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [116][180/391]\tTime  0.096 ( 0.099)\tLoss 8.0149e-02 (4.9327e-02)\tAcc@1  97.66 ( 99.11)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][210/391]\tTime  0.097 ( 0.098)\tLoss 3.4991e-02 (4.9294e-02)\tAcc@1  99.22 ( 99.11)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [116][240/391]\tTime  0.097 ( 0.098)\tLoss 4.1172e-02 (4.9252e-02)\tAcc@1  99.22 ( 99.12)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [116][270/391]\tTime  0.095 ( 0.098)\tLoss 4.8647e-02 (4.9474e-02)\tAcc@1  99.22 ( 99.14)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [116][300/391]\tTime  0.095 ( 0.098)\tLoss 4.6956e-02 (4.8980e-02)\tAcc@1 100.00 ( 99.16)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [116][330/391]\tTime  0.096 ( 0.098)\tLoss 3.3715e-02 (4.9091e-02)\tAcc@1  99.22 ( 99.16)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][360/391]\tTime  0.098 ( 0.097)\tLoss 6.4577e-02 (4.9334e-02)\tAcc@1  99.22 ( 99.16)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [116][390/391]\tTime  0.047 ( 0.097)\tLoss 4.0013e-02 (4.9560e-02)\tAcc@1 100.00 ( 99.16)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.164 || Acc@5 99.996\n",
            "==> Test Accuracy:  Acc@1 70.750 || Acc@5 90.600\n",
            "==> 55.03 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 117, lr: 0.004000000000000001 -----\n",
            "Epoch: [117][  0/391]\tTime  0.346 ( 0.346)\tLoss 3.8326e-02 (3.8326e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [117][ 30/391]\tTime  0.093 ( 0.106)\tLoss 6.8867e-02 (4.3907e-02)\tAcc@1  96.88 ( 99.14)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [117][ 60/391]\tTime  0.097 ( 0.102)\tLoss 3.4229e-02 (4.3998e-02)\tAcc@1 100.00 ( 99.24)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][ 90/391]\tTime  0.101 ( 0.101)\tLoss 4.9006e-02 (4.3147e-02)\tAcc@1  99.22 ( 99.30)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][120/391]\tTime  0.096 ( 0.100)\tLoss 5.6944e-02 (4.4172e-02)\tAcc@1  98.44 ( 99.27)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][150/391]\tTime  0.094 ( 0.099)\tLoss 4.8791e-02 (4.4541e-02)\tAcc@1  98.44 ( 99.29)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][180/391]\tTime  0.094 ( 0.099)\tLoss 4.8143e-02 (4.4867e-02)\tAcc@1  99.22 ( 99.30)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][210/391]\tTime  0.097 ( 0.099)\tLoss 2.6754e-02 (4.5577e-02)\tAcc@1 100.00 ( 99.29)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][240/391]\tTime  0.096 ( 0.098)\tLoss 3.6404e-02 (4.5220e-02)\tAcc@1 100.00 ( 99.30)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][270/391]\tTime  0.096 ( 0.098)\tLoss 3.9216e-02 (4.4918e-02)\tAcc@1 100.00 ( 99.31)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][300/391]\tTime  0.093 ( 0.098)\tLoss 4.6883e-02 (4.5233e-02)\tAcc@1  98.44 ( 99.30)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][330/391]\tTime  0.094 ( 0.098)\tLoss 3.6324e-02 (4.5540e-02)\tAcc@1  99.22 ( 99.29)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][360/391]\tTime  0.094 ( 0.098)\tLoss 4.7585e-02 (4.6059e-02)\tAcc@1  99.22 ( 99.27)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [117][390/391]\tTime  0.049 ( 0.098)\tLoss 1.3743e-01 (4.6606e-02)\tAcc@1  97.50 ( 99.26)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 99.258 || Acc@5 99.988\n",
            "==> Test Accuracy:  Acc@1 70.910 || Acc@5 90.740\n",
            "==> 55.51 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 118, lr: 0.004000000000000001 -----\n",
            "Epoch: [118][  0/391]\tTime  0.317 ( 0.317)\tLoss 3.2873e-02 (3.2873e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][ 30/391]\tTime  0.096 ( 0.105)\tLoss 3.6748e-02 (4.3764e-02)\tAcc@1 100.00 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][ 60/391]\tTime  0.096 ( 0.103)\tLoss 5.2180e-02 (4.3573e-02)\tAcc@1  99.22 ( 99.33)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][ 90/391]\tTime  0.099 ( 0.101)\tLoss 4.4871e-02 (4.3293e-02)\tAcc@1  98.44 ( 99.34)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][120/391]\tTime  0.100 ( 0.100)\tLoss 3.6091e-02 (4.2820e-02)\tAcc@1 100.00 ( 99.36)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][150/391]\tTime  0.098 ( 0.099)\tLoss 6.5444e-02 (4.3401e-02)\tAcc@1  99.22 ( 99.33)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][180/391]\tTime  0.093 ( 0.099)\tLoss 6.2807e-02 (4.3143e-02)\tAcc@1 100.00 ( 99.33)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][210/391]\tTime  0.093 ( 0.098)\tLoss 5.4969e-02 (4.3505e-02)\tAcc@1  99.22 ( 99.33)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][240/391]\tTime  0.099 ( 0.098)\tLoss 5.2214e-02 (4.3811e-02)\tAcc@1  99.22 ( 99.32)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][270/391]\tTime  0.097 ( 0.098)\tLoss 3.4669e-02 (4.4178e-02)\tAcc@1 100.00 ( 99.32)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][300/391]\tTime  0.094 ( 0.098)\tLoss 1.1598e-01 (4.4643e-02)\tAcc@1  98.44 ( 99.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][330/391]\tTime  0.103 ( 0.098)\tLoss 5.3079e-02 (4.4736e-02)\tAcc@1 100.00 ( 99.32)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][360/391]\tTime  0.100 ( 0.098)\tLoss 6.9462e-02 (4.4675e-02)\tAcc@1  98.44 ( 99.31)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [118][390/391]\tTime  0.049 ( 0.098)\tLoss 3.4976e-02 (4.5441e-02)\tAcc@1 100.00 ( 99.31)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 99.314 || Acc@5 99.994\n",
            "==> Test Accuracy:  Acc@1 70.510 || Acc@5 90.680\n",
            "==> 55.34 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 119, lr: 0.004000000000000001 -----\n",
            "Epoch: [119][  0/391]\tTime  0.354 ( 0.354)\tLoss 3.4882e-02 (3.4882e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 30/391]\tTime  0.101 ( 0.107)\tLoss 4.1685e-02 (4.1406e-02)\tAcc@1  99.22 ( 99.60)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 60/391]\tTime  0.101 ( 0.104)\tLoss 4.0293e-02 (4.2551e-02)\tAcc@1  99.22 ( 99.42)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][ 90/391]\tTime  0.103 ( 0.102)\tLoss 3.5715e-02 (4.3298e-02)\tAcc@1 100.00 ( 99.38)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [119][120/391]\tTime  0.095 ( 0.100)\tLoss 4.2058e-02 (4.3125e-02)\tAcc@1  99.22 ( 99.39)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [119][150/391]\tTime  0.105 ( 0.100)\tLoss 1.8040e-02 (4.2671e-02)\tAcc@1 100.00 ( 99.38)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [119][180/391]\tTime  0.094 ( 0.099)\tLoss 3.3877e-02 (4.2987e-02)\tAcc@1 100.00 ( 99.39)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][210/391]\tTime  0.098 ( 0.099)\tLoss 5.1989e-02 (4.3418e-02)\tAcc@1  99.22 ( 99.37)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][240/391]\tTime  0.099 ( 0.099)\tLoss 3.2853e-02 (4.4132e-02)\tAcc@1 100.00 ( 99.35)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][270/391]\tTime  0.094 ( 0.098)\tLoss 2.5062e-02 (4.3766e-02)\tAcc@1 100.00 ( 99.37)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [119][300/391]\tTime  0.098 ( 0.098)\tLoss 3.2097e-02 (4.4413e-02)\tAcc@1  99.22 ( 99.36)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [119][330/391]\tTime  0.094 ( 0.098)\tLoss 4.9962e-02 (4.4498e-02)\tAcc@1  99.22 ( 99.34)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [119][360/391]\tTime  0.098 ( 0.098)\tLoss 2.3296e-02 (4.4667e-02)\tAcc@1 100.00 ( 99.32)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [119][390/391]\tTime  0.045 ( 0.097)\tLoss 4.4319e-02 (4.4579e-02)\tAcc@1  98.75 ( 99.33)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 99.332 || Acc@5 99.994\n",
            "==> Test Accuracy:  Acc@1 70.510 || Acc@5 90.760\n",
            "==> 55.15 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 120, lr: 0.0008000000000000003 -----\n",
            "Epoch: [120][  0/391]\tTime  0.342 ( 0.342)\tLoss 3.5350e-02 (3.5350e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][ 30/391]\tTime  0.099 ( 0.105)\tLoss 4.9407e-02 (4.1662e-02)\tAcc@1  98.44 ( 99.37)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][ 60/391]\tTime  0.112 ( 0.101)\tLoss 3.6173e-02 (4.0837e-02)\tAcc@1 100.00 ( 99.39)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [120][ 90/391]\tTime  0.095 ( 0.100)\tLoss 3.2919e-02 (4.0202e-02)\tAcc@1 100.00 ( 99.38)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [120][120/391]\tTime  0.094 ( 0.099)\tLoss 3.9786e-02 (4.0466e-02)\tAcc@1 100.00 ( 99.38)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [120][150/391]\tTime  0.096 ( 0.099)\tLoss 2.9041e-02 (3.9354e-02)\tAcc@1 100.00 ( 99.40)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [120][180/391]\tTime  0.098 ( 0.099)\tLoss 2.7027e-02 (3.8804e-02)\tAcc@1 100.00 ( 99.42)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][210/391]\tTime  0.103 ( 0.099)\tLoss 3.5673e-02 (3.8762e-02)\tAcc@1 100.00 ( 99.41)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][240/391]\tTime  0.097 ( 0.099)\tLoss 2.4646e-02 (3.8791e-02)\tAcc@1 100.00 ( 99.43)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][270/391]\tTime  0.104 ( 0.099)\tLoss 8.1222e-02 (3.8538e-02)\tAcc@1  99.22 ( 99.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][300/391]\tTime  0.095 ( 0.099)\tLoss 2.4197e-02 (3.8326e-02)\tAcc@1  99.22 ( 99.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][330/391]\tTime  0.101 ( 0.099)\tLoss 2.6654e-02 (3.8307e-02)\tAcc@1 100.00 ( 99.45)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][360/391]\tTime  0.094 ( 0.098)\tLoss 3.4842e-02 (3.8132e-02)\tAcc@1 100.00 ( 99.46)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [120][390/391]\tTime  0.049 ( 0.098)\tLoss 5.1485e-02 (3.8519e-02)\tAcc@1  97.50 ( 99.44)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.444 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 71.010 || Acc@5 90.600\n",
            "==> 55.27 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 121, lr: 0.0008000000000000003 -----\n",
            "Epoch: [121][  0/391]\tTime  0.318 ( 0.318)\tLoss 2.6121e-02 (2.6121e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][ 30/391]\tTime  0.104 ( 0.106)\tLoss 2.2391e-02 (3.8523e-02)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [121][ 60/391]\tTime  0.095 ( 0.102)\tLoss 4.0276e-02 (3.7767e-02)\tAcc@1  99.22 ( 99.47)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [121][ 90/391]\tTime  0.091 ( 0.100)\tLoss 2.8583e-02 (3.8303e-02)\tAcc@1 100.00 ( 99.48)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [121][120/391]\tTime  0.102 ( 0.100)\tLoss 2.2236e-02 (3.7762e-02)\tAcc@1  99.22 ( 99.49)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [121][150/391]\tTime  0.100 ( 0.099)\tLoss 3.3112e-02 (3.6736e-02)\tAcc@1  99.22 ( 99.50)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [121][180/391]\tTime  0.108 ( 0.099)\tLoss 2.5796e-02 (3.6296e-02)\tAcc@1 100.00 ( 99.52)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][210/391]\tTime  0.095 ( 0.099)\tLoss 3.0953e-02 (3.5732e-02)\tAcc@1  99.22 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][240/391]\tTime  0.101 ( 0.098)\tLoss 2.6005e-02 (3.5773e-02)\tAcc@1 100.00 ( 99.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][270/391]\tTime  0.094 ( 0.098)\tLoss 4.6753e-02 (3.5654e-02)\tAcc@1  98.44 ( 99.53)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][300/391]\tTime  0.095 ( 0.098)\tLoss 5.5970e-02 (3.5289e-02)\tAcc@1  99.22 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][330/391]\tTime  0.094 ( 0.098)\tLoss 3.8108e-02 (3.5183e-02)\tAcc@1 100.00 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][360/391]\tTime  0.092 ( 0.098)\tLoss 4.3403e-02 (3.5288e-02)\tAcc@1  99.22 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [121][390/391]\tTime  0.049 ( 0.097)\tLoss 5.8612e-02 (3.5160e-02)\tAcc@1  98.75 ( 99.55)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.550 || Acc@5 99.996\n",
            "==> Test Accuracy:  Acc@1 71.290 || Acc@5 90.940\n",
            "==> 55.13 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 122, lr: 0.0008000000000000003 -----\n",
            "Epoch: [122][  0/391]\tTime  0.370 ( 0.370)\tLoss 3.4885e-02 (3.4885e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 30/391]\tTime  0.107 ( 0.107)\tLoss 4.2934e-02 (3.7506e-02)\tAcc@1  99.22 ( 99.42)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 60/391]\tTime  0.096 ( 0.103)\tLoss 3.9443e-02 (3.4874e-02)\tAcc@1  99.22 ( 99.49)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][ 90/391]\tTime  0.094 ( 0.101)\tLoss 4.3856e-02 (3.4185e-02)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][120/391]\tTime  0.095 ( 0.100)\tLoss 2.3904e-02 (3.4812e-02)\tAcc@1  99.22 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][150/391]\tTime  0.099 ( 0.100)\tLoss 2.9752e-02 (3.4788e-02)\tAcc@1  99.22 ( 99.54)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][180/391]\tTime  0.094 ( 0.100)\tLoss 1.6281e-02 (3.4487e-02)\tAcc@1 100.00 ( 99.56)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][210/391]\tTime  0.093 ( 0.099)\tLoss 3.5220e-02 (3.4065e-02)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][240/391]\tTime  0.094 ( 0.099)\tLoss 1.4494e-02 (3.3539e-02)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][270/391]\tTime  0.101 ( 0.099)\tLoss 3.8602e-02 (3.3249e-02)\tAcc@1  99.22 ( 99.59)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][300/391]\tTime  0.097 ( 0.098)\tLoss 2.0610e-02 (3.3022e-02)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][330/391]\tTime  0.096 ( 0.098)\tLoss 2.8992e-02 (3.2942e-02)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][360/391]\tTime  0.093 ( 0.098)\tLoss 3.1382e-02 (3.2873e-02)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [122][390/391]\tTime  0.048 ( 0.098)\tLoss 1.6858e-02 (3.3097e-02)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.586 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.240 || Acc@5 90.760\n",
            "==> 55.20 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 123, lr: 0.0008000000000000003 -----\n",
            "Epoch: [123][  0/391]\tTime  0.335 ( 0.335)\tLoss 2.9405e-02 (2.9405e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][ 30/391]\tTime  0.094 ( 0.108)\tLoss 3.2402e-02 (3.2692e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][ 60/391]\tTime  0.099 ( 0.103)\tLoss 3.1060e-02 (3.2646e-02)\tAcc@1  99.22 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][ 90/391]\tTime  0.099 ( 0.101)\tLoss 3.9042e-02 (3.2976e-02)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][120/391]\tTime  0.098 ( 0.100)\tLoss 2.8233e-02 (3.2410e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][150/391]\tTime  0.095 ( 0.100)\tLoss 3.4067e-02 (3.1999e-02)\tAcc@1  99.22 ( 99.64)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][180/391]\tTime  0.105 ( 0.100)\tLoss 4.1962e-02 (3.2044e-02)\tAcc@1  98.44 ( 99.62)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][210/391]\tTime  0.105 ( 0.100)\tLoss 2.2640e-02 (3.2345e-02)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][240/391]\tTime  0.095 ( 0.099)\tLoss 3.6956e-02 (3.2647e-02)\tAcc@1  99.22 ( 99.61)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][270/391]\tTime  0.094 ( 0.100)\tLoss 1.9864e-02 (3.2569e-02)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][300/391]\tTime  0.092 ( 0.099)\tLoss 3.9089e-02 (3.2626e-02)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][330/391]\tTime  0.096 ( 0.099)\tLoss 1.7840e-02 (3.2274e-02)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][360/391]\tTime  0.094 ( 0.099)\tLoss 2.4337e-02 (3.2226e-02)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [123][390/391]\tTime  0.048 ( 0.098)\tLoss 2.4549e-02 (3.2376e-02)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.624 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.450 || Acc@5 90.930\n",
            "==> 55.37 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 124, lr: 0.0008000000000000003 -----\n",
            "Epoch: [124][  0/391]\tTime  0.362 ( 0.362)\tLoss 1.9331e-02 (1.9331e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [124][ 30/391]\tTime  0.107 ( 0.109)\tLoss 2.6431e-02 (3.3007e-02)\tAcc@1  99.22 ( 99.45)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [124][ 60/391]\tTime  0.097 ( 0.104)\tLoss 3.8402e-02 (3.1026e-02)\tAcc@1  99.22 ( 99.56)\tAcc@5 100.00 ( 99.97)\n",
            "Epoch: [124][ 90/391]\tTime  0.093 ( 0.101)\tLoss 2.7221e-02 (3.1054e-02)\tAcc@1  99.22 ( 99.60)\tAcc@5 100.00 ( 99.98)\n",
            "Epoch: [124][120/391]\tTime  0.092 ( 0.100)\tLoss 2.6671e-02 (3.0832e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [124][150/391]\tTime  0.093 ( 0.099)\tLoss 4.3665e-02 (3.1216e-02)\tAcc@1  99.22 ( 99.66)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [124][180/391]\tTime  0.095 ( 0.099)\tLoss 4.8105e-02 (3.1368e-02)\tAcc@1  99.22 ( 99.66)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [124][210/391]\tTime  0.093 ( 0.098)\tLoss 2.6398e-02 (3.1208e-02)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [124][240/391]\tTime  0.099 ( 0.098)\tLoss 1.2201e-02 (3.1483e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [124][270/391]\tTime  0.097 ( 0.099)\tLoss 4.7937e-02 (3.1608e-02)\tAcc@1  99.22 ( 99.64)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [124][300/391]\tTime  0.102 ( 0.099)\tLoss 2.6554e-02 (3.1411e-02)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [124][330/391]\tTime  0.096 ( 0.099)\tLoss 2.7384e-02 (3.1348e-02)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [124][360/391]\tTime  0.096 ( 0.099)\tLoss 2.9737e-02 (3.1388e-02)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [124][390/391]\tTime  0.048 ( 0.098)\tLoss 3.6977e-02 (3.1276e-02)\tAcc@1  98.75 ( 99.64)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 99.644 || Acc@5 99.994\n",
            "==> Test Accuracy:  Acc@1 71.540 || Acc@5 91.050\n",
            "==> 55.37 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 125, lr: 0.0008000000000000003 -----\n",
            "Epoch: [125][  0/391]\tTime  0.334 ( 0.334)\tLoss 3.4154e-02 (3.4154e-02)\tAcc@1  98.44 ( 98.44)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][ 30/391]\tTime  0.097 ( 0.107)\tLoss 1.5393e-02 (2.9104e-02)\tAcc@1 100.00 ( 99.57)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][ 60/391]\tTime  0.094 ( 0.102)\tLoss 2.6029e-02 (3.0837e-02)\tAcc@1 100.00 ( 99.55)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][ 90/391]\tTime  0.096 ( 0.101)\tLoss 2.6721e-02 (3.0738e-02)\tAcc@1 100.00 ( 99.63)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [125][120/391]\tTime  0.094 ( 0.099)\tLoss 2.5516e-02 (3.0685e-02)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [125][150/391]\tTime  0.094 ( 0.099)\tLoss 1.9354e-02 (3.1317e-02)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [125][180/391]\tTime  0.103 ( 0.099)\tLoss 2.7344e-02 (3.1666e-02)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [125][210/391]\tTime  0.094 ( 0.098)\tLoss 3.8721e-02 (3.1207e-02)\tAcc@1  99.22 ( 99.62)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [125][240/391]\tTime  0.092 ( 0.098)\tLoss 2.6328e-02 (3.1130e-02)\tAcc@1 100.00 ( 99.61)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [125][270/391]\tTime  0.098 ( 0.098)\tLoss 2.8111e-02 (3.1478e-02)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [125][300/391]\tTime  0.094 ( 0.098)\tLoss 2.1650e-02 (3.1405e-02)\tAcc@1 100.00 ( 99.60)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [125][330/391]\tTime  0.094 ( 0.098)\tLoss 2.0430e-02 (3.1444e-02)\tAcc@1 100.00 ( 99.59)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [125][360/391]\tTime  0.100 ( 0.098)\tLoss 2.5859e-02 (3.1401e-02)\tAcc@1 100.00 ( 99.58)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [125][390/391]\tTime  0.048 ( 0.098)\tLoss 6.0926e-02 (3.1376e-02)\tAcc@1  96.25 ( 99.58)\tAcc@5 100.00 ( 99.99)\n",
            "==> Train Accuracy: Acc@1 99.584 || Acc@5 99.994\n",
            "==> Test Accuracy:  Acc@1 71.770 || Acc@5 90.780\n",
            "==> 55.29 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 126, lr: 0.0008000000000000003 -----\n",
            "Epoch: [126][  0/391]\tTime  0.339 ( 0.339)\tLoss 3.8307e-02 (3.8307e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 30/391]\tTime  0.095 ( 0.107)\tLoss 2.0765e-02 (2.8661e-02)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 60/391]\tTime  0.096 ( 0.102)\tLoss 3.6068e-02 (2.7939e-02)\tAcc@1  99.22 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][ 90/391]\tTime  0.096 ( 0.100)\tLoss 3.3191e-02 (2.8332e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][120/391]\tTime  0.095 ( 0.099)\tLoss 5.6750e-02 (2.8874e-02)\tAcc@1  98.44 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][150/391]\tTime  0.094 ( 0.099)\tLoss 3.5770e-02 (2.8829e-02)\tAcc@1  99.22 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][180/391]\tTime  0.098 ( 0.099)\tLoss 2.8349e-02 (2.8487e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][210/391]\tTime  0.094 ( 0.098)\tLoss 5.0964e-02 (2.8907e-02)\tAcc@1  99.22 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][240/391]\tTime  0.107 ( 0.098)\tLoss 2.8681e-02 (2.9171e-02)\tAcc@1  99.22 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][270/391]\tTime  0.094 ( 0.098)\tLoss 2.4483e-02 (2.9415e-02)\tAcc@1 100.00 ( 99.64)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][300/391]\tTime  0.111 ( 0.098)\tLoss 3.2072e-02 (2.9166e-02)\tAcc@1  99.22 ( 99.64)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][330/391]\tTime  0.097 ( 0.098)\tLoss 4.1328e-02 (2.9315e-02)\tAcc@1  99.22 ( 99.64)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][360/391]\tTime  0.101 ( 0.098)\tLoss 2.4598e-02 (2.9455e-02)\tAcc@1 100.00 ( 99.63)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [126][390/391]\tTime  0.048 ( 0.098)\tLoss 4.3371e-02 (2.9849e-02)\tAcc@1 100.00 ( 99.62)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.616 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.480 || Acc@5 90.830\n",
            "==> 55.28 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 127, lr: 0.0008000000000000003 -----\n",
            "Epoch: [127][  0/391]\tTime  0.326 ( 0.326)\tLoss 1.8681e-02 (1.8681e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 30/391]\tTime  0.101 ( 0.108)\tLoss 1.9426e-02 (2.9412e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 60/391]\tTime  0.094 ( 0.103)\tLoss 2.8412e-02 (2.9274e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][ 90/391]\tTime  0.095 ( 0.101)\tLoss 1.9402e-02 (2.9157e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][120/391]\tTime  0.092 ( 0.099)\tLoss 2.8060e-02 (2.8963e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][150/391]\tTime  0.093 ( 0.099)\tLoss 3.4519e-02 (2.9061e-02)\tAcc@1  99.22 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][180/391]\tTime  0.095 ( 0.098)\tLoss 2.5391e-02 (2.9357e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][210/391]\tTime  0.094 ( 0.098)\tLoss 2.7754e-02 (2.9473e-02)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][240/391]\tTime  0.109 ( 0.098)\tLoss 1.9607e-02 (2.8993e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][270/391]\tTime  0.100 ( 0.098)\tLoss 1.8954e-02 (2.8973e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][300/391]\tTime  0.094 ( 0.098)\tLoss 2.7606e-02 (2.9152e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][330/391]\tTime  0.094 ( 0.098)\tLoss 2.3461e-02 (2.9263e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][360/391]\tTime  0.097 ( 0.098)\tLoss 2.1094e-02 (2.9115e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [127][390/391]\tTime  0.048 ( 0.097)\tLoss 2.7912e-02 (2.9002e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.682 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.670 || Acc@5 90.740\n",
            "==> 55.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 128, lr: 0.0008000000000000003 -----\n",
            "Epoch: [128][  0/391]\tTime  0.353 ( 0.353)\tLoss 3.0593e-02 (3.0593e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 30/391]\tTime  0.096 ( 0.106)\tLoss 3.1850e-02 (2.9064e-02)\tAcc@1  99.22 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 60/391]\tTime  0.096 ( 0.102)\tLoss 2.1924e-02 (2.9411e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][ 90/391]\tTime  0.099 ( 0.100)\tLoss 1.4971e-02 (2.9775e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][120/391]\tTime  0.097 ( 0.099)\tLoss 2.5101e-02 (2.8479e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][150/391]\tTime  0.107 ( 0.099)\tLoss 2.6771e-02 (2.7896e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][180/391]\tTime  0.096 ( 0.099)\tLoss 2.1670e-02 (2.8020e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][210/391]\tTime  0.102 ( 0.098)\tLoss 3.2518e-02 (2.8314e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][240/391]\tTime  0.103 ( 0.099)\tLoss 1.3792e-02 (2.8423e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][270/391]\tTime  0.097 ( 0.098)\tLoss 3.1346e-02 (2.8629e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][300/391]\tTime  0.095 ( 0.098)\tLoss 2.8730e-02 (2.8589e-02)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][330/391]\tTime  0.094 ( 0.098)\tLoss 5.7329e-02 (2.9026e-02)\tAcc@1  97.66 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][360/391]\tTime  0.100 ( 0.098)\tLoss 3.3437e-02 (2.9055e-02)\tAcc@1 100.00 ( 99.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [128][390/391]\tTime  0.048 ( 0.098)\tLoss 5.4542e-02 (2.9231e-02)\tAcc@1  98.75 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.652 || Acc@5 99.996\n",
            "==> Test Accuracy:  Acc@1 71.430 || Acc@5 90.810\n",
            "==> 55.30 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 129, lr: 0.0008000000000000003 -----\n",
            "Epoch: [129][  0/391]\tTime  0.321 ( 0.321)\tLoss 1.9338e-02 (1.9338e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][ 30/391]\tTime  0.095 ( 0.106)\tLoss 9.3365e-02 (3.1263e-02)\tAcc@1  98.44 ( 99.55)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][ 60/391]\tTime  0.100 ( 0.102)\tLoss 1.8812e-02 (2.8155e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][ 90/391]\tTime  0.104 ( 0.100)\tLoss 2.1300e-02 (2.7686e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [129][120/391]\tTime  0.094 ( 0.099)\tLoss 2.2936e-02 (2.7728e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [129][150/391]\tTime  0.101 ( 0.099)\tLoss 1.3655e-02 (2.7828e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [129][180/391]\tTime  0.096 ( 0.098)\tLoss 1.9900e-02 (2.7607e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][210/391]\tTime  0.094 ( 0.098)\tLoss 4.0542e-02 (2.7400e-02)\tAcc@1  98.44 ( 99.70)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [129][240/391]\tTime  0.109 ( 0.099)\tLoss 3.7356e-02 (2.7390e-02)\tAcc@1  99.22 ( 99.71)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [129][270/391]\tTime  0.107 ( 0.099)\tLoss 2.1816e-02 (2.7320e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [129][300/391]\tTime  0.114 ( 0.099)\tLoss 1.9198e-02 (2.7712e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [129][330/391]\tTime  0.099 ( 0.099)\tLoss 1.9804e-02 (2.7896e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][360/391]\tTime  0.094 ( 0.099)\tLoss 1.8244e-02 (2.8038e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [129][390/391]\tTime  0.048 ( 0.098)\tLoss 3.1369e-02 (2.8293e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.678 || Acc@5 99.996\n",
            "==> Test Accuracy:  Acc@1 71.530 || Acc@5 90.750\n",
            "==> 55.98 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 130, lr: 0.0008000000000000003 -----\n",
            "Epoch: [130][  0/391]\tTime  0.385 ( 0.385)\tLoss 1.5327e-02 (1.5327e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][ 30/391]\tTime  0.100 ( 0.117)\tLoss 4.7094e-02 (2.6047e-02)\tAcc@1  98.44 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][ 60/391]\tTime  0.099 ( 0.109)\tLoss 2.1701e-02 (2.5802e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][ 90/391]\tTime  0.096 ( 0.105)\tLoss 4.3959e-02 (2.6379e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][120/391]\tTime  0.097 ( 0.104)\tLoss 2.8891e-02 (2.7610e-02)\tAcc@1  99.22 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][150/391]\tTime  0.094 ( 0.103)\tLoss 2.8003e-02 (2.7968e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][180/391]\tTime  0.095 ( 0.102)\tLoss 3.6060e-02 (2.7753e-02)\tAcc@1  99.22 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][210/391]\tTime  0.100 ( 0.101)\tLoss 1.6614e-02 (2.7680e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][240/391]\tTime  0.107 ( 0.101)\tLoss 2.0456e-02 (2.7656e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][270/391]\tTime  0.103 ( 0.101)\tLoss 1.7195e-02 (2.7631e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][300/391]\tTime  0.097 ( 0.101)\tLoss 2.6786e-02 (2.7303e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][330/391]\tTime  0.097 ( 0.101)\tLoss 2.9205e-02 (2.7232e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][360/391]\tTime  0.100 ( 0.101)\tLoss 2.3982e-02 (2.7266e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [130][390/391]\tTime  0.049 ( 0.100)\tLoss 2.6985e-02 (2.7293e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.732 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 71.690 || Acc@5 90.870\n",
            "==> 56.36 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 131, lr: 0.0008000000000000003 -----\n",
            "Epoch: [131][  0/391]\tTime  0.331 ( 0.331)\tLoss 1.5473e-02 (1.5473e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][ 30/391]\tTime  0.096 ( 0.106)\tLoss 4.5696e-02 (2.6582e-02)\tAcc@1  99.22 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][ 60/391]\tTime  0.096 ( 0.102)\tLoss 3.8096e-02 (2.7009e-02)\tAcc@1  99.22 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][ 90/391]\tTime  0.095 ( 0.101)\tLoss 3.7856e-02 (2.7358e-02)\tAcc@1  99.22 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][120/391]\tTime  0.095 ( 0.100)\tLoss 4.1058e-02 (2.7443e-02)\tAcc@1  99.22 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][150/391]\tTime  0.094 ( 0.100)\tLoss 3.3476e-02 (2.7577e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][180/391]\tTime  0.099 ( 0.099)\tLoss 2.7527e-02 (2.7686e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][210/391]\tTime  0.101 ( 0.099)\tLoss 2.4278e-02 (2.7546e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][240/391]\tTime  0.105 ( 0.099)\tLoss 2.7476e-02 (2.7473e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][270/391]\tTime  0.095 ( 0.099)\tLoss 2.8745e-02 (2.7374e-02)\tAcc@1  99.22 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][300/391]\tTime  0.095 ( 0.098)\tLoss 3.6668e-02 (2.7442e-02)\tAcc@1  99.22 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][330/391]\tTime  0.097 ( 0.098)\tLoss 2.7800e-02 (2.7583e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][360/391]\tTime  0.096 ( 0.098)\tLoss 2.0409e-02 (2.7552e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [131][390/391]\tTime  0.047 ( 0.098)\tLoss 1.4861e-02 (2.7816e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.692 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.800 || Acc@5 90.830\n",
            "==> 55.44 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 132, lr: 0.0008000000000000003 -----\n",
            "Epoch: [132][  0/391]\tTime  0.343 ( 0.343)\tLoss 6.7356e-02 (6.7356e-02)\tAcc@1  97.66 ( 97.66)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][ 30/391]\tTime  0.097 ( 0.108)\tLoss 2.7138e-02 (3.0530e-02)\tAcc@1 100.00 ( 99.47)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][ 60/391]\tTime  0.095 ( 0.103)\tLoss 2.5881e-02 (2.9115e-02)\tAcc@1  99.22 ( 99.55)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [132][ 90/391]\tTime  0.114 ( 0.102)\tLoss 2.9283e-02 (2.7849e-02)\tAcc@1  99.22 ( 99.65)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [132][120/391]\tTime  0.097 ( 0.101)\tLoss 2.6800e-02 (2.7760e-02)\tAcc@1  99.22 ( 99.66)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [132][150/391]\tTime  0.098 ( 0.101)\tLoss 1.8176e-02 (2.7159e-02)\tAcc@1 100.00 ( 99.68)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [132][180/391]\tTime  0.095 ( 0.100)\tLoss 2.4483e-02 (2.7496e-02)\tAcc@1 100.00 ( 99.69)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][210/391]\tTime  0.119 ( 0.100)\tLoss 2.0842e-02 (2.7490e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][240/391]\tTime  0.097 ( 0.100)\tLoss 3.6448e-02 (2.7405e-02)\tAcc@1  98.44 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][270/391]\tTime  0.097 ( 0.099)\tLoss 2.9063e-02 (2.7535e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][300/391]\tTime  0.094 ( 0.099)\tLoss 2.4168e-02 (2.7293e-02)\tAcc@1  99.22 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][330/391]\tTime  0.094 ( 0.099)\tLoss 3.2283e-02 (2.7662e-02)\tAcc@1  99.22 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][360/391]\tTime  0.096 ( 0.099)\tLoss 2.4647e-02 (2.7889e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [132][390/391]\tTime  0.049 ( 0.098)\tLoss 2.7183e-02 (2.7818e-02)\tAcc@1  98.75 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.700 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 71.800 || Acc@5 90.810\n",
            "==> 55.42 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 133, lr: 0.0008000000000000003 -----\n",
            "Epoch: [133][  0/391]\tTime  0.312 ( 0.312)\tLoss 2.4541e-02 (2.4541e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][ 30/391]\tTime  0.099 ( 0.105)\tLoss 3.2578e-02 (2.7492e-02)\tAcc@1  99.22 ( 99.60)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][ 60/391]\tTime  0.101 ( 0.102)\tLoss 1.5139e-02 (2.6703e-02)\tAcc@1 100.00 ( 99.63)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][ 90/391]\tTime  0.093 ( 0.101)\tLoss 1.9350e-02 (2.6593e-02)\tAcc@1  99.22 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][120/391]\tTime  0.094 ( 0.100)\tLoss 2.4627e-02 (2.6813e-02)\tAcc@1  99.22 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][150/391]\tTime  0.097 ( 0.099)\tLoss 2.2068e-02 (2.6537e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][180/391]\tTime  0.097 ( 0.098)\tLoss 4.1650e-02 (2.6793e-02)\tAcc@1  98.44 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][210/391]\tTime  0.098 ( 0.099)\tLoss 2.6580e-02 (2.6673e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][240/391]\tTime  0.094 ( 0.098)\tLoss 2.0139e-02 (2.6545e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][270/391]\tTime  0.100 ( 0.098)\tLoss 2.1345e-02 (2.6312e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][300/391]\tTime  0.099 ( 0.098)\tLoss 1.8013e-02 (2.6387e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][330/391]\tTime  0.097 ( 0.098)\tLoss 2.0009e-02 (2.6311e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][360/391]\tTime  0.095 ( 0.098)\tLoss 4.1861e-02 (2.6563e-02)\tAcc@1  99.22 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [133][390/391]\tTime  0.047 ( 0.098)\tLoss 1.9033e-02 (2.6700e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.722 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.580 || Acc@5 90.860\n",
            "==> 55.35 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 134, lr: 0.0008000000000000003 -----\n",
            "Epoch: [134][  0/391]\tTime  0.373 ( 0.373)\tLoss 2.7560e-02 (2.7560e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 30/391]\tTime  0.095 ( 0.108)\tLoss 1.9989e-02 (2.6451e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 60/391]\tTime  0.096 ( 0.103)\tLoss 1.9828e-02 (2.7289e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][ 90/391]\tTime  0.103 ( 0.102)\tLoss 3.5367e-02 (2.6816e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][120/391]\tTime  0.096 ( 0.102)\tLoss 1.8659e-02 (2.6316e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][150/391]\tTime  0.097 ( 0.101)\tLoss 1.6484e-02 (2.6173e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][180/391]\tTime  0.095 ( 0.101)\tLoss 2.1662e-02 (2.5886e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][210/391]\tTime  0.098 ( 0.100)\tLoss 2.0428e-02 (2.5882e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][240/391]\tTime  0.102 ( 0.100)\tLoss 1.7197e-02 (2.6036e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][270/391]\tTime  0.093 ( 0.100)\tLoss 1.7194e-02 (2.5939e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][300/391]\tTime  0.095 ( 0.100)\tLoss 5.2922e-02 (2.6049e-02)\tAcc@1  99.22 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][330/391]\tTime  0.095 ( 0.099)\tLoss 4.3854e-02 (2.6294e-02)\tAcc@1  99.22 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][360/391]\tTime  0.096 ( 0.099)\tLoss 2.0521e-02 (2.6215e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [134][390/391]\tTime  0.048 ( 0.099)\tLoss 2.9247e-02 (2.6086e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.732 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.760 || Acc@5 90.990\n",
            "==> 55.83 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 135, lr: 0.0008000000000000003 -----\n",
            "Epoch: [135][  0/391]\tTime  0.297 ( 0.297)\tLoss 2.1085e-02 (2.1085e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 30/391]\tTime  0.097 ( 0.105)\tLoss 1.2640e-02 (2.4758e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 60/391]\tTime  0.095 ( 0.101)\tLoss 2.1023e-02 (2.4938e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][ 90/391]\tTime  0.100 ( 0.101)\tLoss 1.6824e-02 (2.5424e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][120/391]\tTime  0.098 ( 0.101)\tLoss 1.7575e-02 (2.5799e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][150/391]\tTime  0.104 ( 0.100)\tLoss 1.9586e-02 (2.6054e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [135][180/391]\tTime  0.097 ( 0.100)\tLoss 1.9628e-02 (2.6132e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][210/391]\tTime  0.098 ( 0.100)\tLoss 1.8640e-02 (2.5933e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][240/391]\tTime  0.096 ( 0.100)\tLoss 1.6559e-02 (2.6292e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][270/391]\tTime  0.094 ( 0.099)\tLoss 1.8918e-02 (2.6130e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][300/391]\tTime  0.098 ( 0.099)\tLoss 3.1758e-02 (2.6362e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][330/391]\tTime  0.095 ( 0.099)\tLoss 5.2547e-02 (2.6600e-02)\tAcc@1  98.44 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][360/391]\tTime  0.098 ( 0.099)\tLoss 1.6234e-02 (2.6692e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [135][390/391]\tTime  0.048 ( 0.098)\tLoss 4.8472e-02 (2.7001e-02)\tAcc@1 100.00 ( 99.71)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.706 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 71.550 || Acc@5 90.870\n",
            "==> 55.53 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 136, lr: 0.0008000000000000003 -----\n",
            "Epoch: [136][  0/391]\tTime  0.345 ( 0.345)\tLoss 2.0574e-02 (2.0574e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 30/391]\tTime  0.092 ( 0.106)\tLoss 1.9587e-02 (2.3743e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 60/391]\tTime  0.097 ( 0.101)\tLoss 1.9252e-02 (2.4612e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][ 90/391]\tTime  0.093 ( 0.099)\tLoss 3.1820e-02 (2.4603e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][120/391]\tTime  0.095 ( 0.098)\tLoss 1.9260e-02 (2.5203e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][150/391]\tTime  0.095 ( 0.098)\tLoss 5.8201e-02 (2.5188e-02)\tAcc@1  98.44 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][180/391]\tTime  0.096 ( 0.098)\tLoss 4.6833e-02 (2.5241e-02)\tAcc@1  98.44 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][210/391]\tTime  0.097 ( 0.098)\tLoss 1.7192e-02 (2.5100e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][240/391]\tTime  0.093 ( 0.098)\tLoss 3.8817e-02 (2.5251e-02)\tAcc@1  99.22 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][270/391]\tTime  0.102 ( 0.098)\tLoss 2.6006e-02 (2.5228e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][300/391]\tTime  0.103 ( 0.098)\tLoss 3.5353e-02 (2.5113e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][330/391]\tTime  0.095 ( 0.098)\tLoss 3.4668e-02 (2.5377e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][360/391]\tTime  0.094 ( 0.098)\tLoss 2.6884e-02 (2.5528e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [136][390/391]\tTime  0.048 ( 0.097)\tLoss 3.4701e-02 (2.5553e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.754 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 71.740 || Acc@5 90.880\n",
            "==> 55.08 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 137, lr: 0.0008000000000000003 -----\n",
            "Epoch: [137][  0/391]\tTime  0.356 ( 0.356)\tLoss 2.3291e-02 (2.3291e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 30/391]\tTime  0.096 ( 0.107)\tLoss 2.4618e-02 (2.6046e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 60/391]\tTime  0.096 ( 0.103)\tLoss 1.7704e-02 (2.6550e-02)\tAcc@1 100.00 ( 99.72)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][ 90/391]\tTime  0.096 ( 0.103)\tLoss 4.2573e-02 (2.6582e-02)\tAcc@1  98.44 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][120/391]\tTime  0.100 ( 0.102)\tLoss 3.1122e-02 (2.5431e-02)\tAcc@1  99.22 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][150/391]\tTime  0.096 ( 0.101)\tLoss 2.1504e-02 (2.5346e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][180/391]\tTime  0.097 ( 0.101)\tLoss 2.2563e-02 (2.5047e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][210/391]\tTime  0.104 ( 0.101)\tLoss 2.8193e-02 (2.5171e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][240/391]\tTime  0.106 ( 0.100)\tLoss 2.2454e-02 (2.5066e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][270/391]\tTime  0.094 ( 0.100)\tLoss 2.6149e-02 (2.5147e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][300/391]\tTime  0.100 ( 0.100)\tLoss 3.2001e-02 (2.5241e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][330/391]\tTime  0.097 ( 0.100)\tLoss 3.0828e-02 (2.5431e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][360/391]\tTime  0.097 ( 0.100)\tLoss 2.0374e-02 (2.5456e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [137][390/391]\tTime  0.049 ( 0.099)\tLoss 3.4458e-02 (2.5579e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.756 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.600 || Acc@5 90.910\n",
            "==> 56.09 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 138, lr: 0.0008000000000000003 -----\n",
            "Epoch: [138][  0/391]\tTime  0.329 ( 0.329)\tLoss 2.9329e-02 (2.9329e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 30/391]\tTime  0.095 ( 0.106)\tLoss 1.9859e-02 (2.6324e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 60/391]\tTime  0.098 ( 0.102)\tLoss 1.9856e-02 (2.4978e-02)\tAcc@1  99.22 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][ 90/391]\tTime  0.098 ( 0.101)\tLoss 1.7096e-02 (2.5049e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][120/391]\tTime  0.094 ( 0.101)\tLoss 1.6535e-02 (2.5213e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][150/391]\tTime  0.095 ( 0.100)\tLoss 2.1507e-02 (2.4938e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][180/391]\tTime  0.102 ( 0.100)\tLoss 1.5701e-02 (2.4932e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][210/391]\tTime  0.100 ( 0.100)\tLoss 1.5009e-02 (2.4654e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][240/391]\tTime  0.098 ( 0.100)\tLoss 2.2011e-02 (2.5005e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][270/391]\tTime  0.096 ( 0.099)\tLoss 2.2047e-02 (2.4970e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][300/391]\tTime  0.103 ( 0.100)\tLoss 2.3604e-02 (2.4875e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][330/391]\tTime  0.096 ( 0.100)\tLoss 2.8302e-02 (2.4869e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][360/391]\tTime  0.095 ( 0.099)\tLoss 3.4615e-02 (2.5002e-02)\tAcc@1  98.44 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [138][390/391]\tTime  0.048 ( 0.099)\tLoss 3.3108e-02 (2.5087e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.756 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.770 || Acc@5 90.800\n",
            "==> 55.82 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 139, lr: 0.0008000000000000003 -----\n",
            "Epoch: [139][  0/391]\tTime  0.374 ( 0.374)\tLoss 1.3828e-02 (1.3828e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 30/391]\tTime  0.096 ( 0.109)\tLoss 2.5597e-02 (2.3436e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 60/391]\tTime  0.095 ( 0.103)\tLoss 5.2998e-02 (2.3575e-02)\tAcc@1  99.22 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][ 90/391]\tTime  0.101 ( 0.102)\tLoss 1.9660e-02 (2.4404e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [139][120/391]\tTime  0.100 ( 0.101)\tLoss 2.4642e-02 (2.4119e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [139][150/391]\tTime  0.098 ( 0.100)\tLoss 1.9336e-02 (2.3870e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [139][180/391]\tTime  0.115 ( 0.100)\tLoss 1.5218e-02 (2.4358e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][210/391]\tTime  0.100 ( 0.100)\tLoss 2.0947e-02 (2.4655e-02)\tAcc@1  99.22 ( 99.80)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [139][240/391]\tTime  0.097 ( 0.099)\tLoss 2.5010e-02 (2.4905e-02)\tAcc@1  99.22 ( 99.80)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [139][270/391]\tTime  0.098 ( 0.099)\tLoss 3.4087e-02 (2.5106e-02)\tAcc@1  99.22 ( 99.79)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [139][300/391]\tTime  0.097 ( 0.100)\tLoss 2.6192e-02 (2.5092e-02)\tAcc@1  99.22 ( 99.79)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [139][330/391]\tTime  0.101 ( 0.100)\tLoss 4.4082e-02 (2.4960e-02)\tAcc@1  98.44 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][360/391]\tTime  0.096 ( 0.099)\tLoss 2.5670e-02 (2.4897e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [139][390/391]\tTime  0.048 ( 0.099)\tLoss 2.8172e-02 (2.4982e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.788 || Acc@5 99.996\n",
            "==> Test Accuracy:  Acc@1 71.780 || Acc@5 90.750\n",
            "==> 55.77 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 140, lr: 0.0008000000000000003 -----\n",
            "Epoch: [140][  0/391]\tTime  0.347 ( 0.347)\tLoss 3.1948e-02 (3.1948e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 30/391]\tTime  0.100 ( 0.109)\tLoss 2.6152e-02 (2.5112e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 60/391]\tTime  0.098 ( 0.104)\tLoss 1.3211e-02 (2.4417e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][ 90/391]\tTime  0.094 ( 0.102)\tLoss 2.1415e-02 (2.4099e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][120/391]\tTime  0.097 ( 0.101)\tLoss 3.0545e-02 (2.3965e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][150/391]\tTime  0.100 ( 0.100)\tLoss 1.5564e-02 (2.4090e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][180/391]\tTime  0.098 ( 0.100)\tLoss 6.3690e-02 (2.4428e-02)\tAcc@1  98.44 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][210/391]\tTime  0.094 ( 0.099)\tLoss 1.0952e-02 (2.4161e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][240/391]\tTime  0.095 ( 0.099)\tLoss 1.9684e-02 (2.4247e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][270/391]\tTime  0.112 ( 0.099)\tLoss 2.1798e-02 (2.4564e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][300/391]\tTime  0.098 ( 0.099)\tLoss 2.8899e-02 (2.4595e-02)\tAcc@1  99.22 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][330/391]\tTime  0.097 ( 0.099)\tLoss 2.2376e-02 (2.4744e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][360/391]\tTime  0.094 ( 0.099)\tLoss 1.9101e-02 (2.4818e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [140][390/391]\tTime  0.048 ( 0.099)\tLoss 2.3592e-02 (2.4759e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.790 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.640 || Acc@5 90.880\n",
            "==> 55.85 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 141, lr: 0.0008000000000000003 -----\n",
            "Epoch: [141][  0/391]\tTime  0.362 ( 0.362)\tLoss 2.7943e-02 (2.7943e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 30/391]\tTime  0.094 ( 0.107)\tLoss 2.3598e-02 (2.5071e-02)\tAcc@1 100.00 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 60/391]\tTime  0.099 ( 0.102)\tLoss 2.3499e-02 (2.4333e-02)\tAcc@1 100.00 ( 99.73)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][ 90/391]\tTime  0.099 ( 0.101)\tLoss 1.3929e-02 (2.4202e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][120/391]\tTime  0.101 ( 0.100)\tLoss 2.6538e-02 (2.4036e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][150/391]\tTime  0.115 ( 0.100)\tLoss 1.6324e-02 (2.4269e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][180/391]\tTime  0.096 ( 0.100)\tLoss 1.7359e-02 (2.4337e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][210/391]\tTime  0.095 ( 0.100)\tLoss 3.2796e-02 (2.4297e-02)\tAcc@1  99.22 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][240/391]\tTime  0.097 ( 0.099)\tLoss 2.8661e-02 (2.4567e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][270/391]\tTime  0.096 ( 0.099)\tLoss 1.0564e-02 (2.4430e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][300/391]\tTime  0.095 ( 0.099)\tLoss 2.5516e-02 (2.4200e-02)\tAcc@1  99.22 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][330/391]\tTime  0.094 ( 0.099)\tLoss 2.8142e-02 (2.4214e-02)\tAcc@1  99.22 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][360/391]\tTime  0.096 ( 0.099)\tLoss 2.3977e-02 (2.4136e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [141][390/391]\tTime  0.049 ( 0.099)\tLoss 1.9231e-02 (2.4169e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.772 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.600 || Acc@5 90.840\n",
            "==> 55.69 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 142, lr: 0.0008000000000000003 -----\n",
            "Epoch: [142][  0/391]\tTime  0.339 ( 0.339)\tLoss 1.9329e-02 (1.9329e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][ 30/391]\tTime  0.094 ( 0.106)\tLoss 1.7345e-02 (2.4696e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][ 60/391]\tTime  0.096 ( 0.101)\tLoss 1.7754e-02 (2.5190e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][ 90/391]\tTime  0.093 ( 0.100)\tLoss 1.4784e-02 (2.5030e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][120/391]\tTime  0.093 ( 0.099)\tLoss 1.9057e-02 (2.4721e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][150/391]\tTime  0.095 ( 0.099)\tLoss 1.3187e-02 (2.4581e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][180/391]\tTime  0.096 ( 0.098)\tLoss 2.3178e-02 (2.4663e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][210/391]\tTime  0.093 ( 0.098)\tLoss 5.0658e-02 (2.4564e-02)\tAcc@1  97.66 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][240/391]\tTime  0.095 ( 0.098)\tLoss 2.8028e-02 (2.4935e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][270/391]\tTime  0.094 ( 0.098)\tLoss 4.4777e-02 (2.5053e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][300/391]\tTime  0.093 ( 0.098)\tLoss 1.6656e-02 (2.4895e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][330/391]\tTime  0.095 ( 0.098)\tLoss 4.8686e-02 (2.4839e-02)\tAcc@1  99.22 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][360/391]\tTime  0.094 ( 0.098)\tLoss 2.9215e-02 (2.4797e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [142][390/391]\tTime  0.048 ( 0.097)\tLoss 3.1227e-02 (2.4726e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.778 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.740 || Acc@5 90.850\n",
            "==> 55.19 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 143, lr: 0.0008000000000000003 -----\n",
            "Epoch: [143][  0/391]\tTime  0.320 ( 0.320)\tLoss 1.9570e-02 (1.9570e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 30/391]\tTime  0.109 ( 0.107)\tLoss 2.1757e-02 (2.2433e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 60/391]\tTime  0.094 ( 0.103)\tLoss 4.5972e-02 (2.3994e-02)\tAcc@1  99.22 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][ 90/391]\tTime  0.095 ( 0.101)\tLoss 2.4868e-02 (2.3832e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][120/391]\tTime  0.103 ( 0.100)\tLoss 3.6064e-02 (2.3742e-02)\tAcc@1  99.22 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][150/391]\tTime  0.094 ( 0.099)\tLoss 2.6390e-02 (2.4000e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][180/391]\tTime  0.095 ( 0.099)\tLoss 2.3988e-02 (2.4208e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][210/391]\tTime  0.095 ( 0.098)\tLoss 1.9974e-02 (2.4232e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][240/391]\tTime  0.099 ( 0.098)\tLoss 4.3416e-02 (2.4244e-02)\tAcc@1  98.44 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][270/391]\tTime  0.104 ( 0.098)\tLoss 2.2735e-02 (2.4057e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][300/391]\tTime  0.099 ( 0.098)\tLoss 1.2325e-02 (2.4045e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][330/391]\tTime  0.098 ( 0.098)\tLoss 2.9257e-02 (2.4278e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][360/391]\tTime  0.102 ( 0.098)\tLoss 4.1958e-02 (2.4206e-02)\tAcc@1  99.22 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [143][390/391]\tTime  0.047 ( 0.098)\tLoss 2.3357e-02 (2.4126e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.776 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.760 || Acc@5 90.750\n",
            "==> 55.35 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 144, lr: 0.0008000000000000003 -----\n",
            "Epoch: [144][  0/391]\tTime  0.340 ( 0.340)\tLoss 1.6241e-02 (1.6241e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 30/391]\tTime  0.100 ( 0.109)\tLoss 1.3486e-02 (2.4126e-02)\tAcc@1 100.00 ( 99.65)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 60/391]\tTime  0.095 ( 0.105)\tLoss 1.8946e-02 (2.4955e-02)\tAcc@1 100.00 ( 99.67)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][ 90/391]\tTime  0.105 ( 0.104)\tLoss 2.6639e-02 (2.4535e-02)\tAcc@1  99.22 ( 99.70)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][120/391]\tTime  0.096 ( 0.102)\tLoss 1.4549e-02 (2.3944e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][150/391]\tTime  0.102 ( 0.102)\tLoss 1.8372e-02 (2.3773e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [144][180/391]\tTime  0.098 ( 0.101)\tLoss 2.8362e-02 (2.3815e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][210/391]\tTime  0.099 ( 0.101)\tLoss 2.1756e-02 (2.3757e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][240/391]\tTime  0.094 ( 0.100)\tLoss 1.7107e-02 (2.3746e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][270/391]\tTime  0.096 ( 0.100)\tLoss 2.7771e-02 (2.3622e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][300/391]\tTime  0.095 ( 0.100)\tLoss 3.0775e-02 (2.3675e-02)\tAcc@1 100.00 ( 99.76)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][330/391]\tTime  0.099 ( 0.100)\tLoss 2.7850e-02 (2.3662e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][360/391]\tTime  0.102 ( 0.100)\tLoss 2.0410e-02 (2.3651e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [144][390/391]\tTime  0.050 ( 0.099)\tLoss 1.9358e-02 (2.3825e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.768 || Acc@5 99.996\n",
            "==> Test Accuracy:  Acc@1 71.660 || Acc@5 90.650\n",
            "==> 55.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 145, lr: 0.0008000000000000003 -----\n",
            "Epoch: [145][  0/391]\tTime  0.352 ( 0.352)\tLoss 1.1260e-02 (1.1260e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 30/391]\tTime  0.100 ( 0.108)\tLoss 1.9496e-02 (2.4349e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 60/391]\tTime  0.099 ( 0.103)\tLoss 3.9623e-02 (2.4184e-02)\tAcc@1  99.22 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][ 90/391]\tTime  0.099 ( 0.102)\tLoss 2.6272e-02 (2.3953e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][120/391]\tTime  0.093 ( 0.101)\tLoss 1.8445e-02 (2.3704e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][150/391]\tTime  0.095 ( 0.101)\tLoss 3.5209e-02 (2.3678e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][180/391]\tTime  0.098 ( 0.100)\tLoss 1.7523e-02 (2.3356e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][210/391]\tTime  0.095 ( 0.100)\tLoss 1.9864e-02 (2.3272e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][240/391]\tTime  0.102 ( 0.100)\tLoss 1.1515e-02 (2.3326e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][270/391]\tTime  0.097 ( 0.099)\tLoss 2.2210e-02 (2.3008e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][300/391]\tTime  0.104 ( 0.099)\tLoss 2.3208e-02 (2.3198e-02)\tAcc@1  99.22 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][330/391]\tTime  0.096 ( 0.099)\tLoss 1.1395e-02 (2.3017e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][360/391]\tTime  0.095 ( 0.099)\tLoss 1.7734e-02 (2.3154e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [145][390/391]\tTime  0.048 ( 0.098)\tLoss 1.7682e-02 (2.3344e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.806 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.550 || Acc@5 90.880\n",
            "==> 55.63 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 146, lr: 0.0008000000000000003 -----\n",
            "Epoch: [146][  0/391]\tTime  0.321 ( 0.321)\tLoss 4.2566e-02 (4.2566e-02)\tAcc@1  99.22 ( 99.22)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][ 30/391]\tTime  0.113 ( 0.111)\tLoss 2.1068e-02 (2.4368e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][ 60/391]\tTime  0.098 ( 0.105)\tLoss 3.1207e-02 (2.3545e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][ 90/391]\tTime  0.096 ( 0.103)\tLoss 1.2063e-02 (2.3179e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][120/391]\tTime  0.093 ( 0.101)\tLoss 1.9010e-02 (2.3123e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][150/391]\tTime  0.095 ( 0.101)\tLoss 2.3254e-02 (2.2967e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][180/391]\tTime  0.095 ( 0.100)\tLoss 1.6890e-02 (2.3215e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][210/391]\tTime  0.103 ( 0.100)\tLoss 4.1895e-02 (2.3303e-02)\tAcc@1  99.22 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][240/391]\tTime  0.098 ( 0.100)\tLoss 2.0738e-02 (2.3294e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][270/391]\tTime  0.097 ( 0.099)\tLoss 2.6504e-02 (2.3454e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][300/391]\tTime  0.098 ( 0.099)\tLoss 3.9907e-02 (2.3369e-02)\tAcc@1  99.22 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][330/391]\tTime  0.098 ( 0.099)\tLoss 2.5263e-02 (2.3299e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][360/391]\tTime  0.095 ( 0.100)\tLoss 2.2478e-02 (2.3416e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [146][390/391]\tTime  0.048 ( 0.099)\tLoss 1.4392e-02 (2.3426e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.808 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.740 || Acc@5 90.690\n",
            "==> 55.84 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 147, lr: 0.0008000000000000003 -----\n",
            "Epoch: [147][  0/391]\tTime  0.387 ( 0.387)\tLoss 1.7080e-02 (1.7080e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 30/391]\tTime  0.094 ( 0.111)\tLoss 3.5526e-02 (2.2002e-02)\tAcc@1  99.22 ( 99.80)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 60/391]\tTime  0.095 ( 0.105)\tLoss 3.5544e-02 (2.2815e-02)\tAcc@1  98.44 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][ 90/391]\tTime  0.095 ( 0.103)\tLoss 4.2814e-02 (2.2743e-02)\tAcc@1  98.44 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][120/391]\tTime  0.095 ( 0.103)\tLoss 2.3460e-02 (2.3450e-02)\tAcc@1 100.00 ( 99.74)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][150/391]\tTime  0.095 ( 0.102)\tLoss 2.3572e-02 (2.3442e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][180/391]\tTime  0.099 ( 0.101)\tLoss 2.4787e-02 (2.3687e-02)\tAcc@1 100.00 ( 99.75)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][210/391]\tTime  0.094 ( 0.101)\tLoss 3.8210e-02 (2.3752e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][240/391]\tTime  0.099 ( 0.100)\tLoss 1.3433e-02 (2.3605e-02)\tAcc@1 100.00 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][270/391]\tTime  0.099 ( 0.100)\tLoss 2.1939e-02 (2.3471e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][300/391]\tTime  0.093 ( 0.100)\tLoss 2.6134e-02 (2.3720e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][330/391]\tTime  0.098 ( 0.100)\tLoss 2.4786e-02 (2.3561e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][360/391]\tTime  0.099 ( 0.100)\tLoss 2.0058e-02 (2.3526e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [147][390/391]\tTime  0.049 ( 0.099)\tLoss 2.5834e-02 (2.3553e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.776 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.830 || Acc@5 90.920\n",
            "==> 55.97 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 148, lr: 0.0008000000000000003 -----\n",
            "Epoch: [148][  0/391]\tTime  0.351 ( 0.351)\tLoss 2.6748e-02 (2.6748e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 30/391]\tTime  0.095 ( 0.110)\tLoss 2.4581e-02 (2.3429e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 60/391]\tTime  0.103 ( 0.106)\tLoss 1.5252e-02 (2.2925e-02)\tAcc@1 100.00 ( 99.87)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][ 90/391]\tTime  0.096 ( 0.103)\tLoss 2.4442e-02 (2.3235e-02)\tAcc@1 100.00 ( 99.85)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][120/391]\tTime  0.094 ( 0.103)\tLoss 4.8863e-02 (2.2967e-02)\tAcc@1  99.22 ( 99.86)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][150/391]\tTime  0.099 ( 0.102)\tLoss 1.8157e-02 (2.3374e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][180/391]\tTime  0.100 ( 0.101)\tLoss 1.2592e-02 (2.3125e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][210/391]\tTime  0.105 ( 0.101)\tLoss 2.6227e-02 (2.3297e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][240/391]\tTime  0.096 ( 0.101)\tLoss 1.2386e-02 (2.3343e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][270/391]\tTime  0.093 ( 0.100)\tLoss 1.9464e-02 (2.3363e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][300/391]\tTime  0.098 ( 0.100)\tLoss 2.3679e-02 (2.3223e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][330/391]\tTime  0.099 ( 0.100)\tLoss 2.5801e-02 (2.3253e-02)\tAcc@1 100.00 ( 99.83)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][360/391]\tTime  0.098 ( 0.100)\tLoss 2.5468e-02 (2.3161e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [148][390/391]\tTime  0.048 ( 0.099)\tLoss 1.6145e-02 (2.3261e-02)\tAcc@1 100.00 ( 99.84)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.840 || Acc@5 100.000\n",
            "==> Test Accuracy:  Acc@1 71.650 || Acc@5 90.830\n",
            "==> 55.93 seconds to train this epoch\n",
            "\n",
            "\n",
            "----- epoch: 149, lr: 0.0008000000000000003 -----\n",
            "Epoch: [149][  0/391]\tTime  0.337 ( 0.337)\tLoss 2.4788e-02 (2.4788e-02)\tAcc@1 100.00 (100.00)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 30/391]\tTime  0.099 ( 0.108)\tLoss 2.5205e-02 (2.3533e-02)\tAcc@1  99.22 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 60/391]\tTime  0.099 ( 0.104)\tLoss 2.0967e-02 (2.3164e-02)\tAcc@1 100.00 ( 99.82)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][ 90/391]\tTime  0.099 ( 0.102)\tLoss 1.6096e-02 (2.3186e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][120/391]\tTime  0.097 ( 0.101)\tLoss 1.8588e-02 (2.2811e-02)\tAcc@1 100.00 ( 99.81)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][150/391]\tTime  0.100 ( 0.101)\tLoss 3.1520e-02 (2.3003e-02)\tAcc@1 100.00 ( 99.80)\tAcc@5 100.00 ( 99.99)\n",
            "Epoch: [149][180/391]\tTime  0.102 ( 0.101)\tLoss 2.1178e-02 (2.3093e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][210/391]\tTime  0.101 ( 0.101)\tLoss 2.4073e-02 (2.3055e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][240/391]\tTime  0.101 ( 0.101)\tLoss 1.6935e-02 (2.3017e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][270/391]\tTime  0.106 ( 0.101)\tLoss 2.2780e-02 (2.2914e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][300/391]\tTime  0.098 ( 0.101)\tLoss 4.1914e-02 (2.2926e-02)\tAcc@1  98.44 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][330/391]\tTime  0.100 ( 0.101)\tLoss 2.1535e-02 (2.3029e-02)\tAcc@1 100.00 ( 99.79)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][360/391]\tTime  0.097 ( 0.101)\tLoss 2.2083e-02 (2.3243e-02)\tAcc@1 100.00 ( 99.78)\tAcc@5 100.00 (100.00)\n",
            "Epoch: [149][390/391]\tTime  0.053 ( 0.100)\tLoss 4.3221e-02 (2.3488e-02)\tAcc@1  98.75 ( 99.77)\tAcc@5 100.00 (100.00)\n",
            "==> Train Accuracy: Acc@1 99.766 || Acc@5 99.998\n",
            "==> Test Accuracy:  Acc@1 71.600 || Acc@5 90.910\n",
            "==> 56.25 seconds to train this epoch\n",
            "\n",
            "Best Top-1 Accuracy: 71.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmZTa-3Uc4YV"
      },
      "source": [
        "### 분석 및 결론:  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKku1yKRc4YU"
      },
      "source": [
        "(%)|Baseline(cutout) | CutShadow(CS)(length:14,p = 8)|Cutmix|Cutshadow + Cutmix| Cutshadow + local_augment|\n",
        "---|---|---|---|---|---|\n",
        "`Top-1 Accuracy` | 78.26 | 77.39 | 80.78 | 80.88 | 71.83 |\n",
        "`Top-5 Accuracy` | 94.34 | 93.82 | 95.21 | 95.71 | 90.92 |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kQNT9icMIjPj"
      },
      "source": [
        "Bounding box의 크기가 작을수록 성능이 좋아지고,  \n",
        "배경이 어두울수록 성능이 좋은 것으로 보아 기존에 학습이 traindata를 너무 학습해버려서  overfitting이 발생한것으로 볼 수 있다.  \n",
        "이 방식이 ovefitting을 cutout방식보다 좋은 성능을 보여주는것 같지는 않았다. \n",
        "하지만 Cutmix와 혼합해서 사용했을때는 제법 괜찮은 효과를 보여주었다. 이 방법은 기존 데이터의 overfitting을 막아주고 상대적으로 적은 변형을 불러오기 때문에 다른 augmentation 방법과 혼용할때 성능이 잘 나와주는 것 같다.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eh_CsNRpJpI8"
      },
      "source": [
        "----------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyIDXhCsc4YV"
      },
      "source": [
        "### 인용(출처)  \n",
        "https://github.com/uoguelph-mlrg/Cutout   \n",
        "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9319662  \n",
        "https://arxiv.org/abs/1905.04899  \n",
        "https://arxiv.org/abs/2101.05361"
      ]
    }
  ]
}